<!--
2.1    Standardized Precipitation Index
2.1.1  Download & munge precipitation data: complete; _04_prco-data_munging
2.1.2  Identify distribution: complete;  _05_L-moment_diagram
2.1.3   Calculate SPI: started but having difficulties!; created a test case to send to author
2.2    Stream Drought Index
2.2.1  Download & mungeStream data: finished - July 16
2.2.2 Learn purrr::map(): ok.finished http://r4ds.had.co.nz/iteration.html#the-map-functions
2.2.3   Cluster time series - in progress: following Kassambara, "Practical Guide to Cluster Analysis in R
2.2.4   Calculate SDI
2.2.5   Delineate watersheds
2.2.6   Cluster ungaged stations
2.2.7 Learn 'rf' function
2.3   Disseminate results
2.3.1 Identify journal

## Broad questions:
What is the drought history of the Pine Ridge Reservation?  
Does the drought extent differ across the study area?

## Narrower question:
What is the underlying distribution of precipitation data?  

## Analysis Steps & progress
1. Recreated analysis from the lmomco text ch 12 (author?) in Tidyverse
2. Imported cleaned precipitation data (see 04_prcp-data_munging)   
3. Applied sqrt & log10 transform to explore effects on skew 
4. Explored the data with box plots, violin plot.
5. Applied Weibull plotting position and graphed the data on sqrt plot
6. Calculated L-moments and L-moment ratios 
7. Calculated SPI for 'cot', 'oel', 'rap', 'int', and 'ora' datasets using Pearson III.

# Next steps: 
1. Exploratory PCA 
2. clustering gages 
3. look at a second package for SPI - on Twitter bookmarks.

## Cleared Issues: there was a duplicate variable - int for 'intermediate' and for 'Interior' - changed 'intermediate' to prep

# Someday - Maybe
1. Map the variable as a function - might put off, but ugly and long code below!
2. figure out how to reference stuff 

## Variable naming convention:   
sta          precipitation station  
_meta        metadata  
_mon         monthly precipitation depths  
_grp         wide data changed to long data #might change to _gath
_notzero     non-zero precip values
_zero        precip values equal to zero
_log         log10 of monthly precipitation depths
_count       number of months in a given record

min          minimum non-zero value
n            number of months in a given record

prep#         intermediate variable used to bind rows; # = 1, 2, ...
intc#        intermediate variable used to bind cols; # = 1, 2, ...
intr#        intermediate variable used to bind rows; # = 1, 2, ...

# SPI output variables
spi          Standardized Precipitation Index vals for a station 
 _gath       Dataframe is long rather than wide
 _cot        Cottonwood station
 _oel        Oelrichs station 
 _rap        Rapid City station 
 _int        Interior station 
 -ora        Oral station

# Gage variables 
gage
_raw         original inputted data 
_prep        intermediate variable 
_scale       standardized (z-score) data, number is averaging period 
_sum         summary data 
_l           data in long format

## Thoughts - the orig depth vs plotting vals look j-shaped.  
## Sqrt trans vs plotting vals look slightly sinusoidal; nice boxplots
## Log-tranformation looks like the mirror of orig depth vs plotting

## Results: Precipitation fits a PE3 distribution


## Introduction


## Methods
I imported Global Historical Climatology Network (GHCN) daily precipitation records for candidate "WEATHER STATIONS" into R-Studio (REF1) using the "rnoaa" package.
I used Theissen polygons and the length and continuity of precipitation records to select stations for further analysis.
I used 'dplyr' to fill NA values with data from nearest station
I used 'dplyr' to create monthly vals from daily vals.
I removed short records: Oral & Long Valley after checking for 
covariance.

<!-- 
Work on finishing describing methods for EDA.
-->

## Results
<!--
Work on describing results of EDA.
-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Sets up the library of packages 
#library("magrittr") # contains easier ways to say things about lists
library("here") # identifies where to save work 
library("rio") # more robust I/O - to import and clean data
library("lubridate") # fixes dates 
library("tidyverse") 
library("janitor") # tools to clean dirty data 

library("forecast") # using the BoxCox function
library("standardize")
library("cluster")
library("factoextra") 
library("broom") # tidies up objects 

#library("DataExplorer")

library("SPEI") # Calculates SPI-index

library("clValid")
#library("lintr")
#library("test_that")
#library("jsonlite") # Convert between JSON data and R objects
#library("curl") # Drop-in replacement for base url
#library("listviewer") # htmlwidget for interactive views of R lists



#lmomco <- citation("lmomco")
#toBibtex(lmomco)

# Session Info
a_session <- devtools::session_info()
```

```{r import-precip-data} 
# General Purpose: prepare data for drought index   
# Specific purpose: graphical EDA  
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) 

# fix date & add year and month  
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date)) 

# make the wide data long, remove NA vals
sta_grp <- sta_mon %>%
  gather(key = "station", value = "depth", -date, -year, -month) %>%
  drop_na(depth)  # %>% 
#  mutate(sqrt_depth = sqrt(depth)) 
```

```{r check-precip-data}
sta_rap <- sta_mon %>% 
  select(date, rap) %>%
  arrange(date) %>%
  filter(rap != is.na(rap))

sta_rap2 <- sta_mon %>%
  select(date, rap) %>%
  arrange(date) %>%
  slice(468:1308)

rap_na <- sta_rap2 %>%
  filter(rap == is.na(rap))
# Zero values are flagged as NA????
```

```{r precip-boxplot, include=FALSE, eval=FALSE} 
sta_sum <- as.tibble(summary(sta_mon)) 
  
# plot the precip data as a boxplot
ggplot(sta_grp, aes(as.factor(station), depth)) +
  geom_violin() +
  geom_boxplot() +
#  scale_y_sqrt() +
#  scale_y_log10() +
  scale_y_sqrt() +
  theme_bw() +
  ggtitle("Weather stations near Pine Ridge Reservation, SD", 
          subtitle = "1909-2018") +
  xlab("") + 
  ylab("Monthly depth in mm") +
  NULL

#ggplot2::ggsave(filename = "rf_boxplot.png", 
#                width = 6, height = 6, units = "in")
```

```{r eda_fiddling, include=FALSE, eval=FALSE}
sta_big <- sta_grp %>%
  filter(depth > 100) 
summary(sta_big)

ggplot(sta_big, aes(month)) +
  geom_histogram(binwidth = 1) 

# the anomolously wet month series is dominated by May & June events.
# what drives precip during this time? 
#   In May & June the area recieves low-level moisture from the Gulf 
#   of Mexico, strong cold fronts, and active upper-level pattern 
#   leading to greater chance for convection.
```

```{r testing, include=FALSE, eval=FALSE}
# Mini-library
library("tidyverse") 
library("lubridate") 
library("rio") 
library("SPEI")
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# load data
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) %>% 
  arrange(date)
  
# prepare date for joining later
Date <- sta_mon %>% 
  select(date) %>%
  mutate(date = ymd(date)) %>%
  arrange(date)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Use a single station - cot
sta_cot_ts <- sta_mon %>% 
  select(cot) %>%
  ts(end = c(2018, 05), frequency = 12)

spi_list  <- spi(sta_cot_ts, 1, 
                 distribution = 'PearsonIII', na.rm = TRUE) 

spi1_coeff_cot <- as.tibble(spi_list$coefficients) %>% 
  t() %>% as.tibble() 

spi1_cot_ts <- as.tibble(spi_list$fitted)  
spi1_cot_ts <- bind_cols(Date, spi1_cot_ts) 

# Results
 as.tibble(summary(spi1_cot_ts))
#   Var1  Var2        n                     
#   <chr> <chr>       <fct>                 
# 1 ""    "     date" "Min.   :1909-06-01  "
# 2 ""    "     date" "1st Qu.:1936-08-24  "
# 3 ""    "     date" "Median :1963-11-16  "
# 4 ""    "     date" "Mean   :1963-11-16  "
# 5 ""    "     date" "3rd Qu.:1991-02-08  "
# 6 ""    "     date" "Max.   :2018-05-01  "
# 7 ""    "     cot"  "Min.   :-2.40240  "  
# 8 ""    "     cot"  "1st Qu.:-0.69324  "  
# 9 ""    "     cot"  "Median : 0.02341  "  
#10 ""    "     cot"  "Mean   : 0.01383  "  
#11 ""    "     cot"  "3rd Qu.: 0.68317  "  
#12 ""    "     cot"  "Max.   : 3.30822  "  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# prepare data for testing Lubridate object
sta_cot_lub <- sta_mon %>% 
  select(cot) 

spi_list  <- spi(sta_cot_lub, 1, 
                 distribution = 'PearsonIII', na.rm = TRUE) 
 
spi1_coeff_cot_lub <- as.tibble(spi_list$coefficients) %>% 
  t() %>% as.tibble() 

spi1_cot_lub <- as.tibble(spi_list$fitted) 
spi1_cot_lub <- bind_cols(Date, spi1_cot_lub) 
rm(sta_cot_lub)

# Results
as.tibble(summary(spi1_cot_lub))
# A tibble: 12 x 3
#   Var1  Var2        n                     
#   <chr> <chr>       <fct>                 
# 1 ""    "     date" "Min.   :1909-06-01  "
# 2 ""    "     date" "1st Qu.:1936-08-24  "
# 3 ""    "     date" "Median :1963-11-16  "
# 4 ""    "     date" "Mean   :1963-11-16  "
# 5 ""    "     date" "3rd Qu.:1991-02-08  "
# 6 ""    "     date" "Max.   :2018-05-01  "
# 7 ""    "     cot"  "Min.   :-2.40240  "  
# 8 ""    "     cot"  "1st Qu.:-0.69324  "  
# 9 ""    "     cot"  "Median : 0.02341  "  
#10 ""    "     cot"  "Mean   : 0.01383  "  
#11 ""    "     cot"  "3rd Qu.: 0.68317  "  
#12 ""    "     cot"  "Max.   : 3.30822  "   
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Use lubridate-created object for date for a batch process
# results are as above for 'cot' but have -Inf for 'rap' 

# prepare data for batch
sta_all <- sta_mon %>% 
  select(-c(date, year, month))  
 
spi_list  <- spi(sta_all, 1,  
                 distribution = 'PearsonIII', na.rm = TRUE) 

spi1_coeff_all <- as.tibble(spi_list$coefficients) %>% 
  t() %>% as.tibble() 

spi1_all <- as.tibble(spi_list$fitted) 
spi1_all <- bind_cols(Date, spi1_all) 

# Selected Results
summary(spi1_all$cot)
#     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
# -2.40240 -0.69324  0.02341  0.01383  0.68317  3.30822 

summary(spi1_all$date)
# Min.      1st Qu.       Median     Mean      3rd Qu.       Max.
# "1909-06-01" "36-08-24" "63-11-16" "63-11-16" "91-02-08" "2018-05-01" 
summary(spi1_all$rap)
#  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
#   -Inf -0.6472  0.0022    -Inf  0.6657  2.9000     467 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Use only 'rap' including NA vals 
# Summary: It looks like the "bug" is in handling the na.rm?
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~
# prepare data for 'rap' only
sta_rap <- sta_mon %>% 
  select(rap) 

spi_list  <- spi(sta_rap, 1, 
                 distribution = 'PearsonIII', na.rm = TRUE) 

spi1_coeff_rap <- as.tibble(spi_list$coefficients) %>% 
  t() %>% as.tibble()  

spi1_rap <- as.tibble(spi_list$fitted) 
spi1_rap <- bind_cols(Date, spi1_rap) 

# Results
as.tibble(summary(spi1_rap))
# A tibble: 14 x 3
#   Var1  Var2        n                     
#   <chr> <chr>       <fct>                 
# 1 ""    "     date" "Min.   :1909-06-01  "
# 2 ""    "     date" "1st Qu.:1936-08-24  " 
# 3 ""    "     date" "Median :1963-11-16  "
# 4 ""    "     date" "Mean   :1963-11-16  "
# 5 ""    "     date" "3rd Qu.:1991-02-08  "
# 6 ""    "     date" "Max.   :2018-05-01  "
# 7 ""    "     date" NA                    
# 8 ""    "     rap"  "Min.   :   -Inf  "   
# 9 ""    "     rap"  "1st Qu.:-0.6472  "   
#10 ""    "     rap"  "Median : 0.0022  "   
#11 ""    "     rap"  "Mean   :   -Inf  "   
#12 ""    "     rap"  "3rd Qu.: 0.6657  "   
#13 ""    "     rap"  "Max.   : 2.9000  "   
#14 ""    "     rap"  "NA's   :467  "  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Use only 'rap' without NA vals 
# Summary: I'm confused about the bug!

# prepare data for 'rap' without NA only
sta_rap <- sta_mon %>% 
  select(rap, date) %>%
  filter(rap != is.na(rap))

# update date for joining later
Date_rap <- sta_rap %>% 
  select(date) %>%
  mutate(date = ymd(date)) %>%
  arrange(date)

# drop date
sta_rap <- sta_rap %>% select(-date)

spi_list  <- spi(sta_rap, 1, 
                 distribution = 'PearsonIII', na.rm = TRUE) 

spi1_coeff_rap <- as.tibble(spi_list$coefficients) %>% 
  t() %>% as.tibble()  

spi1_rap <- as.tibble(spi_list$fitted) 
spi1_rap <- bind_cols(Date_rap, spi1_rap) 

spi1_rap <- spi1_rap %>%
  rename(spi1 = rap) %>%
  arrange(spi1)

spi1_rap <- bind_cols(sta_rap, spi1_rap) 
spi_rap_test <- spi1_rap
```

```{r testing2}
# this is a new test to check on why differences between two ways of 
# calculating code

sta_rap3 <- sta_mon %>%
  arrange(date) %>%
  slice(468:1308) %>%
  select(date, rap)

spi_list  <- spi(sta_rap3[, 'rap'], 1, 
                 distribution = 'PearsonIII') 

spi1_rap3 <- as.tibble(spi_list$fitted) 

spi1_rap3 <- bind_cols(spi1_rap3, sta_rap3)

ggplot(spi1_rap3, aes(rap, rap1)) +
  geom_point()


# prepare data for 'rap' without NA only
sta_rap1 <- sta_mon %>% 
  select(rap, date) %>%
  filter(rap != is.na(rap)) %>%
  arrange(date) # This might be the issue!

# update date for joining later
Date_rap1 <- sta_rap1 %>% 
  select(date) %>%
  mutate(date = ymd(date)) %>%
  arrange(date)

# drop date
#sta_rap1 <- sta_rap1 %>% select(-date)

# calculate SPI
spi_list  <- spi(sta_rap1[, 'rap'], 1, 
                 distribution = 'PearsonIII') 

#spi1_coeff_rap <- as.tibble(spi_list$coefficients) %>% 
#  t() %>% as.tibble()  

spi1_rap1 <- as.tibble(spi_list$fitted) 
spi1_rap1 <- bind_cols(Date_rap1, spi1_rap1) 

spi1_rap1 <- spi1_rap1 %>%
  rename(spi1 = rap) %>%
  arrange(spi1)

spi1_rap1 <- bind_cols(sta_rap1, spi1_rap1) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Second approach 
sta_trans <- sta_mon %>% 
  select(date, year, month, rap) %>% 
  arrange(date) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Pull apart the NA and non-NA vals
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   1. Split the raw data into two parts at 1948-05-01
  sta_ge49      <- sta_trans %>% filter(year >= 1949) # yr above
  sta_48m05     <- sta_trans %>% filter(year == 1948 & month >= 5)
sta_rap2         <- bind_rows(sta_ge49, sta_48m05) # this is active
  rm(sta_ge49, sta_48m05)
# remove year and month
sta_rap2 <- sta_rap2 %>%
  select(date, rap)
#  2. Save NA observations  
  sta_lt48      <- sta_trans %>% filter(year < 1948)
  sta_48m01_m05 <- sta_trans %>% filter(year == 1948 & month < 5)
sta_NA          <- bind_rows(sta_lt48, sta_48m01_m05) # this is not
  rm(sta_lt48, sta_48m01_m05, sta_trans)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Calculate Rapid City SPI 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi1_rap2  <- spi(sta_rap2[,'rap'],  1, distribution = 'PearsonIII') 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# save & rename coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
#spi_1rap_coeff <- as.tibble(spi_1rap$coefficients) %>% 
 # t() %>% as.tibble() 

#spi_1rap_coeff <- rownames_to_column(spi_1rap_coeff, "month")
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# save SPI values as a Tibble
spi1_rap2 <- as.tibble(spi1_rap2$fitted) %>% 
  mutate(duration = 1)



# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~




# Why does sta_rap1 have 839 $ sta_rap2 have 841???




summary(sta_rap1$date)
#  Min.      1st Qu.       Median         Mean      3rd Qu. 
#"1948-05-01" "1965-11-16" "1983-05-01" "1983-05-03" "2000-10-16" 
#        Max. 
#"2018-05-01" 
summary(sta_rap2$date)
#        Min.      1st Qu.       Median         Mean      3rd Qu. 
#"1948-05-01" "1965-11-01" "1983-05-01" "1983-05-02" "2000-11-01" 
#        Max. 
#"2018-05-01" 
sta_rap1_a <- sta_rap1 %>% 
  arrange(date) %>%
  slice(131:150)
sta_rap2_a <- sta_rap2 %>%
  arrange(date) %>%
  slice(131:150)

test_a <- full_join(sta_rap1_a, sta_rap2_a, by = "date")
test_a <- test_a %>%
  mutate(dif = rap.y - rap.x)

```

```{r spi-cot} 
# This code chunk calculates SPI coefficients for 
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Cottonwood, SD. 
# Code is mostly following the SPI vignette. 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Select Cottonwoods dataset 
sta_cot <- sta_mon %>% 
  select(date, cot) %>% 
  arrange(date) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Calculate Cottonwood SPI 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1cot  <- spi(sta_cot[,'cot'], 1, distribution = 'PearsonIII') 
spi_2cot  <- spi(sta_cot[,'cot'], 2, distribution = 'PearsonIII') 
spi_3cot  <- spi(sta_cot[,'cot'], 3, distribution = 'PearsonIII') 
spi_4cot  <- spi(sta_cot[,'cot'], 4, distribution = 'PearsonIII') 
spi_5cot  <- spi(sta_cot[,'cot'], 5, distribution = 'PearsonIII') 
spi_6cot  <- spi(sta_cot[,'cot'], 6, distribution = 'PearsonIII') 
spi_9cot  <- spi(sta_cot[,'cot'], 9, distribution = 'PearsonIII') 
spi_12cot <- spi(sta_cot[,'cot'], 12, distribution = 'PearsonIII')  
spi_18cot <- spi(sta_cot[,'cot'], 18, distribution = 'PearsonIII') 
spi_24cot <- spi(sta_cot[,'cot'], 24, distribution = 'PearsonIII') 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# save coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1cot_coeff <- as.tibble(spi_1cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_2cot_coeff <- as.tibble(spi_2cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_3cot_coeff <- as.tibble(spi_3cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_4cot_coeff <- as.tibble(spi_4cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_5cot_coeff <- as.tibble(spi_5cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_6cot_coeff <- as.tibble(spi_6cot$coefficients) %>% 
  t() %>%
  as.tibble() 

spi_9cot_coeff <- as.tibble(spi_9cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_12cot_coeff <- as.tibble(spi_12cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_18cot_coeff <- as.tibble(spi_18cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_24cot_coeff <- as.tibble(spi_24cot$coefficients) %>% 
  t() %>% as.tibble() 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Rename coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1cot_coeff <- spi_1cot_coeff %>% 
  rename(mu_1 = mu) %>%
   rename(sigma_1 = sigma) %>% 
   rename(gamma_1 = gamma)
  
spi_2cot_coeff <- spi_2cot_coeff %>% 
  rename(mu_2 = mu) %>%
   rename(sigma_2 = sigma) %>% 
   rename(gamma_2 = gamma) 

spi_3cot_coeff <- spi_3cot_coeff %>% 
  rename(mu_3 = mu) %>%
   rename(sigma_3 = sigma) %>% 
   rename(gamma_3 = gamma) 

spi_4cot_coeff <- spi_4cot_coeff %>% 
  rename(mu_4 = mu) %>%
   rename(sigma_4 = sigma) %>% 
   rename(gamma_4 = gamma) 

spi_5cot_coeff <- spi_5cot_coeff %>% 
  rename(mu_5 = mu) %>%
   rename(sigma_5 = sigma) %>% 
   rename(gamma_5 = gamma) 

spi_6cot_coeff <- spi_6cot_coeff %>% 
  rename(mu_6 = mu) %>%
   rename(sigma_6 = sigma) %>% 
   rename(gamma_6 = gamma) 

spi_9cot_coeff <- spi_9cot_coeff %>% 
  rename(mu_9 = mu) %>%
   rename(sigma_9 = sigma) %>% 
   rename(gamma_9 = gamma) 

spi_12cot_coeff <- spi_12cot_coeff %>% 
  rename(mu_12 = mu) %>%
   rename(sigma_12 = sigma)  %>% 
   rename(gamma_12 = gamma) 

spi_18cot_coeff <- spi_18cot_coeff %>% 
  rename(mu_18 = mu) %>%
   rename(sigma_18 = sigma) %>% 
   rename(gamma_18 = gamma) 

spi_24cot_coeff <- spi_24cot_coeff %>% 
  rename(mu_24 = mu) %>%
   rename(sigma_24 = sigma) %>% 
   rename(gamma_24 = gamma) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Join the values 
# THIS CODE COULD BE DONE MUCH BETTER! 
prep1 <- bind_cols(spi_1cot_coeff, spi_2cot_coeff) 
rm(spi_1cot_coeff, spi_2cot_coeff) 

prep2 <- bind_cols(prep1, spi_3cot_coeff) 
rm(prep1, spi_3cot_coeff) 

prep3 <- bind_cols(prep2, spi_4cot_coeff) 
rm(prep2, spi_4cot_coeff) 

prep4 <- bind_cols(prep3, spi_5cot_coeff) 
rm(prep3, spi_5cot_coeff) 

prep5 <- bind_cols(prep4, spi_6cot_coeff) 
rm(prep4, spi_6cot_coeff) 

prep6 <- bind_cols(prep5, spi_9cot_coeff) 
rm(prep5, spi_9cot_coeff) 

prep7 <- bind_cols(prep6, spi_12cot_coeff) 
rm(prep6, spi_12cot_coeff) 

prep8 <- bind_cols(prep7, spi_18cot_coeff) 
rm(prep7, spi_18cot_coeff) 

spi_coeff_cot <- bind_cols(prep8, spi_24cot_coeff) 
rm(prep8, spi_24cot_coeff, sta_cot) 

spi_coeff_cot <- rownames_to_column(spi_coeff_cot, "month")
# export(spi_coeff_cot, "data/spi_coeff_cot.csv") 
# rm(spi_coeff_cot)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# save SPI values as a Tibble
spi_1cot <- as.tibble(spi_1cot$fitted) %>% 
  mutate(duration = 1) 

spi_2cot <- as.tibble(spi_2cot$fitted) %>% 
  mutate(duration = 2)

spi_3cot <- as.tibble(spi_3cot$fitted) %>% 
  mutate(duration = 3) 

spi_4cot <- as.tibble(spi_4cot$fitted) %>% 
  mutate(duration = 4) 

spi_5cot <- as.tibble(spi_5cot$fitted) %>% 
  mutate(duration = 5) 

spi_6cot <- as.tibble(spi_6cot$fitted) %>% 
  mutate(duration = 6) 

spi_9cot <- as.tibble(spi_9cot$fitted) %>% 
  mutate(duration = 9)

spi_12cot <- as.tibble(spi_12cot$fitted) %>% 
  mutate(duration = 12) 

spi_18cot <- as.tibble(spi_18cot$fitted) %>% 
  mutate(duration = 18) 

spi_24cot <- as.tibble(spi_24cot$fitted) %>% 
  mutate(duration = 24) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# add date to the SPI data 
date <- sta_mon %>%
  select(date) %>%
  arrange(date)

spi_1cot  <-  bind_cols(date, spi_1cot) 
spi_2cot  <-  bind_cols(date, spi_2cot) 
spi_3cot  <-  bind_cols(date, spi_3cot) 
spi_4cot  <-  bind_cols(date, spi_4cot) 
spi_5cot  <-  bind_cols(date, spi_5cot) 
spi_6cot  <-  bind_cols(date, spi_6cot) 
spi_9cot  <-  bind_cols(date, spi_9cot) 
spi_12cot <-  bind_cols(date, spi_12cot) 
spi_18cot <-  bind_cols(date, spi_18cot) 
spi_24cot <-  bind_cols(date, spi_24cot) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Rowwise join of SPI data
intr1 <- bind_rows(spi_1cot, spi_2cot) 
rm(spi_1cot, spi_2cot) 

intr2 <- bind_rows(intr1, spi_3cot) 
rm(intr1, spi_3cot) 

intr3 <- bind_rows(intr2, spi_4cot) 
rm(intr2, spi_4cot) 

intr4 <- bind_rows(intr3, spi_5cot) 
rm(intr3, intc3, spi_5cot) 

intr5 <- bind_rows(intr4, spi_6cot) 
rm(intr4, spi_6cot) 

intr6 <- bind_rows(intr5, spi_9cot) 
rm(intr5, spi_9cot) 

intr7 <- bind_rows(intr6, spi_12cot) 
rm(intr6, spi_12cot) 

intr8 <- bind_rows(intr7, spi_18cot) 
rm(intr7, spi_18cot) 

spi_cot <- bind_rows(intr8, spi_24cot) 
rm(intr8, spi_24cot)  

# export(spi_cot, "data/spi_cot.csv") 
# rm(spi_cot)
```

```{r spi-oel}   
# This code chunk calculates SPI coefficients for 
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Oelrichs  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Select Oelrichs dataset
sta_oel <- sta_mon %>%  
  select(date, oel) %>% 
  arrange(date)  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Calculate Cottonwood SPI 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1oel  <- spi(sta_oel[,'oel'], 1, distribution = 'PearsonIII') 
spi_2oel  <- spi(sta_oel[,'oel'], 2, distribution = 'PearsonIII') 
spi_3oel  <- spi(sta_oel[,'oel'], 3, distribution = 'PearsonIII') 
spi_4oel  <- spi(sta_oel[,'oel'], 4, distribution = 'PearsonIII') 
spi_5oel  <- spi(sta_oel[,'oel'], 5, distribution = 'PearsonIII') 
spi_6oel  <- spi(sta_oel[,'oel'], 6, distribution = 'PearsonIII') 
spi_9oel  <- spi(sta_oel[,'oel'], 9, distribution = 'PearsonIII') 
spi_12oel <- spi(sta_oel[,'oel'], 12, distribution = 'PearsonIII')  
spi_18oel <- spi(sta_oel[,'oel'], 18, distribution = 'PearsonIII') 
spi_24oel <- spi(sta_oel[,'oel'], 24, distribution = 'PearsonIII') 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# save coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1oel_coeff <- as.tibble(spi_1oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_2oel_coeff <- as.tibble(spi_2oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_3oel_coeff <- as.tibble(spi_3oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_4oel_coeff <- as.tibble(spi_4oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_5oel_coeff <- as.tibble(spi_5oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_6oel_coeff <- as.tibble(spi_6oel$coefficients) %>% 
  t() %>%
  as.tibble() 

spi_9oel_coeff <- as.tibble(spi_9oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_12oel_coeff <- as.tibble(spi_12oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_18oel_coeff <- as.tibble(spi_18oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_24oel_coeff <- as.tibble(spi_24oel$coefficients) %>% 
  t() %>% as.tibble() 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Rename coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1oel_coeff <- spi_1oel_coeff %>% 
  rename(mu_1 = mu) %>%
   rename(sigma_1 = sigma) %>% 
   rename(gamma_1 = gamma)
  
spi_2oel_coeff <- spi_2oel_coeff %>% 
  rename(mu_2 = mu) %>%
   rename(sigma_2 = sigma) %>% 
   rename(gamma_2 = gamma) 

spi_3oel_coeff <- spi_3oel_coeff %>% 
  rename(mu_3 = mu) %>%
   rename(sigma_3 = sigma) %>% 
   rename(gamma_3 = gamma) 

spi_4oel_coeff <- spi_4oel_coeff %>% 
  rename(mu_4 = mu) %>%
   rename(sigma_4 = sigma) %>% 
   rename(gamma_4 = gamma) 

spi_5oel_coeff <- spi_5oel_coeff %>% 
  rename(mu_5 = mu) %>%
   rename(sigma_5 = sigma) %>% 
   rename(gamma_5 = gamma) 

spi_6oel_coeff <- spi_6oel_coeff %>% 
  rename(mu_6 = mu) %>%
   rename(sigma_6 = sigma) %>% 
   rename(gamma_6 = gamma) 

spi_9oel_coeff <- spi_9oel_coeff %>% 
  rename(mu_9 = mu) %>%
   rename(sigma_9 = sigma) %>% 
   rename(gamma_9 = gamma) 

spi_12oel_coeff <- spi_12oel_coeff %>% 
  rename(mu_12 = mu) %>%
   rename(sigma_12 = sigma)  %>% 
   rename(gamma_12 = gamma) 

spi_18oel_coeff <- spi_18oel_coeff %>% 
  rename(mu_18 = mu) %>%
   rename(sigma_18 = sigma) %>% 
   rename(gamma_18 = gamma) 

spi_24oel_coeff <- spi_24oel_coeff %>% 
  rename(mu_24 = mu) %>%
   rename(sigma_24 = sigma) %>% 
   rename(gamma_24 = gamma)  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Join the values 
# THIS CODE COULD BE DONE MUCH BETTER! 
prep1 <- bind_cols(spi_1oel_coeff, spi_2oel_coeff) 
rm(spi_1oel_coeff, spi_2oel_coeff) 

prep2 <- bind_cols(prep1, spi_3oel_coeff) 
rm(prep1, spi_3oel_coeff) 

prep3 <- bind_cols(prep2, spi_4oel_coeff) 
rm(prep2, spi_4oel_coeff) 

prep4 <- bind_cols(prep3, spi_5oel_coeff) 
rm(prep3, spi_5oel_coeff) 

prep5 <- bind_cols(prep4, spi_6oel_coeff) 
rm(prep4, spi_6oel_coeff) 

prep6 <- bind_cols(prep5, spi_9oel_coeff) 
rm(prep5, spi_9oel_coeff) 

prep7 <- bind_cols(prep6, spi_12oel_coeff) 
rm(prep6, spi_12oel_coeff) 
 
prep8 <- bind_cols(prep7, spi_18oel_coeff) 
rm(prep7, spi_18oel_coeff) 

spi_coeff_oel <- bind_cols(prep8, spi_24oel_coeff) 
rm(prep8, spi_24oel_coeff) 

spi_coeff_oel <- rownames_to_column(spi_coeff_oel, "month")
# export(spi_coeff_oel, "data/spi_coeff_oel.csv") 
# rm(spi_coeff_oel, sta_oel)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# save SPI values as a Tibble
spi_1oel <- as.tibble(spi_1oel$fitted) %>% 
  mutate(duration = 1)

spi_2oel <- as.tibble(spi_2oel$fitted) %>% 
  mutate(duration = 2)

spi_3oel <- as.tibble(spi_3oel$fitted) %>% 
  mutate(duration = 3) 

spi_4oel <- as.tibble(spi_4oel$fitted) %>% 
  mutate(duration = 4) 

spi_5oel <- as.tibble(spi_5oel$fitted) %>% 
  mutate(duration = 5) 

spi_6oel <- as.tibble(spi_6oel$fitted) %>% 
  mutate(duration = 6) 

spi_9oel <- as.tibble(spi_9oel$fitted) %>% 
  mutate(duration = 9)

spi_12oel <- as.tibble(spi_12oel$fitted) %>% 
  mutate(duration = 12) 

spi_18oel <- as.tibble(spi_18oel$fitted) %>% 
  mutate(duration = 18) 

spi_24oel <- as.tibble(spi_24oel$fitted) %>% 
  mutate(duration = 24) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# add date to the SPI data
date <- sta_mon %>%
  select(date) %>%
  arrange(date)

spi_1oel  <-  bind_cols(date, spi_1oel) 
spi_2oel  <-  bind_cols(date, spi_2oel) 
spi_3oel  <-  bind_cols(date, spi_3oel) 
spi_4oel  <-  bind_cols(date, spi_4oel) 
spi_5oel  <-  bind_cols(date, spi_5oel) 
spi_6oel  <-  bind_cols(date, spi_6oel) 
spi_9oel  <-  bind_cols(date, spi_9oel) 
spi_12oel <-  bind_cols(date, spi_12oel) 
spi_18oel <-  bind_cols(date, spi_18oel) 
spi_24oel <-  bind_cols(date, spi_24oel) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Rowwise join of SPI data
intr1 <- bind_rows(spi_1oel, spi_2oel) 
rm(spi_1oel, spi_2oel) 

intr2 <- bind_rows(intr1, spi_3oel) 
rm(intr1, spi_3oel) 

intr3 <- bind_rows(intr2, spi_4oel) 
rm(intr2, spi_4oel) 

intr4 <- bind_rows(intr3, spi_5oel) 
rm(intr3, spi_5oel) 

intr5 <- bind_rows(intr4, spi_6oel) 
rm(intr4, intc4, spi_6oel) 

intr6 <- bind_rows(intr5, spi_9oel) 
rm(intr5, spi_9oel) 

intr7 <- bind_rows(intr6, spi_12oel) 
rm(intr6, spi_12oel) 

intr8 <- bind_rows(intr7, spi_18oel) 
rm(intr7, spi_18oel) 

spi_oel <- bind_rows(intr8, spi_24oel) 
rm(intr8, spi_24oel, sta_oel) 

# export(spi_oel, "data/spi_oel.csv") 
# rm(spi_oel)
```

```{r spi-rap} 
# This code chunk calculates SPI coefficients for 
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Rapid City, SD.
# Note that this resulted in -Inf vals before
# Added na.rm = TRUE to handle the missing vals; didn't
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Select Rapid City dataset 
sta_trans <- sta_mon %>% 
  select(date, year, month, rap) %>% 
  arrange(date) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Pull apart the NA and non-NA vals
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# reusing code from _04_prcp-data_munging
# Use nearest year as split-point
#   1. Split the raw data into two parts at 1948-05-01
  sta_ge49      <- sta_trans %>% filter(year >= 1949) # yr above
  sta_48m05     <- sta_trans %>% filter(year == 1948 & month >= 5)
sta_rap         <- bind_rows(sta_ge49, sta_48m05) # this is active
  rm(sta_ge49, sta_48m05)
# remove year and month
sta_rap <- sta_rap %>%
  select(date, rap)
#  2. Save NA observations  
  sta_lt48      <- sta_trans %>% filter(year < 1948)
  sta_48m01_m05 <- sta_trans %>% filter(year == 1948 & month < 5)
sta_NA          <- bind_rows(sta_lt48, sta_48m01_m05) # this is not
  rm(sta_lt48, sta_48m01_m05, sta_trans)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Calculate Rapid City SPI 
# THIS CODE COULD BE DONE MUCH BETTER! 
# Added na.rm = TRUE to handle the missing vals, but didn't work!
spi_1rap  <- spi(sta_rap[,'rap'],  1, distribution = 'PearsonIII') 
spi_2rap  <- spi(sta_rap[,'rap'],  2, distribution = 'PearsonIII') 
spi_3rap  <- spi(sta_rap[,'rap'],  3, distribution = 'PearsonIII') 
spi_4rap  <- spi(sta_rap[,'rap'],  4, distribution = 'PearsonIII') 
spi_5rap  <- spi(sta_rap[,'rap'],  5, distribution = 'PearsonIII') 
spi_6rap  <- spi(sta_rap[,'rap'],  6, distribution = 'PearsonIII') 
spi_9rap  <- spi(sta_rap[,'rap'],  9, distribution = 'PearsonIII') 
spi_12rap <- spi(sta_rap[,'rap'], 12, distribution = 'PearsonIII')  
spi_18rap <- spi(sta_rap[,'rap'], 18, distribution = 'PearsonIII') 
spi_24rap <- spi(sta_rap[,'rap'], 24, distribution = 'PearsonIII') 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# save coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1rap_coeff <- as.tibble(spi_1rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_2rap_coeff <- as.tibble(spi_2rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_3rap_coeff <- as.tibble(spi_3rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_4rap_coeff <- as.tibble(spi_4rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_5rap_coeff <- as.tibble(spi_5rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_6rap_coeff <- as.tibble(spi_6rap$coefficients) %>% 
  t() %>%
  as.tibble() 

spi_9rap_coeff <- as.tibble(spi_9rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_12rap_coeff <- as.tibble(spi_12rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_18rap_coeff <- as.tibble(spi_18rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_24rap_coeff <- as.tibble(spi_24rap$coefficients) %>% 
  t() %>% as.tibble() 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Rename coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1rap_coeff <- spi_1rap_coeff %>% 
  rename(mu_1 = mu) %>%
   rename(sigma_1 = sigma) %>% 
   rename(gamma_1 = gamma)
  
spi_2rap_coeff <- spi_2rap_coeff %>% 
  rename(mu_2 = mu) %>%
   rename(sigma_2 = sigma) %>% 
   rename(gamma_2 = gamma) 

spi_3rap_coeff <- spi_3rap_coeff %>% 
  rename(mu_3 = mu) %>%
   rename(sigma_3 = sigma) %>% 
   rename(gamma_3 = gamma) 

spi_4rap_coeff <- spi_4rap_coeff %>% 
  rename(mu_4 = mu) %>%
   rename(sigma_4 = sigma) %>% 
   rename(gamma_4 = gamma) 

spi_5rap_coeff <- spi_5rap_coeff %>% 
  rename(mu_5 = mu) %>%
   rename(sigma_5 = sigma) %>% 
   rename(gamma_5 = gamma) 

spi_6rap_coeff <- spi_6rap_coeff %>% 
  rename(mu_6 = mu) %>%
   rename(sigma_6 = sigma) %>% 
   rename(gamma_6 = gamma) 

spi_9rap_coeff <- spi_9rap_coeff %>% 
  rename(mu_9 = mu) %>%
   rename(sigma_9 = sigma) %>% 
   rename(gamma_9 = gamma) 

spi_12rap_coeff <- spi_12rap_coeff %>% 
  rename(mu_12 = mu) %>%
   rename(sigma_12 = sigma)  %>% 
   rename(gamma_12 = gamma) 

spi_18rap_coeff <- spi_18rap_coeff %>% 
  rename(mu_18 = mu) %>%
   rename(sigma_18 = sigma) %>% 
   rename(gamma_18 = gamma) 

spi_24rap_coeff <- spi_24rap_coeff %>% 
  rename(mu_24 = mu) %>%
   rename(sigma_24 = sigma) %>% 
   rename(gamma_24 = gamma) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Join the values 
# THIS CODE COULD BE DONE MUCH BETTER! 
prep1 <- bind_cols(spi_1rap_coeff, spi_2rap_coeff) 
rm(spi_1rap_coeff, spi_2rap_coeff) 

prep2 <- bind_cols(prep1, spi_3rap_coeff) 
rm(prep1, spi_3rap_coeff) 

prep3 <- bind_cols(prep2, spi_4rap_coeff) 
rm(prep2, spi_4rap_coeff) 

prep4 <- bind_cols(prep3, spi_5rap_coeff) 
rm(prep3, spi_5rap_coeff) 

prep5 <- bind_cols(prep4, spi_6rap_coeff) 
rm(prep4, spi_6rap_coeff) 

prep6 <- bind_cols(prep5, spi_9rap_coeff) 
rm(prep5, spi_9rap_coeff) 

prep7 <- bind_cols(prep6, spi_12rap_coeff) 
rm(prep6, spi_12rap_coeff) 

prep8 <- bind_cols(prep7, spi_18rap_coeff) 
rm(prep7, spi_18rap_coeff) 

spi_coeff_rap <- bind_cols(prep8, spi_24rap_coeff) 
rm(prep8, spi_24rap_coeff) 

spi_coeff_rap <- rownames_to_column(spi_coeff_rap, "month")
# export(spi_coeff_rap, "data/spi_coeff_rap.csv") 
# rm(spi_coeff_rap)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# save SPI values as a Tibble
spi_1rap <- as.tibble(spi_1rap$fitted) %>% 
  mutate(duration = 1)

spi_2rap <- as.tibble(spi_2rap$fitted) %>% 
  mutate(duration = 2)

spi_3rap <- as.tibble(spi_3rap$fitted) %>% 
  mutate(duration = 3) 

spi_4rap <- as.tibble(spi_4rap$fitted) %>% 
  mutate(duration = 4) 

spi_5rap <- as.tibble(spi_5rap$fitted) %>% 
  mutate(duration = 5) 

spi_6rap <- as.tibble(spi_6rap$fitted) %>% 
  mutate(duration = 6) 

spi_9rap <- as.tibble(spi_9rap$fitted) %>% 
  mutate(duration = 9)

spi_12rap <- as.tibble(spi_12rap$fitted) %>% 
  mutate(duration = 12) 

spi_18rap <- as.tibble(spi_18rap$fitted) %>% 
  mutate(duration = 18) 

spi_24rap <- as.tibble(spi_24rap$fitted) %>% 
  mutate(duration = 24) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# add date to the SPI data & bind cols
date <- sta_rap %>%
  select(date) %>%
  arrange(date)
#rm(sta_rap)
# ~~~~~~~~~~~~~~~
spi_1rap  <-  bind_cols(date, spi_1rap) 
spi_2rap  <-  bind_cols(date, spi_2rap) 
spi_3rap  <-  bind_cols(date, spi_3rap) 
spi_4rap  <-  bind_cols(date, spi_4rap) 
spi_5rap  <-  bind_cols(date, spi_5rap) 
spi_6rap  <-  bind_cols(date, spi_6rap) 
spi_9rap  <-  bind_cols(date, spi_9rap) 
spi_12rap <-  bind_cols(date, spi_12rap) 
spi_18rap <-  bind_cols(date, spi_18rap) 
spi_24rap <-  bind_cols(date, spi_24rap) 
# Rowwise join of SPI data
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
intr1 <- bind_rows(spi_1rap, spi_2rap) 
rm(spi_1rap, spi_2rap) 

intr2 <- bind_rows(intr1, spi_3rap) 
rm(intr1, spi_3rap) 

intr3 <- bind_rows(intr2, spi_4rap) 
rm(intr2, spi_4rap) 

intr4 <- bind_rows(intr3, spi_5rap) 
rm(intr3, spi_5rap) 

intr5 <- bind_rows(intr4, spi_6rap)  
rm(intr4, spi_6rap) 

intr6 <- bind_rows(intr5, spi_9rap) 
rm(intr5, spi_9rap) 

intr7 <- bind_rows(intr6, spi_12rap) 
rm(intr6, spi_12rap) 

intr8 <- bind_rows(intr7, spi_18rap) 
rm(intr7, spi_18rap) 

spi_rap <- bind_rows(intr8, spi_24rap) 
rm(intr8, spi_24rap) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# check on the -Inf vals
spi_1rap <- spi_rap %>%
  filter(duration == 1)
# ~~~~~~~~~~~~~~~~~~~~~~
# join data and rename
sta_rap <- full_join(sta_rap, spi_1rap, by = "date") 
sta_rap <- sta_rap %>%
  rename(depth = rap.x) %>%
  rename(spi1 = rap.y) %>%
  arrange(spi1)

broken_rap <- sta_rap %>%
  filter(spi1 < -5)

 
```

```{r spi-algorithm-coeff-int}  
# This code chunk calculates SPI coefficients for  
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Interior, SD. 

# Add Interior dataset and change to time series 
sta_int <- sta_mon %>% 
  arrange(date) %>% 
  select(year, month, int) %>% 
  ts(end = c(2018, 05), frequency = 12)

# Calculate SPI 
# THIS CODE COULD BE DONE MUCH BETTER! 
# Added na.rm = TRUE to handle the missing vals
spi_1int  <- spi(sta_int[,'int'], 1, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_2int  <- spi(sta_int[,'int'], 2, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_3int  <- spi(sta_int[,'int'], 3, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_4int  <- spi(sta_int[,'int'], 4, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_5int  <- spi(sta_int[,'int'], 5, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_6int  <- spi(sta_int[,'int'], 6, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_9int  <- spi(sta_int[,'int'], 9, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_12int <- spi(sta_int[,'int'], 12, na.rm = TRUE, 
                 distribution = 'PearsonIII')  
spi_18int <- spi(sta_int[,'int'], 18, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_24int <- spi(sta_int[,'int'], 24, na.rm = TRUE, 
                 distribution = 'PearsonIII') 

# save coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1int_coeff <- as.tibble(spi_1int$coefficients) %>% 
  t() %>% as.tibble() 

spi_2int_coeff <- as.tibble(spi_2int$coefficients) %>% 
  t() %>% as.tibble() 

spi_3int_coeff <- as.tibble(spi_3int$coefficients) %>% 
  t() %>% as.tibble() 

spi_4int_coeff <- as.tibble(spi_4int$coefficients) %>% 
  t() %>% as.tibble() 

spi_5int_coeff <- as.tibble(spi_5int$coefficients) %>% 
  t() %>% as.tibble() 

spi_6int_coeff <- as.tibble(spi_6int$coefficients) %>% 
  t() %>%
  as.tibble() 

spi_9int_coeff <- as.tibble(spi_9int$coefficients) %>% 
  t() %>% as.tibble() 

spi_12int_coeff <- as.tibble(spi_12int$coefficients) %>% 
  t() %>% as.tibble() 

spi_18int_coeff <- as.tibble(spi_18int$coefficients) %>% 
  t() %>% as.tibble() 

spi_24int_coeff <- as.tibble(spi_24int$coefficients) %>% 
  t() %>% as.tibble() 

# Rename coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1int_coeff <- spi_1int_coeff %>% 
  rename(mu_1 = mu) %>%
   rename(sigma_1 = sigma) %>% 
   rename(gamma_1 = gamma)
  
spi_2int_coeff <- spi_2int_coeff %>% 
  rename(mu_2 = mu) %>%
   rename(sigma_2 = sigma) %>% 
   rename(gamma_2 = gamma) 

spi_3int_coeff <- spi_3int_coeff %>% 
  rename(mu_3 = mu) %>%
   rename(sigma_3 = sigma) %>% 
   rename(gamma_3 = gamma) 

spi_4int_coeff <- spi_4int_coeff %>% 
  rename(mu_4 = mu) %>%
   rename(sigma_4 = sigma) %>% 
   rename(gamma_4 = gamma) 

spi_5int_coeff <- spi_5int_coeff %>% 
  rename(mu_5 = mu) %>%
   rename(sigma_5 = sigma) %>% 
   rename(gamma_5 = gamma) 

spi_6int_coeff <- spi_6int_coeff %>% 
  rename(mu_6 = mu) %>%
   rename(sigma_6 = sigma) %>% 
   rename(gamma_6 = gamma) 

spi_9int_coeff <- spi_9int_coeff %>% 
  rename(mu_9 = mu) %>%
   rename(sigma_9 = sigma) %>% 
   rename(gamma_9 = gamma) 

spi_12int_coeff <- spi_12int_coeff %>% 
  rename(mu_12 = mu) %>%
   rename(sigma_12 = sigma)  %>% 
   rename(gamma_12 = gamma) 

spi_18int_coeff <- spi_18int_coeff %>% 
  rename(mu_18 = mu) %>%
   rename(sigma_18 = sigma) %>% 
   rename(gamma_18 = gamma) 

spi_24int_coeff <- spi_24int_coeff %>% 
  rename(mu_24 = mu) %>%
   rename(sigma_24 = sigma) %>% 
   rename(gamma_24 = gamma) 


# Join the values 
# THIS CODE COULD BE DONE MUCH BETTER! 
prep1 <- bind_cols(spi_1int_coeff, spi_2int_coeff) 
rm(spi_1int_coeff, spi_2int_coeff) 

prep2 <- bind_cols(prep1, spi_3int_coeff) 
rm(prep1, spi_3int_coeff) 

prep3 <- bind_cols(prep2, spi_4int_coeff) 
rm(prep2, spi_4int_coeff) 

prep4 <- bind_cols(prep3, spi_5int_coeff) 
rm(prep3, spi_5int_coeff) 

prep5 <- bind_cols(prep4, spi_6int_coeff) 
rm(prep4, spi_6int_coeff) 

prep6 <- bind_cols(prep5, spi_9int_coeff) 
rm(prep5, spi_9int_coeff) 

prep7 <- bind_cols(prep6, spi_12int_coeff) 
rm(prep6, spi_12int_coeff) 

int8 <- bind_cols(int7, spi_18int_coeff) 
rm(int7, spi_18int_coeff) 

spi_coeff_int <- bind_cols(int8, spi_24int_coeff) 
rm(int8, spi_24int_coeff, sta_int) 

# export(spi_coeff_int, "data/spi_coeff_int.csv") 
# rm(spi_coeff_int)
```

```{r spi-algorithm-fit-int}  
# This code chunk calculates SPI fitted values for  
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Interior, SD. 
# It is a continuation of 'spi-algorithm-coeff-int'

# extract SPI values & add duration
spi_1int <- as.tibble(spi_1int$fitted) %>% 
  mutate(duration = 1)

spi_2int <- as.tibble(spi_2int$fitted) %>% 
  mutate(duration = 2)

spi_3int <- as.tibble(spi_3int$fitted) %>% 
  mutate(duration = 3) 

spi_4int <- as.tibble(spi_4int$fitted) %>% 
  mutate(duration = 4) 

spi_5int <- as.tibble(spi_5int$fitted) %>% 
  mutate(duration = 5) 

spi_6int <- as.tibble(spi_6int$fitted) %>% 
  mutate(duration = 6) 

spi_9int <- as.tibble(spi_9int$fitted) %>% 
  mutate(duration = 9)

spi_12int <- as.tibble(spi_12int$fitted) %>% 
  mutate(duration = 12) 

spi_18int <- as.tibble(spi_18int$fitted) %>% 
  mutate(duration = 18) 

spi_24int <- as.tibble(spi_24int$fitted) %>% 
  mutate(duration = 24) 

# add date to the SPI data
date <- sta_mon %>%
  select(date) %>%
  arrange(date)

spi_1int  <-  bind_cols(date, spi_1int) 
spi_2int  <-  bind_cols(date, spi_2int) 
spi_3int  <-  bind_cols(date, spi_3int) 
spi_4int  <-  bind_cols(date, spi_4int) 
spi_5int  <-  bind_cols(date, spi_5int) 
spi_6int  <-  bind_cols(date, spi_6int) 
spi_9int  <-  bind_cols(date, spi_9int) 
spi_12int <-  bind_cols(date, spi_12int) 
spi_18int <-  bind_cols(date, spi_18int) 
spi_24int <-  bind_cols(date, spi_24int) 

# join the SPI data by wide and long
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1- & 2-month
intr1 <- bind_rows(spi_1int, spi_2int) 

intc1 <- bind_cols(spi_1int, spi_2int) 
intc1 <- intc1 %>%
  select(-c(date1, duration, duration1)) %>%
  rename(int_1 = "Series 1") %>%
  rename(int_2 = "Series 11")
rm(spi_1int, spi_2int) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3-month
intr2 <- bind_rows(intr1, spi_3int) 

intc2 <- bind_cols(intc1, spi_3int) 
intc2 <- intc2 %>%
  select(-c(date1, duration)) %>%
  rename(int_3 = "Series 1") 
rm(intr1, intc1, spi_3int) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 4-month
intr3 <- bind_rows(intr2, spi_4int) 

intc3 <- bind_cols(intc2, spi_4int) 
intc3 <- intc3 %>%
  select(-c(date1, duration)) %>%
  rename(int_4 = "Series 1") 
rm(intr2, intc2, spi_4int) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 5-month
intr4 <- bind_rows(intr3, spi_5int) 

intc4 <- bind_cols(intc3, spi_5int) 
intc4 <- intc4 %>%
  select(-c(date1, duration)) %>%
  rename(int_5 = "Series 1") 
rm(intr3, intc3, spi_5int) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 6-month
intr5 <- bind_rows(intr4, spi_6int) 

intc5 <- bind_cols(intc4, spi_6int) 
intc5 <- intc5 %>%
  select(-c(date1, duration)) %>%
  rename(int_6 = "Series 1") 
rm(intr4, intc4, spi_6int) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 9-month
intr6 <- bind_rows(intr5, spi_9int) 

intc6 <- bind_cols(intc5, spi_9int) 
intc6 <- intc6 %>%
  select(-c(date1, duration)) %>%
  rename(int_9 = "Series 1") 
rm(intr5, intc5, spi_9int) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 12-month
intr7 <- bind_rows(intr6, spi_12int) 

intc7 <- bind_cols(intc6, spi_12int) 
intc7 <- intc7 %>%
  select(-c(date1, duration)) %>%
  rename(int_12 = "Series 1") 
rm(intr6, intc6, spi_12int) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 18-month
intr8 <- bind_rows(intr7, spi_18int) 

intc8 <- bind_cols(intc7, spi_18int) 
intc8 <- intc8 %>%
  select(-c(date1, duration)) %>%
  rename(int_18 = "Series 1") 
rm(intr7, intc7, spi_18int) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 24-month
spi_int_gath <- bind_rows(intr8, spi_24int) 
spi_int_gath <- spi_int_gath %>%
  rename(spi_int = "Series 1")

spi_int <- bind_cols(intc8, spi_24int) 
spi_int <- spi_int %>%
  select(-c(date1, duration)) %>%
  rename(int_24 = "Series 1") 

rm(intr8, intc8, spi_24int) 
# Next steps:
# distribution = 'PersonIII',
```

```{r spi-algorithm-coeff-ora}  
# This code chunk calculates SPI coefficients for  
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Oral, SD.

# Add Oral dataset and change to time series 
sta_ora <- sta_mon %>% 
  arrange(date) %>% 
  select(year, month, ora) %>% 
  ts(end = c(2018, 05), frequency = 12)

# Calculate SPI 
# THIS CODE COULD BE DONE MUCH BETTER! 
# Added na.rm = TRUE to handle the missing vals
spi_1ora  <- spi(sta_ora[,'ora'], 1, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_2ora  <- spi(sta_ora[,'ora'], 2, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_3ora  <- spi(sta_ora[,'ora'], 3, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_4ora  <- spi(sta_ora[,'ora'], 4, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_5ora  <- spi(sta_ora[,'ora'], 5, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_6ora  <- spi(sta_ora[,'ora'], 6, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_9ora  <- spi(sta_ora[,'ora'], 9, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_12ora <- spi(sta_ora[,'ora'], 12, na.rm = TRUE, 
                 distribution = 'PearsonIII')  
spi_18ora <- spi(sta_ora[,'ora'], 18, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_24ora <- spi(sta_ora[,'ora'], 24, na.rm = TRUE, 
                 distribution = 'PearsonIII') 

# save coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1ora_coeff <- as.tibble(spi_1ora$coefficients) %>% 
  t() %>% as.tibble() 

spi_2ora_coeff <- as.tibble(spi_2ora$coefficients) %>% 
  t() %>% as.tibble() 

spi_3ora_coeff <- as.tibble(spi_3ora$coefficients) %>% 
  t() %>% as.tibble() 

spi_4ora_coeff <- as.tibble(spi_4ora$coefficients) %>% 
  t() %>% as.tibble() 

spi_5ora_coeff <- as.tibble(spi_5ora$coefficients) %>% 
  t() %>% as.tibble() 

spi_6ora_coeff <- as.tibble(spi_6ora$coefficients) %>% 
  t() %>%
  as.tibble() 

spi_9ora_coeff <- as.tibble(spi_9ora$coefficients) %>% 
  t() %>% as.tibble() 

spi_12ora_coeff <- as.tibble(spi_12ora$coefficients) %>% 
  t() %>% as.tibble() 

spi_18ora_coeff <- as.tibble(spi_18ora$coefficients) %>% 
  t() %>% as.tibble() 

spi_24ora_coeff <- as.tibble(spi_24ora$coefficients) %>% 
  t() %>% as.tibble() 

# Rename coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1ora_coeff <- spi_1ora_coeff %>% 
  rename(mu_1 = mu) %>%
   rename(sigma_1 = sigma) %>% 
   rename(gamma_1 = gamma)
  
spi_2ora_coeff <- spi_2ora_coeff %>% 
  rename(mu_2 = mu) %>%
   rename(sigma_2 = sigma) %>% 
   rename(gamma_2 = gamma) 

spi_3ora_coeff <- spi_3ora_coeff %>% 
  rename(mu_3 = mu) %>%
   rename(sigma_3 = sigma) %>% 
   rename(gamma_3 = gamma) 

spi_4ora_coeff <- spi_4ora_coeff %>% 
  rename(mu_4 = mu) %>%
   rename(sigma_4 = sigma) %>% 
   rename(gamma_4 = gamma) 

spi_5ora_coeff <- spi_5ora_coeff %>% 
  rename(mu_5 = mu) %>%
   rename(sigma_5 = sigma) %>% 
   rename(gamma_5 = gamma) 

spi_6ora_coeff <- spi_6ora_coeff %>% 
  rename(mu_6 = mu) %>%
   rename(sigma_6 = sigma) %>% 
   rename(gamma_6 = gamma) 

spi_9ora_coeff <- spi_9ora_coeff %>% 
  rename(mu_9 = mu) %>%
   rename(sigma_9 = sigma) %>% 
   rename(gamma_9 = gamma) 

spi_12ora_coeff <- spi_12ora_coeff %>% 
  rename(mu_12 = mu) %>%
   rename(sigma_12 = sigma)  %>% 
   rename(gamma_12 = gamma) 

spi_18ora_coeff <- spi_18ora_coeff %>% 
  rename(mu_18 = mu) %>%
   rename(sigma_18 = sigma) %>% 
   rename(gamma_18 = gamma) 

spi_24ora_coeff <- spi_24ora_coeff %>% 
  rename(mu_24 = mu) %>%
   rename(sigma_24 = sigma) %>% 
   rename(gamma_24 = gamma) 


# Join the values 
# THIS CODE COULD BE DONE MUCH BETTER! 
prep1 <- bind_cols(spi_1ora_coeff, spi_2ora_coeff) 
rm(spi_1ora_coeff, spi_2ora_coeff) 

prep2 <- bind_cols(prep1, spi_3ora_coeff) 
rm(prep1, spi_3ora_coeff) 

prep3 <- bind_cols(prep2, spi_4ora_coeff) 
rm(prep2, spi_4ora_coeff) 

prep4 <- bind_cols(prep3, spi_5ora_coeff) 
rm(prep3, spi_5ora_coeff) 

prep5 <- bind_cols(prep4, spi_6ora_coeff) 
rm(prep4, spi_6ora_coeff) 

prep6 <- bind_cols(prep5, spi_9ora_coeff) 
rm(prep5, spi_9ora_coeff) 

prep7 <- bind_cols(prep6, spi_12ora_coeff) 
rm(prep6, spi_12ora_coeff) 

prep8 <- bind_cols(prep7, spi_18ora_coeff) 
rm(prep7, spi_18ora_coeff) 

spi_coeff_ora <- bind_cols(prep8, spi_24ora_coeff) 
rm(prep8, spi_24ora_coeff, sta_ora) 

# export(spi_coeff_ora, "data/spi_coeff_ora.csv") 
# rm(spi_coeff_ora)
```

```{r spi-algorithm-fit-ora} 
# This code chunk calculates SPI fitted values for  
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Oral, SD. 
# It is a continuation of 'spi-algorithm-coeff-ora'

# extract SPI values & add duration
spi_1ora <- as.tibble(spi_1ora$fitted) %>% 
  mutate(duration = 1)

spi_2ora <- as.tibble(spi_2ora$fitted) %>% 
  mutate(duration = 2)

spi_3ora <- as.tibble(spi_3ora$fitted) %>% 
  mutate(duration = 3) 

spi_4ora <- as.tibble(spi_4ora$fitted) %>% 
  mutate(duration = 4) 

spi_5ora <- as.tibble(spi_5ora$fitted) %>% 
  mutate(duration = 5) 

spi_6ora <- as.tibble(spi_6ora$fitted) %>% 
  mutate(duration = 6) 

spi_9ora <- as.tibble(spi_9ora$fitted) %>% 
  mutate(duration = 9)

spi_12ora <- as.tibble(spi_12ora$fitted) %>% 
  mutate(duration = 12) 

spi_18ora <- as.tibble(spi_18ora$fitted) %>% 
  mutate(duration = 18) 

spi_24ora <- as.tibble(spi_24ora$fitted) %>% 
  mutate(duration = 24) 

# add date to the SPI data
date <- sta_mon %>%
  select(date) %>%
  arrange(date)

spi_1ora  <-  bind_cols(date, spi_1ora) 
spi_2ora  <-  bind_cols(date, spi_2ora) 
spi_3ora  <-  bind_cols(date, spi_3ora) 
spi_4ora  <-  bind_cols(date, spi_4ora) 
spi_5ora  <-  bind_cols(date, spi_5ora) 
spi_6ora  <-  bind_cols(date, spi_6ora) 
spi_9ora  <-  bind_cols(date, spi_9ora) 
spi_12ora <-  bind_cols(date, spi_12ora) 
spi_18ora <-  bind_cols(date, spi_18ora) 
spi_24ora <-  bind_cols(date, spi_24ora) 

# join the SPI data by wide and long
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1- & 2-month
intr1 <- bind_rows(spi_1ora, spi_2ora) 

intc1 <- bind_cols(spi_1ora, spi_2ora) 
intc1 <- intc1 %>%
  select(-c(date1, duration, duration1)) %>%
  rename(int_1 = "Series 1") %>%
  rename(int_2 = "Series 11")
rm(spi_1ora, spi_2ora) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3-month
intr2 <- bind_rows(intr1, spi_3ora) 

intc2 <- bind_cols(intc1, spi_3ora) 
intc2 <- intc2 %>%
  select(-c(date1, duration)) %>%
  rename(ora_3 = "Series 1") 
rm(intr1, intc1, spi_3ora) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 4-month
intr3 <- bind_rows(intr2, spi_4ora) 

intc3 <- bind_cols(intc2, spi_4ora) 
intc3 <- intc3 %>%
  select(-c(date1, duration)) %>%
  rename(ora_4 = "Series 1") 
rm(intr2, intc2, spi_4ora) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 5-month
intr4 <- bind_rows(intr3, spi_5ora) 

intc4 <- bind_cols(intc3, spi_5ora) 
intc4 <- intc4 %>%
  select(-c(date1, duration)) %>%
  rename(ora_5 = "Series 1") 
rm(intr3, intc3, spi_5ora) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 6-month
intr5 <- bind_rows(intr4, spi_6ora) 

intc5 <- bind_cols(intc4, spi_6ora) 
intc5 <- intc5 %>%
  select(-c(date1, duration)) %>%
  rename(ora_6 = "Series 1") 
rm(intr4, intc4, spi_6ora) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 9-month
intr6 <- bind_rows(intr5, spi_9ora) 

intc6 <- bind_cols(intc5, spi_9ora) 
intc6 <- intc6 %>%
  select(-c(date1, duration)) %>%
  rename(ora_9 = "Series 1") 
rm(intr5, intc5, spi_9ora) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 12-month
intr7 <- bind_rows(intr6, spi_12ora) 

intc7 <- bind_cols(intc6, spi_12ora) 
intc7 <- intc7 %>%
  select(-c(date1, duration)) %>%
  rename(ora_12 = "Series 1") 
rm(intr6, intc6, spi_12ora) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 18-month
intr8 <- bind_rows(intr7, spi_18ora) 

intc8 <- bind_cols(intc7, spi_18ora) 
intc8 <- intc8 %>%
  select(-c(date1, duration)) %>%
  rename(ora_18 = "Series 1") 
rm(intr7, intc7, spi_18ora) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 24-month
spi_ora_gath <- bind_rows(intr8, spi_24ora) 
spi_ora_gath <- spi_ora_gath %>%
  rename(spi_ora = "Series 1")

spi_ora <- bind_cols(intc8, spi_24ora) 
spi_ora <- spi_ora %>%
  select(-c(date1, duration)) %>%
  rename(ora_24 = "Series 1") 

rm(intr8, intc8, spi_24ora) 
# Next steps:
# distribution = 'PersonIII',
```

```{r spi-plot-cot, include=FALSE, eval=FALSE}
# visual check of output for cottonwood SPI
ggplot(spi_cot_gath, aes(date, spi_cot)) + 
  geom_line() +
  facet_grid(duration~.) +
  theme_classic() + 
  labs(title = "Standardized Precipitation Index (SPI)",
       subtitle = "Cottonwood, SD") +
       xlab("") + 
       ylab("SPI-value") +
  NULL 
```

```{r spi-plot-oel, include=FALSE, eval=FALSE} 
# visual check of Oelrichs SPI 
ggplot(spi_oel_gath, aes(date, spi_oel)) +  
  geom_line() + 
  facet_grid(duration~.) + 
  theme_classic() +  
  labs(title = "Standardized Precipitation Index (SPI)", 
       subtitle = "Oral, SD") + 
       xlab("") + 
       ylab("SPI-value") 
```

```{r spi-plot-rap, include=FALSE, eval=FALSE} 
# visual check of Rapid City SPI 
ggplot(spi_rap_gath, aes(date, spi_rap)) +  
  geom_line(aes(na.rm = TRUE)) + 
  facet_grid(duration~.) + 
  theme_classic() + 
  labs(title = "Standardized Precipitation Index (SPI)", 
       subtitle = "Rapid City, SD") + 
       xlab("") + 
       ylab("SPI-value") 
# Next steps : how to remove NA from all of the facets 
```

```{r spi-plot-int, include=FALSE, eval=FALSE} 
# visual check of Interior SPI  
ggplot(spi_int_gath, aes(date, spi_int)) +  
  geom_line(aes(na.rm = TRUE)) + 
  facet_grid(duration~.) +
  theme_classic() + 
  labs(title = "Standardized Precipitation Index (SPI)",
       subtitle = "Interior, SD") +
       xlab("") +
       ylab("SPI-value")
# Next steps : how to remove NA from all of the facets
```

```{r spi-plot-ora, include=FALSE, eval=FALSE} 
ggplot(spi_ora_gath, aes(date, spi_ora)) +  
  geom_line(aes(na.rm = TRUE)) + 
  facet_grid(duration~.) + 
  theme_classic() +  
  labs(title = "Standardized Precipitation Index (SPI)", 
       subtitle = "Oral, SD") + 
       xlab("") + 
       ylab("SPI-value") 
# Next steps : how to remove NA from all of the facets  
```

```{r spi-algorithm-coeff-cot-DEPR} 
# This code chunk calculates SPI coefficients for 
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Cottonwood, SD. 
# Code is mostly following the SPI vignette. 

# Add Cottonwoods dataset and change to time series 
sta_cot <- sta_mon %>% 
  select(date, cot) %>% 
  arrange(date) 




# Calculate Cottonwood SPI 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1cot  <- spi(sta_cot[,'cot'], 1, distribution = 'PearsonIII') 
spi_2cot  <- spi(sta_cot[,'cot'], 2, distribution = 'PearsonIII') 
spi_3cot  <- spi(sta_cot[,'cot'], 3, distribution = 'PearsonIII') 
spi_4cot  <- spi(sta_cot[,'cot'], 4, distribution = 'PearsonIII') 
spi_5cot  <- spi(sta_cot[,'cot'], 5, distribution = 'PearsonIII') 
spi_6cot  <- spi(sta_cot[,'cot'], 6, distribution = 'PearsonIII') 
spi_9cot  <- spi(sta_cot[,'cot'], 9, distribution = 'PearsonIII') 
spi_12cot <- spi(sta_cot[,'cot'], 12, distribution = 'PearsonIII')  
spi_18cot <- spi(sta_cot[,'cot'], 18, distribution = 'PearsonIII') 
spi_24cot <- spi(sta_cot[,'cot'], 24, distribution = 'PearsonIII') 

# save coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1cot_coeff <- as.tibble(spi_1cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_2cot_coeff <- as.tibble(spi_2cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_3cot_coeff <- as.tibble(spi_3cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_4cot_coeff <- as.tibble(spi_4cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_5cot_coeff <- as.tibble(spi_5cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_6cot_coeff <- as.tibble(spi_6cot$coefficients) %>% 
  t() %>%
  as.tibble() 

spi_9cot_coeff <- as.tibble(spi_9cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_12cot_coeff <- as.tibble(spi_12cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_18cot_coeff <- as.tibble(spi_18cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_24cot_coeff <- as.tibble(spi_24cot$coefficients) %>% 
  t() %>% as.tibble() 

# Rename coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1cot_coeff <- spi_1cot_coeff %>% 
  rename(mu_1 = mu) %>%
   rename(sigma_1 = sigma) %>% 
   rename(gamma_1 = gamma)
  
spi_2cot_coeff <- spi_2cot_coeff %>% 
  rename(mu_2 = mu) %>%
   rename(sigma_2 = sigma) %>% 
   rename(gamma_2 = gamma) 

spi_3cot_coeff <- spi_3cot_coeff %>% 
  rename(mu_3 = mu) %>%
   rename(sigma_3 = sigma) %>% 
   rename(gamma_3 = gamma) 

spi_4cot_coeff <- spi_4cot_coeff %>% 
  rename(mu_4 = mu) %>%
   rename(sigma_4 = sigma) %>% 
   rename(gamma_4 = gamma) 

spi_5cot_coeff <- spi_5cot_coeff %>% 
  rename(mu_5 = mu) %>%
   rename(sigma_5 = sigma) %>% 
   rename(gamma_5 = gamma) 

spi_6cot_coeff <- spi_6cot_coeff %>% 
  rename(mu_6 = mu) %>%
   rename(sigma_6 = sigma) %>% 
   rename(gamma_6 = gamma) 

spi_9cot_coeff <- spi_9cot_coeff %>% 
  rename(mu_9 = mu) %>%
   rename(sigma_9 = sigma) %>% 
   rename(gamma_9 = gamma) 

spi_12cot_coeff <- spi_12cot_coeff %>% 
  rename(mu_12 = mu) %>%
   rename(sigma_12 = sigma)  %>% 
   rename(gamma_12 = gamma) 

spi_18cot_coeff <- spi_18cot_coeff %>% 
  rename(mu_18 = mu) %>%
   rename(sigma_18 = sigma) %>% 
   rename(gamma_18 = gamma) 

spi_24cot_coeff <- spi_24cot_coeff %>% 
  rename(mu_24 = mu) %>%
   rename(sigma_24 = sigma) %>% 
   rename(gamma_24 = gamma) 

# Join the values 
# THIS CODE COULD BE DONE MUCH BETTER! 
prep1 <- bind_cols(spi_1cot_coeff, spi_2cot_coeff) 
rm(spi_1cot_coeff, spi_2cot_coeff) 

prep2 <- bind_cols(prep1, spi_3cot_coeff) 
rm(prep1, spi_3cot_coeff) 

prep3 <- bind_cols(prep2, spi_4cot_coeff) 
rm(prep2, spi_4cot_coeff) 

prep4 <- bind_cols(prep3, spi_5cot_coeff) 
rm(prep3, spi_5cot_coeff) 

prep5 <- bind_cols(prep4, spi_6cot_coeff) 
rm(prep4, spi_6cot_coeff) 

prep6 <- bind_cols(prep5, spi_9cot_coeff) 
rm(prep5, spi_9cot_coeff) 

prep7 <- bind_cols(prep6, spi_12cot_coeff) 
rm(prep6, spi_12cot_coeff) 

prep8 <- bind_cols(prep7, spi_18cot_coeff) 
rm(prep7, spi_18cot_coeff) 

spi_coeff_cot <- bind_cols(prep8, spi_24cot_coeff) 
rm(prep8, spi_24cot_coeff, sta_cot) 

# export(spi_coeff_cot, "data/spi_coeff_cot.csv") 
# rm(spi_coeff_cot)
```

```{r combine-spi-coeff}   
# prepare for combining
# THIS COULD BE DONE BETTER
spi_coeff_cot <- spi_coeff_cot %>% 
  mutate(sta = "cot") %>%
  mutate(month = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)) 

spi_coeff_oel <- spi_coeff_oel %>% 
  mutate(sta = "oel") %>%
  mutate(month = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)) 

spi_coeff_rap <- spi_coeff_rap %>% 
  mutate(sta = "rap") %>%
  mutate(month = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)) 

spi_coeff_int <- spi_coeff_int %>% 
  mutate(sta = "int") %>%
  mutate(month = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)) 

spi_coeff_ora <- spi_coeff_ora %>% 
  mutate(sta = "ora") %>%
  mutate(month = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)) 

# combine in steps
prep1 <- bind_rows(spi_coeff_cot, spi_coeff_oel) 
rm(spi_coeff_cot, spi_coeff_oel) 

prep2 <- bind_rows(prep1, spi_coeff_rap) 
rm(prep1, spi_coeff_rap) 

prep3 <- bind_rows(prep2, spi_coeff_int) 
rm(prep2, spi_coeff_int) 

spi_coeff <- bind_rows(prep3, spi_coeff_ora) 
rm(prep3, spi_coeff_ora) 
```

```{r boxplots_1month, include=FALSE, eval=FALSE}
#ggplot(spi_1mon_grp, aes(month, value, group = month)) + 
#  geom_boxplot() + 
#  facet_wrap(~station) + 
#  theme_classic() +  
#  labs(title = "Monthly precipitation depths", 
#       subtitle = "Pine Ridge Reservation, SD for 1910-2017") + 
#       xlab("Date") + 
#       ylab("Depth, mm") 
```

```{r munging-DEPR, include=FALSE, eval=FALSE}

# add a small value to zeros to solve a downstream issue 
# maybe have this fixed now using ts rather than date class
#sta_mon <- sta_mon %>% 
#  gather(key = "station", value = "depth", -date, -year, -month) %>%
#  mutate(depth = replace(depth, depth == 0.0, 0.15)) %>%
#  spread(station, depth) 

# Check on log transformation
#sta_notzero <- sta_grp %>%
#  filter(depth != 0)

#min <- min(sta_notzero$depth)

#sta_zero <- sta_grp %>%
#  filter(depth == 0) %>%
#  mutate(depth = depth + min/2)

#sta_log <- bind_rows(sta_zero, sta_notzero)
#sta_log <- sta_log %>%
#  mutate(log_depth = log10(depth))

#rm(min) 
```

```{r purrr-DEPR, include=FALSE, eval=FALSE} 
# This code chunk applies the SPI function across list of stations
# There seems to be an error with zeros and NA vals in 'SPEI'
# The sta_grp data from import-data code chunk above has NA removed

# Change the data into a simple list 
by_sta <- sta_grp %>% 
  select(station, depth, date) %>% 
    split(.$station) %>%
  transpose() # invert the list
by_sta <- by_sta$depth # drop the unneeded character elements

# Apply SPI to the list
spi_list  <- by_sta %>%  
  purrr::map(~spi(data = ., 1,  
                 distribution = 'PearsonIII', na.rm = TRUE)) %>%
  transpose()
spi_fit <- as.array(spi_list$fitted, make.names = TRUE)

test <- as.tibble(unlist(spi_fit))

cot <- as.tibble(spi_fit$cot)

# Next Steps - work with dates to join the lists???
by_sta_date <- sta_grp %>% 
  select(station, date) %>% 
    split(.$station) %>%
  transpose() # invert the list
multi_join <- function(list_of_loaded_data, join_func, ...){
    require("dplyr")
    output <- Reduce(function(x, y) {join_func(x, y, ...)}, list_of_loaded_data)
    return(output)
}
merged_data <- multi_join(spi_list, full_join)

by_sta_date <- by_sta_date$date # drop the unneeded character elements

test <- as.tibble(import("data/stations_monthly.csv")) %>% 
  select(date, cot)

Date <- test %>% 
  select(date) %>%
  mutate(date = ymd(date)) 

test <- test %>%
  ts(end = c(2018, 05), frequency = 12)

spi_list  <- spi(test[,'cot'], 1, 
                 distribution = 'PearsonIII', na.rm = TRUE) 

test_coeff <- as.tibble(spi_list$coefficients) %>% 
  t() %>% as.tibble() 

spi_test <- as.tibble(spi_list$fitted) %>%
  rename(cot = "Series 1")
spi_test <- bind_cols(Date, spi_test) 

# visual check of output for cottonwood SPI
ggplot(spi_test, aes(date, cot)) + 
  geom_line() +
  theme_classic() + 
  labs(title = "Standardized Precipitation Index (SPI)",
       subtitle = "Cottonwood, SD") +
       xlab("") + 
       ylab("SPI-value") +
  NULL 
```

```{r testing-DEPR, include=FALSE, eval=FALSE}
# Mini-library
library("tidyverse") 
library("lubridate") 
library("rio") 
library("SPEI")

# load data
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) %>% 
  arrange(date)
  
# prepare date for joining later
Date <- sta_mon %>% 
  select(date) %>%
  mutate(date = ymd(date)) %>%
  arrange(date)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Use a single station - cot
sta_cot_ts <- sta_mon %>% 
  select(cot) %>%
  ts(end = c(2018, 05), frequency = 12)

spi_list  <- spi(sta_cot_ts, 1, 
                 distribution = 'PearsonIII', na.rm = TRUE) 

spi1_coeff_cot <- as.tibble(spi_list$coefficients) %>% 
  t() %>% as.tibble() 

spi1_cot_ts <- as.tibble(spi_list$fitted)  
spi1_cot_ts <- bind_cols(Date, spi1_cot_ts) 

# Results
# as.tibble(summary(spi1_cot_ts))
#   Var1  Var2        n                     
#   <chr> <chr>       <fct>                 
# 1 ""    "     date" "Min.   :1909-06-01  "
# 2 ""    "     date" "1st Qu.:1936-08-24  "
# 3 ""    "     date" "Median :1963-11-16  "
# 4 ""    "     date" "Mean   :1963-11-16  "
# 5 ""    "     date" "3rd Qu.:1991-02-08  "
# 6 ""    "     date" "Max.   :2018-05-01  "
# 7 ""    "     cot"  "Min.   :-2.40240  "  
# 8 ""    "     cot"  "1st Qu.:-0.69324  "  
# 9 ""    "     cot"  "Median : 0.02341  "  
#10 ""    "     cot"  "Mean   : 0.01383  "  
#11 ""    "     cot"  "3rd Qu.: 0.68317  "  
#12 ""    "     cot"  "Max.   : 3.30822  "  

#sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
#sta_mon     <- as.tibble(import("data/stations_monthly.csv")) %>% 
 # arrange(date)

# prepare to rejoin date
#Date <- sta_mon %>% 
#  select(date) %>%
#  mutate(date = ymd(date)) %>%
#  arrange(date)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# prepare data for testing Lubridate object
sta_cot_lub <- sta_mon %>% 
  select(cot) 

spi_list  <- spi(sta_cot_lub, 1, 
                 distribution = 'PearsonIII', na.rm = TRUE) 
 
spi1_coeff_cot_lub <- as.tibble(spi_list$coefficients) %>% 
  t() %>% as.tibble() 

spi1_cot_lub <- as.tibble(spi_list$fitted) 
spi1_cot_lub <- bind_cols(Date, spi1_cot_lub) 
rm(sta_cot_lub)

# Results
# as.tibble(summary(spi1_cot_lub))
# A tibble: 12 x 3
#   Var1  Var2        n                     
#   <chr> <chr>       <fct>                 
# 1 ""    "     date" "Min.   :1909-06-01  "
# 2 ""    "     date" "1st Qu.:1936-08-24  "
# 3 ""    "     date" "Median :1963-11-16  "
# 4 ""    "     date" "Mean   :1963-11-16  "
# 5 ""    "     date" "3rd Qu.:1991-02-08  "
# 6 ""    "     date" "Max.   :2018-05-01  "
# 7 ""    "     cot"  "Min.   :-2.40240  "  
# 8 ""    "     cot"  "1st Qu.:-0.69324  "  
# 9 ""    "     cot"  "Median : 0.02341  "  
#10 ""    "     cot"  "Mean   : 0.01383  "  
#11 ""    "     cot"  "3rd Qu.: 0.68317  "  
#12 ""    "     cot"  "Max.   : 3.30822  "   

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Use lubridate-created object for date for a batch process
# results are as above for 'cot' but have -Inf for 'rap' 

#library("tidyverse") 
#library("lubridate")
#library("rio") 
#library("SPEI")

#sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
#sta_mon     <- as.tibble(import("data/stations_monthly.csv")) %>% 
#  arrange(date)

# prepare to rejoin date
# Date <- sta_mon %>% 
#  select(date) %>%
#  mutate(date = ymd(date)) %>%
#  arrange(date)

# prepare data for batch
sta_all <- sta_mon %>% 
  select(-c(date, year, month))  
 
spi_list  <- spi(sta_all, 1,  
                 distribution = 'PearsonIII', na.rm = TRUE) 

spi1_coeff_all <- as.tibble(spi_list$coefficients) %>% 
  t() %>% as.tibble() 

spi1_all <- as.tibble(spi_list$fitted) 
spi1_all <- bind_cols(Date, spi1_all) 

# Selected Results
summary(spi1_all$cot)
#     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
# -2.40240 -0.69324  0.02341  0.01383  0.68317  3.30822 

summary(spi1_all$date)
# Min.      1st Qu.       Median     Mean      3rd Qu.       Max.
# "1909-06-01" "36-08-24" "63-11-16" "63-11-16" "91-02-08" "2018-05-01" 
summary(spi1_all$rap)
#  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
#   -Inf -0.6472  0.0022    -Inf  0.6657  2.9000     467 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Use only 'rap' with NA vals 
# Summary: It looks like the "bug" is in handling the na.rm?
# Work around: Split, apply combine.

# Use lubridate-created object for date for a batch process
# results are as above for 'cot' but have -Inf for 'rap' 

#library("tidyverse") 
#library("lubridate")
#library("rio") 
#library("SPEI")

#sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
#sta_mon     <- as.tibble(import("data/stations_monthly.csv")) %>% 
#  arrange(date)

# prepare to rejoin date
#Date <- sta_mon %>% 
#  select(date) %>%
 # mutate(date = ymd(date)) %>%
 # arrange(date)

# prepare data for 'rap' only
sta_rap <- sta_mon %>% 
  select(rap) 

spi_list  <- spi(sta_rap, 1, 
                 distribution = 'PearsonIII', na.rm = TRUE) 

spi1_coeff_rap <- as.tibble(spi_list$coefficients) %>% 
  t() %>% as.tibble()  

spi1_rap <- as.tibble(spi_list$fitted) 
spi1_rap <- bind_cols(Date, spi1_rap) 

# Results
as.tibble(summary(spi1_rap))
# A tibble: 14 x 3
#   Var1  Var2        n                     
#   <chr> <chr>       <fct>                 
# 1 ""    "     date" "Min.   :1909-06-01  "
# 2 ""    "     date" "1st Qu.:1936-08-24  " 
# 3 ""    "     date" "Median :1963-11-16  "
# 4 ""    "     date" "Mean   :1963-11-16  "
# 5 ""    "     date" "3rd Qu.:1991-02-08  "
# 6 ""    "     date" "Max.   :2018-05-01  "
# 7 ""    "     date" NA                    
# 8 ""    "     rap"  "Min.   :   -Inf  "   
# 9 ""    "     rap"  "1st Qu.:-0.6472  "   
#10 ""    "     rap"  "Median : 0.0022  "   
#11 ""    "     rap"  "Mean   :   -Inf  "   
#12 ""    "     rap"  "3rd Qu.: 0.6657  "   
#13 ""    "     rap"  "Max.   : 2.9000  "   
#14 ""    "     rap"  "NA's   :467  "       
```

```{r spi-cot-DEPR} 
# This code chunk calculates SPI coefficients for 
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Cottonwood, SD. 
# Code is mostly following the SPI vignette. 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# Add Cottonwoods dataset and change to time series 
sta_cot <- sta_mon %>% 
  select(date, cot) %>% 
  arrange(date) 

# Calculate Cottonwood SPI 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1cot  <- spi(sta_cot[,'cot'], 1, distribution = 'PearsonIII') 
spi_2cot  <- spi(sta_cot[,'cot'], 2, distribution = 'PearsonIII') 
spi_3cot  <- spi(sta_cot[,'cot'], 3, distribution = 'PearsonIII') 
spi_4cot  <- spi(sta_cot[,'cot'], 4, distribution = 'PearsonIII') 
spi_5cot  <- spi(sta_cot[,'cot'], 5, distribution = 'PearsonIII') 
spi_6cot  <- spi(sta_cot[,'cot'], 6, distribution = 'PearsonIII') 
spi_9cot  <- spi(sta_cot[,'cot'], 9, distribution = 'PearsonIII') 
spi_12cot <- spi(sta_cot[,'cot'], 12, distribution = 'PearsonIII')  
spi_18cot <- spi(sta_cot[,'cot'], 18, distribution = 'PearsonIII') 
spi_24cot <- spi(sta_cot[,'cot'], 24, distribution = 'PearsonIII') 

# save coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1cot_coeff <- as.tibble(spi_1cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_2cot_coeff <- as.tibble(spi_2cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_3cot_coeff <- as.tibble(spi_3cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_4cot_coeff <- as.tibble(spi_4cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_5cot_coeff <- as.tibble(spi_5cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_6cot_coeff <- as.tibble(spi_6cot$coefficients) %>% 
  t() %>%
  as.tibble() 

spi_9cot_coeff <- as.tibble(spi_9cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_12cot_coeff <- as.tibble(spi_12cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_18cot_coeff <- as.tibble(spi_18cot$coefficients) %>% 
  t() %>% as.tibble() 

spi_24cot_coeff <- as.tibble(spi_24cot$coefficients) %>% 
  t() %>% as.tibble() 

# Rename coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1cot_coeff <- spi_1cot_coeff %>% 
  rename(mu_1 = mu) %>%
   rename(sigma_1 = sigma) %>% 
   rename(gamma_1 = gamma)
  
spi_2cot_coeff <- spi_2cot_coeff %>% 
  rename(mu_2 = mu) %>%
   rename(sigma_2 = sigma) %>% 
   rename(gamma_2 = gamma) 

spi_3cot_coeff <- spi_3cot_coeff %>% 
  rename(mu_3 = mu) %>%
   rename(sigma_3 = sigma) %>% 
   rename(gamma_3 = gamma) 

spi_4cot_coeff <- spi_4cot_coeff %>% 
  rename(mu_4 = mu) %>%
   rename(sigma_4 = sigma) %>% 
   rename(gamma_4 = gamma) 

spi_5cot_coeff <- spi_5cot_coeff %>% 
  rename(mu_5 = mu) %>%
   rename(sigma_5 = sigma) %>% 
   rename(gamma_5 = gamma) 

spi_6cot_coeff <- spi_6cot_coeff %>% 
  rename(mu_6 = mu) %>%
   rename(sigma_6 = sigma) %>% 
   rename(gamma_6 = gamma) 

spi_9cot_coeff <- spi_9cot_coeff %>% 
  rename(mu_9 = mu) %>%
   rename(sigma_9 = sigma) %>% 
   rename(gamma_9 = gamma) 

spi_12cot_coeff <- spi_12cot_coeff %>% 
  rename(mu_12 = mu) %>%
   rename(sigma_12 = sigma)  %>% 
   rename(gamma_12 = gamma) 

spi_18cot_coeff <- spi_18cot_coeff %>% 
  rename(mu_18 = mu) %>%
   rename(sigma_18 = sigma) %>% 
   rename(gamma_18 = gamma) 

spi_24cot_coeff <- spi_24cot_coeff %>% 
  rename(mu_24 = mu) %>%
   rename(sigma_24 = sigma) %>% 
   rename(gamma_24 = gamma) 

# Join the values 
# THIS CODE COULD BE DONE MUCH BETTER! 
prep1 <- bind_cols(spi_1cot_coeff, spi_2cot_coeff) 
rm(spi_1cot_coeff, spi_2cot_coeff) 

prep2 <- bind_cols(prep1, spi_3cot_coeff) 
rm(prep1, spi_3cot_coeff) 

prep3 <- bind_cols(prep2, spi_4cot_coeff) 
rm(prep2, spi_4cot_coeff) 

prep4 <- bind_cols(prep3, spi_5cot_coeff) 
rm(prep3, spi_5cot_coeff) 

prep5 <- bind_cols(prep4, spi_6cot_coeff) 
rm(prep4, spi_6cot_coeff) 

prep6 <- bind_cols(prep5, spi_9cot_coeff) 
rm(prep5, spi_9cot_coeff) 

prep7 <- bind_cols(prep6, spi_12cot_coeff) 
rm(prep6, spi_12cot_coeff) 

prep8 <- bind_cols(prep7, spi_18cot_coeff) 
rm(prep7, spi_18cot_coeff) 

spi_coeff_cot <- bind_cols(prep8, spi_24cot_coeff) 
rm(prep8, spi_24cot_coeff, sta_cot) 

spi_coeff_cot <- rownames_to_column(spi_coeff_cot, "month")

# export(spi_coeff_cot, "data/spi_coeff_cot.csv") 
# rm(spi_coeff_cot)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# save SPI values as a Tibble
spi_1cot <- as.tibble(spi_1cot$fitted) %>% 
  mutate(duration = 1) 

spi_2cot <- as.tibble(spi_2cot$fitted) %>% 
  mutate(duration = 2)

spi_3cot <- as.tibble(spi_3cot$fitted) %>% 
  mutate(duration = 3) 

spi_4cot <- as.tibble(spi_4cot$fitted) %>% 
  mutate(duration = 4) 

spi_5cot <- as.tibble(spi_5cot$fitted) %>% 
  mutate(duration = 5) 

spi_6cot <- as.tibble(spi_6cot$fitted) %>% 
  mutate(duration = 6) 

spi_9cot <- as.tibble(spi_9cot$fitted) %>% 
  mutate(duration = 9)

spi_12cot <- as.tibble(spi_12cot$fitted) %>% 
  mutate(duration = 12) 

spi_18cot <- as.tibble(spi_18cot$fitted) %>% 
  mutate(duration = 18) 

spi_24cot <- as.tibble(spi_24cot$fitted) %>% 
  mutate(duration = 24) 

# add date to the SPI data
date <- sta_mon %>%
  select(date) %>%
  arrange(date)

spi_1cot  <-  bind_cols(date, spi_1cot) 
spi_2cot  <-  bind_cols(date, spi_2cot) 
spi_3cot  <-  bind_cols(date, spi_3cot) 
spi_4cot  <-  bind_cols(date, spi_4cot) 
spi_5cot  <-  bind_cols(date, spi_5cot) 
spi_6cot  <-  bind_cols(date, spi_6cot) 
spi_9cot  <-  bind_cols(date, spi_9cot) 
spi_12cot <-  bind_cols(date, spi_12cot) 
spi_18cot <-  bind_cols(date, spi_18cot) 
spi_24cot <-  bind_cols(date, spi_24cot) 

# join the SPI data by wide and long
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1- & 2-month
intr1 <- bind_rows(spi_1cot, spi_2cot) 

#intc1 <- bind_cols(spi_1cot, spi_2cot) 
#intc1 <- intc1 %>%
#  select(-c(date1, duration, duration1)) %>%
#  rename(cot_1 = "Series 1") %>%
#  rename(cot_2 = "Series 11")
rm(spi_1cot, spi_2cot) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3-month
intr2 <- bind_rows(intr1, spi_3cot) 

#intc2 <- bind_cols(intc1, spi_3cot) 
#intc2 <- intc2 %>%
#  select(-c(date1, duration)) %>%
#  rename(cot_3 = "Series 1") 
rm(intr1, intc1, spi_3cot) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 4-month
intr3 <- bind_rows(intr2, spi_4cot) 

#intc3 <- bind_cols(intc2, spi_4cot) 
#intc3 <- intc3 %>%
#  select(-c(date1, duration)) %>%
#  rename(cot_4 = "Series 1") 
rm(intr2, intc2, spi_4cot) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 5-month
intr4 <- bind_rows(intr3, spi_5cot) 

#intc4 <- bind_cols(intc3, spi_5cot) 
#intc4 <- intc4 %>%
#  select(-c(date1, duration)) %>%
#  rename(cot_5 = "Series 1") 
rm(intr3, intc3, spi_5cot) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 6-month
intr5 <- bind_rows(intr4, spi_6cot) 

#intc5 <- bind_cols(intc4, spi_6cot) 
#intc5 <- intc5 %>%
#  select(-c(date1, duration)) %>%
#  rename(cot_6 = "Series 1") 
rm(intr4, intc4, spi_6cot) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 9-month
intr6 <- bind_rows(intr5, spi_9cot) 

#intc6 <- bind_cols(intc5, spi_9cot) 
#intc6 <- intc6 %>%
#  select(-c(date1, duration)) %>%
#  rename(cot_9 = "Series 1") 
rm(intr5, intc5, spi_9cot) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 12-month
intr7 <- bind_rows(intr6, spi_12cot) 

#intc7 <- bind_cols(intc6, spi_12cot) 
#intc7 <- intc7 %>%
#  select(-c(date1, duration)) %>%
#  rename(cot_12 = "Series 1") 
rm(intr6, intc6, spi_12cot) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 18-month
intr8 <- bind_rows(intr7, spi_18cot) 

#intc8 <- bind_cols(intc7, spi_18cot) 
#intc8 <- intc8 %>%
#  select(-c(date1, duration)) %>%
#  rename(cot_18 = "Series 1") 
rm(intr7, intc7, spi_18cot) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 24-month
spi_cot <- bind_rows(intr8, spi_24cot) 

#spi_cot <- bind_cols(intc8, spi_24cot) 
#spi_cot <- spi_cot %>%
#  select(-c(date1, duration)) %>%
#  rename(cot_24 = "Series 1") 

# clean up
rm(intr8, intc8, spi_24cot)  
```

```{r spi-oel-DEPR}   
# This code chunk calculates SPI coefficients for 
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Oelrichs  
 
# Add Oelrichs dataset and change to time series 
sta_oel <- sta_mon %>% 
  arrange(date) %>% 
  select(year, month, oel) %>% 
  ts(end = c(2018, 05), frequency = 12) 

# Calculate SPI 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1oel  <- spi(sta_oel[,'oel'], 1, distribution = 'PearsonIII') 
spi_2oel  <- spi(sta_oel[,'oel'], 2, distribution = 'PearsonIII') 
spi_3oel  <- spi(sta_oel[,'oel'], 3, distribution = 'PearsonIII') 
spi_4oel  <- spi(sta_oel[,'oel'], 4, distribution = 'PearsonIII') 
spi_5oel  <- spi(sta_oel[,'oel'], 5, distribution = 'PearsonIII') 
spi_6oel  <- spi(sta_oel[,'oel'], 6, distribution = 'PearsonIII') 
spi_9oel  <- spi(sta_oel[,'oel'], 9, distribution = 'PearsonIII') 
spi_12oel <- spi(sta_oel[,'oel'], 12, distribution = 'PearsonIII')  
spi_18oel <- spi(sta_oel[,'oel'], 18, distribution = 'PearsonIII') 
spi_24oel <- spi(sta_oel[,'oel'], 24, distribution = 'PearsonIII') 

# save coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1oel_coeff <- as.tibble(spi_1oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_2oel_coeff <- as.tibble(spi_2oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_3oel_coeff <- as.tibble(spi_3oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_4oel_coeff <- as.tibble(spi_4oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_5oel_coeff <- as.tibble(spi_5oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_6oel_coeff <- as.tibble(spi_6oel$coefficients) %>% 
  t() %>%
  as.tibble() 

spi_9oel_coeff <- as.tibble(spi_9oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_12oel_coeff <- as.tibble(spi_12oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_18oel_coeff <- as.tibble(spi_18oel$coefficients) %>% 
  t() %>% as.tibble() 

spi_24oel_coeff <- as.tibble(spi_24oel$coefficients) %>% 
  t() %>% as.tibble() 

# Rename coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1oel_coeff <- spi_1oel_coeff %>% 
  rename(mu_1 = mu) %>%
   rename(sigma_1 = sigma) %>% 
   rename(gamma_1 = gamma)
  
spi_2oel_coeff <- spi_2oel_coeff %>% 
  rename(mu_2 = mu) %>%
   rename(sigma_2 = sigma) %>% 
   rename(gamma_2 = gamma) 

spi_3oel_coeff <- spi_3oel_coeff %>% 
  rename(mu_3 = mu) %>%
   rename(sigma_3 = sigma) %>% 
   rename(gamma_3 = gamma) 

spi_4oel_coeff <- spi_4oel_coeff %>% 
  rename(mu_4 = mu) %>%
   rename(sigma_4 = sigma) %>% 
   rename(gamma_4 = gamma) 

spi_5oel_coeff <- spi_5oel_coeff %>% 
  rename(mu_5 = mu) %>%
   rename(sigma_5 = sigma) %>% 
   rename(gamma_5 = gamma) 

spi_6oel_coeff <- spi_6oel_coeff %>% 
  rename(mu_6 = mu) %>%
   rename(sigma_6 = sigma) %>% 
   rename(gamma_6 = gamma) 

spi_9oel_coeff <- spi_9oel_coeff %>% 
  rename(mu_9 = mu) %>%
   rename(sigma_9 = sigma) %>% 
   rename(gamma_9 = gamma) 

spi_12oel_coeff <- spi_12oel_coeff %>% 
  rename(mu_12 = mu) %>%
   rename(sigma_12 = sigma)  %>% 
   rename(gamma_12 = gamma) 

spi_18oel_coeff <- spi_18oel_coeff %>% 
  rename(mu_18 = mu) %>%
   rename(sigma_18 = sigma) %>% 
   rename(gamma_18 = gamma) 

spi_24oel_coeff <- spi_24oel_coeff %>% 
  rename(mu_24 = mu) %>%
   rename(sigma_24 = sigma) %>% 
   rename(gamma_24 = gamma)  


# Join the values 
# THIS CODE COULD BE DONE MUCH BETTER! 
prep1 <- bind_cols(spi_1oel_coeff, spi_2oel_coeff) 
rm(spi_1oel_coeff, spi_2oel_coeff) 

prep2 <- bind_cols(prep1, spi_3oel_coeff) 
rm(prep1, spi_3oel_coeff) 

prep3 <- bind_cols(prep2, spi_4oel_coeff) 
rm(prep2, spi_4oel_coeff) 

prep4 <- bind_cols(prep3, spi_5oel_coeff) 
rm(prep3, spi_5oel_coeff) 

prep5 <- bind_cols(prep4, spi_6oel_coeff) 
rm(prep4, spi_6oel_coeff) 

prep6 <- bind_cols(prep5, spi_9oel_coeff) 
rm(prep5, spi_9oel_coeff) 

prep7 <- bind_cols(prep6, spi_12oel_coeff) 
rm(prep6, spi_12oel_coeff) 
 
prep8 <- bind_cols(prep7, spi_18oel_coeff) 
rm(prep7, spi_18oel_coeff) 

spi_coeff_oel <- bind_cols(prep8, spi_24oel_coeff) 
rm(prep8, spi_24oel_coeff) 

# export(spi_coeff_oel, "data/spi_coeff_oel.csv") 
# rm(spi_coeff_oel, sta_oel)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# This code chunk calculates SPI fitted values for 
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Oelrichs.  
# It is a continuation of 'spi-algorithm-coeff-oel'

# extract SPI values & add duration
spi_1oel <- as.tibble(spi_1oel$fitted) %>% 
  mutate(duration = 1)

spi_2oel <- as.tibble(spi_2oel$fitted) %>% 
  mutate(duration = 2)

spi_3oel <- as.tibble(spi_3oel$fitted) %>% 
  mutate(duration = 3) 

spi_4oel <- as.tibble(spi_4oel$fitted) %>% 
  mutate(duration = 4) 

spi_5oel <- as.tibble(spi_5oel$fitted) %>% 
  mutate(duration = 5) 

spi_6oel <- as.tibble(spi_6oel$fitted) %>% 
  mutate(duration = 6) 

spi_9oel <- as.tibble(spi_9oel$fitted) %>% 
  mutate(duration = 9)

spi_12oel <- as.tibble(spi_12oel$fitted) %>% 
  mutate(duration = 12) 

spi_18oel <- as.tibble(spi_18oel$fitted) %>% 
  mutate(duration = 18) 

spi_24oel <- as.tibble(spi_24oel$fitted) %>% 
  mutate(duration = 24) 

# add date to the SPI data
date <- sta_mon %>%
  select(date) %>%
  arrange(date)

spi_1oel  <-  bind_cols(date, spi_1oel) 
spi_2oel  <-  bind_cols(date, spi_2oel) 
spi_3oel  <-  bind_cols(date, spi_3oel) 
spi_4oel  <-  bind_cols(date, spi_4oel) 
spi_5oel  <-  bind_cols(date, spi_5oel) 
spi_6oel  <-  bind_cols(date, spi_6oel) 
spi_9oel  <-  bind_cols(date, spi_9oel) 
spi_12oel <-  bind_cols(date, spi_12oel) 
spi_18oel <-  bind_cols(date, spi_18oel) 
spi_24oel <-  bind_cols(date, spi_24oel) 

# join the SPI data by wide and long
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1- & 2-month
intr1 <- bind_rows(spi_1oel, spi_2oel) 

intc1 <- bind_cols(spi_1oel, spi_2oel) 
intc1 <- intc1 %>%
  select(-c(date1, duration, duration1)) %>%
  rename(oel_1 = "Series 1") %>%
  rename(oel_2 = "Series 11")
rm(spi_1oel, spi_2oel) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3-month
intr2 <- bind_rows(intr1, spi_3oel) 

intc2 <- bind_cols(intc1, spi_3oel) 
intc2 <- intc2 %>%
  select(-c(date1, duration)) %>%
  rename(oel_3 = "Series 1") 
rm(intr1, intc1, spi_3oel) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 4-month
intr3 <- bind_rows(intr2, spi_4oel) 

intc3 <- bind_cols(intc2, spi_4oel) 
intc3 <- intc3 %>%
  select(-c(date1, duration)) %>%
  rename(oel_4 = "Series 1") 
rm(intr2, intc2, spi_4oel) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 5-month
intr4 <- bind_rows(intr3, spi_5oel) 

intc4 <- bind_cols(intc3, spi_5oel) 
intc4 <- intc4 %>%
  select(-c(date1, duration)) %>%
  rename(oel_5 = "Series 1") 
rm(intr3, intc3, spi_5oel) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 6-month
intr5 <- bind_rows(intr4, spi_6oel) 

intc5 <- bind_cols(intc4, spi_6oel) 
intc5 <- intc5 %>%
  select(-c(date1, duration)) %>%
  rename(oel_6 = "Series 1") 
rm(intr4, intc4, spi_6oel) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 9-month
intr6 <- bind_rows(intr5, spi_9oel) 

intc6 <- bind_cols(intc5, spi_9oel) 
intc6 <- intc6 %>%
  select(-c(date1, duration)) %>%
  rename(oel_9 = "Series 1") 
rm(intr5, intc5, spi_9oel) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 12-month
intr7 <- bind_rows(intr6, spi_12oel) 

intc7 <- bind_cols(intc6, spi_12oel) 
intc7 <- intc7 %>%
  select(-c(date1, duration)) %>%
  rename(oel_12 = "Series 1") 
rm(intr6, intc6, spi_12oel) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 18-month
intr8 <- bind_rows(intr7, spi_18oel) 

intc8 <- bind_cols(intc7, spi_18oel) 
intc8 <- intc8 %>%
  select(-c(date1, duration)) %>%
  rename(oel_18 = "Series 1") 
rm(intr7, intc7, spi_18oel) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 24-month
spi_oel_gath <- bind_rows(intr8, spi_24oel) 
spi_oel_gath <- spi_oel_gath %>%
  rename(spi_oel = "Series 1")

spi_oel <- bind_cols(intc8, spi_24oel) 
spi_oel <- spi_oel %>%
  select(-c(date1, duration)) %>%
  rename(oel_24 = "Series 1") 

rm(intr8, intc8, spi_24oel, sta_oel) 
# Next steps:
# distribution = 'PersonIII',
```

```{r spi-rap-DEPR} 
# This code chunk calculates SPI coefficients for 
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Rapid City, SD.

# Add Rapid City dataset and change to time series 
sta_rap <- sta_mon %>% 
  arrange(date) %>% 
  select(year, month, rap) %>% 
  ts(end = c(2018, 05), frequency = 12)

# Calculate SPI 
# THIS CODE COULD BE DONE MUCH BETTER! 
# Added na.rm = TRUE to handle the missing vals
spi_1rap  <- spi(sta_rap[,'rap'], 1, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_2rap  <- spi(sta_rap[,'rap'], 2, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_3rap  <- spi(sta_rap[,'rap'], 3, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_4rap  <- spi(sta_rap[,'rap'], 4, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_5rap  <- spi(sta_rap[,'rap'], 5, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_6rap  <- spi(sta_rap[,'rap'], 6, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_9rap  <- spi(sta_rap[,'rap'], 9, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_12rap <- spi(sta_rap[,'rap'], 12, na.rm = TRUE, 
                 distribution = 'PearsonIII')  
spi_18rap <- spi(sta_rap[,'rap'], 18, na.rm = TRUE, 
                 distribution = 'PearsonIII') 
spi_24rap <- spi(sta_rap[,'rap'], 24, na.rm = TRUE, 
                 distribution = 'PearsonIII') 

# save coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1rap_coeff <- as.tibble(spi_1rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_2rap_coeff <- as.tibble(spi_2rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_3rap_coeff <- as.tibble(spi_3rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_4rap_coeff <- as.tibble(spi_4rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_5rap_coeff <- as.tibble(spi_5rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_6rap_coeff <- as.tibble(spi_6rap$coefficients) %>% 
  t() %>%
  as.tibble() 

spi_9rap_coeff <- as.tibble(spi_9rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_12rap_coeff <- as.tibble(spi_12rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_18rap_coeff <- as.tibble(spi_18rap$coefficients) %>% 
  t() %>% as.tibble() 

spi_24rap_coeff <- as.tibble(spi_24rap$coefficients) %>% 
  t() %>% as.tibble() 

# Rename coefficients 
# THIS CODE COULD BE DONE MUCH BETTER! 
spi_1rap_coeff <- spi_1rap_coeff %>% 
  rename(mu_1 = mu) %>%
   rename(sigma_1 = sigma) %>% 
   rename(gamma_1 = gamma)
  
spi_2rap_coeff <- spi_2rap_coeff %>% 
  rename(mu_2 = mu) %>%
   rename(sigma_2 = sigma) %>% 
   rename(gamma_2 = gamma) 

spi_3rap_coeff <- spi_3rap_coeff %>% 
  rename(mu_3 = mu) %>%
   rename(sigma_3 = sigma) %>% 
   rename(gamma_3 = gamma) 

spi_4rap_coeff <- spi_4rap_coeff %>% 
  rename(mu_4 = mu) %>%
   rename(sigma_4 = sigma) %>% 
   rename(gamma_4 = gamma) 

spi_5rap_coeff <- spi_5rap_coeff %>% 
  rename(mu_5 = mu) %>%
   rename(sigma_5 = sigma) %>% 
   rename(gamma_5 = gamma) 

spi_6rap_coeff <- spi_6rap_coeff %>% 
  rename(mu_6 = mu) %>%
   rename(sigma_6 = sigma) %>% 
   rename(gamma_6 = gamma) 

spi_9rap_coeff <- spi_9rap_coeff %>% 
  rename(mu_9 = mu) %>%
   rename(sigma_9 = sigma) %>% 
   rename(gamma_9 = gamma) 

spi_12rap_coeff <- spi_12rap_coeff %>% 
  rename(mu_12 = mu) %>%
   rename(sigma_12 = sigma)  %>% 
   rename(gamma_12 = gamma) 

spi_18rap_coeff <- spi_18rap_coeff %>% 
  rename(mu_18 = mu) %>%
   rename(sigma_18 = sigma) %>% 
   rename(gamma_18 = gamma) 

spi_24rap_coeff <- spi_24rap_coeff %>% 
  rename(mu_24 = mu) %>%
   rename(sigma_24 = sigma) %>% 
   rename(gamma_24 = gamma) 


# Join the values 
# THIS CODE COULD BE DONE MUCH BETTER! 
prep1 <- bind_cols(spi_1rap_coeff, spi_2rap_coeff) 
rm(spi_1rap_coeff, spi_2rap_coeff) 

prep2 <- bind_cols(prep1, spi_3rap_coeff) 
rm(prep1, spi_3rap_coeff) 

prep3 <- bind_cols(prep2, spi_4rap_coeff) 
rm(prep2, spi_4rap_coeff) 

prep4 <- bind_cols(prep3, spi_5rap_coeff) 
rm(prep3, spi_5rap_coeff) 

prep5 <- bind_cols(prep4, spi_6rap_coeff) 
rm(prep4, spi_6rap_coeff) 

prep6 <- bind_cols(prep5, spi_9rap_coeff) 
rm(prep5, spi_9rap_coeff) 

prep7 <- bind_cols(prep6, spi_12rap_coeff) 
rm(prep6, spi_12rap_coeff) 

prep8 <- bind_cols(prep7, spi_18rap_coeff) 
rm(prep7, spi_18rap_coeff) 

spi_coeff_rap <- bind_cols(prep8, spi_24rap_coeff) 
rm(prep8, spi_24rap_coeff, sta_rap) 

# export(spi_coeff_rap, "data/spi_coeff_rap.csv") 
# rm(spi_coeff_rap)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# This code chunk calculates SPI fitted values for 
# 1, 2, 3, 4, 5, 6, 9, 12, 24 months for Rapid City, SD. 
# It is a continuation of 'spi-algorithm-coeff-rap'

# extract SPI values & add duration
spi_1rap <- as.tibble(spi_1rap$fitted) %>% 
  mutate(duration = 1)

spi_2rap <- as.tibble(spi_2rap$fitted) %>% 
  mutate(duration = 2)

spi_3rap <- as.tibble(spi_3rap$fitted) %>% 
  mutate(duration = 3) 

spi_4rap <- as.tibble(spi_4rap$fitted) %>% 
  mutate(duration = 4) 

spi_5rap <- as.tibble(spi_5rap$fitted) %>% 
  mutate(duration = 5) 

spi_6rap <- as.tibble(spi_6rap$fitted) %>% 
  mutate(duration = 6) 

spi_9rap <- as.tibble(spi_9rap$fitted) %>% 
  mutate(duration = 9)

spi_12rap <- as.tibble(spi_12rap$fitted) %>% 
  mutate(duration = 12) 

spi_18rap <- as.tibble(spi_18rap$fitted) %>% 
  mutate(duration = 18) 

spi_24rap <- as.tibble(spi_24rap$fitted) %>% 
  mutate(duration = 24) 

# add date to the SPI data
date <- sta_mon %>%
  select(date) %>%
  arrange(date)

spi_1rap  <-  bind_cols(date, spi_1rap) 
spi_2rap  <-  bind_cols(date, spi_2rap) 
spi_3rap  <-  bind_cols(date, spi_3rap) 
spi_4rap  <-  bind_cols(date, spi_4rap) 
spi_5rap  <-  bind_cols(date, spi_5rap) 
spi_6rap  <-  bind_cols(date, spi_6rap) 
spi_9rap  <-  bind_cols(date, spi_9rap) 
spi_12rap <-  bind_cols(date, spi_12rap) 
spi_18rap <-  bind_cols(date, spi_18rap) 
spi_24rap <-  bind_cols(date, spi_24rap) 

# join the SPI data by wide and long
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1- & 2-month
intr1 <- bind_rows(spi_1rap, spi_2rap) 

intc1 <- bind_cols(spi_1rap, spi_2rap) 
intc1 <- intc1 %>%
  select(-c(date1, duration, duration1)) %>%
  rename(int_1 = "Series 1") %>%
  rename(int_2 = "Series 11")
rm(spi_1rap, spi_2rap) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3-month
intr2 <- bind_rows(intr1, spi_3rap) 

intc2 <- bind_cols(intc1, spi_3rap) 
intc2 <- intc2 %>%
  select(-c(date1, duration)) %>%
  rename(rap_3 = "Series 1") 
rm(intr1, intc1, spi_3rap) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 4-month
intr3 <- bind_rows(intr2, spi_4rap) 

intc3 <- bind_cols(intc2, spi_4rap) 
intc3 <- intc3 %>%
  select(-c(date1, duration)) %>%
  rename(rap_4 = "Series 1") 
rm(intr2, intc2, spi_4rap) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 5-month
intr4 <- bind_rows(intr3, spi_5rap) 

intc4 <- bind_cols(intc3, spi_5rap) 
intc4 <- intc4 %>%
  select(-c(date1, duration)) %>%
  rename(rap_5 = "Series 1") 
rm(intr3, intc3, spi_5rap) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 6-month
intr5 <- bind_rows(intr4, spi_6rap) 

intc5 <- bind_cols(intc4, spi_6rap) 
intc5 <- intc5 %>%
  select(-c(date1, duration)) %>%
  rename(rap_6 = "Series 1") 
rm(intr4, intc4, spi_6rap) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 9-month
intr6 <- bind_rows(intr5, spi_9rap) 

intc6 <- bind_cols(intc5, spi_9rap) 
intc6 <- intc6 %>%
  select(-c(date1, duration)) %>%
  rename(rap_9 = "Series 1") 
rm(intr5, intc5, spi_9rap) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 12-month
intr7 <- bind_rows(intr6, spi_12rap) 

intc7 <- bind_cols(intc6, spi_12rap) 
intc7 <- intc7 %>%
  select(-c(date1, duration)) %>%
  rename(rap_12 = "Series 1") 
rm(intr6, intc6, spi_12rap) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 18-month
intr8 <- bind_rows(intr7, spi_18rap) 

intc8 <- bind_cols(intc7, spi_18rap) 
intc8 <- intc8 %>%
  select(-c(date1, duration)) %>%
  rename(rap_18 = "Series 1") 
rm(intr7, intc7, spi_18rap) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 24-month
spi_rap_gath <- bind_rows(intr8, spi_24rap) 
spi_rap_gath <- spi_rap_gath %>%
  rename(spi_rap = "Series 1")

spi_rap <- bind_cols(intc8, spi_24rap) 
spi_rap <- spi_rap %>%
  select(-c(date1, duration)) %>%
  rename(rap_24 = "Series 1") 

rm(intr8, intc8, spi_24rap) 
# Next steps:
# distribution = 'PersonIII'
```

```{r exploratory-PCA-gages}
# Overview
# ~~~~~~~~
# PCA is a method to summarize data using fewer variables by 
# constructing new linear descriptors from variables. The new 
# linear discriptors describe maximum variation across observations. 
# The new discriptors can be used to predict, or "reconstruct",
# observations as well as possible.

# PCA finds the axis the describes the maximum covariance and 
# projecting all of the observations points onto this line. The line 
# called the "first principal component" simultanesous describes 
# maximal variation of values along the line & minimizes the 
# reconstruction error 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# The original data is saved in a long format with rows as daily 
# observations and columns as variables

# glimpse(gage_raw)
# Variables: 26
# count_yr              <int> 67, 67, 67... count of years of record
# sta                   <chr> "bat_bhr"...  station name
# site_no               <int> 6406500...    USGS site number 
# station_nm            <chr> "BATTLE CR BELOW HERMOSA,SD"... 
# dec_lat_va            <dbl> 43.72543...   latitude 
# dec_long_va           <dbl> -102.9061...  longitude 
# state_cd              <int> 46, 46...     fips? code for State  
# county_cd             <int> 103, 103...   fips? code for County  
# alt_va                <dbl> 2800.32...    altitude in feet 
# drain_area_va         <dbl> 284, 284...   drainage area in sq mi. 
# contrib_drain_area_va <dbl> 284, 284...   contrib. da in sq mi.
# min_yr                <int> 1951...       first year of record 
# max_yr                <int> 2017...       last year of record 
# Date                  <chr> "1991-10-01"  date 
# i                     <int> 2191, 2192... count from 1st day of rec. 
# Q                     <dbl> 0.12518933... discharge in cms
# Julian                <int> 51772...      Julian calendar date  
# Month                 <int> 10, 10...     month 
# Day                   <int> 275, 276...   day  
# DecYear               <dbl> 1991.749...   decimal year  
# MonthSeq              <int> 1702...       NA 
# waterYear             <int> 1992...       water year 
# Qualifier             <chr> "A", "A"...   data quality code  
# LogQ                  <dbl> -2.077928...  log of zero-adj discharge 
# Q7                    <dbl> 0.14420207... 7-day moving average  
# Q30                   <dbl> 0.1342507...  30-day moving average 

# Prepare data for exploratory PCA -----------------------------------
# 1. Import data & drop Cheyenne River at Angustora with ~50% NA vals 
gage_raw <- import("data/gage_92_97.csv") %>%  
  filter(sta != "chr_ang")
gage_meta <- import("data/gage_meta_92_97.csv") 

# 2. Eliminate the effects of different sizes of watersheds:  
#    I calculated daily flow depths by dividing flow (cms) by watershed 
#    area (sq-km) and multiplying the resultant by the number of 
#    seconds in a day.  The result is cu-m-d per sq-km.

# 3. Estimate or remove missing values in the data 
#    The NA vals created by calculating Q7 & Q30 need to be removed or 
#    estimated.  Removal seems the more conservative approach - 
#    especially as the NA values are very small given the number of 
#    observations of 365 obs/yr * 7 years. 

gage_scaled <- gage_raw %>% 
  as.tibble() %>% 
  clean_names() %>% 
  mutate(contrib_drain_area_km = contrib_drain_area_va * 2.59) %>% 
  mutate(q1_depth = q * (60*60*24) / contrib_drain_area_km) %>% 
  mutate(q7_depth = q7 * (60*60*24) / contrib_drain_area_km) %>% 
  mutate(q30_depth = q30 * (60*60*24) / contrib_drain_area_km)  %>%
  drop_na() 

# 4. Transform using BoxCox to approach normality 
# daily flow data are highly skewed & tend to approach a logrithmic 
# distribution.  BoxCox transformation utilizes a lamda value to 
# transform a dataset to approach a normal distribution.
# Lambda = 1 is normal distribution (no change), 
# lambda = 0.5 is a square-root transformation, 
# lamda = 2 is a square transformation,
# lambda = 0 is a logrithmic transformation.

# find lambda values for BoxCox transformation  
lambda_q1 <- BoxCox.lambda(gage_scale$q1_depth)
lambda_q7 <- BoxCox.lambda(gage_scale$q7_depth)
lambda_q30 <- BoxCox.lambda(gage_scale$q30_depth)

# 5.Standardize the data:
# PCA requires that data are scaled with a mean of zero and standard 
# deviation of unity, e.g. a z-score.  This could be done within the 
# PCA, but I did it manually.

# Apply transformation and scale data
gage_scaled <- gage_scaled %>%
  mutate(q1_tr = BoxCox(gage_scale$q1_depth,lambda_q1)) %>%
  mutate(q7_tr = BoxCox(gage_scale$q7_depth,lambda_q7)) %>% 
  mutate(q30_tr = BoxCox(gage_scale$q30_depth,lambda_q30)) %>%
  mutate(q1_mean = mean(q1_tr, na.rm = TRUE)) %>% 
  mutate(q1_sd = sd(q1_tr, na.rm = TRUE)) %>% 
  mutate(q1_scaled = (q1_tr - q1_mean)/q1_sd) %>% 
  mutate(q7_mean = mean(q7_tr, na.rm = TRUE)) %>% 
  mutate(q7_sd = sd(q7_tr, na.rm = TRUE)) %>% 
  mutate(q7_scaled = (q7_tr - q7_mean)/q7_sd) %>% 
  mutate(q30_mean = mean(q30_tr, na.rm = TRUE)) %>% 
  mutate(q30_sd = sd(q30_tr, na.rm = TRUE)) %>% 
  mutate(q30_scaled = (q30_tr - q30_mean)/q30_sd) %>% 
  select(sta, date, q1_depth, q7_depth, q30_depth, 
         q1_scaled,  q7_scaled, q30_scaled) 

# glimpse(gage_scale) 
# sta        <chr> "bat_bhr", "bat_bhr", "bat_bhr", "bat_bhr", ... 
# date       <chr> "1991-10-01", "1991-10-02", "1991-10-03", "1... 
# q1_depth   <dbl> 14.704930, 14.704930, 16.700614, 18.696298, ... 
# q7_depth   <dbl> 16.93820, 16.46303, 16.32048, 16.46303, 16.4... 
# q30_depth  <dbl> 15.76929, 15.81364, 15.93560, 16.12408, 16.2... 
# q1_scaled  <dbl> -0.4163661, -0.4163661, -0.3542800, -0.29912... 
# q7_scaled  <dbl> -0.5215705, -0.5363362, -0.5408399, -0.53633... 
# q30_scaled <dbl> -0.7615155, -0.7600352, -0.7559816, -0.74976... 

# Exploratory PCA--------------------------------------------------- 
# PCA is related to eigenvectors and eigenvalues.  The variance or 
# spread of the observations is measured as the average squared 
# distance from the center of the point cloud to each observation (c).  
# The total reconstruction error is measured as the average squared 
# length of the errors (b), and distance along the principal axis (a) 
# can also be measured.  Therefore the sum of the square of the errors 
# plus the sum of the square distance along the principal axis equals 
# the average squared distance between the center of the point cloud 
# each observation; this is precisely Pythagoras theorem. 

# You can imagine that the PC axis is a solid rod and each error 
# is a spring. The energy of the spring is proportional to its squared 
# length (this is known in physics as the Hooke's law), so the rod 
# will orient itself such as to minimize the sum of these squared 
# distances. 

# Regarding eigenvectors and eigenvalues. A 2×2 matrix given by: 
#   (1.07     0.63)
#   (0.63     0.64)

# The variance of the x variable is 1.07, 
# the variance of the y variable is 0.64, 
# and the covariance between them is 0.63. 

# As it is a square symmetric matrix, it can be diagonalized by 
# choosing a new orthogonal coordinate system, given by its 
# eigenvectors (incidentally, this is called spectral theorem); 
# corresponding eigenvalues will then be located on the diagonal. 
# In this new coordinate system, the covariance matrix is diagonal 
# and looks like this:
#   (1.52     0) 
#   (0     0.19)

# The correlation between points is now zero. It becomes clear that 
# the variance of any projection will be given by a weighted average 
# of the eigenvalues.  Consequently, the maximum possible variance 
# (1.52) will be achieved if we simply take the projection on the 
# first coordinate axis. It follows that the direction of the first 
# principal component is given by the first eigenvector of the 
# covariance matrix. 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Select numeric data for PCA input &  names to connect to result 
# prcomp() requires a dataset with only the variables for the 
# unsupervised classification 
pca_input <- gage_scaled %>% 
  select(q1_scaled, q7_scaled, q30_scaled) 

pca_meta <- gage_scaled %>% 
  select(sta, date, q1_depth, q7_depth, q30_depth) 

# Calculate PCA matrix & summary info
pca_matrix <- prcomp(pca_input, scale = TRUE)

# this plots the PCA biplot - takes a LONG time
# biplot(gage_pc, scale = 0)

# Gather PCA results----
# The broom package is used to gather results into tibbles.

# Eigenvectors
pca_eigen <-  tidy(pca_matrix, matrix = "pcs") 

#gage_pc_eigen
#    PC std.dev percent cumulative
#  <dbl>   <dbl>   <dbl>      <dbl>
#1     1   1.68  0.941        0.941
#2     2   0.385 0.0494       0.990
#3     3   0.170 0.00958      1  
# This means that 94% of covarience is explained by PCA1 & 
# 5% of varience by PCA2

# PCA variables 
# these are the loadings on the PCA axes.  Dropped the 3rd PCA 
# because it's not useful
pca_vars <-  tidy(pca_matrix, matrix = "variables") 
pca_vars <- pca_vars %>% 
  filter(PC != 3) %>% 
  rename(var = column) %>% 
  mutate(var = as.factor(var))

#gage_pc_vars
#var           PC  value
#  <fct>      <dbl>  <dbl>
#1 q1_scaled      1  0.576
#2 q7_scaled      1  0.589
#3 q30_scaled     1  0.567
#4 q1_scaled      2  0.598
#5 q7_scaled      2  0.169
#6 q30_scaled     2 -0.784 
# This explains approximately equal loadings of Q1, Q7, Q30 on PCA1 & 
# large positive loading of Q1 & large negative loading of Q30. 

# Bind sample vals to PCA matrix 
pca_au <- augment(pca_matrix, data = pca_input) 
pca_au <- bind_cols(pca_meta, pca_au)
rm(pca_meta)

# Calculate median eigenvectors 
# this summarizes the individual points by station
pca_summary <- pca_au %>% 
  group_by(sta) %>% 
  summarize(PC1_mean = mean(.fittedPC1),
            PC2_mean = mean(.fittedPC2), 
           q1_mean = mean(log10(q1_depth)), 
            q7_mean = mean(log10(q7_depth)),
            q30_mean = mean(log10(q30_depth)), 
            q1_sd = sd(log10(q1_depth)), 
            q7_sd = sd(log10(q7_depth)),
            q30_sd = sd(log10(q30_depth))) %>% 
  mutate(q1_minus_q30 = q1_mean - q30_mean) %>% 
  ungroup()

# quick plot of means
ggplot(pca_summary, aes(PC1_mean, PC2_mean)) +
  geom_point() +
  geom_text(aes(label = sta), vjust = 1, hjust = 1) 

# PCA1 Interpretation--------------------------
pca_au_small <- pca_au %>% 
  filter(sta == "hor_oel" | 
           sta == "whi_ogl" |
           sta == "whi_kad" |
           sta == "blp_bel" |
           sta == "wkc_wok" |
           sta == "lwr_mar" |
           sta == "lcr_vet" |
           sta == "lwr_abv" |
           sta == "fal_hot" |
         sta == "lcr_bel") %>% 
  select(sta, q1_depth, q7_depth, q30_depth) 

# set levels for plotting
pca_au_small$sta <- as.factor(pca_au_small$sta)
pca_au_small$sta <- factor(pca_au_small$sta, 
                          levels = c("hor_oel", "whi_ogl", 
                                     "whi_kad", "blp_bel",
                                     "wkc_wok", "lwr_mar", 
                                     "lcr_vet", "lwr_abv", 
                                     "fal_hot", "lcr_bel")
                          )

# plot gradient along axis
ggplot(pca_au_small, aes(sta, q7_depth)) +
  geom_boxplot() +
  scale_y_log10() + 
  theme_classic() +
  xlab("") +
  ylab("log Q7 depth")

# Examine the second axis loadings 
pca_input_small <- gage_scaled %>% 
      filter(sta == "hor_oel" | 
           sta == "wcc_ogl" |
           sta == "blp_bel" |
         sta == "lcr_bel") %>%
  select(q1_scaled, q7_scaled, q30_scaled) 

pca_meta_small <- gage_scaled %>% 
      filter(sta == "hor_oel" | 
           sta == "wcc_ogl" |
           sta == "blp_bel" |

         sta == "lcr_bel") %>%
  select(sta, date, q1_depth, q7_depth, q30_depth) 

pca_matrix_small <- prcomp(pca_input_small, scale = TRUE)

pca_au_small <- augment(pca_matrix_small, data = pca_meta_small) 
pca_au_small <- bind_cols(pca_meta_small, pca_au_small)
rm(pca_meta_small)

pca_summary_small <- pca_summary %>% 
      filter(sta == "hor_oel" | 
           sta == "wcc_ogl" |
           sta == "blp_bel" |
         sta == "lcr_bel")

ggplot() +
  geom_jitter(data = pca_au_small, 
             mapping = aes(x = .fittedPC1, y = .fittedPC2, 
                           color = factor(sta))) +
  geom_point(data = pca_summary, 
             mapping = aes(PC1_mean, PC2_mean)) + 
    geom_text(data = pca_summary_small,
              mapping = aes(PC1_mean, PC2_mean, label = sta), 
              vjust = 0, hjust = 0) + 
  theme_classic()
  



#fviz_pca_ind(prcomp(gage_matrix_small), 
#             title = "PCA - Iris data", 
#             habillage = gage_matrix_small_name$sta, 
#             palette = "jco", geom = "point", 
#             ggtheme = theme_classic(), 
#             legend = "bottom") 


gage_matrix_name <- gage_scale %>% 
  select(sta, date, q1_depth, q7_depth, q30_depth) 

# Calculate PCA matrix & summary info
gage_pc <- prcomp(gage_matrix, scale = TRUE)



gage_check2 <- gage_au %>% 
  filter(
         sta == "brsf_co" |  
         sta == "blp_bel" |  
         sta == "lcr_bel" | 
         sta == "whi_kad" |  
         sta == "lwr_abv" | 
         sta == "lcr_vet" |  
         sta == "wkc_wok" | 
         sta == "lwr_mar" | 
         sta == "whi_kad" |  
         sta == "wcc_ogl" 
           ) %>% 
  select(sta, q1_depth, q30_depth) %>% 
  gather(key = "duration", value = "depth", -sta)

# set levels for plotting
gage_check2$sta <- as.factor(gage_check2$sta) 
gage_check2$sta <- factor(gage_check2$sta, 
                          levels = c("brsf_co", "blp_bel", 
                                     "lcr_bel", "whi_kad", 
                                     "lwr_abv", "lcr_vet", 
                                     "wkc_wok", "lwr_mar", 
                                     "whi_sta", "wcc_ogl")
                          ) 

ggplot(gage_check2, aes(sta, depth)) +
  geom_boxplot() +
  scale_y_log10() + 
   facet_grid(duration ~ .)

#gage_eigen <- full_join(meta, gage_eigen, by = "sta")




```

```{r visualize}


#We'll use two data sets:
#the built-in R data set iris. and a random data set generated from the iris data set.
#The iris data sets look like this:

head(iris, 3)

#  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
#1          5.1         3.5          1.4         0.2  setosa
#2          4.9         3.0          1.4         0.2  setosa
#3          4.7         3.2          1.3         0.2  setosa

#We start by excluding the column "Species" at position 5

# Iris data set 
df <- iris[, -5] 
df <- as.data.frame(df)

# Random data generated from the iris data set 
random_df <- apply(df, 2,
function(x){
  runif(length(x), min(x), (max(x)))
  }) 

random_df <- as.data.frame(random_df) 

# Standardize the data sets 
df <- iris.scaled <- scale(df) 
random_df <- scale(random_df)

iris <- iris 
#________________
#16.3 Visual inspection of the data

#We start by visualizing the data to assess whether they contains any #meaningful clusters.

#As the data contain more than two variables, we need to reduce the #dimensionality in order to plot a scatter plot. This can be done using #principal component analysis (PCA) algorithm (R function: prcomp()). #After performing PCA, we use the function fviz_pca_ind() [factoextra R #package] to visualize the output.

#The iris and the random data sets can be illustrated as follow: 

library("factoextra") 
# Plot faithful data set 
fviz_pca_ind(prcomp(df), title = "PCA - Iris data",
habillage = iris$Species, palette = "jco", geom = "point", ggtheme = theme_classic(), legend = "bottom")

gage_pca <- gage_scale %>% 
  select(-date)

fviz_pca_ind(prcomp(gage_pca), title = "PCA - Gage data", palette = "jco", geom = "point", ggtheme = theme_classic(), legend = "bottom")

# this can be long!
```



1. To remove any missing value that might be present in the data, type this:
df <- na.omit(df)
2. As we don't want the clustering algorithm to depend to an arbitrary variable unit, we start by scaling/standardizing the data using the R function scale():
df <- scale(df) head(df, n = 3)
## Murder Assault UrbanPop Rape ## Alabama 1.2426 0.783 -0.521 -0.00342 ## Alaska 0.5079 1.107 -1.212 2.48420 ## Arizona 0.0716 1.479 0.999 1.04288

Several R packages available from CRAN or Bioconducto perform cluster validation, including: 

|    Package   |    Function(s)   |      Author       |      Notes    |
|:------------:|:----------------:|:-----------------:|:-------------:|
|   cclust     | clustIndex()     |    Dimitriadou    | No user guide |
|     fpc      | cluster.stats()  |       Hennig      | No user guide |
|              | clusterboot()    |                   |               |
| clusterRepro |                  | Kapp & Tibshirani | not general   |
|  clusterSim  |                  | Walesiak & Dudek  | poor user guide |
|  clusterStab |                  | MacDonald et al.  | narrow vignette |
|     clue     | cl_validity() +  | Hornik, September |     maybe...    |
|     e1071    | fclustIndex() ++ | Dimitriadou et al.| 2006  | unk.

+ validation for both paritioning methods (“dissimilarity accounted for”) and hierarchical methods (“variance accounted for”) 
++ fuzzy cluster validation measures.

pam() in recommended pack- age cluster (Rousseeuw, Struyf, Hubert, and Maechler, 2005; Struyf, Hubert, and Rousseeuw, 1996), and Mclust() in package mclust (Fraley, Raftery, and Wehrens, 2005; Fraley and Raftery, 2003), are available as components named cluster, clustering, and classification, 

RWeka (Hornik, Hothorn, and Karatzoglou, 2006), cba (Buchta and Hahsler, 2005), cclust (Dimitriadou, 2005), cluster, e1071 (Dimitriadou, Hornik, Leisch, Meyer, and Weingessel, 2005), flexclust (Leisch, 2006), flexmix (Leisch, 2004), kernlab (Karatzoglou, Smola, Hornik, and Zeileis, 2004), and mclust (and of course, clue itself).









# this is the simplist case approach
#gage_scale_l <- gage_prep %>% 
#  select(sta, q_depth, date) %>% 
#  mutate(q_mean = mean(q_depth)) %>% 
#  mutate(q_sd = sd(q_depth)) %>% 
#  mutate(q_scaled = (q_depth - q_mean)/q_sd) %>% 
#  select(sta, q_scaled, date)

# calculate summary values
gage_sum <- gage_scale_l %>% 
  group_by(sta) %>% 
  summarise(mean = mean(q_scaled),
            sd = sd(q_scaled)) %>%
    ungroup()

# standardize the variables
gage_scale1_l <- gage_prep %>% 
  select(sta, q_depth, date) %>% 
  mutate(q_mean = mean(q_depth)) %>% 
  mutate(q_sd = sd(q_depth)) %>% 
  mutate(q_scaled = (q_depth - q_mean)/q_sd) %>% 
  mutate(avg_period = "1") %>% 
  mutate(sta_type = paste(sta, avg_period, sep = "")) %>% 
  select(sta_type, q_scaled, date)

gage_scale7_l <- gage_prep %>%  
 filter(!is.na(q7_depth)) %>% 
  mutate(q7_mean = mean(q7_depth)) %>% 
  mutate(q7_sd = sd(q7_depth)) %>% 
  mutate(q7_scaled = (q7_depth - q7_mean)/q7_sd) %>% 
  mutate(avg_period = "7") %>% 
  mutate(sta_type = paste(sta, avg_period, sep = "")) %>% 
  select(sta_type, q7_scaled, date)
    
gage_scale30_l <- gage_prep %>% 
  filter(!is.na(q30_depth)) %>% 
  mutate(q30_mean = mean(q30_depth)) %>% 
  mutate(q30_sd = sd(q30_depth)) %>% 
  mutate(q30_scaled = (q30_depth - q30_mean)/q30_sd) %>% 
  mutate(avg_period = "30") %>% 
  mutate(sta_type = paste(sta, avg_period, sep = "")) %>% 
  select(sta_type, q30_scaled, date)

# spread the long variables
gage_scale1 <- gage_scale_l %>% 
  spread(sta_type, q_scaled) 

gage_scale7 <- gage_scale7_l %>% 
  spread(sta_type, q7_scaled) 

gage_scale30 <- gage_scale30_l %>% 
  spread(sta_type, q30_scaled) 

gage_scale <- full_join(gage_scale1, gage_scale7)
gage_scale <- full_join(gage_scale, gage_scale30)

rm(gage_scale_l, gage_scale1, gage_scale1_l, gage_scale7, 
   gage_scale7_l, gage_scale30, gage_scale30_l)

# A check on the data finds Wounded Knee Creek has ~11% NA values
#plot_missing(gage_scale)

check_sta <- gage_scale %>% 
  select(wkc_wok30, date) %>% 
  filter(is.na(wkc_wok30))

# drop the NA values (num obs drops from 2192 to 1916)
gage_scale <- gage_scale %>% 
  drop_na() 

gage_scale_l <- gage_scale %>%
  gather(key = )
```

$xi−center(x)scale(x) \frac{x_i - center(x)}{scale(x)}$
$xi−mean(x)sd(x) \frac{x_i - mean(x)}{(x)}$

Where center(x) can be the mean or the median of x values, and scale(x) can be the standard deviation (SD), the interquartile range, or the MAD (median absolute deviation).


