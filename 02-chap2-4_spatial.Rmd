---
title: "02-chapt2-4_spatial"
author: "CJ Tinant"
date: "7/15/2019"
output: html_document
---

<!--
Purpose: 
develop a regression function for gaged stations by fitting PC1 of mean daily 
streamflow to environmental variables.  Then estimate PC1 for ungaged stations  
from the regression equation.  Using 'caret' to train ridge, lasso, and 
elastic net models and select best model fit by root mean square error (RMSE). 
OLS regression models fitted to correlated explanatory variables have a tendency 
to overfit to noisy or unrepresentative training data resulting in 
predictive inaccuracy when used to predict.

Regularization methods introduce bias into the regression solution that can reduce variance considerably relative to the ordinary least squares (OLS) solution. 
Regression regularization methods decrease v

That's why we regularize: to lower the variance at the cost of some bias, thus moving left on the plot, towards the optimum.

Data: 
  the data to train the model consists of 42 gaged catchments, 
  the data for the fitted model consists of 45 ungaged catchments  

Approach: 
1) EDA 
-- check histograms 
-- check univariate response 
2) Split train/test data 
   Training Dataset: The sample of data used to fit the model.
   Validation Dataset: the sample of data used to provide an unbiased 
     valuation of a model fit on the training dataset while tuning model 
     hyperparameters. The validation set is used to frequently evaluate a 
     given model.  Instead, we are using cross-validation to create splits 
     of the training data to evaluate a given model.
  Test Dataset: The sample of data used to provide an unbiased evaluation 
     of a final model fit on the training dataset. It is only used once a model 
     is completely trained (using the train and validation sets). The test set 
     is generally well curated. It (should) contain carefully sampled data that 
     spans the various classes that the model would face, when used in the 
     real world.

   We are creating a test dataset based on hydrologic export to create a 
   balanced split using caret::createDataPartition.   
     For a numeric y (hydrologic export coeff - PC1), the sample is split 
     into groups based on percentiles and sampling is done within groups. 
     The number of percentiles is set via the groups argument with 
     5-groups as default.  See also: 
     https://topepo.github.io/caret/model-training-and-tuning.html 
   
   For the 80/20 training/test set = 34 training stations and 8 test stations

3a) Train models 

# Elastic net regression is computed using the caret workflow, which invokes 
# the glmnet package.  caret will automatically select the best tuning 
# parameters alpha and lambda by testing a range of possible alpha and lambda # values, then selecting the best values for lambda and alpha 

# Here, we’ll test the combination of 10 different values for alpha and lambda. 
# This is specified using the option tuneLength.
# The best alpha and lambda values are those values that minimize the 
# cross-validation error (Chapter @ref(cross-validation)).
a ridge regression model 
    Decrease model complexity while keeping all variables in the model by 
    penalizing predictors if they are too far from zero, thus enforcing them to 
    be small in a continuous way. 
    
    The λ parameter is the regularization penalty. Setting λ to 0 is the same 
    as using the OLS estimate. As λ becomes larger, the variance decreases, 
    and the bias increases. 
    
    Cross-validation is used to select the value of λ that minimizes the 
    cross-validated sum of squared residuals (or some other measure) to 
    maximize predictive performance. 

3) Train model - Fit a generalized linear model via penalized maximum 
   likelihood using the glmnet package (Friedman, Hastie, and Tibshirani 2008).  
   The algorithm: 1) computes the regularization path denoted with λ that 
   controls the overall strength of the penalty, and 2) applies an elastic-net 
   penalty called the mixing percentage and denoted with α (Zou and Hastie 
   2005) to bridge the gap between lasso (α = 1) and ridge (α = 0) regression. 

   Model parameters (λ and α) are tuned to minimizes our loss function by 
   cross-validation. The approach is as follows:
     1. Set the parameter you want to tune to some value.
     2. Split your data into K ‘folds’ (sections).
     3. Train your model using K-1 folds using the parameter value.
     4. Test your model on the remaining fold.
     5. Repeat steps 3 and 4 so that every fold is the test data once.
     6. Repeat steps 1 to 5 for every possible value of the parameter.
     7. Report the parameter that produced the best result.

Since the test set is used both to select the values of the parameter and 
to evaluate the model, we risk optimistically biasing our model evaluations. 
For this reason, if a test set is used to select model parameters, then we 
need a different test set to get an unbiased evaluation of that selected model.


# About the train() function in the caret package.  The goal is to 
# automatically split the data, fit the models and assess model performance. 
# One example is from Cross-Validation for Predictive Analytics Using R
# http://www.milanor.net/blog/cross-validation-for-predictive-analytics-using-r/

#
# The train() function requires 1) the model formula, 2) the indication of the 
# model to fit, 3) the grid of tuning parameter values to use, specified 
# through the tuneGrid argument, 4) the method to choose optimal tuning 
# parameter values (in our case, 5-fold cross-validation) through the trControl 
# argument.  The preProcess argument specifies pre-processing operations on the 
# predictors (in our case, centering and scaling the predictor values). 


Next Steps: 
-- check into stylr-packag

Variable naming convention:   
# ~~~~~~~~~~~~~~~~~~~~~~~~~
gpg_layers          names of layers in gpkg file for the watershed summaries 
   _gage_summary 
   _prr_wq_sites
   _wbd_summary

wsd_summary     zonal statistics of watershed environmental parameters 
*   _id          unique id
*  _sta_id      four- or seven-digit station ID   
   _type        distinguishes gaged from ungaged 
   _watshed     describes the HUC06 watershed 
   _HUC12       hydrologic unit code 12
   _sta_name    station name derived from outlet HUC12 catchment name
   _gage_num    USGS site number 
   _gage_nm     station name from USGS gage
   _dec_lat     latitude in decimal degrees
   _dec_lon     longitude in decimal degrees
   _cat_area    catchment area in sq km
*  _cat_area_l  natural logarithm of catchment area 
   _cat_length  catchment length
   _cat_width   catchment width
*  _lw_ratio    catchment length divided by catchment width
   _str_len     stream length
*  _drain_dens  stream length divided by catchment area
*  _prcp_mean   areal mean precipitation depth 1992-2012
*  _t07_mean    average July temperature 1992-2012
*  _vpd_ann     areal mean of max vapor deficit 1992-2012
*  _vpd_07      areal mean of max July vapor deficit 1992-2012
*  _cat_out     catchment outlet elevation
*  _cat_rel     difference in max and min elevation
*  _slop_med    median percent slope
*  _TWI_mean    mean terrain wetness index
*  _perc_cov    percent forest cover from NLCD 2016
*  _fc_mean     mean field capacity
*  _ksat_mean   mean horizontal saturated hydraulic conductivity
*  _kvert_mean  mean vertical saturated hydrologic conductivity 

* indicates variables used in EDA using 'env_vars'

trainIndex      index variable for data splitting 
test            environmental parameters for gaged watersheds - test set 
train           environmental parameters for gaged watersheds - training set 
  _area_linv    recropocal of the natural logarithm of catchment area 
  _cout_sqr     square-root of catchment outlet elevation
  _crel_sqr     square-root of catchment relief
  _dden_sqr     square-root of drainage density
  _fc_mean      mean field capacity
  _kvert_ln     natural log of mean vertical saturated hydrologic conductivity 
  _lwrat_sqr    square-root of catchment outlet elevation
  _pcov_ln      natural log of percent forest cover from NLCD 2016
  _prcp_sq      square of areal mean precipitation depth 1992-2012
  _slop_ln      natural log of median percent slope 
  _t07_sq       square of average July temperature 1992-2012
  _TWI_sq       square of mean terrain wetness index
  _vpdan_sq     square of areal mean of max vapor deficit 1992-2012





vars_ung        environmental parameters for ungaged watersheds
gage_summary    input data used in geospatial analysis 
*   _sta        
*   _log_q1_dep 
*   _log_q7_dep 
*   _log_q30_de 
   _.class 
   _.uncertain 
   _site_no 
   _min_year 
   _max_year 
   _num_year 
   _agency_cd 
   _station_nm 
   _dec_lat_va 
   _dec_long_v 
   _state_cd 
   _county_cd 
   _drain_area 
   _contrib_dr 
   _huc_cd 
   _alt_va 
   _geom    

        




-->

```{r setup, include=FALSE}
# set up global options ------------------------------------------------------
knitr::opts_chunk$set(echo = TRUE)
options(tibble.print_max = 70) # sets tibble output for printing
set.seed(42)          # seed for reproducibility - also THE answer

# load libraries -------------------------------------------------------------
library("here")         # identifies where to save work
library("janitor")      # tools for examining and cleaning dirty data
library("sf")
library("funModeling")  # functions related to exploratory data analysis 
library("Hmisc")        # functions useful for data analysis
library("DataExplorer") # functions related to exploratory data analysis 
library("broom")        # sweep up results into tidy frames 
library("doMC")         # parallelization for caret 
library("glmnet")       # fit a GLM with lasso or elasticnet regularization 
library("caret")        # classification and regression training 

# library("MASS")         # for 'Boston' dataset used in example
library("corrr")        # explore correlations in R 
library("ggcorrplot") 
library("tidyverse")    # data munging tools 


#library("psych")         # for function tr() to compute trace of a matrix
#library("rsample")      # functions to create and summarize cross-validation  
#library("scales")       # scales for automatically determining graphical breaks 
#library("mlbench")      # artificial and real-world machine learning datasets 
#library("kernlab")        # kernel-based machine learning methods 
#library(sessioninfo)




#library("glmnetUtils")   # formula interface for 'glmnet' elasticnet regression 

#library("styler")

#library("RCurl")        # General Network (HTTP/FTP/...) Client Interface for R 
#library("prettyR")      # Pretty descriptive stats
# library("lubridate")     # easier dates

# set seed for reproducibility & theme for printing  -------------------------

theme_set(theme_bw()) 

# check number of cores for parallel processing
# numCores <- detectCores()


# Create functions ------------------------------------------------------------
# basic EDA function from 
# https://blog.datascienceheroes.com/exploratory-data-analysis-in-r-intro/
basic_eda <- function(data)      
{                                
  glimpse(data)
  df_status(data)
  freq(data) 
  profiling_num(data)
  plot_num(data)
  describe(data)
}
```


```{r import_data} 

# check layer names for the project geopackage 
gpg_layers <- st_layers("sp_data/eco-drought.gpkg")$name[1:5] %>% 
  tibble::enframe(.) %>% 
  select(value) 

# read in geopackage data of zonal summaries for watersheds 
gage_summary <- st_read("sp_data/eco-drought.gpkg", 
                       layer = "gage_summary", 
                       as_tibble = TRUE) %>% 
  st_drop_geometry()

wsd_summary <- st_read("sp_data/eco-drought.gpkg", 
                       layer = "wbd_summary", 
                       as_tibble = TRUE) %>% 
  st_drop_geometry() 

# convert environmental data to tibbles 
gage_summary <- as_tibble(gage_summary) %>% 
  modify_if(., is.factor, as.character) 

wsd_summary <- as_tibble(wsd_summary) %>% 
  modify_if(., is.factor, as.character) %>% 
  select(id, everything()) 

```

```{r munge_explore_enviro_data}
env_vars <-  wsd_summary %>% 
  filter(type == "gaged") %>% 
  select(sta_id, cat_area_l, lw_ratio, drain_dens, prcp_mean, t07_mean, 
         vpd_ann, vpd_07, cat_out, cat_rel, slop_med, TWI_mean, perc_cov, 
         fc_mean, ksat_mean, kvert_mean) %>% 
  rename(cat_area_ln = cat_area_l) 

basic_eda(env_vars) 

```

```{r EDA_01-box-cox}

# use Box Cox to estimate transforms 
lambda <- env_vars %>% 
  select(-sta_id) 

lambda <- enframe(
                  sapply(lambda, forecast::BoxCox.lambda)
                  ) %>% 
  rename(sta = name) %>% 
  rename(lambda_val = value) %>% 
  arrange(lambda_val) 

``` 

```{r EDA_02-transforms} 

# transform variables in the following way: 
## variable    lambda_val     transform
## ------------------------------------------
## cat_area_ln	-1.00			    reciprocal
## cat_out	     0.36			    square root 
## cat_rel       0.46			    square root 			
## drain_dens	   0.66			    square root 			
## fc_mean	     1.36 
## kvert_mean	  -0.13			    natural log 
## ksat_mean  	-0.11			    natural log 
## lw_ratio	    -0.18			    natural log 
## perc_cov	     0.17			    natural log 
## prcp_mean	   2.00			    square
## slop_med	    -0.13			    natural log 
## t07_mean	     2.00			    square
## TWI_mean	     2.00				  square
## vpd_ann	     2.00				  square		
## vpd_07	       2.00					square	

env_vars <- env_vars %>% 
  mutate(area_linv  = 1/cat_area_ln) %>% 
  mutate(cout_sqr   = sqrt(cat_out)) %>% 
  mutate(crel_sqr   = sqrt(cat_rel)) %>% 
  mutate(dden_sqr   = sqrt(drain_dens)) %>% 
  mutate(ksat_ln    = log(ksat_mean)) %>% 		
  mutate(kvert_ln   = log(kvert_mean)) %>% 
  mutate(lwrat_sqr  = log(lw_ratio)) %>% 
  mutate(pcov_ln    = log(1 + perc_cov)) %>% 	
  mutate(prcp_sq    = prcp_mean^2) %>% 
  mutate(slop_ln    = log(slop_med)) %>%   
  mutate(t07_sq     = t07_mean^2) %>%     
  mutate(TWI_sq     = TWI_mean^2) %>%   
  mutate(vpd07_sq   = vpd_07^2) %>% 	
  mutate(vpdan_sq   = vpd_ann^2) %>%   		
  select(area_linv, cat_area_ln, cout_sqr, cat_out, crel_sqr, cat_rel, 
         dden_sqr, drain_dens, fc_mean, ksat_ln, ksat_mean, kvert_ln, 
         kvert_mean, lwrat_sqr, lw_ratio, pcov_ln, perc_cov, prcp_sq, 
         prcp_mean, slop_ln, slop_med, t07_sq, t07_mean, TWI_sq, 
         vpd07_sq, vpd_07, vpd_ann, vpdan_sq) 

# plot quantiles 
plot_qq(env_vars) 

```

```{r EDA_03-correlation} 

# select environmental variables 
env_vars <- env_vars %>% 
  select(area_linv, cout_sqr, crel_sqr, dden_sqr, fc_mean, ksat_ln, 
         kvert_ln, lwrat_sqr, pcov_ln, prcp_sq, slop_ln, t07_sq, 
         TWI_sq, vpd07_sq, vpdan_sq) 
    
plot_correlation(env_vars) 

# highly correlated (> 0.65) data 
## variable    transform_var    correlated vars             drop?
## ---------------------------------------------------------------------------
## drain_dens	  dden_sqr			  fc_mean, prcp_sq, 
##                              ksat_ln, kvert_ln			      
## fc_mean	                    ksat_ln, k_vert_ln, 
##                              dden_sqr           
## ksat_mean  	ksat_ln 		    dden_sqrm fc_mean,
##                              kvert_ln                    yes
## kvert_mean	  kvert_ln        dden_sqr, fc_mean, 
##                              ksat_ln 
## lw_ratio	    lwrat_sqr		     
## prcp_mean	 	prcp_sq         vpd_ann, vpd_07	
## perc_cov	    pcov_ln		      slop_ln, t07_ln            
##                              TWI_sq, vpd07_sq
##                              vpdan_sq                    
## slop_med	    slop_ln         pcov_ln, TWI_sq 
## t07_mean	    t07_sq          pcov_ln, vpdann_sq, 
##                              vpd07_sq 
## TWI_mean	    TWI_sq 				  pcov_ln, slop_ln
## vpd_ann	    vpdan_sq			  pcov_ln, prcp_sq, 
##                              t07_mean, vpd07_sq 
## vpd_07	      vpd07_sq			  pcov_ln, prcp_sq, 
##                              t07_mean, vpdan_sq          yes

``` 

```{r EDA_04-response_var} 

# transformed environmental vars to approximate gaussian 
gaged <- wsd_summary %>% 
  filter(type == "gaged") %>%  
  mutate(area_linv  = 1/cat_area_l) %>%  
  mutate(cout_sqr   = sqrt(cat_out)) %>% 
  mutate(crel_sqr   = sqrt(cat_rel)) %>% 
  mutate(dden_sqr   = sqrt(drain_dens)) %>% 
  mutate(kvert_ln   = log(kvert_mean)) %>% 
  mutate(lwrat_sqr  = log(lw_ratio)) %>% 
  mutate(pcov_ln    = log(1 + perc_cov)) %>% 	
  mutate(prcp_sq    = prcp_mean^2) %>% 
  mutate(slop_ln    = log(slop_med)) %>%   
  mutate(t07_sq     = t07_mean^2) %>%     
  mutate(TWI_sq     = TWI_mean^2) %>%   
  mutate(vpdan_sq   = vpd_ann^2) %>%   		
  select(sta_id, area_linv, cout_sqr, crel_sqr, dden_sqr, fc_mean, 
         kvert_ln, lwrat_sqr, pcov_ln, prcp_sq, slop_ln, t07_sq, 
         TWI_sq, vpdan_sq) 

# response variable needs to be an ordered PC for training/test splits 
resp_vars <- gage_summary %>% 
  select(sta, log_q1_dep, log_q7_dep, log_q30_de) 

pca <- prcomp(resp_vars[,c(2:4)], 
              center = TRUE, scale. = TRUE) 

tidy(pca, "pcs") 

resp_vars <- augment(pca, data = resp_vars) %>% 
  select(sta_id = sta, hydro_exp = .fittedPC1) 
  
# prepare for regression 
gaged <- full_join(gaged, resp_vars, 
                   by = "sta_id") %>% 
  arrange(hydro_exp) %>% 
  select(sta_id, hydro_exp, everything()) 

# clean up global environment 
rm(gage_summary, gpg_layers, lambda, pca, resp_vars)  
```

```{r train-models-catchments, eval=FALSE}

# Split the data into training and test set --------------------------
response <- gaged$hydro_exp 
groups <- min(5, length(response))

# create a training index based on hydrologic export coefficient 
set.seed(42)
trainIndex <- createDataPartition(response, p = .8, 
                                  list = FALSE, times = 1,
                                  groups = groups)

# create a training and a test set 
train.data <- gaged[trainIndex,] %>% 
  select(-sta_id)
test.data  <- gaged[-trainIndex,] %>%
  select(-sta_id)

rm(trainIndex, response, groups) 

# Build models----------------------------------------------------------------
# set possible lambda values 
lambda <- 10^seq(-3, 3, length = 100) # sets 100 possible lambda vals [-3, 3] 

# set up parallel processing 
cores <- parallel::detectCores(all.tests = FALSE, logical = TRUE)
registerDoMC(cores) 

# set up a training control 
set.seed(42)
reg.ctrl <-  trainControl(method = "repeatedcv", number = 5, repeats = 5, 
                          search = "grid", allowParallel = TRUE)

# ridge
set.seed(42)                # need to set a seed each time you call a rand num
ridge <- train(
  hydro_exp ~.,                  # x = 'medv', y = the rest of the columns, from 
  data = train.data,        # the dataset 'train.data'
  method = "glmnet",        # using method "glmnet" 
  preProcess = c("center", "scale"), 
  trControl = reg.ctrl,  
  tuneGrid = expand.grid(alpha = 0, lambda = lambda) # df with tuning values
  )

# lasso
set.seed(42)                # need to set a seed each time you call a rand num
lasso <- train(
  hydro_exp ~.,                  # x = 'medv', y = the rest of the columns, from  
  data = train.data,        # the dataset 'train.data'
  method = "glmnet",        # using method "glmnet" 
  preProcess = c("center", "scale"), 
  trControl = reg.ctrl, 
  tuneGrid = expand.grid(alpha = 1, lambda = lambda) # df with tuning values
  )

# elastic net 
set.seed(42) 
elastic <- train(
  hydro_exp ~.,                  # x = 'medv', y = the rest of the columns, from  
  data = train.data,        # the dataset 'train.data'
  method = "glmnet",        # using method "glmnet" 
  preProcess = c("center", "scale"), 
  trControl = reg.ctrl, 
  tuneLength = 10
  )

# make a list of the models --------------------------------------------------
models <- list(ridge = ridge, lasso = lasso, elastic = elastic) 

rm(cores, lambda, reg.ctrl)
```

```{r select-model-catchments}

# Model prediction performance-------------------------------------------------
# The performance of the different models - ridge, lasso and elastic net - 
# can be easily compared using caret. The best model is defined as the one that minimizes the prediction error.

# find best fit by RMSE 
rmse_call <- resamples(models) %>%  
  summary(metric = c("RMSE")) 

rmse_vals <- as_tibble( 
  as.data.frame(
    pluck(rmse_call, 'statistics')
  ), rownames = "model"
)

names(rmse_vals) <- c(
  "model", "min", "Q1", "med", "mean", "Q3", "max", "na_ct") 

# plot model RMSE
ggplot(rmse_vals, aes(x = as.factor(model))) + 
  geom_point(aes(y = med)) + 
  geom_boxplot(aes(
      lower = Q1, 
      upper = Q3, 
      middle = med, 
      ymin = min, 
      ymax = max),
    stat = "identity") + 
    geom_point(
      aes(y = mean)
      ) + 
  labs(title = "Regression method accuracy") + 
  xlab("") + 
  ylab("RMSE")

#listviewer::jsonedit(rmse_call) 
``` 

```{r model-coefs-catchments}

# save ggplot above & clean up
ggsave("figure/super_reg_acc.png") 
rm(rmse_call, rmse_vals) 

# Get model coefficients------------------------------------------------------
# ridge 
coef_ridge <- as_tibble(
  as.matrix(
    coef(ridge$finalModel, ridge$bestTune$lambda)
    ), 
  rownames = "coefficients") 

coef_ridge <- coef_ridge %>% 
  slice(-1) %>% 
  rename(ridge = 2) 

# lasso 
coef_lasso <- as_tibble(
  as.matrix(
    coef(lasso$finalModel, lasso$bestTune$lambda)
    ), 
  rownames = "coefficients") 

coef_lasso <- coef_lasso %>% 
  slice(-1) %>% 
  rename(lasso = 2) 

# elastic 
coef_elastic <- as_tibble(
  as.matrix(
    coef(elastic$finalModel, elastic$bestTune$lambda)
    ), 
  rownames = "coefficients") 

coef_elastic <- coef_elastic %>% 
  slice(-1) %>% 
  rename(elastic = 2) 

# bind the coefs together
coefs <- full_join(coef_ridge, coef_lasso, 
                   by = "coefficients") 
coefs <- full_join(coefs, coef_elastic, 
                   by = "coefficients") 

coefs <- coefs %>% 
  map_if(is.numeric, ~round(., digits = 2)) %>% 
  as_tibble() 

rm(coef_elastic, coef_lasso, coef_ridge)
```

```{r test-model-catchments} 

#  prepare to plot training observations and predictions 
observed_train   <- tibble(observed = train.data$hydro_exp)
preds_train <- map_dfc(models, predict, newdata = train.data) 
fit_train <- bind_cols(observed_train, preds_train) 

#  prepare to plot test observations and predictions 
observed_test   <- tibble(observed = test.data$hydro_exp) 
preds_test <- map_dfc(models, predict, newdata = test.data) 
fit_test <- bind_cols(observed_test, preds_test) 

# use the test data to calculate Rsquared and RMSE 
model_fit <- fit_test %>% 
  map_dfc(~postResample(., fit_test$observed)) %>% 
  mutate(measurement = c("RMSE", "Rsquared", "MAE")) %>% 
  select(measurement, ridge, lasso, elastic) %>% 
  gather(var, value, -measurement) %>%                 # transposes df
  spread(measurement, value) %>% 
  rename(model = var) 

# combine the training and test dataframes 
fit_train <- fit_train %>% 
  mutate(split = "train")

fit_test <- fit_test %>% 
  mutate(split = "test") 

obs_fitted <- bind_rows(fit_train, fit_test)

rm(observed_train, preds_train, observed_test, preds_test, fit_train, fit_test)

# calculate adjusted R2 -----------------------------------------------------
# find the number of observations
n_test <- nrow(test.data) 
n_train <- nrow(train.data)

# find number of parameters for each regression method 
num_param <- coefs %>% 
  map_dfc(~sum(. != 0)
) %>% 
  select(-coefficients) %>% 
  gather(model, num_param) #%>%                 # transposes df

# add number of params and number of obs  
model_fit <- full_join(model_fit, num_param, 
                  by = "model") %>% 
  mutate(n_test = n_test) %>% 
  mutate(n_train = n_train)

# calculate adj R2
model_fit <- model_fit %>% 
  mutate(
    R2adj_test = 
      Rsquared - ((1-Rsquared) * (num_param) / (n_test - num_param -1)) 
  ) %>% 
  mutate(R2adj_test = if_else(R2adj_test > 1, 0, R2adj_test)
  ) %>% 
  mutate(R2adj_train = 
      Rsquared - ((1-Rsquared) * (num_param) / (n_train - num_param -1)) 
  ) %>% 
  select(model, MAE, RMSE, Rsquared, R2adj_train, R2adj_test)
```

```{r plot_model_predictions}

# gather data
obs_fitted_l <- obs_fitted %>% 
  gather(key = "model", value = "fitted", -c(observed, split)) 

# prepare to add text 
num_obs <- num_param %>% 
    mutate(n_test = n_test) %>% 
    mutate(n_train = n_train) %>% 
    select(-num_param) %>% 
    gather(key, val, -model) %>% 
    mutate(split = 
           c("test", "test", "test", "train", "train", "train")
    ) %>% 
   select(-key)  

adjR2_text <- model_fit %>% 
  select(-c(MAE, RMSE, Rsquared)) %>% 
  gather(key, val, -model) %>% 
  mutate(val = round(val, digits = 2)
         ) %>% 
  mutate(split = 
           c("train", "train", "train", "test", "test", "test")) %>% 
  select(-key)  
  
rm(n_test, n_train)

# create a factor variable to control plotting order
obs_fitted_l$split <- factor(obs_fitted_l$split, 
                             levels=c("train", "test")
                             )  

# make the plot 
ggplot(obs_fitted_l, aes(observed, fitted)) + 
    geom_text(
    data = num_obs,
    mapping = aes(x = -4, 
                  y = -4, 
                  label = paste("n: ", val, sep="")),
    parse = TRUE, 
    size = 2.5,  
    nudge_x = 7,
    nudge_y = 2.3   
    ) + 
  geom_text(
    data = adjR2_text,
    mapping = aes(x = -4, 
                  y = -4, 
                  label = paste("adjR^2: ", val, sep="")),
    parse = TRUE, 
    size = 2.5,  
    nudge_x = 7,
    nudge_y = 1
    ) + 
  geom_point(aes(shape = split)) + 
  geom_smooth(method = "lm") + 
  geom_abline(intercept = 0, slope = 1, size = 0.25) +
  xlim(-4, 4) + 
  ylim(-4, 4) + 
  theme(legend.position = "none") + 
  labs(title = "Observed vs. fitted hydrologic export coefficients") + 
  facet_grid(model ~ split) 
``` 


```{r correlations}
# save last plot and model parameters: 
ggsave("figure/super_obs-fitted.png") 
write_csv(coefs, path = "figure/super_coefs.csv") 
write_csv(model_fit, path = "figure/super_fit.csv") 
write_csv(obs_fitted, path = "figure/sup_obs_preds.csv") 

rm(obs_fitted_l, adjR2_text, obs_fitted, model_fit) 

# explore correlations results
env_cor <- correlate(env_vars) %>%            # create a correlation df
  shave() %>%                                 # shave off bottom half
  select(rowname, dden_sqr, fc_mean) %>%      # keep only the important vars 
  replace(., is.na(.), 0) %>%                 # change na to zero    
  mutate(dden_abs = abs(dden_sqr)) %>%
  mutate(fc_abs = abs(fc_mean)) %>% 
  mutate(abs_sum = dden_abs + fc_abs) %>%     # make abs vals & add
  arrange(abs_sum) %>% 
  filter(abs_sum > 0.75) %>%                  # remove low correlation cols 
  filter(rowname != "ksat_ln") %>% 
  select(rowname, dden_sqr, fc_mean)
  
# plot highly correlated vars 
env_cor_fn <- env_vars %>% 
  select(dden_sqr, fc_mean, vpdan_sq, prcp_sq, kvert_ln) %>%
  cor() %>% 
  round(., 2)
  
ggcorrplot(env_cor_fn, hc.order = FALSE, type = "lower",
   lab = TRUE, insig = "blank", 
   title = "Correlation matrix of environmental variables") 
```



```{r predict-ungaged} 
# save last plot and clean up
ggsave("figure/corr_plot.png")
rm(env_vars, env_cor, env_cor_fn)

# get ungaged data for prediction----------------------------------------------
# transform ungaged vars 
ungaged <- wsd_summary %>% 
    filter(type == "ungaged") %>% 
  rename(cat_area_ln = cat_area_l) %>% 
  mutate(area_linv  = 1/cat_area_ln) %>% 
  mutate(cout_sqr   = sqrt(cat_out)) %>% 
  mutate(crel_sqr   = sqrt(cat_rel)) %>% 
  mutate(dden_sqr   = sqrt(drain_dens)) %>% 
  mutate(kvert_ln   = log(kvert_mean)) %>% 
  mutate(lwrat_sqr  = log(lw_ratio)) %>% 
  mutate(pcov_ln    = log(1 + perc_cov)) %>% 	
  mutate(prcp_sq    = prcp_mean^2) %>% 
  mutate(slop_ln    = log(slop_med)) %>%   
  mutate(t07_sq     = t07_mean^2) %>%     
  mutate(TWI_sq     = TWI_mean^2) %>%   
  mutate(vpd07_sq   = vpd_07^2) %>% 	
  mutate(vpdan_sq   = vpd_ann^2) %>%   		
  select(sta_id, area_linv, cout_sqr, crel_sqr, dden_sqr, fc_mean, 
         kvert_ln, lwrat_sqr, pcov_ln, prcp_sq, slop_ln, t07_sq, 
         TWI_sq, vpdan_sq) 
 
# predict hydro_exp  
pred.data <- ungaged %>% 
  select(-sta_id)
 
lasso.predict <- tibble(hydro_exp = 
  predict(lasso, newdata = pred.data)
  )   

# join predictions to tranformed variables 
ungaged <- bind_cols(lasso.predict, ungaged) %>% 
  select(sta_id, hydro_exp, everything()) %>% 
  arrange(hydro_exp) 

test <- gaged %>% 
  select(sta_id, hydro_exp) %>% 
  mutate(type = "gaged") 

test_a <- tibble(
  sta_id = c("NA", "NA", "NA"), 
  hydro_exp = c(0, 0, 0)
  ) %>% 
  mutate(sta_id = na_if(sta_id, "NA")) %>% 
  mutate(hydro_exp = na_if(sta_id, 0))  

test <- bind_rows(test, test_a)

test2 <- ungaged %>% 
  select(sta_id, hydro_exp) %>% 
  mutate(type = "ungaged")

test3 <- bind_cols(test, test2) 

a <- data_frame(id = c("A","A","A","B","B","B"),
                b = c(1.2, 1.5, 1.8, 1.1, 1.6, 1.4),
                c = c(1.3, 1.2, 1.7, 1.0, 1.5, 1.6)
                ) 

test <- a %>% group_by(id) %>% filter(abs(b - c) == min(abs(b - 1.43))) 


test <- a %>%
    mutate(AbsDiff = abs(b - c)) %>%
    group_by(id) %>%
    mutate(AbsDiff_r = rank(AbsDiff, ties.method = 'first')) %>%
    filter(AbsDiff_r == 1)


x= tibble(val = c(1:10^6))
test = c(1.1, 11.2)

map_dfc()

which(abs(x-your.number)==min(abs(x-your.number)))




by_cyl <- mtcars %>% split(.$cyl)
mods <- by_cyl %>% map(~ lm(mpg ~ wt, data = .))
map2(mods, by_cyl, predict)




mtcars %>%
  split(.$cyl) %>%
  map(~ lm(mpg ~ wt, data = .)) %>%
  map(summary) %>%
  map_dbl("r.squared")

mtcars %>%
  split(.$test) %>%
  map(~abs()) 
    
    ~ lm(mpg ~ wt, data = .)) %>%
  map(summary) %>%
  map_dbl("r.squared")
test <- which.min(abs(a-1.1))


 a %>% group_by(id) %>% nth(which.min(abs(.$b-1.43)))


ggplot(ungaged, aes(xposition, hydro_exp)) + 
  geom_point() 

```

```{r possible-improvements}
library(caret)
# Define training control
set.seed(42)
train.control <- trainControl(method = "repeatedcv", 
                              number = 10, repeats = 3)
# Train the model
model <- train(Fertility ~., data = swiss, method = "lm",
               trControl = train.control)
# Summarize the results
print(model) 

data <- swiss


# Set training control
train_control <- trainControl(method = "repeatedcv",
                              number = 5,
                              repeats = 5,
                              search = "random",
                              verboseIter = TRUE)

# Train the model
elastic_net_model <- train(hydro_exp ~ .,
                           data = cbind(y, X),
                           method = "glmnet",
                           preProcess = c("center", "scale"),
                           tuneLength = 25,
                           trControl = train_control)




set.seed(seed)
 
cs_data_train <- cs_data[train_set, ]
cs_data_test <- cs_data[-train_set, ]
 
glmnet_grid <- expand.grid(alpha = c(0,  .1,  .2, .4, .6, .8, 1),
                           lambda = seq(.01, .2, length = 20))



glmnet_ctrl <- trainControl(method = "cv", number = 10)
glmnet_fit <- train(Status ~ ., data = cs_data_train,
                    method = "glmnet",
                    preProcess = c("center", "scale"),
                    tuneGrid = glmnet_grid,
                    trControl = glmnet_ctrl)

# create the tibble with the resampling specifications:
results <- nested_cv(train_dat, 
                     outside = vfold_cv(repeats = 5), 
                     inside = bootstraps(25))
results

## # 10-fold cross-validation repeated 5 times 
## # Nested : vfold_cv(repeats = 5) / bootstraps(25) 
## # A tibble: 50 x 4
##          splits      id    id2   inner_resamples
##          <list>   <chr>  <chr>            <list>
##  1 <S3: rsplit> Repeat1 Fold01 <tibble [25 x 2]>
##  2 <S3: rsplit> Repeat1 Fold02 <tibble [25 x 2]>
##  3 <S3: rsplit> Repeat1 Fold03 <tibble [25 x 2]>
##  4 <S3: rsplit> Repeat1 Fold04 <tibble [25 x 2]>
##  5 <S3: rsplit> Repeat1 Fold05 <tibble [25 x 2]>
##  6 <S3: rsplit> Repeat1 Fold06 <tibble [25 x 2]>
##  7 <S3: rsplit> Repeat1 Fold07 <tibble [25 x 2]>
##  8 <S3: rsplit> Repeat1 Fold08 <tibble [25 x 2]>
##  9 <S3: rsplit> Repeat1 Fold09 <tibble [25 x 2]>
## 10 <S3: rsplit> Repeat1 Fold10 <tibble [25 x 2]>
## # ... with 40 more rows

The splitting information for each resample is contained in the split objects. Focusing on the second fold of the first repeat:

results$splits[[2]]

## <90/10/100>

<90/10/100> indicates the number of data in the analysis set, assessment set, and the original data.

Each element of inner_resamples has its own tibble with the bootstrapping splits.

results$inner_resamples[[5]]

## # Bootstrap sampling with 25 resamples 
## # A tibble: 25 x 2
##          splits          id
##          <list>       <chr>
##  1 <S3: rsplit> Bootstrap01
##  2 <S3: rsplit> Bootstrap02
##  3 <S3: rsplit> Bootstrap03
##  4 <S3: rsplit> Bootstrap04
##  5 <S3: rsplit> Bootstrap05
##  6 <S3: rsplit> Bootstrap06
##  7 <S3: rsplit> Bootstrap07
##  8 <S3: rsplit> Bootstrap08
##  9 <S3: rsplit> Bootstrap09
## 10 <S3: rsplit> Bootstrap10
## # ... with 15 more rows

These are self-contained, meaning that the bootstrap sample is aware that it is a sample of a specific 90% of the data:

results$inner_resamples[[5]]$splits[[1]]

## <90/37/90>

To start, we need to define how the model will be created and measured. For our example, a radial basis support vector machine model will be created using the function kernlab::ksvm. This model is generally thought of as having two tuning parameters: the SVM cost value and the kernel parameter sigma. For illustration, only the cost value will be tuned and the function kernlab::sigest will be used to estimate sigma during each model fit. This is automatically done by ksvm.

After the model is fit to the analysis set, the root-mean squared error (RMSE) is computed on the assessment set. One important note: for this model, it is critical to center and scale the predictors before computing dot products. We don't do this operation here because mlbench.friedman1 simulates all of the predictors to be standard uniform random variables.


```

```{r styler, message=FALSE} 
#tidyverse_style(scope = "tokens", strict = TRUE, indent_by = 2, 
 # start_comments_with_one_space = FALSE, 
 # reindention = tidyverse_reindention(), 
#  math_token_spacing = tidyverse_math_token_spacing())  

# style_file() 
```

```{r train-models-example, eval=FALSE}

# Load example data from 
# Penalized Regression Essentials: Ridge, Lasso & Elastic Net
# http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/153-penalized-regression-essentials-ridge-lasso-elastic-net/

data("Boston", package = "MASS") 

# Split the example data into training and test set
set.seed(42)
training.samples <- Boston$medv %>%
  createDataPartition(p = 0.8, list = FALSE)

train.data  <- Boston[training.samples, ]
test.data <- Boston[-training.samples, ]

rm(training.samples, Boston)

# Build models----------------------------------------------------------------
# Build the regression models using the caret workflow to automatically 
# choose the best tuning parameter values, compute the final model and 
# evaluate the model performance using cross-validation techniques.

# Caret computes penalized linear regression models to tune the glmnet model.  
# The simplified format is: glmnet(x, y, alpha = 1, lambda = NULL), where
#    x: matrix of predictor variables
#    y: the response or outcome variable, which is a binary variable.
#    alpha: the elasticnet mixing parameter. Allowed values include:
#        “1”: for lasso regression,
#        “0”: for ridge regression &
#        a value between 0 and 1 (say 0.3) for elastic net regression.
#    lamba: a numeric value defining the amount of shrinkage.  
# The best lambda for your data, can be defined as the lambda that minimizes 
# the cross-validation prediction error rate. This can be determined 
# automatically using the function cv.glmnet(). 

# set model conditions -------------------------------------------------------
# set possible lambda values 
lambda <- 10^seq(-3, 3, length = 100) # sets 100 possible lambda vals [-3, 3] 

# set up parallel processing 
cores <- parallel::detectCores(all.tests = FALSE, logical = TRUE)
doMC::registerDoMC(cores) 

# ridge
set.seed(42)                # need to set a seed each time you call a rand num
ridge <- train(
  medv ~.,                  # x = 'medv', y = the rest of the columns, from  
  data = train.data,        # the dataset 'train.data'
  method = "glmnet",        # using method "glmnet" 
#  preProcess = c("center", "scale"), 
  trControl = trainControl("cv", number = 10), # 'number'-fold CV
  tuneGrid = expand.grid(alpha = 0, lambda = lambda) # df with tuning values
  )

# lasso
set.seed(42)                # need to set a seed each time you call a rand num
lasso <- train(
  medv ~.,                  # x = 'medv', y = the rest of the columns, from  
  data = train.data,        # the dataset 'train.data'
  method = "glmnet",        # using method "glmnet" 
#  preProcess = c("center", "scale"), 
  trControl = trainControl("cv", number = 10), # 'number'-fold CV
  tuneGrid = expand.grid(alpha = 1, lambda = lambda) # df with tuning values
  )

# elastic net 
set.seed(42)
elastic <- train(
  medv ~.,                  # x = 'medv', y = the rest of the columns, from  
  data = train.data,        # the dataset 'train.data'
  method = "glmnet",        # using method "glmnet" 
#  preProcess = c("center", "scale"), 
  trControl = trainControl("cv", number = 10), # 'number'-fold CV
  tuneLength = 100 
  )

# make a list of the models --------------------------------------------------
models <- list(ridge = ridge, lasso = lasso, elastic = elastic)

```

```{r select-model-example, eval=FALSE}
 
# Model prediction performance------------------------------------------------- 
# The performance of the different models - ridge, lasso and elastic net -  
# can be easily compared using caret. The best model is defined as the one that  minimizes the prediction error. 

# find best fit by table and plot  
rmse_call <- resamples(models) %>%   
  summary(metric = c("RMSE"))  

#rmse_vals <- pluck(rmse_call, 'statistics')
#rmse_vals2 <- as_tibble(as.data.frame(
#  rmse_vals), rownames = "model") 

rmse_vals <- as_tibble(
  as.data.frame(
    pluck(rmse_call, 'statistics')
  ), rownames = "model"
)

rmse_plot <- bwplot(resamples(models), 
       metric = "statistics") 

#listviewer::jsonedit(rmse_call) 
rm(cores, lambda, rmse_call)
``` 

```{r test-model-example, eval=FALSE}
 
# make a new dataframe of test data observations and predictions 
observed   <- tibble(observed = test.data$medv)
allPreds <- map_dfc(models, predict, newdata = test.data) 
model_preds <- bind_cols(observed, allPreds) 
rm(observed, allPreds)

# use the new dataframe to calculate Rsquared and RMSE 
model_fit <- model_preds %>% 
  map_dfc(~postResample(.,model_preds$observed)) %>% 
  mutate(measurement = c("RMSE", "Rsquared", "MAE")) %>% 
  select(measurement, ridge, lasso, elastic)

# plot model predictions------------------------------------------------------  
model_pred_l <- model_preds %>% 
  gather(key = "model", value = "predicted", -observed)

ggplot(model_pred_l, aes(predicted, observed)) + 
         geom_point() + 
  geom_smooth(method = "lm") + 
         facet_grid(. ~ model) + 
  geom_abline(intercept = 0, slope = 1, size = 0.25) +
  xlim(0, 50) + 
  ylim(0, 50)
  
 
#tidied <- tidy(models) #%>% filter(term != "(Intercept)")
```

```{r model-coefs-example, eval=FALSE}

# Get model coefficients------------------------------------------------------
# ridge 
coef_ridge <- as_tibble(
  as.matrix(
    coef(ridge$finalModel, ridge$bestTune$lambda)
    ), 
  rownames = "coefficients") 

coef_ridge <- coef_ridge %>% 
  slice(-1) %>% 
  rename(ridge = 2) 

# lasso 
coef_lasso <- as_tibble(
  as.matrix(
    coef(lasso$finalModel, lasso$bestTune$lambda)
    ), 
  rownames = "coefficients") 

coef_lasso <- coef_lasso %>% 
  slice(-1) %>% 
  rename(lasso = 2) 

# elastic 
coef_elastic <- as_tibble(
  as.matrix(
    coef(elastic$finalModel, elastic$bestTune$lambda)
    ), 
  rownames = "coefficients") 

coef_elastic <- coef_elastic %>% 
  slice(-1) %>% 
  rename(elastic = 2) 

# bind the coefs together
coefs <- full_join(coef_ridge, coef_lasso, 
                   by = "coefficients") 
coefs <- full_join(coefs, coef_elastic, 
                   by = "coefficients") 

coefs <- coefs %>% 
  map_if(is.numeric, ~round(., digits = 2)) %>% 
  as_tibble()
```