---
title: "Maps and Charts"
author: "Charles Jason Tinant"
creation date: "5/9/2018"
last update: "5/13/2018"
output: pdf_document
---

This rmd contains spatial data analysis and mapping
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# sets the path and what to do with chunks----
#opts_chunk$set(fig.width=10,
#               fig.height=7,
#               out.width = "600px",
#               out.height = "420px",
#               fig.path = "lecture_figs/making-maps-")

# token for NOAA API tied to jtinant@olc.edu
options(noaakey = "VpcuARumMpCfFyclKHPfvskEYnaiLJHD")
# see 'rnoaa' for details
# Get API key (aka, token) at http://www.ncdc.noaa.gov/cdo-web/token
```

```{r library}
# Sets up the library of packages 
# I/O and simple data cleaning
library("rio") # more robust I/O - to import and clean data
library("janitor") # tools for examining and cleaning dirty data
library("here")

library("maps") # outlines of continents, countries, states & counties
library("mapdata") # higher-resolution outlines
library('ggmap')
library("tidyverse")

# for downloading data from USGS and NOAA websites
library("dataRetrieval") # USGS data import
library("rnoaa")

# for Theissen polygons
library("deldir") 

# Packages that are not likely to be called
# library("DiagrammeR") # used to call 'mermaid' for a Gantt chart
# library("thesisdown") # used to knit a thesis follows bookdown
# library("bookdown") # 
# library(knitr) # not sure if this needs to be loaded??
# library(DataExplorer)
# library("workflowr") # creates a research website
# library("colorspace")
# library("RColorBrewer")
```

```{r map_points, eval=FALSE}
# Creates points for maps. No need to evaluate.  
# The output files have been created.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 'station' is a variable for NOAA weather station locations
# 'gage' is a variable for USGS stream gages
# 'site' is a variable for OST monitoring stations

# 'station' 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# get station id with the mapping tool at 
# https://www.ncdc.noaa.gov/cdo-web/datatools/findstation
# iterate across a list of station ids by purrr::map 
# to get NOAA station meta data using rnoaa::ncdc_stations
# the output is a list of 7 x 2 x 9.
# flatten into a dataframe by purrr::flatten 
# reorder and rename columns by dplyr
# save the station df by rio
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
sta_input <- data.frame(name = c('RAPID CITY RGNL AP', 
                                 'HOT SPRINGS', 
                                'OELRICHS', 
                                'INTERIOR 3 NE', 
                                'COTTONWOOD 2 E', 
                                'LONG VALLEY',
                                'HARRISON',
                                'AINSWORTH, NE',
                                'MURDO, SD US',
                                'MISSION 14 S, SD US',
                                'ORAL, SD US',
                                'KADOKA 0.3 N, SD US'),
                        id = c("GHCND:USW00024090", 
                               "GHCND:US1SDFR0001",
                               "GHCND:USC00396212",
                               "GHCND:USC00394184",
                               "GHCND:USC00391972",
                               "GHCND:USC00394983",
                               "GHCND:USC00253615",
                               "GHCND:USC00250050",
                               "GHCND:USC00395891",
                               "GHCND:USC00395638",
                               "GHCND:USC00396304",
                               "GHCND:US1SDJK0006"),
                        stringsAsFactors = FALSE)

station <- map(sta_input$id, ncdc_stations)
station <- flatten_dfr(station)

station <- station %>%
  rename(lat = latitude) %>%
  rename(lon = longitude) %>%
  select(id, name, lat, lon, everything())

export(station, "index/data/station_meta2.csv")
library(here)
here()
# 'gage' 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# get gage ids by USGS watermapper
# iterate across a list of gage ids by purrr::map_dfr 
# to get gage metadata using dataRetrieval::readNWISsite
# reorder and rename columns by dplyr
# save the station df by rio
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

gage_id <- data.frame(name = c("WHITE R NR NE-SD STATE LINE", 
                              "WHITE R NEAR OGLALA SD", 
                              "WHITE CLAY CR NEAR OGLALA SD", 
                              "WHITE R NEAR INTERIOR SD", 
                              "WOUNDED KNEE CREEK AT WOUNDED KNEE SD",
                              "BEAR IN THE LODGE CR NEAR WANBLEE SD", 
                              "WHITE R NEAR KADOKA SD", 
                              "BLACK PIPE CREEK NR BELVIDERE SD", 
                              "LITTLE WHITE R NEAR MARTIN SD", 
                              "LAKE CR BELOW REFUGE NEAR TUTHILL SD", 
                              "LITTLE WHITE R NEAR VETAL SD", 
                              "SOUTH FORK BAD R NEAR COTTONWOOD SD", 
                              "BAD R NEAR MIDLAND SD"),
                     id = c('06445685', '06446000', '06445980', 
                            '06446500', '06446100', '06446700', 
                            '06447000', '06447230', '06447500', 
                            '06449000',  '06449100', '06440200',
                            '06441000'),
                     stringsAsFactors = FALSE)
# CHECK: long valley end date

gage <- map_dfr(gage_id$id, readNWISsite) 
gage <- gage %>%
  select(site_no, station_nm, dec_lat_va, dec_long_va, everything())
export(gage, "data/gage_meta.csv")

# site
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
site <- import("data/Chemistry-1993-2013_17Mar21.csv")
eco <- import("data/MacroSummaries.csv")

eco <- eco %>%
  clean_names() %>%
  select(1:2) %>%
  rename(id = station) %>%
  distinct(id, .keep_all = TRUE)
  
site <- site %>%
  clean_names() %>% 
  arrange(sample_sites) %>%
  filter(sample_sites != "Bear in the Lodge USGS1") %>% 
  filter(sample_sites != "Bear in the Lodge USGS2") %>%
  filter(sample_sites != "Bear in the Lodge USGS3") %>%
  filter(sample_sites != "Black Pipe II") %>% 
  filter(sample_sites != "Corn Creek I") %>%
  filter(sample_sites != "Little Corn Creek I") %>% 
  filter(sample_sites != "Medicine Root II") %>% 
  filter(sample_sites != "Porcupine Lagoon downstream") %>%
  filter(sample_sites != "Porcupine Lagoon upstream") %>%
  filter(sample_sites != "Pine Ridge Lift Station Downstream") %>%
  distinct(sample_sites, .keep_all = TRUE) %>%
  select(1:4) %>%
  select(-1) %>%
  rename(name = sample_sites) %>%
  rename(lat = latitude) %>%
  rename(lon = longitude) %>%
  mutate(lon = -1 * lon)

site_id <- data.frame(id = c("AMH1", "BEA1", "BEA2", "BEA3", "BEL1", 
                              "BEL2", "BLP1", "BUZ1", "CHR1", "CHR2",
                              "CRA1", "EAN1", "EAN2", "LWR1", "LWR2", 
                              "LWR3", "LWR4", "LON1", "LOD1",  "MER1", 
                              "MER2", "MER3", "MER4", "NFL1", "PAS1", 
                              "PAS2", "PAS3", "POR1", "POR2", "POR3", 
                              "POT1", "RED1", "WCC1", "WCC2", "WCC3", 
                              "WHR1", "WHR2", "WHR3", "WHR4", "WHR5", 
                              "WOL1", "WOK1", "WOK2", "WOK3", "WOK4"),
                       name = c("American Horse I", 
                               "Bear Creek I", 
                               "Bear Creek II", 
                               "Bear Creek III", 
                               "Bear in the Lodge I", 
                               "Bear in the Lodge II", 
                               "Black Pipe I", 
                               "Buzzard Creek I", 
                               "Cheyenne River I", 
                               "Cheyenne River II", 
                               "Craven Creek I", 
                               "Eagle Nest I", 
                               "Eagle Nest II", 
                               "Little White River I",  
                               "Little White River II", 
                               "Little White River III", 
                               "Little White River IV", 
                               "Long Creek I", 
                               "Lost Dog Creek I", 
                               "Medicine Root I", 
                               "Medicine Root II", 
                               "Medicine Root III", 
                               "Medicine Root IV", 
                               "No Flesh Creek I", 
                               "Pass Creek I", 
                               "Pass Creek II", 
                               "Pass Creek III", 
                               "Porcupine Creek I", 
                               "Porcupine Creek II", 
                               "Porcupine Creek III", 
                               "Potato Creek", 
                               "Red Water Creek", 
                               "White Clay Creek I", 
                               "White Clay Creek II", 
                               "White Clay Creek III", 
                               "White River I", 
                               "White River II", 
                               "White River III", 
                               "White River IV", 
                               "White River V", 
                               "Wolf Creek I", 
                               "Wounded Knee I", 
                               "Wounded Knee II", 
                               "Wounded Knee III", 
                               "Wounded Knee IV"),
                      stringsAsFactors = FALSE)

site <- full_join(site, site_id, by = "name")

site <- site %>%
  drop_na()

site <- full_join(site, eco, by="id")

site <- site %>%
  replace_na(list(ecoregion = "Tablelands")) %>%
  filter(id != "CHR1") %>%
  filter(id != "CHR2") %>%
  mutate(ecoregion = case_when(
    id == "WHR1" ~ "Tablelands",
    id == "WHR2" ~ "Badlands",
    id == "WHR3" ~ "Badlands",
    id == "WHR4" ~ "Badlands",
    id == "WHR5" ~ "Badlands",
    TRUE ~ as.character(ecoregion)))

rm(site_id, eco)
export(site, "data/site_meta.csv")
```

```{r voroni-diagram-initial}
# import location data 
sta_meta <- import("index/data/Archived/station_meta2.csv")
sta_meta <- sta_meta %>%
  filter(id != "GHCND:US1SDCS0027") # filters out hermosa (short rec.)

# define the study area using data from the 'maps' package
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# import polygon data - counties
counties <- map_data("county") 
counties <- subset(counties, region %in% 
   c("south dakota", "nebraska"))
prr <- subset(counties, subregion %in% 
   c("shannon", "jackson", "bennett"))

# create voroni line segments
voronoi <- deldir(sta_meta$lon, sta_meta$lat)

#Plot the points, voronoi lines, and annotate
# grabbed this code off of a website by googling 'Voroni diag. R'
ggplot(data = sta_meta, aes(x = lon, y = lat)) +
  geom_point(
    fill = rgb(70, 130, 180, 255, maxColorValue = 255),
    pch = 21,
    size = 4,
    color = "#333333") +   
  geom_segment(
    aes(x = x1, y = y1, xend = x2, yend = y2),
    size = 2,
    data = voronoi$dirsgs,
    linetype = 1,
    color = "#FFB958") +
  geom_polygon(data = prr, aes(x = long, y = lat, group = group), 
              color = "black", linetype = "dashed", fill = "NA") +
  theme_bw() +
  geom_text(data = sta_meta, aes(label = name), size = 2.5) +
  ggtitle("Original Theissen Polygon Map")

# Results: 
# We can drop Ainsworth, Harrison that are outside of study area &
# Oral would be better than Hot Springs for elev, location & coverage

#ggplot2::ggsave(filename = "theissen_init.png", 
#                width = 6, height = 6, units = "in")
```

```{r voroni-diagram-inter}
# import site location data and filter out:
#   hermosa, ainsworth, harrison, hot springs
sta_meta <- import("index/data/Archived/station_meta2.csv")
sta_meta <- sta_meta %>%
  filter(id != "GHCND:US1SDCS0027") %>% # very short length - HER
  filter(id != "GHCND:USC00250050") %>% # outside region - AIN
  filter(id != "GHCND:USC00253615") %>% # outside region - HAR
  filter(id != "GHCND:US1SDFR0001") %>% # close to oral - HOT
  filter(id != "GHCND:USC00395891") %>% # outside range - MUR
  filter(id != "GHCND:USC00394983") %>% # love - but stopped 2012 - LON
  filter(id != "GHCND:US1SDJK0006") 

# import gage location data
gage_meta <- import("index/data/gage_meta.csv")
  
# define the study area using data from the 'maps' package
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# import polygon data - counties
counties <- map_data("county") 
counties <- subset(counties, region %in% 
   c("south dakota", "nebraska"))
prr <- subset(counties, subregion %in% 
   c("shannon", "jackson", "bennett"))

# create voroni line segments
voronoi <- deldir(sta_meta$lon, sta_meta$lat)

#Plot the points, voronoi lines, and annotate
p_site <- ggplot(data = sta_meta, aes(x = lon, y = lat)) +
  geom_point(
    fill = rgb(70, 130, 180, 255, maxColorValue = 255),
    pch = 21,
    size = 4,
    color = "#333333") +   
  geom_segment(
    aes(x = x1, y = y1, xend = x2, yend = y2),
    size = 2,
    data = voronoi$dirsgs,
    linetype = 1,
    color = "#FFB958") +
  geom_polygon(data = prr, aes(x = long, y = lat, group = group), 
              color = "black", linetype = "dashed", fill = "NA") +
  theme_bw() +
  geom_text(data = sta_meta, aes(label = name), size = 2.5) +
  ggtitle("Final Theissen Polygon Map")
  
p_site +
  geom_point(data = gage_meta, aes(x = dec_long_va, 
                                   y = dec_lat_va),
    fill = rgb(70, 130, 180, 255, maxColorValue = 255),
    fill = rgb(70, 130, 180, 255, maxColorValue = 255)) 
  

#sta_meta <- as.tibble(sta_meta)
# final list of stations
# id                name                              
#  <chr>             <chr>                             
# 1 GHCND:USW00024090 RAPID CITY REGIONAL AIRPORT, SD US
# 2 GHCND:USC00396212 OELRICHS, SD US                   
# 3 GHCND:USC00394184 INTERIOR 3 NE, SD US              
# 4 GHCND:USC00391972 COTTONWOOD 2 E, SD US             
# 5 GHCND:USC00395638 MISSION 14 S, SD US               
# 6 GHCND:USC00396304 ORAL, SD US   

#ggplot2::ggsave(filename = "theissen_fin.png", 
#                width = 6, height = 6, units = "in")
# export(sta_meta, file = "index/data/sta_meta_fin.csv")
```

```{r voroni-diagram-final}
# import site location data and filter out:
#   hermosa, ainsworth, harrison, hot springs
sta_meta <- import("index/data/sta_meta_fin3.csv")

# import gage location data
gage_meta <- import("index/data/gage_meta.csv")
  
# define the study area using data from the 'maps' package
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# import polygon data - counties
counties <- map_data("county") 
counties <- subset(counties, region %in% 
   c("south dakota", "nebraska"))
prr <- subset(counties, subregion %in% 
   c("shannon", "jackson", "bennett"))

# create voroni line segments
voronoi <- deldir(sta_meta$lon, sta_meta$lat)

#Plot the points, voronoi lines, and annotate
p_site <- ggplot(data = sta_meta, aes(x = lon, y = lat)) +
  geom_point(
    fill = rgb(70, 130, 180, 255, maxColorValue = 255),
    pch = 21,
    size = 4,
    color = "#333333") +   
  geom_segment(
    aes(x = x1, y = y1, xend = x2, yend = y2),
    size = 2,
    data = voronoi$dirsgs,
    linetype = 1,
    color = "#FFB958") +
  geom_polygon(data = prr, aes(x = long, y = lat, group = group), 
              color = "black", linetype = "dashed", fill = "NA") +
  theme_bw() +
  geom_text(data = sta_meta, aes(label = name), size = 2.5) +
  ggtitle("Final Theissen Polygon Map")
  
p_site +
  geom_point(data = gage_meta, aes(x = dec_long_va, 
                                   y = dec_lat_va),
    fill = rgb(70, 130, 180, 255, maxColorValue = 255),
    fill = rgb(70, 130, 180, 255, maxColorValue = 255)) 
  

#sta_meta <- as.tibble(sta_meta)
# final list of stations
# id                name                              
#  <chr>             <chr>                             
# 1 GHCND:USW00024090 RAPID CITY REGIONAL AIRPORT, SD US
# 2 GHCND:USC00396212 OELRICHS, SD US                   
# 3 GHCND:USC00394184 INTERIOR 3 NE, SD US              
# 4 GHCND:USC00391972 COTTONWOOD 2 E, SD US             
# 5 GHCND:USC00395638 MISSION 14 S, SD US               
# 6 GHCND:USC00396304 ORAL, SD US   

#ggplot2::ggsave(filename = "theissen_fin.png", 
#                width = 6, height = 6, units = "in")
# export(sta_meta, file = "index/data/sta_meta_fin.csv")
```

```{r projectAreaMap}
# import point data
station <- import("index/data/station_meta2.csv")
gage <- import("index/data/gage_meta.csv")
site <- import("index/data/site_meta.csv")
site <- site %>% 
  mutate(ecoregion = as.factor(ecoregion))

site <- as_tibble(column_to_rownames(site, var = "id"))

# subset region using data from the 'maps' package
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# import polygon data - counties
counties <- map_data("county") 
counties <- subset(counties, region %in% 
   c("south dakota", "nebraska"))
prr <- subset(counties, subregion %in% 
   c("shannon", "jackson", "bennett"))

# import polygon data - state
sd_neb <- map_data("state")
sd_neb <- subset(sd_neb, region %in% 
   c("south dakota", "nebraska"))

# download a basemap from Google Maps
map_base <- ggmap::get_googlemap(center = c(lon = mean(gage$dec_long_va), 
lat = mean(gage$dec_lat_va)), zoom = 7, size = c(640, 640), 
style = c(feature = "terrain", element = "labels", 
          visibility = "off"), legend = "bottom")

# plot points on top of basemap
site_map <- ggmap(map_base) +
geom_polygon(data = prr, aes(x = long, y = lat, group = group), 
              color = "gray", linetype = "dashed", fill = "NA") +
geom_point(data = station, aes(x = lon, y = lat), 
           alpha = 1.0, size = 2, shape = 5, color = "red") +
geom_point(data = gage, aes(x = dec_long_va, y = dec_lat_va), 
           alpha = 1.0, size = 2, shape = 15, color = "blue") +
geom_point(data = site, aes(x = lon, y = lat, color = ecoregion, 
                            size = 2,label = rownames(site))) +
  geom_text(data = site, label = rownames(site), 
            size = 2, hjust = "left") +
    geom_text(data = station, aes(label = name, label.size = 1)) +
theme(legend.position = "bottom") +
ggtitle("Pine Ridge Reservation EMAP Stations", 
          subtitle = "Oglala Lakota, Jackson and Bennett Counties") +
xlab("") +
ylab("")

site_map
ggplot2::ggsave(filename = "site_map2.png", plot = site_map, 
                width = 6, height = 6, units = "in")

#ggplot2::geom_polygon(data = sd_neb, 
#              aes(x = long, y = lat, group = group), 
#              color = "black", fill = "NA") 

# plot points on top of basemap
site_map <- ggmap(map_base) +
geom_polygon(data = prr, aes(x = long, y = lat, group = group), 
              color = "gray", linetype = "dashed", fill = "NA") +
geom_point(data = station, aes(x = lon, y = lat), 
           alpha = 1.0, size = 2, shape = 5, color = "red") +
geom_point(data = site, aes(x = lon, y = lat, color = ecoregion, 
                            size = 1, label = rownames(site))) +
theme(legend.position = "bottom") +
ggtitle("Pine Ridge Reservation EMAP Stations", 
          subtitle = "Oglala Lakota, Jackson and Bennett Counties") +
xlab("") +
ylab("")


mtcars <- mtcars
p <- ggplot(mtcars, aes(wt, mpg, label = rownames(mtcars)))

p + geom_text()

#+  
  geom_polygon(data = prr, 
              aes(x = long, y = lat, group = group), 
              color = "black", fill = "red") +
  coord_fixed(1.3) +
  ggtitle("Pine Ridge Reservation", 
          subtitle = "Oglala Lakota, Jackson and Bennett Counties") +
  xlab("") +
  ylab("") +
  theme_minimal()
#map_full <- 
#print(map_full)

#ggmap(sq_map2) + 
#      geom_point(data = sisquoc, color = "red", size = 4) +
#      geom_text(data = sisquoc, aes(label = paste("  ", 
#      as.character(name), sep = "")), angle = 60, hjust = 0, 
#      color = "yellow")
```

```{r map-tutorial}
# I think this is to set for bookdown?
#title: Making Maps With R
#author: "Eric C. Anderson"
#output:
#  html_document:
#    toc: yes
#  bookdown::html_chapter:
#    toc: no
#layout: default_with_disqus

# Making Maps with R {#map-making-in-R} 
# https://raw.githubusercontent.com/eriqande/rep-res-course/master/lectures/making-maps-with-R.rmd

## Intro {#map-making-intro}
# old package ->  `maps` package for making simple outlines
# of maps and plotting lat-long points and paths on them.

# New packages -> `sp`, `rgdal`, and `rgeos` functionality of 
# traditional GIS packages (like ArcGIS, etc).  *Not covered*
  
# Middle way -> `ggmap` to tile detailed base maps from Google Earth 
# or Open Street Maps, upon which spatial data may be plotted.
# all the power of ggplot.  Goes out to different map servers and
# grabs base maps to plot things on, then it sets up the coordinate 
# system and writes it out as the base layer for further ggplotting.  
# *but does not support different projections*

# some standard map packages.
#install.packages(c("maps", "mapdata"))
#devtools::install_github("dkahle/ggmap")

# You need to translate the `maps` data into a data frame format for 
# `ggplot`.  `ggplot2` provides the `map_data()` function. 

# Syntax: `map_data("name")` where "name" is a quoted string of the 
# name of a map in the `maps` or `mapdata` package.

# Data Structure for ggplot & maps
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# `long` is longitude.  W of prime meridian = negative
# `lat` is latitude.
# `order` gives order that `ggplot` should "connect the dots"
# `region` and `subregion` tell what region or subregion a set of 
#    points surrounds.
# `group`  *Very_important!*  Controls whether adjacent points should 
#    be connected by lines.  Members of the same group get connected.
#    "having points in diff. groups means `ggplot` "lifts the pen" 

# A simple US map
# ~~~~~~~~~~~~~~~
# Plot using `geom_polygon()` draw lines between points & "close them 
#    up" (i.e. draws a line from the last point back to the 1st point)
# Map the `group` aesthetic to the `group` column
#    `x = long` and `y = lat` are the other aesthetics.
# 'coord_fixed(x)' is important when drawing maps to fix the relationship 
#    between one unit in the $y$ direction and one unit in the 
#    $x$ direction. If you change the window size or the size of the 
#    pdf file then the _aspect ratio_ remains unchanged.
#    the 'x' above is by visual inspection
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# gg1 <- map_data("usa") # prepare data as data frame for ggplot
# ggplot() + 
# geom_polygon(data = usa, aes(x=long, y = lat, group = group)) + 
# fill = NA, color = "red") + 
# coord_fixed(1.3)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Adding points to the map
# ~~~~~~~~~~~~~~~~~~~~~~~~
# To add black and yellow points to the map

# labs <- data.frame(
#   long = c(-122.064873, -122.306417),
#   lat = c(36.951968, 47.644855),
#   names = c("SWFSC-FED", "NWFSC"),
#   stringsAsFactors = FALSE
# )  
#
# gg1 + 
#   geom_point(data = labs, aes(x = long, y = lat), 
#   color = "black", size = 5) +
#   geom_point(data = labs, aes(x = long, y = lat), 
#   color = "yellow", size = 4)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# State maps
# ~~~~~~~~~~
# states <- map_data("state")
# dim(states)
# head(states)
# tail(states)

# Plot all the states, all colored a little differently
# As above, but map fill to `region` and state border lines are white
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ggplot(data = states) + 
#  geom_polygon(aes(x = long, y = lat, fill = region, group = group),
#               color = "white") + 
#  coord_fixed(1.3) +
#  guides(fill=FALSE)  # do this to leave off the color legend

# Plot a subset of states with the `subset` command
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# west_coast <- subset(states, region %in% 
#   c("california", "oregon", # "washington"))
#    
# ggplot(data = west_coast) + 
#   geom_polygon(aes(x = long, y = lat, group = group), 
#     fill = "palegreen", color = "black") +
# coord_fixed(1.3)

#### Zoom in on California and look at counties
# ca_df <- subset(states, region == "california")
#    head(ca_df)

# Now, let's also get the county lines there
 #   counties <- map_data("county")
 #   ca_county <- subset(counties, region == "california")

 #   head(ca_county)

# Plot the state first 
# but let's ditch the axes gridlines, and gray background by
# using the super-wonderful `theme_nothing()`.

#    ca_base <- ggplot(data = ca_df, mapping = aes(x = long, y = lat, 
# group = group)) + 
#      coord_fixed(1.3) + 
 #     geom_polygon(color = "black", fill = "gray")
#    ca_base + theme_nothing()

# Now plot the county boundaries in white:
#
#    ca_base + theme_nothing() + 
#      geom_polygon(data = ca_county, fill = NA, color = "white") +
# get the state border back on top
#      geom_polygon(color = "black", fill = NA)  
```

```{r ggmap}
## ggmap {#ggmap-hooray}----

# The `ggmap` package is the most exciting R mapping tool in a long 
# time!  You might be able to get better looking maps at some 
# resolutions by using shapefiles and rasters from 
# naturalearthdata.com
# but `ggmap` will get you 95% of the way there with only 5% of the 
# work!

### How ggmap works

# ggmap simplifies the process of downloading base maps from Google or 
# Open Street Maps or Stamen Maps to use in the background of your 
# plots. It also sets the axis scales, etc, in a nice way.  
# Once you have gotten your maps, you make a call with `ggmap()` much 
# as you would with `ggplot()`
# Let's do by example.

### Sisquoctober
# Here is a small data frame of points from the Sisquoc River.
sisquoc <- read.table("data/sisquoc-points.txt", sep = "\t", header = TRUE)
# notes: ggmap tends to use "lon" instead of "long" for longitude.

# make a bounding box
# ~~~~~~~~~~~~~~~~~~~
# `ggmap` typically asks you for a zoom level, 
# But we can try using `ggmap`'s `make_bbox` function to make a boun

sbbox <- make_bbox(lon = sisquoc$lon, lat = sisquoc$lat, f = .1)

# Now, when we grab the map ggmap will try to fit it into that 
# bounding box by first getting the map. 
# By default it gets it from Google.  I want it to be a satellite map

# Wrong way!
# ~~~~~~~~~~
# sq_map <- get_map(location = sbbox, maptype = "satellite", 
#                  source = "google")
# ggmap(sq_map) + geom_point(data = sisquoc, 
#                          mapping = aes(x = lon, y = lat), 
#                           color = "red")

# Nope! That was a fail, but we got a warning about it too. 
# (Actually it is a little better than before because I hacked `ggmap` 
# a bit...) 

# Using the zoom level in ggmap 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#  Zoom levels go from 3 (world scale to 20 (house scale)).
#    compute the mean lat and lon

# ggmap-satelite
ll_means <- sapply(sisquoc[2:3], mean)

sq_map2 <- get_map(location = ll_means,  maptype = "satellite", source = "google", zoom = 15)

ggmap(sq_map2) + 
      geom_point(data = sisquoc, color = "red", size = 4) +
      geom_text(data = sisquoc, aes(label = paste("  ", 
      as.character(name), sep = "")), angle = 60, hjust = 0, 
      color = "yellow")


# ggmap-terrain
# Use the "terrain" type of ggmap - with bad lettering

sq_map3 <- get_map(location = ll_means,  
                   maptype = "terrain", source = "google", 
                   zoom = 15)
ggmap(sq_map3) + 
      geom_point(data = sisquoc, color = "red", size = 4) +
      geom_text(data = sisquoc, 
                aes(label = paste("  ", as.character(name), 
                                  sep = "")), angle = 60, 
                hjust = 0, color = "yellow")

#  ggmap-gps
# plot a gps route----
# Map elevation to the color of the path using rainbow colors.

# The right zoom and position for the map is trial and error.  
# Go to Google maps to figure out where the center should be (right click and choose "What's here?" to get the lat-long of any point. )
# The `make_bbox` function has never really worked for me.
bike <- read.csv("data/bike-ride.csv")

bikemap1 <- get_map(location = c(-122.080954, 36.971709), 
                    maptype = "terrain", source = "google", zoom = 14)

ggmap(bikemap1) + 
      geom_path(data = bike, aes(color = elevation), size = 3, 
                lineend = "round") + 
      scale_color_gradientn(colours = rainbow(7), 
                            breaks = seq(25, 200, by = 25))
    

# fish-sampling
### Fish sampling locations
# Example - coded wire tag data base to georeferenced marine locations 

# I did all that you can check out 
# [this](https://github.com/eriqande/pbt-feasibility/blob/4ea2fc960f74f66b5ec3a11c107cdc52bfb346dc/Rmd/02-02-explore-recovery-and-catch-sample-data.Rmd#looking-at-locations-of-location-codes)

# The data are hierarchically structured.  Author is interested in how 
# close together sites in the same "region" or "area" or "sector" are, 
# and pondering whether it is OK to aggregate fish recoveries at a 
# certain level for the purposes of getting a better overall estimate 
# of the proportion of fish from different hatcheries in these areas.

# So, pretty simple stuff.  I just want to plot these points on a map, 
# and paint them a different color according to their sector, region, 
# area, etc.

# bc <- readRDS("data/bc_sites.rds")

# look at some wide georeferenced data (1,113 observations)
# bc %>% select(state_or_province:sub_location, longitude, latitude)

# Enumerate using `dplyr`:
# bc %>% 
# group_by(sector, region, area) %>%
# tally()

# That looks good.  It appears like we could probably color code over 
# the whole area down to region, and then down to area within 
# subregions.

#### Makin' a map.

# Let us try again to use `make_bbox()` to see if it will work better 
# when used on a large scale.

# compute the bounding box
bc_bbox <- make_bbox(lat = latitude, lon = longitude, data = bc)
bc_bbox

# grab the maps from google
bc_big <- get_map(location = bc_bbox, source = "google", 
                  maptype = "terrain")

# * Cool! That was about as easy as could be.  North is in the north, 
# south is in the south, and  the three reddish points are clearly 
# aberrant ones at the mouths of rivers.

# Plot the points and color them by sector
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ggmap(bc_big) + 
  geom_point(data = bc, mapping = aes(x = longitude, y = latitude, 
                                      color = sector))


# r ggmap-coloring
#### Coloring it by region

# We should be able to color these all by region to some extent 
# (it might get overwhelming), but let us have a go with it.
# Notice that region names are unique overall (not just within N or S) so we can just color by region name.

ggmap(bc_big) + 
  geom_point(data = bc, mapping = aes(x = longitude, y = latitude, color = region))

# Once again that was dirt easy, though at this scale with all the different regions, it is hard to resolve all the colors.


# ggmap-zoom-in
#### Zooming in on each region and coloring by area

# Use a function to make a series of maps: one for each region, in 
# which the areas in that region are colored differently.
# Approach: you pass it the region and it makes the plot.

region_plot <- function(MyRegion) {
  tmp <- bc %>% filter(region == MyRegion)
  bbox <- make_bbox(lon = longitude, lat = latitude, data = tmp)
  mymap <- get_map(location = bbox, source = "google", 
                   maptype = "terrain")
  
# now we want to count up how many areas there are
NumAreas <- tmp %>% summarise(n_distinct(area))
NumPoints <- nrow(tmp)
  
the_map <- ggmap(mymap) +
    geom_point(data = tmp, mapping = aes(x = longitude, y = latitude), 
               size = 4, color = "black") +
    geom_point(data = tmp, mapping = aes(x = longitude, y = latitude, 
                                         color = area), size = 3) +
    ggtitle(
      paste("BC Region: ", MyRegion, " with ", NumPoints, 
            " locations in ", NumAreas, " area(s)", sep = "")
      )

ggsave(paste("bc_region", MyRegion, ".pdf", sep = ""), the_map, 
       width = 9, height = 9)
}

dump <- lapply(unique(bc$region), region_plot)
```

