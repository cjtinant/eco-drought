---
title: "02-chapt2-5_study-area"
author: "CJ Tinant"
date: "8/06/2019"
output: html_document 
---

<!--
Purpose: 
Refactors prior code to develop tables and plots for the study area description 
section of Chapter 2 

Data:
Predominant datasets used are:  
1) USGS daily streamflow and station metadata,  
2) Summary data from a QGIS analysis of ungaged watersheds of interest.  

Approach: 
1) find potential USGS gages by bounding box 
     bBox = a contiguous range of decimal latitude and longitude, starting 
     with the west longitude, then the south latitude, then the east longitude, 
     and then the north latitude with each value separated by a comma. 
# https://waterservices.usgs.gov/rest/Site-Service.html#bBox 
# the Pine Ridge Reservation boundary is c(-103.0, 43.0, -100.2, 43.8)

2) filter gages for the following reasons
     - upstream control, 
     - in crystaline or karst catchments
     - provisional data 
     - (sigh) overlooked in the first data screening from 1990-2017 

3) clean metadata by removing non-needed variables  

4) obtain USGS gage daily flow data

5) filter stations based on record length 
    - no data gages for 1980-2018 water years 
    - less than 6-years of continuous data for 1990-2018
      for filtering info see: https://help.waterdata.usgs.gov/site_tp_cd 

6) create metadata tables 
    - gage_table - summary of gage metadata 
    - ung_table - summary of ungaged watershed metadata 
    - soils_table - summary of geology, soils, and vegetation 



Next Steps: 
-- line up gage_dv (n=474,070) with prior download data (n=438,231)
-- check into stylr-packag

Variable naming convention:   
# ~~~~~~~~~~~~~~~~~~~~~~~~~
gage_poss           possible USGS gaging stations in the study area 
gage_meta_poss      metadata for possible gaging stations
-- _int1            scratch df for pulling gages with integer fields 
-- _int2            scratch df for pulling gages with integer fields 
-- _char            scratch df for pulling gages with character fields 

gage_meta           cleaned metadata for USGS gaging stations in the study area 
  "site_no"                site number     
  "station_nm"             station name     
  "dec_lat_va"             latitude value in decimal degrees 
  "dec_long_va"            longitude value in decimal degrees 
  "state_cd"               State code
  "county_cd"              County code
  "alt_va"                 altitude 
  "huc_cd"                 hydrologic unit code 
  "drain_area_va"          drainage area ???in square miles???
  "contrib_drain_area_va"  contributing drainage area ???in square miles???

endDate             used for calling Egret::readNWISDaily 
parameter_cd        used for calling Egret::readNWISDaily 
startDate           used for calling Egret::readNWISDaily 

lon_riv_dv          scratch df for pulling lon_riv 
gage_most_dv        scratch df for pulling !lon_riv 
yrs_rec             calculates years of record 
gage_dv             daily flow values for waterYear 1980-2017 

wsd_summary     zonal statistics of watershed environmental parameters 
*   "_id"       unique id
*  "_sta_id"    four- or seven-digit station ID   
   "_type "     distinguishes gaged from ungaged 
   "_watshed"   describes the HUC06 watershed 
   "_HUC12"     hydrologic unit code 12
   "_sta_name"    station name derived from outlet HUC12 catchment name
   "_gage_num"    USGS site number 
   "_gage_nm"     station name from USGS gage
   "_dec_lat"     latitude in decimal degrees
   "_dec_lon"     longitude in decimal degrees
   "_cat_area"    catchment area in sq km
*  "_cat_area_l"  natural logarithm of catchment area 
   "_cat_length"  catchment length
   "_cat_width"   catchment width
*  "_lw_ratio"    catchment length divided by catchment width
   "_str_len"     stream length
*  "_drain_dens"  stream length divided by catchment area
*  "_prcp_mean"   areal mean precipitation depth 1992-2012
*  "_t07_mean"    average July temperature 1992-2012
*  "_vpd_ann"     areal mean of max vapor deficit 1992-2012
*  _"vpd_07"      areal mean of max July vapor deficit 1992-2012
*  "_cat_out"     catchment outlet elevation
*  "_cat_rel"     difference in max and min elevation
*  "_slop_med"    median percent slope
*  "_TWI_mean"    mean terrain wetness index
*  "_perc_cov"    percent forest cover from NLCD 2016
*  "_fc_mean"     mean field capacity
*  "_ksat_mean"   mean horizontal saturated hydraulic conductivity
*  "_kvert_mean"  mean vertical saturated hydrologic conductivity 

gage_table        summary of gage metadata for flextable 
ung_table         summary of ungaged watershed metadata for flextable  
soils_table       summary of geology, soils, and vegetation for flextable  

the tables above use flextable control keys: 
col_key_char      controls character elelements for flextables
col_key_int       controls integer elelements for flextables
col_key_num       controls numeric elelements for flextables

--> 

```{r setup, include=FALSE, message=FALSE}  
#knitr::opts_chunk$set(echo = FALSE)   
options(tibble.print_max = 70) # sets tibble output for printing   

# Sets up the library of packages   
library("here")                   # identifies where to save work  
library("EGRET")                  # Exploration and Graphics for RivEr Trends 
library("rio")                    # more robust I/O - to import and clean data  
library("lubridate")              # easier dates 
library("janitor")                # tools for examining and cleaning dirty data  
library("dataRetrieval")          # USGS data import  
library("measurements")           # eases measurement system manipulation 
library("flextable")              # construct complex table with 'kable'  
library("officer")                # facilitates '.docx' access for table export 
library("tidyverse")              # data munging tools 
```

```{r import_daily_flow_metadata, eval=FALSE} 
gage_poss <- whatNWISsites(bBox = c(-103.8, 42.2, -99.2, 44.6),  
                       parameterCd = "00060", 
                       hasDataTypeCd = "dv") %>% 
  arrange(site_no)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 2. get metadata 
# this needs to be run in parts because some project numbers & 
# inventories are stored as integers & others are stored as characters 

gage_meta_int1 <- gage_poss %>% 
    slice(7, 17, 142, 148) %>% 
  split(.$site_no) %>% 
  map_dfr(~ readNWISsite(siteNumbers = .$site_no)) %>% 
  select(-c(project_no, inventory_dt)) 

gage_meta_int2 <- gage_poss %>% 
    slice(94) %>% 
  split(.$site_no) %>% 
  map_dfr(~ readNWISsite(siteNumbers = .$site_no)) %>% 
  select(-c(project_no, inventory_dt)) 

gage_meta_int3 <- gage_poss %>% 
    slice(-c(7, 17, 94, 142, 148)) %>% 
  split(.$site_no) %>% 
  map_dfr(~ readNWISsite(siteNumbers = .$site_no)) %>% 
  select(-c(project_no, inventory_dt)) 

# 3. join gage metadata 
gage_meta_poss <- bind_rows(gage_meta_int1, 
                            gage_meta_int2, 
                            gage_meta_int3)  

gage_meta_poss <- gage_meta_poss %>% 
  mutate(site_no = zeroPad(site_no, 8)) 

# clean up
rm(gage_meta_int1, gage_meta_int2, gage_meta_int3, gage_poss) 

# 4. export metadata to data folder 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
export(gage_meta_poss, "data/gage_meta_poss.csv")  
```

```{r clean_gage_metadata}
gage_meta_poss <- import("data/gage_meta_poss.csv")  

# 1. remove gages that do not meet standards 
gage_meta <- gage_meta_poss %>%   
  mutate(site_no = as.character(site_no)) %>% 
  mutate(site_no = zeroPad(site_no, 8)) %>%              # pad site_no  
  mutate(reliability_cd = replace_na(reliability_cd, 0))  %>% #  NA <- zero 
  filter(site_no != "06461150"& 
         site_no != "06463670"&  
         site_no != "06461595") %>%  # remove short sites with provisional data 
  filter(site_no != "06441000") %>%  # only active 180 days/yr 
  filter(site_no != "06438000") %>% 
  filter(site_no != "06437000") %>%  # remove northern Black Hills stations 
  filter(site_no != "06442718") %>%  # remove East River stations
  filter(reliability_cd != "M") %>% # M is minimal data 
  filter(!str_detect(station_nm, 'DAM|DITCH|DRAIN')) %>% # upstream control 
  filter(!str_detect(station_nm, 
                     'CUSTER|KEYSTONE|HILL CITY|HAYWARD')) %>% 
  filter(site_no != "06424000") %>% 
  # crystaline catchments 
  filter(!str_detect(station_nm, 
                     'LEAD|DEADWOOD|WHITEWOOD')) %>%   
  # crystaline catchments 
  filter(!str_detect(station_nm, 'CLEGHORN')) %>% # karstic? spring 
  filter(!str_detect(station_nm, 'BOXELDER|LIME')) %>% # karstic 
  filter(!str_detect(station_nm, 'RAPID')) %>%   
  # Rapid Creek & upper Spring Creek 
  filter(!str_detect(station_nm, 'MISSOURI'))

# 2. remove provisional sites 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_meta <- gage_meta %>% 
  mutate(site_no = as.character(site_no)) %>% 
  select(-reliability_cd) %>% 
  mutate(length = str_length(site_no)) %>% 
  filter(length <= 8) %>%   # removes two provisional sites 
  select(-length)

# 3. remove codes not needed for this project 
gage_meta <- gage_meta %>% 
  select(-agency_cd) %>% 
  select(-site_tp_cd) %>% # all streams so delete 
  select(-c(lat_va, long_va)) %>% # in DMS so delete 
  select(-c(coord_meth_cd, coord_acy_cd)) %>% # coord method & agency, so delete 
  select(-c(coord_datum_cd, dec_coord_datum_cd)) %>% # NAD83 or NAD27 
  select(-c(district_cd, country_cd)) %>% # Congressional dist & Country 
  select(-c(land_net_ds, map_nm, map_scale_fc)) %>%  # refers to USGS maps 
  select(-c(alt_meth_cd, alt_datum_cd, alt_acy_va)) %>% #%>% # altitude metadata  
  select(-c(basin_cd, topo_cd, instruments_cd)) %>% 
  select(-c(construction_dt)) %>% 
  select(-c(tz_cd, local_time_fg)) %>% # daily data, so NA 
  select(-c(gw_file_cd, nat_aqfr_cd, aqfr_type_cd, aqfr_cd)) %>% 
  select(-c(well_depth_va, hole_depth_va, depth_src_cd)) 

```

```{r add_names_to_gage_meta}

# get data from QGIS analysis of gaged & ungaged watersheds of interest 
wsd_summary <- st_read("sp_data/eco-drought.gpkg", 
                       layer = "wbd_summary", 
                       as_tibble = TRUE) %>% 
  st_drop_geometry() %>% 
  mutate_if(is.factor, as.character) 

# join names to gage_meta  
names <- wsd_summary %>% 
  select(site_no = gage_num, sta = sta_id) %>% 
  drop_na() %>% 
  mutate(site_no = zeroPad(site_no, 8)) 

gage_meta <- full_join(names, gage_meta, 
                     by ="site_no")  

```


```{r import_daily_flow_data} 

# set parameters for Egret::readNWISDaily 
startDate    <- "1979-08-01" # pulling two months early to get Q7 & Q30 
endDate      <- "2018-09-30" 
parameter_cd <- "00060" 

# get daily flows ------------------------------------------------------------ 
# Long River gage needs to be called separately or it creates an error 
gage_lonriv_dv <- gage_meta %>% 
  filter(site_no == "06463500") %>% 
  split(.$site_no) %>% 
  map_dfr(~ readNWISDaily(
    siteNumber = .$site_no, 
    parameter_cd, 
    startDate, 
    endDate), 
    .id = "site_no") 

gage_most_dv <- gage_meta %>% 
  filter(site_no != "06463500") %>%           # drop long river from call 
  split(.$site_no) %>% 
  map_dfr(~ readNWISDaily(
    siteNumber = .$site_no, 
    parameter_cd, 
    startDate, 
    endDate), 
    .id = "site_no") 

# join into a single dataframe, remove add names, & clean up   
gage_dv <-bind_rows(gage_most_dv, gage_lonriv_dv) 

gage_dv <- gage_dv %>% 
  filter(waterYear > "1979")

gage_dv <- full_join(names, gage_dv, 
                     by ="site_no")  

rm(startDate, endDate, parameter_cd)

``` 

```{r filter_short_flow_recs}

# 1. prepare to filter gages with short flow records---------------------------
# calculate min & max years of record 
yrs_summary <- gage_dv %>% 
  group_by(site_no) %>%                  
  summarise(years_rec = n_distinct(waterYear),  
            min_year = min(waterYear),  
            max_year = max(waterYear)  
            ) %>%                    
  ungroup() %>% 
  mutate(apparent_yrs = 1 + max_year - min_year) 

gage_meta <- full_join(yrs_summary, gage_meta,      # N = 88 
                       by = "site_no") 
rm(yrs_summary)

# 2. filter gages with less than 6 years of record----------------------------  
# filter gages with no records 
gage_check <- gage_meta %>% 
  filter(is.na(years_rec)) 

gage_meta <- gage_meta %>% 
  filter(!is.na(years_rec))                           # N = 69

# 06400500 CHEYENNE R NEAR HOT SPRINGS SD
# 06403500 FRENCH CR NEAR FAIRBURN SD
# 06404500 BATTLE CR NEAR HERMOSA SD
# 06424500 ELK CR ABOVE PIEDMONT SD
# 06437200 BEAR BUTTE CR NEAR GALENA,SD
# 06437500 BEAR BUTTE CR NEAR STURGIS SD
# 06440500 NORTH FORK BAD R NEAR PHILIP SD
# 06445000 WHITE R BELW COTTONWOOD C N WHITNEY, NEBR.
# 06445500 WHITE R NEAR CHADRON NEBR
# 06446200 WHITE R NEAR ROCKYFORD SD
# 06449250 SPRING CR NEAR ST FRANCIS SD
# 06455900 NIOBRARA RIVER NEAR DUNLAP, NEBR.
# 06456500 NIOBRARA RIVER NR HAY SPRINGS, NEBR.
# 06457000 NIOBRARA RIVER NEAR COLCLESSER, NEBR.
# 06458500 BEAR C NR ELI NEBR
# 06459000 NIOBRARA R NEAR CODY, NEBR.
# 06460900 MINNECHADUZA CREEK NEAR KILGORE, NEBRASKA
# 06463000 NIOBRARA RIVER AT MEADVILLE NE
# 06464000 KEYA PAHA R NEAR HIDDEN TIMBER SD 

# drop stations with less than 6 years of record  
gage_check <- gage_meta %>% 
  filter(years_rec < 6) 

gage_meta <- gage_meta %>% 
  filter(years_rec >= 6)                         # N = 58 

# The following were removed because less than 6 years of record  
# 06400870 HORSEHEAD CR NEAR OELRICHS SD
# 06405400 GRACE COOLIDGE CR NEAR FAIRBURN SD
# 06405500 GRACE COOLIDGE CR NEAR HERMOSA SD
# 06437400 BEAR BUTTE CREEK AT STURGIS, SD
# 06441400 WILLOW CREEK NEAR FORT PIERRE, SD
# 06442130 CEDAR CREEK NR PRESHO, SD
# 06442600 MEDICINE CREEK NR LOWER BRULE, SD
# 06442950 CROW CR NEAR GANN VALLEY SD
# 06445590 BIG BORDEAUX CREEK NEAR CHADRON NEBR
# 06459200 SNAKE RIVER ABV MERRITT RESERVOIR NEBR
# 10150005 Big Beaver Cr at Nebr Hwy 12 nr Valentine, Nebr


# 3. check for incomplete days of record --------------------------------------  
yr_incomp <- gage_dv %>%                          
  group_by(site_no, waterYear) %>%                  
  summarise(days_yr = n()) %>%                    
  ungroup() %>% 
  filter(days_yr < 360) %>% 
  group_by(site_no) %>%   
  summarise(yrs_incomp = n()) %>%    
  ungroup() 

gage_meta <- full_join(yr_incomp, gage_meta,  
                       by = "site_no") %>% 
  filter(!is.na(years_rec))

# 4. remove data with short record between 1990-2015 ------------------------- 

gage_check <- gage_meta %>% 
  filter(is.na(sta))
  
gage_meta <- gage_meta %>% 
  filter(!is.na(sta))

## These didn't make the cut because the original data selection was 
# for 1990-2015  & it would be extremely difficult to put in post-hoc.
# it would be good for the future! 
# Also - its possible to use these for model testing...

# station   min_yr  maxyr  name 
# 06442000   1980   1990   MEDICINE KNOLL CR NEAR BLUNT SD 
# 06459175   1982   1995   SNAKE R AT DOUGHBOY, NE
# 06459500   1980   1995   SNAKE RIVER NEAR BURGE, NEBR. 
# 06454100   1980   1992   Niobrara River at Agate, Nebr. 
# 06461000   1980   1995   MINNECHADUZA CREEK AT VALENTINE, NEBR.
# 06462500   1980   1995   PLUM CREEK AT MEADVILLE, NE
# 06463720   2012   2018   Niobrara River at Mariaville, Nebr. 
# 06400497   1980   1995   CASCADE SPRINGS NEAR HOT SPRINGS SD  
# 06462000   1980   1986   NIOBRARA RIVER NR NORDEN NEBR
# 06463080   1980   1991   LONG PINE CREEK NR LONG PINE, NE
# 06439300   1980   1994   CHEYENNE RIVER AT CHERRY CREEK,SD
# 06442500   1980   1990   MEDICINE CR AT KENNEBEC SD
# 06444000   1980   2004   White River at Crawford, Nebr.
# 06454500   1980   1994   NIOBRARA RIVER ABOVE BOX BUTTE RESERVOIR, NE
# 06455500   1980   1991   NIOBRARA RIVER BELOW BOX BUTTE RESERVOIR NEBR
# 06457500   1980   1991   NIOBRARA RIVER NEAR GORDON, NEBR.

rm(gage_check, yr_incomp, names) 

# sync gage_dv with gage_meta & export results as posthoc to avoid interference 
gage_dv <- semi_join(gage_dv, gage_meta, 
                     by = "site_no")   

export(gage_dv, "data/gage_dv_posthoc.csv") 
```

```{r prepare-table_gage_metadata}
 
# prepare df for gaging station metadata  
gage_table <- gage_meta %>%  
  mutate(contrib_drain_area_va = 
           coalesce(contrib_drain_area_va, drain_area_va) 
  ) %>% 
  mutate(alt_si = 
           conv_unit(alt_va, "ft", "m")
         ) %>% 
  mutate(contrib_drain_area_si = 
           conv_unit(contrib_drain_area_va, "mi2", "km2")
         ) 

gage_table$years_rec <-  as.integer(gage_table$years_rec) 

gage_table <- gage_table %>% 
select(site_no, station_nm, dec_lat_va, dec_long_va, alt_si, years_rec, 
         contrib_drain_area_si) 

# set column keys for flextable -- these variables also used below 
col_key_num <-gage_table %>% 
  select(dec_lat_va:alt_si, contrib_drain_area_si) %>% 
  names() 

col_key_int <-gage_table %>% 
  select(years_rec, site_no) %>% 
  names() 

# convert tibble to a flextable 
gage_table <- flextable(gage_table) %>% 
  colformat_num(col_keys = col_key_num, 
                big.mark=",", 
                digits = 1, na_str = "N/A") %>% 
  set_header_labels(site_no = "Sta. Number", 
                    station_nm = "Name", 
                    dec_lat_va = "Latitude", 
                    dec_long_va = "Longitude", 
                    alt_si = "Elevation, m", 
                    years_rec = "Years of Record", 
                    contrib_drain_area_si = "Drainage Area, sq-km") %>% 
  autofit() %>% 
  theme_booktabs() 

```

```{r prepare-table_ungaged_metadata}

# prepare df for ungaged watershed metadata 
ung_table <- wsd_summary %>% 
  filter(type == "ungaged") %>% 
  select(HUC12, sta_id, sta_name, dec_lat, dec_lon, cat_out, cat_area)  

# set column keys for flextable 
col_key_num <- ung_table %>% 
  select(dec_lat, dec_lon, cat_out, cat_area) %>% 
  names() 

col_key_int <-ung_table %>% 
  select() %>% 
  names() 

# convert tibble to a flextable 
ung_table <- flextable(ung_table) %>% 
  colformat_num(col_keys = col_key_num, 
                big.mark=",", 
                digits = 1, na_str = "N/A") %>% 
  set_header_labels(HUC12 = "Hydrologic Unit Code", 
                    sta_id = "Station Id", 
                    sta_name = "Name", 
                    dec_lat = "Latitude", 
                    dec_lon = "Longitude", 
                    cat_out = "Elevation, m", 
                    cat_area = "Drainage Area, sq-km") %>% 
  autofit() %>% 
  theme_booktabs() 

```

```{r prepare-table_soils}

# prepare data for soils table 
soils_table <- tibble(
  order = c(6, 5, 4, 3, 2, 1), 
  geo_age = c("Quaternary", "Tertiary", "Tertiary", 
              "Tertiary", "Cretaceous", "Cretaceous"), 
  geo_units = c("Eolean deposits", "Arikaree Group", "Arikaree Group", 
            "White River Group", "Pierre Formation", "Inyan Kara Group"), 
  ecoregion_lvl4	= 
    c("Nebraska Sand Hills", 
      "Keya Paha Tablelands", 
      "Pine Ridge Escarpment", 
      "White River Badlands", 
      "Pierre Shale Plains", 
      "Black Hills Foothills"), 
  soil_order = c("Entisols", 
                 "Entisols, Mollisols", 
                 "Entisols, Mollisols", 
                 "Aridisols, Entisols, Inceptisols", 
                 "Mollisols", 
                 "Alfisols, Entisols"),
  vegetation = 
    c("Sand bluestem, Little bluestem, Prairie sandreed, Big bluestem, Switchgrass", 
      "Blue grama, Sideoats grama, Western wheatgrass, Little bluestem, Needleandthread", 
      "Ponderosa pine, Eastern redcedar, Western snowberry, Skunkbush sumac, Chokecherry, Prairie rose, Little bluestem, Western wheatgrass, Green needlegrass, Prairie sandreed", 
    "Sand sagebrush, Silver sagebrush, Western wheatgrass, Blue gramma, Sideoats grama, Buffalograss", 
    "Little bluestem, Buffalograss", 
    "Ponderosa pine, Little bluestem, Western wheatgrass, Sideoats gramma") 
    ) %>% 
  arrange(order)

# export table for import later 
#export(soils_table, "data/soils_table.csv")

#print.noquote(names(soils_table))

# set column keys for flextable 
col_key_char <- soils_table %>% 
  select(geo_age, geo_units, ecoregion_lvl4, soil_order, vegetation) %>% 
  names() 

# convert tibble to a flextable 
soils_table <- flextable(soils_table) %>% 
   colformat_char(col_keys = col_key_char) %>% 
  set_header_labels(geo_age = "Geologic age", 
                    geo_units = "Major geologic unit", 
                    ecoregion_lvl4	= "Level IV ecoregion", 
                    soil_order = "Soil order", 
                    vegetation = "Major vegetation types") %>% 
  autofit() %>% 
  theme_booktabs()  
```

```{r prepare-table_hydro_metrics}

# prepare df for hydrologic metric table 
hydro_table <- wsd_summary %>% 
  select(type, cat_area, lw_ratio, drain_dens, prcp_mean, t07_mean, vpd_ann, 
         vpd_07, cat_out, cat_rel, slop_med, TWI_mean, perc_cov, fc_mean, 
         ksat_mean, kvert_mean) %>% 
  gather(metric, value, -type) %>% 
  group_by(metric, type) %>% 
  summarize(max = max(value), 
            median = median(value), 
            min = min(value)) %>% 
  ungroup() %>% 
  modify_if(is.numeric, ~round(., digits = 1)) %>% 
  gather(key, stat, -c(type, metric)) %>% 
  unite_("combined", c("key","type")) %>% 
  spread(combined, stat) %>% 
  select(metric, max_gaged, median_gaged, min_gaged, 
         max_ungaged, median_ungaged, min_ungaged) 

# add additional columns 
hydro_tab2 <- tibble(metric = hydro_table$metric, 
                     type = c("planimetric", "elevation", "elevation", 
                              "planimetric", "soils", "soils", "soils", 
                              "planimetric", "cover", "climate", 
                              "elevation", "climate", "elevation", "climate",   
                              "climate"), 
                     transformation = c("1/ln(x)", "sqrt(x)", "sqrt(x)", 
                                        "none", "none", "ln(x)", "ln(x)", 
                                        "ln(x)", "ln(x)", "x^2", "ln(x)", 
                                        "x^2", "x^2", "x^2", "x^2"), 
                     description = c("catchment area", 
                                     "catchment outlet elevation", 
                                     "catchment relief", 
                                     "drainage density", 
                                     "field capacity", 
                                     "forested area (proportion of catchment)", 
                                     "horizontal saturated hydraulic conductivity", 
                                     "vertical saturated hydraulic conductivity", 
                                     "catchment length to width ratio", 
                                     "mean annual precipitation", 
                                     "median catchment slope", 
                                     "mean July temperature", 
                                     "mean topographic wetness index value", 
                                     "July maximum vapor pressure deficit", 
                                     "annual maximum vapor pressure deficit"), 
                     units = c("hectares", "meters", "meters", 
                               "km per square km", "meters per meter", 
                               "sq. meters per sq. meter", "micrometers/sec", 
                               "micrometers/sec", "meters per meter", 
                               "millimeters", "percent", "Centigrade", 
                               "dimensionless", "kilopascals", "kilopascals"), 
                     base_data = c("USGS metadata & feature geometry", "NED", 
                     "NED", "NED", "SSURGO", "NLCD", "SSURGO", "SSURGO", 
                     "feature geometry", "PRISM", "NED", "PRISM", "NED", 
                     "PRISM", "PRISM")
                     ) 

hydro_table <- full_join(hydro_table, hydro_tab2, 
                         by = "metric"
                         )  

hydro_table <- hydro_table %>% 
  select(metric, type, transformation, description, 
         units, base_data, everything()) %>% 
  arrange(type) 

# set column keys & header labels for flextable 
col_key_num <- hydro_table %>% 
  select(-metric) %>% 
  names() 

header_labels <- c(
    metric = "Indicator", 
    type = "Indicator type",       
    transformation = "Transformation", 
    description = "Description",
    units = "Units", 
    base_data = "Base data",    
    max_gaged = "max", 
    median_gaged = "median", 
    min_gaged = "min",      
    max_ungaged = "max", 
    median_ungaged = "median", 
    min_ungaged = "min"
    )    

top_row <- c("", "", "", "", "", "", "Gaged", "Gaged", "Gaged", 
             "Ungaged", "ungaged", "Ungaged")  

hydro_table <- hydro_table %>% 
  flextable() %>% 
  theme_booktabs() %>% 
  colformat_num(col_keys = col_key_num, 
                big.mark=",", 
                digits = 1, na_str = "N/A") %>% 
  set_header_labels(values = header_labels) %>% 
  add_header_row(values = top_row, 
  top = TRUE) %>% 
  merge_at(i = 1, j = 7:9, part = "header") %>% 
  merge_at(i = 1, j = 10:12, part = "header") %>% 
  autofit() 

hydro_table

```

```{r export_flextables_as_docx} 
 
# export a docx of flextables 
tables_ch2 <- read_docx() %>% 
  body_add_flextable(value = gage_table)  %>% 
  body_add_break() %>% 
  body_add_flextable(value = ung_table) %>%  
  body_add_break() %>% 
  body_add_flextable(value = soils_table) %>% 
  body_add_break() %>% 
  body_add_flextable(value = hydro_table) 

print(tables_ch2, target = "output/tables_ch2.docx") 

rm(col_key_char, col_key_int, col_key_num, header_labels, names, top_row, 
   ung_summary)  
rm(gage_table, soils_table, ung_table, tables_ch2)
```





```{r clean_daily_flow, eval=FALSE} 

# checking prior code - using gage_raw to avoid rerunning code above 
gage_raw <- gage_dv 

# 1. check NA vals for Q 
gage_check <- gage_dv %>% 
  filter(is.na(Q))  

gage_dv <- gage_dv %>% 
  filter(!is.na(Q)) # remove NA discharge values from record  

## These are the missing records for Q1 
# "site_no"   "sta"   "Date"    "Q"   "Julian"    
# 06448000 lcr_abv 2016-08-09   NA    60851
# 06448000 lcr_abv 2016-08-10   NA    60852

# 2. check NA vals for Q7 
gage_check <- gage_dv %>% 
  filter(is.na(Q7))  

gage_dv <- gage_dv %>% 
  filter(!is.na(Q7)) # remove NA discharge values from record  
## the missing data (n = 114 ~= 19 x 7) because of start of record > WY 

# 3. check NA vals for Q30  
gage_check <- gage_dv %>% 
  filter(is.na(Q30))  

gage_dv <- gage_dv %>% 
  filter(!is.na(Q30)) # remove NA discharge values from record  
## the missing data (n = 437 ~= 19 x 30 - 114) because of start of record > WY 

# 4. remove provincial data - we removed WY 2018 in the prior analysis 
gage_check <- gage_dv %>% 
  filter(Qualifier != "A") %>% 
  filter(Qualifier != "A:e") %>%  
  filter(Qualifier != "A:<")  

gage_check <- gage_dv %>% 
  filter(waterYear == "2018")

gage_dv <- gage_dv %>% 
  filter(waterYear != "2018")

``` 








# 3. fill the station-years with missing data  
wy_1991 <- tibble(date = seq.Date(from=as.Date("1990-10-01"),  
                 to=as.Date("1991-09-30"), by="day")) 

wy_2003 <- tibble(date = seq.Date(from=as.Date("2002-10-01"),  
                 to=as.Date("2003-09-30"), by="day")) 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
bev_pri_1991 <- gage_dv_raw %>%  
  filter(sta == "bev_pri") %>%  
  filter(water_year == 1991) 

bev_pri_1991 <- full_join(bev_pri_1991, wy_1991) 

bev_pri_1991 <- bev_pri_1991 %>%  
  mutate(sta = "bev_pri") %>%  
  mutate(incomp_yr = "Y") %>%  
  mutate(water_year = 1991) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
whi_slm_1991 <- gage_dv_raw %>%  
  filter(sta == "whi_slm") %>%  
  filter(water_year == 1991) 

whi_slm_1991 <- full_join(whi_slm_1991, wy_1991) 

whi_slm_1991 <- whi_slm_1991 %>%  
  mutate(sta = "whi_slm") %>%  
  mutate(incomp_yr = "Y") %>%  
  mutate(water_year = 1991) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
lwr_aro_2003 <- gage_dv_raw %>%  
  filter(sta == "lwr_aro") %>%  
  filter(water_year == 2003) 

lwr_aro_2003 <- full_join(lwr_aro_2003 , wy_2003) 

lwr_aro_2003 <- lwr_aro_2003 %>%  
  mutate(sta = "lwr_aro") %>%   
  mutate(incomp_yr = "Y") %>%   
  mutate(water_year = 2003) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  

# 4. append and join data  
yr_dv_incomp <- bind_rows(bev_pri_1991, whi_slm_1991, lwr_aro_2003) 

gage_dv <- bind_rows(yr_dv_incomp, gage_dv_raw) %>%  
  distinct() %>%  
  group_by(sta, water_year) %>%                  
  mutate(days_yr = n()) %>%                   
  ungroup()   

# 4. remove short years  
gage_dv_incomp <-  gage_dv %>% 
  filter(days_yr < 365) 

gage_dv <- gage_dv %>% 
  filter(days_yr >= 365)  

# 5. check results  
gage_ck <- gage_dv %>%  
  filter(sta == "lwr_aro") %>%  
  filter(water_year == "2003") 

yr_sum <- gage_dv %>%                          
  group_by(sta, water_year) %>%                  
  summarise(days_yr = n()) %>%                    
  ungroup() 

# 6. clean up  
rm(bev_pri_1991, gage_dv_incomp, gage_dv_raw, lwr_aro_2003, whi_slm_1991, 
   wy_1991, wy_2003, yr_dv_incomp, yr_incomp, wkc_wok, gage_ck)  
``` 