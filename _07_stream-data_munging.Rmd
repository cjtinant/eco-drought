
<!--
Exploratory Data Analysis Checklist by Roger Peng 
https://leanpub.com/exdata  

1.0  Formulate your question  
Spend a few minutes to figure out the question you’re really interested in, and narrow it down to be as specific as possible (without becoming uninteresting).

General question:
Are air pollution levels higher on the east coast than on the west coast?
More specific question:
Are hourly ozone levels on average higher in New York City than they are in Los Angeles?

2.0   Read in your data  
Sometimes the data will need some cleaning and every dataset has its unique quirks. The dataset is a comma-separated value (CSV) file, where each row of the file contains one daily measurement of precipation depth.  The readr package can rewrite column names to remove spaces.
> names(ozone) <- make.names(names(ozone))

3.0  Check the dataset 
3.1  Check the number of rows and columns.
3.2  Check the types of data
3.3  Look at the top and the bottom of your data 
3.4  Check your “n”s & NAs 
3.5  Validate with at least one external data source  
4.0  Try the easy solution first to answer question
5.0  Challenge your solution 
6.0  Follow up questions 

## Broad questions:
What is the drought history of the Pine Ridge Reservation?  
Does the drought extent differ across the study area?
What is streamflow variation across the Pine Ridge Reservation?

## Narrower questions:

What is streamflow variation across the Pine Ridge Reservation?

## Analysis Steps:
1.  Data read in from USGS website by EGRET (cfs) 
2.  Added names & station numbers & joined data 
3.  Data saved in a flat format (.csv) 

Didn't work these
1.  Data read in from USGS website by dataRetrieval (cfs)
2.  Data saved as array (.JSON), and flat format (.csv) 

# Next STEPS
1. blc_wan <- readNWISDaily("06446700") # this not working!
2. Identify percent coverage

2. Check on next steps from Chapter 2 list 


# Someday Maybe
# USGS 06447050 UNNAMED TRIB BUZZARD CREEK NR LONG VALLEY, SD -instant meas
https://nwis.waterdata.usgs.gov/usa/nwis/qwdata/?huc_cd=10140202&format=station_list&sort_key=site_no&index_pmcode_00065=3&index_pmcode_00060=4&index_pmcode_00062=5&index_pmcode_72020=6&sort_key=site_no&group_key=county_cd&sitefile_output_format=station_list

## Variable naming convention:   
  for USGS functions: EGRET & dataRetrieval:
startDate    Beginning date for downloading USGS gage data
endDate      End date for downloading USGS gage data
parameter_cd USGS parameter codes

xxx_yyy      individual gage names xxx = stream & yyy = location

gage         USGS streamgage station 
  _cont      set of active gages 
  _disc      set of discontinued gages   
  _othr      set of gages not found in initial analysis 

  _full      equals {_cont + _disc + _othr}; 741,215 obs for 61 sta 
  _drp#      observations sequentially dropped from _full
  _fin#      equals {_full} - {_drp#} 

  _meta      metadata  
  _incomp    temporary variable to find station-years w/ incomp data 
  _mdp#      gages sequentially dropped from _meta
  _met#      equals {_meta} - {_mdp#} 
  _yr        temporary variable to calculate years of stations
 
 for filtering original set of gages 
  _ltxx      less than year xx
  _comp      complete {post-1990}
  _incomp    incomplete
  _res       within the Pine Ridge Reservation administrative boundary

 
 
  
check_sta    check variable


## Results: 


-->

```{r setup, include=FALSE} 
#knitr::opts_chunk$set(echo = FALSE) 
options(tibble.print_max = 70) # sets tibble output for printing 
 

# Sets up the library of packages   
library("here") # identifies where to save work  
library("dataRetrieval") # USGS data import  
library("EGRET") # Exploration and Graphics for RivEr Trends 
library("rio") # more robust I/O - to import and clean data  
library("lubridate") # easier dates 
library("tidyverse") 
library("janitor") # tools for examining and cleaning dirty data  
# library("DataExplorer") # quick look at NA vals 
#library('jsonlite') # tools for working with lists  
#library("magrittr") # provides aliases for easier reading 
# library("friendlyeval") 

# a useful description of commits: 
# http://r-pkgs.had.co.nz/git.html 
```

```{r import_daily_flow_active_EGRET, eval=FALSE} 
# Loads USGS gage data individually, bind_cols & exports data
# Note: found gage ids by USGS watermapper.  However, this was an
#   iterative process in deciding sites to choose.  This is reflected
#   in the row numbers (see table below) non-sequential arrangement
# Also note: the joined file of active & discontinued stations >87 mb 
# Saving this file separately may protect data integrity
# 
#   readNWISDaily(siteNumber, parameterCd = "00060", startDate = "",
#      endDate = "", interactive = TRUE, convert = TRUE) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# List of active sites
# ~~~~~~~~~~~~~~~~~~~~
# A tibble: 55 x 3
#   sta     site_no station_nm                                   
# * <chr>     <int> <chr>                                        
# 1 bad_mid 6441000 BAD R NEAR MIDLAND,SD                        
# 2 bat_bhr 6406500 BATTLE CR BELOW HERMOSA,SD                   
# 3 brsf_co 6440200 SOUTH FORK BAD R NEAR COTTONWOOD,SD          
# 4 blp_bel 6447230 BLACK PIPE CREEK NR BELVIDERE, SD            
# 5 bev_buf 6402500 BEAVER CR NEAR BUFFALO GAP,SD                
# 6 bev_pri 6402430 BEAVER CREEK NEAR PRINGLE, SD   
#26 che_buf 6402600 CHEYENNE R NEAR BUFFALO GAP SD                        
# 7 che_red 6403700 CHEYENNE RIVER AT RED SHIRT, SD              
# 8 che_sce 6408650 CHEYENNE RIVER NEAR SCENIC, SD       
#27 che_was 6423500 CHEYENNE RIVER NEAR WASTA, SD 
# 9 fal_hot 6402000 FALL R AT HOT SPRINGS,SD                     
#10 hat_edg 6400000 HAT CR NEAR EDGEMONT,SD                      
#11 hor_oel 6400875 HORSEHEAD CR AT OELRICHS,SD                  
#12 lcr_bel 6449000 LAKE CR BELOW REFUGE NEAR TUTHILL,SD 
#13 lcr_vet 6449100 LITTLE WHITE R NEAR VETAL,SD                 
#14 lwr_mar 6447500 LITTLE WHITE R NEAR MARTIN,SD                
#15 lwr_ros 6449500 LITTLE WHITE R NEAR ROSEBUD SD               
#16 lwr_whi 6450500 LITTLE WHITE R BELOW WHITE RIVER,SD          
#17 rap_far 6421500 RAPID CR NEAR FARMINGDALE,SD                 
#18 wcc_ogl 6445980 WHITE CLAY CR NEAR OGLALA SD                 
#19 whi_int 6446500 WHITE R NEAR INTERIOR,SD                     
#20 whi_kad 6447000 WHITE R NEAR KADOKA,SD                       
#21 whi_ogl 6446000 WHITE R NEAR OGLALA SD       
#28 whi_roc 6446200 WHITE R NEAR ROCKYFORD SD         
#22 whi_slm 6445700 WHITE RIVER AT SLIM BUTTE, SD                
#23 whi_sta 6445685 WHITE R NR NE-SD STATE LINE                  
#24 whi_whi 6447450 WHITE RIVER NEAR WHITE RIVER, SD             
#25 wkc_wok 6446100 WOUNDED KNEE CREEK AT WOUNDED KNEE, SD       
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. load individual gages
# add an end date to remove provisional data & gaps in vals
startDate    <- "" # blank gets earliest date
endDate      <- "2017-09-30"
parameter_cd <- "00060" 
# ~~~~~~~~~~~~~~~~~~~~~ 

bad_mid <- readNWISDaily("06441000", parameter_cd, startDate, endDate) 
bat_bhr <- readNWISDaily("06406500", parameter_cd, startDate, endDate) 
bev_buf <- readNWISDaily("06402500", parameter_cd, startDate, endDate) 
bev_pri <- readNWISDaily("06402430", parameter_cd, startDate, endDate) 
blp_bel <- readNWISDaily("06447230", parameter_cd, startDate, endDate) 
brsf_co <- readNWISDaily("06440200", parameter_cd, startDate, endDate) 
che_buf <- readNWISDaily("06402600", parameter_cd, startDate, endDate) 
che_red <- readNWISDaily("06403700", parameter_cd, startDate, endDate)  
che_sce <- readNWISDaily("06408650", parameter_cd, startDate, endDate) 
che_was <- readNWISDaily("06423500", parameter_cd, startDate, endDate) 
fal_hot <- readNWISDaily("06402000", parameter_cd, "1947-06-01", endDate) 
hat_edg <- readNWISDaily("06400000", parameter_cd, startDate, endDate) 
hor_oel <- readNWISDaily("06400875", parameter_cd, startDate, endDate) 
lcr_bel <- readNWISDaily("06449000", parameter_cd, startDate, endDate) 
lcr_vet <- readNWISDaily("06449100", parameter_cd, startDate, endDate) 
lwr_mar <- readNWISDaily("06447500", parameter_cd, startDate, endDate) 
lwr_ros <- readNWISDaily("06449500", parameter_cd, startDate, endDate) 
lwr_whi <- readNWISDaily("06450500", parameter_cd, startDate, endDate)
rap_far <- readNWISDaily("06421500", parameter_cd, startDate, endDate)
wcc_ogl <- readNWISDaily("06445980", parameter_cd, startDate, endDate) 
wkc_wok <- readNWISDaily("06446100", parameter_cd, startDate, endDate) 
whi_int <- readNWISDaily("06446500", parameter_cd, startDate, endDate) 
whi_kad <- readNWISDaily("06447000", parameter_cd, startDate, endDate)
whi_ogl <- readNWISDaily("06446000", parameter_cd, startDate, endDate)  
whi_roc <- readNWISDaily("06446200", parameter_cd, startDate, endDate) 
whi_slm <- readNWISDaily("06445700", parameter_cd, startDate, endDate) 
whi_sta <- readNWISDaily("06445685", parameter_cd, startDate, endDate) 
whi_whi <- readNWISDaily("06447450", parameter_cd, startDate ,endDate)

# 2. add short name and abbreviation to gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
bad_mid <- bad_mid %>% 
  mutate(sta = "bad_mid") %>%
  mutate(site_no = "06441000") 

bat_bhr <- bat_bhr %>%
  mutate(sta = "bat_bhr") %>%
  mutate(site_no = "06406500") 

bev_buf <- bev_buf %>%
  mutate(sta = "bev_buf") %>%
  mutate(site_no = "06402500") 

bev_pri <- bev_pri %>%
  mutate(sta = "bev_pri") %>%
  mutate(site_no = "06402430") 

blp_bel <- blp_bel %>% 
  mutate(sta = "blp_bel") %>%
  mutate(site_no = "06447230")

 brsf_co <- brsf_co %>% 
  mutate(sta = "brsf_co") %>%
  mutate(site_no = "06440200")

che_buf <- che_buf %>% 
  mutate(sta = "che_buf") %>%
  mutate(site_no = "06402600")

che_red <- che_red %>% 
  mutate(sta = "che_red") %>%
  mutate(site_no = "06403700")

che_sce <- che_sce %>% 
  mutate(sta = "che_sce") %>%
  mutate(site_no = "06408650") 

che_was <- che_was %>% 
  mutate(sta = "che_was") %>%
  mutate(site_no = "06423500") 

fal_hot <- fal_hot %>% 
  mutate(sta = "fal_hot") %>%
  mutate(site_no = "06402000") 

hat_edg <- hat_edg %>% 
  mutate(sta = "hat_edg") %>%
  mutate(site_no = "06400000") 

hor_oel <- hor_oel %>% 
  mutate(sta = "hor_oel") %>%
  mutate(site_no = "06400875") 

lcr_bel <- lcr_bel %>% 
  mutate(sta = "lcr_bel") %>%
  mutate(site_no = "06449000")

lcr_vet <- lcr_vet %>% 
  mutate(sta = "lcr_vet") %>%
  mutate(site_no = "06449100")

lwr_mar <- lwr_mar  %>% 
  mutate(sta = "lwr_mar") %>%
  mutate(site_no = "06447500")

lwr_ros <- lwr_ros  %>% 
  mutate(sta = "lwr_ros") %>%
  mutate(site_no = "06449500")

lwr_whi <- lwr_whi  %>% 
  mutate(sta = "lwr_whi") %>%
  mutate(site_no = "06450500")
 
rap_far <- rap_far  %>% 
  mutate(sta = "rap_far") %>%
  mutate(site_no = "06421500")

wcc_ogl <- wcc_ogl %>% 
  mutate(sta = "wcc_ogl") %>%
  mutate(site_no = "06445980") 

whi_int <- whi_int %>% 
  mutate(sta = "whi_int") %>%
  mutate(site_no = "06446500") 

whi_kad <- whi_kad %>% 
  mutate(sta = "whi_kad") %>%
  mutate(site_no = "06447000") 

whi_ogl <- whi_ogl %>% 
  mutate(sta = "whi_ogl") %>%
  mutate(site_no = "06446000") 

whi_slm <- whi_slm %>% 
  mutate(sta = "whi_slm") %>%
  mutate(site_no = "06445700") 

whi_roc <- whi_roc %>% 
  mutate(sta = "whi_roc") %>%
  mutate(site_no = "06446200") 

whi_sta <- whi_sta %>% 
  mutate(sta = "whi_sta") %>%
  mutate(site_no = "06445685") 

whi_whi <- whi_whi %>% 
  mutate(sta = "whi_whi") %>%
  mutate(site_no = "06447450") 

wkc_wok <- wkc_wok %>% 
  mutate(sta = "wkc_wok") %>%
  mutate(site_no = "06446100") 

# 3. join together in long format
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int1  <- bind_rows(bad_mid, bat_bhr) 
gage_int2  <- bind_rows(gage_int1, brsf_co) 
gage_int3  <- bind_rows(gage_int2, blp_bel) 
gage_int4  <- bind_rows(gage_int3, bev_buf) 
gage_int5  <- bind_rows(gage_int4, bev_pri) 
gage_int6  <- bind_rows(gage_int5, che_red) 
gage_int7  <- bind_rows(gage_int6, che_sce) 
gage_int8  <- bind_rows(gage_int7, fal_hot) 
gage_int9  <- bind_rows(gage_int8, hat_edg) 
gage_int10 <- bind_rows(gage_int9, hor_oel) 
gage_int11 <- bind_rows(gage_int10, lcr_bel) 
gage_int12 <- bind_rows(gage_int11, lcr_vet) 
gage_int13 <- bind_rows(gage_int12, lwr_mar) 
gage_int14 <- bind_rows(gage_int13, lwr_ros) 
gage_int15 <- bind_rows(gage_int14, lwr_whi) 
gage_int16 <- bind_rows(gage_int15, rap_far) 
gage_int17 <- bind_rows(gage_int16, wcc_ogl) 
gage_int18 <- bind_rows(gage_int17, whi_int) 
gage_int19 <- bind_rows(gage_int18, whi_kad) 
gage_int20 <- bind_rows(gage_int19, whi_ogl) 
gage_int21 <- bind_rows(gage_int20, whi_slm) 
gage_int22 <- bind_rows(gage_int21, whi_sta) 
gage_int23 <- bind_rows(gage_int22, whi_whi) 
gage_int24 <- bind_rows(gage_int23, wkc_wok) 
gage_int25 <- bind_rows(gage_int24, che_buf) 
gage_int26 <- bind_rows(gage_int25, che_was) 
gage_int27 <- bind_rows(gage_int26, whi_roc) 

# export daily flows to data folder
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_int27, "data/gage_cont.csv") 

#>>> git push origin refs/heads/master
#remote: warning: GH001: Large files detected. You may want to try Git #Large File Storage - https://git-lfs.github.com.        
#remote: warning: See http://git.io/iEPt8g for more information.        
#remote: warning: File data/gage_cont.csv is 60.77 MB; this is larger than #GitHub's recommended maximum file size of 50.00 MB        
#To https://github.com/cjtinant/eco-drought.git
#   be32000..a6c9c26  master -> master
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# export top half of active gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
export(gage_int14, "data/gage_cont_1st_half.csv")

# bind bottom half of active gage data - start at 36 to avoid dups
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

gage_int36 <- bind_rows(lwr_whi, rap_far) 
gage_int37 <- bind_rows(gage_int36, wcc_ogl) 
gage_int38 <- bind_rows(gage_int37, whi_int) 
gage_int39 <- bind_rows(gage_int38, whi_kad) 
gage_int40 <- bind_rows(gage_int39, whi_ogl) 
gage_int41 <- bind_rows(gage_int40, whi_slm) 
gage_int42 <- bind_rows(gage_int41, whi_sta) 
gage_int43 <- bind_rows(gage_int42, whi_whi) 
gage_int44 <- bind_rows(gage_int43, wkc_wok) 
gage_int45 <- bind_rows(gage_int44, che_buf) 
gage_int46 <- bind_rows(gage_int45, che_was) 
gage_int47 <- bind_rows(gage_int46, whi_roc) 

# export bottom half of active gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_int47, "data/gage_cont_2nd_half.csv")

```

```{r import_dailyflow_EGRET-bearLodge, eval=FALSE}
# long story, but Bear in the Lodge streamflow is restricted.  So,
# need to find another approach to getting the data. 
# one way is annual reports - but only to 2013
# Need to email the webmaster to get streamflow data.
# https://waterdata.usgs.gov/sd/nwis/inventory/?site_no=06446700&agency_cd= 

#blc_wan <- readNWISDaily("06446700") # this not working! 
#blc_wan <- blc_wan %>%
#  mutate(sta = blc_wan) %>%
#  mutate(site_no = "06446700")

```

```{r import_daily_flow_discontinued_EGRET, eval=FALSE} 

# List of discontinued sites w/in 30 mi. of PRR boundary
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# A tibble: 55 x 3
#   sta     site_no station_nm                                   
# * <chr>     <int> <chr>          
#29 ant_gor 6458000 Antelope Creek near Gordon, Nebr.           
#33 brnf_ph 6440500 NORTH FORK BAD R NEAR PHILIP SD    
#30 bea_eli 6458500 BEAR C NR ELI NEBR                           
#31 bev_abf 6402470 BEAVER CREEK ABOVE BUFFALO GAP, SD           
#32 bor_cha 6445590 BIG BORDEAUX CREEK NEAR CHADRON NEBR         
#34 cas_hot 6400497 CASCADE SPRINGS NEAR HOT SPRINGS SD          
#35 che_hot 6400500 CHEYENNE R NEAR HOT SPRINGS SD               
#36 fre_fai 6403500 FRENCH CR NEAR FAIRBURN SD                   
#37 hor_aoe 6400870 HORSEHEAD CR NEAR OELRICHS SD                
#38 lcr_abv 6448000 LAKE CR ABOVE REFUGE NEAR TUTHILL,SD         
#39 lwr_abv 6449300 LITTLE WHITE R ABV ROSEBUD SD                
#40 min_kil 6460900 MINNECHADUZA CREEK NEAR KILGORE, NEBRASKA   
#41 nio_abb 6454500 NIOBRARA RIVER ABOVE BOX BUTTE RESERVOIR, NE 
#42 nio_bbb 6455500 NIOBRARA RIVER BELOW BOX BUTTE RESERVOIR NEBR
#43 nio_cod 6459000 NIOBRARA R NEAR CODY, NEBR.                  
#44 nio_col 6457000 NIOBRARA RIVER NEAR COLCLESSER, NEBR.        
#45 nio_dun 6455900 NIOBRARA RIVER NEAR DUNLAP, NEBR.            
#46 nio_hay 6456500 NIOBRARA RIVER NR HAY SPRINGS, NEBR.         
#47 rap_cre 6422000 RAPID CR AT CRESTON SD                       
#48 ros_ros 6449400 ROSEBUD CR AT ROSEBUD SD                     
#49 sna_bur 6459500 SNAKE RIVER NEAR BURGE, NEBR.                
#50 sna_dou 6459175 SNAKE R AT DOUGHBOY, NE                      
#51 sna_mer 6459200 SNAKE RIVER ABV MERRITT RESERVOIR NEBR       
#52 spr_stf 6449250 SPRING CR NEAR ST FRANCIS SD                 
#53 whi_cha 6445500 WHITE R NEAR CHADRON NEBR                    
#54 whi_cra 6444000 White River at Crawford, Nebr.               
#55 whi_wht 6445000 WHITE R BELW COTTONWOOD C N WHITNEY, NEBR.  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. load individual gages
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# add an end date to remove provisional data & gaps in vals
startDate    <- "" #Gets earliest date
endDate      <- "2017-09-30"
parameter_cd <- "00060" 
# ~~~~~~~~~~~~~~~~~~~~~ 

ant_gor <- readNWISDaily("06458000", parameter_cd, startDate ,endDate) 
brnf_ph <- readNWISDaily("06440500", parameter_cd, startDate, endDate) 
bea_eli <- readNWISDaily("06458500", parameter_cd, startDate, endDate) 
bev_abf <- readNWISDaily("06402470", parameter_cd, startDate, endDate) 
bor_cha <- readNWISDaily("06445590", parameter_cd, startDate, endDate) 
cas_hot <- readNWISDaily("06400497", parameter_cd, startDate, endDate) 
che_hot <- readNWISDaily("06400500", parameter_cd, startDate, endDate) 
fre_fai <- readNWISDaily("06403500", parameter_cd, "1946-01-14", endDate) 
hor_aoe <- readNWISDaily("06400870", parameter_cd, startDate, endDate) 
lcr_abv <- readNWISDaily("06448000", parameter_cd, startDate, endDate) 
lwr_abv <- readNWISDaily("06449300", parameter_cd, startDate, endDate) 
min_kil <- readNWISDaily("06460900", parameter_cd, startDate, endDate) 
nio_abb <- readNWISDaily("06454500", parameter_cd, startDate, endDate) 
nio_bbb <- readNWISDaily("06455500", parameter_cd, startDate, endDate) 
nio_col <- readNWISDaily("06457000", parameter_cd, startDate, endDate) 
nio_cod <- readNWISDaily("06459000", parameter_cd, startDate, endDate) 
nio_dun <- readNWISDaily("06455900", parameter_cd, startDate, endDate) 
nio_hay <- readNWISDaily("06456500", parameter_cd, startDate, endDate) 
rap_cre <- readNWISDaily("06422000", parameter_cd, startDate, endDate) 
ros_ros <- readNWISDaily("06449400", parameter_cd, startDate, endDate) 
sna_bur <- readNWISDaily("06459500", parameter_cd, startDate, endDate) 
sna_dou <- readNWISDaily("06459175", parameter_cd, startDate, endDate) 
sna_mer <- readNWISDaily("06459200", parameter_cd, startDate, endDate) 
spr_stf <- readNWISDaily("06449250", parameter_cd, startDate, endDate) 
whi_cha <- readNWISDaily("06445500", parameter_cd, startDate, endDate) 
whi_cra <- readNWISDaily("06444000", parameter_cd, startDate, endDate)
whi_wht <- readNWISDaily("06445000", parameter_cd, startDate, endDate) 

# 2. add short name and abbreviation to gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ant_gor <- ant_gor %>% 
  mutate(sta = "ant_gor") %>%
  mutate(site_no = "06458000") 

brnf_ph <- brnf_ph %>% 
  mutate(sta = "brnf_ph") %>%
  mutate(site_no = "06440500") 

bea_eli <- bea_eli %>% 
  mutate(sta = "bea_eli") %>%
  mutate(site_no = "06458500") 

bev_abf <- bev_abf %>% 
  mutate(sta = "bev_abf") %>%
  mutate(site_no = "06402470") 

bor_cha <- bor_cha %>% 
  mutate(sta = "bor_cha") %>%
  mutate(site_no = "06445590") 

cas_hot <- cas_hot %>% 
  mutate(sta = "cas_hot") %>%
  mutate(site_no = "06400497") 

che_hot <- che_hot %>% 
  mutate(sta = "che_hot") %>%
  mutate(site_no = "06400500") 

fre_fai <- fre_fai %>% 
  mutate(sta = "fre_fai") %>%
  mutate(site_no = "06403500") 

hor_aoe <- hor_aoe %>% 
  mutate(sta = "hor_aoe") %>%
  mutate(site_no = "06400870") 

lcr_abv <- lcr_abv %>% 
  mutate(sta = "lcr_abv") %>%
  mutate(site_no = "06448000") 

lwr_abv <- lwr_abv %>% 
  mutate(sta = "lwr_abv") %>%
  mutate(site_no = "06449300") 

min_kil <- min_kil %>% 
  mutate(sta = "min_kil") %>%
  mutate(site_no = "06460900") 

nio_abb <- nio_abb %>% 
  mutate(sta = "nio_abb") %>%
  mutate(site_no = "06454500") 

nio_bbb <- nio_bbb %>% 
  mutate(sta = "nio_bbb") %>%
  mutate(site_no = "06455500") 

nio_col <- nio_col %>% 
  mutate(sta = "nio_col") %>%
  mutate(site_no = "06457000") 

nio_cod <- nio_cod %>% 
  mutate(sta = "nio_cod") %>%
  mutate(site_no = "06459000") 

nio_dun <- nio_dun %>% 
  mutate(sta = "nio_dun") %>%
  mutate(site_no = "06455900")

nio_hay <- nio_hay %>% 
  mutate(sta = "nio_hay") %>%
  mutate(site_no = "06456500") 

rap_cre <- rap_cre %>% 
  mutate(sta = "rap_cre") %>%
  mutate(site_no = "06422000")

ros_ros <- ros_ros %>% 
  mutate(sta = "ros_ros") %>%
  mutate(site_no = "06449400") 

sna_bur <- sna_bur %>% 
  mutate(sta = "sna_bur") %>%
  mutate(site_no = "06459500")

sna_dou <- sna_dou %>% 
  mutate(sta = "sna_dou") %>%
  mutate(site_no = "06459175") 

sna_mer <- sna_mer %>% 
  mutate(sta = "sna_mer") %>%
  mutate(site_no = "06459200")

spr_stf <- spr_stf %>% 
  mutate(sta = "spr_stf") %>%
  mutate(site_no = "06449250") 

whi_cha <- whi_cha %>% 
  mutate(sta = "whi_cha") %>%
  mutate(site_no = "06445500") 

whi_cra <- whi_cra %>% 
  mutate(sta = "whi_cra") %>%
  mutate(site_no = "06444000") 

whi_wht <- whi_wht %>% 
  mutate(sta = "whi_wht") %>%
  mutate(site_no = "06445000") 

# 3. join together in long format
# Next step: probably could be done more efficiently with map_df()
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int1  <- bind_rows(ant_gor, bea_eli) 
gage_int2  <- bind_rows(gage_int1, bev_abf) 
gage_int3  <- bind_rows(gage_int2, bor_cha) 
gage_int4  <- bind_rows(gage_int3, brnf_ph) 
gage_int5  <- bind_rows(gage_int4, cas_hot) 
gage_int6  <- bind_rows(gage_int5, che_hot) 
gage_int7  <- bind_rows(gage_int6, fre_fai) 
gage_int8  <- bind_rows(gage_int7, hor_aoe) 
gage_int9  <- bind_rows(gage_int8, lcr_abv) 
gage_int10 <- bind_rows(gage_int9, lwr_abv) 
gage_int11 <- bind_rows(gage_int10, min_kil) 
gage_int12 <- bind_rows(gage_int11, nio_abb) 
gage_int13 <- bind_rows(gage_int12, nio_bbb) 
gage_int14 <- bind_rows(gage_int13, nio_cod) 
gage_int15 <- bind_rows(gage_int14, nio_col) 
gage_int16 <- bind_rows(gage_int15, nio_dun) 
gage_int17 <- bind_rows(gage_int16, nio_hay) 
gage_int18 <- bind_rows(gage_int17, rap_cre) 
gage_int19 <- bind_rows(gage_int18, ros_ros) 
gage_int20 <- bind_rows(gage_int19, sna_bur) 
gage_int21 <- bind_rows(gage_int20, sna_dou) 
gage_int22 <- bind_rows(gage_int21, sna_mer) 
gage_int23 <- bind_rows(gage_int22, spr_stf) 
gage_int24 <- bind_rows(gage_int23, whi_cha) 
gage_int25 <- bind_rows(gage_int24, whi_cra) 
gage_int26 <- bind_rows(gage_int25, whi_wht) 

# export daily flows to data folder
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
export(gage_int26, "data/gage_disc.csv") 
```

```{r import_daily_flow_overlooked, eval=FALSE} 

# List of possible extra sites - list was iteratively constructed
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# A tibble: 6 x 2
#   sta     site_no station_nm                                   
# * <chr>     <int> <chr>          
#1 che_ang 06401500 CHEYENNE R BELOW ANGOSTURA DAM,SD
#2 frn_fai 06403300 FRENCH CR ABOVE FAIRBURN SD      
#3 bat_key 06404000 BATTLE CR NEAR KEYSTONE,SD       
#4 bat_bhr 06406000 BATTLE CR AT HERMOSA,SD          
#5 spr_her 06408500 SPRING CR NEAR HERMOSA,SD        
#6 nio_gor 06457500 NIOBRARA RIVER NEAR GORDON, NEBR.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# this is what was done to find the stations above: 

# this code chunk checks for "missed" stations.  
# for filtering info see: https://help.waterdata.usgs.gov/site_tp_cd
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. get huc codes for gages already selected
gage_meta <- import("data/gage_meta.csv") %>% 
  arrange(sta)

hucs <- gage_meta %>% 
  distinct(huc_cd) %>%
  arrange() %>%
  mutate(huc_cd = as.character(huc_cd))

# 2. split the API query into smaller parts
hucs1 <- hucs %>%
  slice(1:6)

hucs2 <- hucs %>%
  slice(7:13) 

# 3. get the set of NWIS data for each of the slices
gages1 <- hucs1 %>% 
     map_df(~ whatNWISdata(huc = .x)) 

gages2 <- hucs2 %>% 
     map_df(~ whatNWISdata(huc = .x)) 

# 4. create a single dataframe and clean up 
gages1 <- gages1 %>% 
  mutate(alt_acy_va = as.numeric(alt_acy_va))

gages_pos <- bind_rows(gages1, gages2)
rm(hucs, hucs1, hucs2, gages1, gages2)

# 5. explore data types
# ~~~~~~~~~~~~~~~~~~~~~~~

#   a. find site_types 
NWIS_type <- gages_pos %>% 
  distinct(site_tp_cd) %>%  
  arrange(site_tp_cd)

#   b. remove atmosphere (AT), land (LA), & subsurface (SB) site types
gage_pos1 <- gages_pos %>% 
  filter(site_tp_cd != "AT" &
           site_tp_cd != "LA-SH" & 
           site_tp_cd != "LA-SNK" &
           site_tp_cd != "SB-CV" &
           site_tp_cd != "SB" 
         ) %>% 
  arrange(site_tp_cd) 

#   c. remove facilities (FA) site type 
gage_pos2 <- gage_pos1 %>% 
  filter(site_tp_cd != "FA-CI" &
           site_tp_cd != "FA-OF" & 
           site_tp_cd != "FA-SEW" & 
           site_tp_cd != "FA-STS" & 
           site_tp_cd != "FA-WDS"
         )

#   d. remove groundwater (GW) & spring site types 
gw <- gage_pos2 %>% 
  filter(site_tp_cd == "GW" |
           site_tp_cd == "GW-CR" | 
           site_tp_cd == "GW-IW" |
           site_tp_cd == "GW-MW" | 
           site_tp_cd == "GW-TH" | 
          site_tp_cd == "SP"
         )

gage_pos3 <- gage_pos2 %>% 
  filter(site_tp_cd != "GW" &
           site_tp_cd != "GW-CR" & 
           site_tp_cd != "GW-IW" &
           site_tp_cd != "GW-MW" & 
           site_tp_cd != "GW-TH" & 
          site_tp_cd != "SP"
         )

#   e. remove lake (LK) & canal (CA) site types 
gage_pos4 <- gage_pos3 %>% 
  filter(site_tp_cd != "LK" & 
           site_tp_cd != "ST-CA" &
           site_tp_cd != "ST-DCH"
           ) 

#   e. check streams == gage_pos4 & clean up
gage_pos5 <- gage_pos4 %>% 
  filter(site_tp_cd != "ST") 

gage_strm <- gages_pos %>% 
  filter(site_tp_cd == "ST") 

rm(NWIS_type, gage_pos, gage_pos1, gage_pos2, gage_pos3, 
   gage_pos4, gage_pos5) 

#   f. remove bio, sediment, wq, report, peak, temp data
bio <- gage_strm %>% 
  filter(medium_grp_cd == "bio")

sed <- gage_strm %>% 
  filter(medium_grp_cd == "sed") 

wq <- gage_strm %>% 
  filter(data_type_cd == "qw") 

ad <- gage_strm %>% 
  filter(data_type_cd == "ad") 

pk <- gage_strm %>% 
  filter(data_type_cd == "pk") 

tmp <- gage_strm %>% 
  filter(parm_cd == "00010") 

gages_dv <- gage_strm %>% 
  filter(medium_grp_cd != "bio" & 
           medium_grp_cd != "sed" & 
           data_type_cd != "qw" & 
           data_type_cd != "uv" & 
           data_type_cd != "ad" &
           data_type_cd != "sv" &
           data_type_cd != "pk" & 
           parm_cd != "00010" & 
           parm_cd != "00065" & 
           parm_cd != "00095" & 
           parm_cd != "00300" & 
           parm_cd != "00400" & 
           parm_cd != "63680" & 
           parm_cd != "80154" & 
           parm_cd != "80155" 
           ) 

# g. clean dataframe to fit the area
gages_pot <- gages_dv %>% 
  mutate(alt_va = as.numeric(alt_va)) %>% 
  filter(count_nu > 365*5) %>%
  filter(dec_lat_va < 43.97) %>% 
  filter(dec_long_va > -103.58825) %>% 
  filter(dec_long_va < -100.55167) %>% 
  filter(alt_va < 4050) %>% 
  mutate(end_date = ymd(end_date)) %>% 
  mutate(end_yr = year(end_date)) %>% 
  filter(end_yr > 1990)

# bind new and old metadata cols together to check
gages_pot_list <- gages_pot %>% 
  select(site_no, station_nm) %>% 
  mutate(site_no = as.integer(site_no))
gages_exist <- gage_meta %>% 
    select(site_no, station_nm) 

gages_new <- full_join(gages_pot_list, gages_exist, by = "site_no") 
gages_new <- gages_new %>% 
  filter(is.na(station_nm.y)) %>% 
  rename(station_nm = station_nm.x) %>% 
  select(-station_nm.y) %>% 
  as.tibble() 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. load individual gages
# ~~~~~~~~~~~~~~~~~~~~~~~~~
# add an end date to remove provisional data & gaps in vals
startDate    <- "" #Gets earliest date
endDate      <- "2017-09-30"
parameter_cd <- "00060" 
# ~~~~~~~~~~~~~~~~~~~~~ 
bat_bhr <- readNWISDaily("06406000", parameter_cd, startDate ,endDate) 
bat_key <- readNWISDaily("06404000", parameter_cd, startDate ,endDate) 
che_ang <- readNWISDaily("06401500", parameter_cd, startDate ,endDate)
frn_fai <- readNWISDaily("06403300", parameter_cd, startDate ,endDate) 
nio_gor <- readNWISDaily("06457500", parameter_cd, startDate ,endDate) 
spr_her <- readNWISDaily("06408500", parameter_cd, startDate ,endDate)  

# 2. add short name and abbreviation to gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

bat_bhr <- bat_bhr %>% 
  mutate(sta = "bat_her") %>%
  mutate(site_no = "6406000") 

bat_key <- bat_key %>% 
  mutate(sta = "bat_key") %>%
  mutate(site_no = "6404000") 

che_ang <- che_ang  %>% 
  mutate(sta = "che_ang") %>%
  mutate(site_no = "6401500")

frn_fai <- frn_fai %>% 
  mutate(sta = "frn_fai") %>%
  mutate(site_no = "6403300") 

nio_gor <- nio_gor %>% 
  mutate(sta = "nio_gor") %>%
  mutate(site_no = "6457500") 

spr_her <- spr_her %>% 
  mutate(sta = "spr_her") %>%
  mutate(site_no = "6408500")

# 3. join together in long format
# Next step: probably could be done more efficiently with map_df()
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int1  <- bind_rows(bat_bhr, bat_key) 
gage_int2  <- bind_rows(gage_int1, che_ang) 
gage_int3  <- bind_rows(gage_int2, frn_fai) 
gage_int4  <- bind_rows(gage_int3, nio_gor) 
gage_int5  <- bind_rows(gage_int4, spr_her) 

# export daily flows to data folder
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_int5, "data/gage_other.csv") 

``` 

```{r import_gage_metadata, eval=FALSE} 
  
# import daily streamflow datasets  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_cont <- import("data/gage_cont.csv") 
gage_disc <- import("data/gage_disc.csv") 
gage_othr <- import("data/gage_other.csv") 
 
# check for duplicate data  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_cont_ck  <- gage_cont %>% 
  distinct(sta, site_no) 

gage_dist_ck  <- gage_disc %>% 
  distinct(sta, site_no) 

gage_othr_ck  <- gage_othr %>% 
  distinct(sta, site_no) 

gage_names <- bind_rows(gage_cont_ck, gage_dist_ck) 
gage_names <- bind_rows(gage_names, gage_othr_ck) 

rm(gage_cont_ck, gage_dist_ck, gage_othr_ck) 

# join data & import metadata 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~ 

gage_full  <- bind_rows(gage_cont, gage_disc)  
gage_full  <- bind_rows(gage_full, gage_othr) 

# gage$site_no is brought in as an integer but needs to be 8-dig char 
gage_full <- gage_full %>% 
  mutate(sta = as.character(sta)) %>%  
  mutate(site_no = zeroPad(site_no, 8)) %>% 
  select(site_no, sta, everything()) 

# reduces the set down to a small number to reduce API calls 
gage_id <- gage_full %>% 
  distinct(site_no, sta) 

# iterate across a list of gage ids by purrr::map_dfr 
# & get gage metadata using dataRetrieval::readNWISsite 
gage_meta_list <- map(gage_id$site_no, readNWISsite) 

# extract the wanted dataframe items from the list 
gage_meta <- gage_meta_list %>% 
  map_df(extract, 
               c("site_no", "station_nm", "site_tp_cd", "dec_lat_va", 
                 "dec_long_va", "dec_coord_datum_cd", "state_cd", 
                 "county_cd", "alt_va", "alt_datum_cd", "huc_cd", 
                 "drain_area_va", "contrib_drain_area_va")) 
rm(gage_meta_list) 

# join the abbreviation to the metadata 
gage_meta <- gage_meta %>%  
  full_join(gage_id, gage_meta, by = "site_no") 

gage_meta <- gage_meta %>% 
  select(sta, everything()) 

# check on integrity of the data by looking at counts 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
ck_sta <- gage_meta %>% 
  distinct(sta) 

ck_num <- gage_meta %>% 
  distinct(site_no) 

ck_sta_num <- gage_meta %>% 
  distinct(sta, site_no) 

ck_nam <- gage_meta %>% 
  distinct(station_nm) 

ck_sta_nam <- gage_meta %>% 
  distinct(sta, station_nm) 

num_nam <- gage_meta %>% 
  distinct(site_no, station_nm) 

ck_sta_nam_num <- gage_meta %>% 
  distinct(sta, site_no, station_nm) 

# export dataframes of the largest population of gages 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# export(gage, "data/gage_full.csv") # too big for GitHub 
# export(gage_meta, "data/gage_meta.csv")  

# create a table to show abbreviation, site no & station name 
gage_table <- gage_meta %>% 
  select(sta, site_no, station_nm) %>% 
  as.tibble() 
```

```{r clean_daily flow} 
# this code chunk checks and removes gages w/o useful characteristics
#   for future analysis 
# This code is a refactor of prior code above, some of it broken
# 
# Steps: 
# 1. Assemble a full dataset (N = 61 stations; 741,215 obs)
# 2. Remove streams prior to 1990 from the analysis series 
#      (N = 19 stations, 103,465 obs) 
# 3. Remove streams with substantial missing data 
# 4. Investigate remaining stations 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1. Assemble a set of all possible recorded streamflows----
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_meta_full <- import("data/gage_meta.csv") %>% 
  arrange(sta) 

gage_cont <- import("data/gage_cont.csv") 
gage_disc <- import("data/gage_disc.csv") 
gage_othr <- import("data/gage_other.csv") 

# Assemble a complete set of stations identifed in prior steps
gage_full  <- bind_rows(gage_cont, gage_disc, gage_othr)  

gage_full <- gage_full %>% 
  arrange(sta) %>% 
  select(site_no, sta, Date, i, everything()) 

# check results - should be 61 stations; yes
check_sta <- gage_full %>% 
  distinct(sta)
rm(gage_cont, gage_disc, gage_othr, check_sta)  

# calculate the minimun and maximum years in the series in metadata
gage_yr <- gage_full %>% 
  group_by(sta) %>% 
  summarize(min_yr = min(waterYear), 
            max_yr = max(waterYear)) %>% 
  mutate(count_yr = 1 + max_yr - min_yr)

gage_meta_full <- full_join(gage_meta_full, gage_yr, by = "sta")

gage_meta_full <- gage_meta_full %>% 
  arrange(count_yr) %>% 
  select(-c(site_tp_cd, dec_coord_datum_cd, alt_datum_cd, huc_cd)) %>% 
  as.tibble() %>% 
  select(count_yr, everything())

# join together gage & gage metadata information
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_full <- full_join(gage_meta_full, gage_full, by = c("site_no", 
                                                         "sta"))
rm(gage_yr)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 2. Remove streams prior to 1990 from the analysis series----
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# identify old stations (<1990): n = 17 stations
gage_meta_drop <- gage_meta_full %>% 
  filter(max_yr < 1990) 

# identify stations for analysis: n = 44 stations; 17 + 44 = 61
gage_meta <- gage_meta_full %>% 
  filter(max_yr > 1989) # 44 sta

gage <- gage_full %>% 
    filter(max_yr > 1989) # 670,492 

gage_drop <- gage_full %>% 
  filter(max_yr <= 1988)  #  70,723

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3. Remove streams with substantial missing data----
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Identify serially incomplete observations 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_incomp <- gage %>% 
  group_by(sta, waterYear) %>% 
  summarize(i_count = n()) %>% 
  filter(i_count <= 364) %>% 
  ungroup() %>% 
  filter(waterYear > 1990) %>% 
  arrange(sta, waterYear, i_count) 

# 18 stations post-1990n are incomplete; two stations 
#   (bad_mid & chr_ang) have many incomplete years

# gage_incomp 
# A tibble: 62 x 3 - redacted & includes a note 
#   sta     waterYear i_count  note
#   <chr>       <int>   <int> <mine>
#  1 bad_mid      1991      28  most years incomplete; remove
# 17 bad_mid      2017       4
# 23 chr_ang      1991     181  most years incomplete; remove
#  7 chr_ang      2017     181

# remove stations with many incomplete years 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
drop_sta <- gage_meta %>% 
   filter(sta == "bad_mid" |    
           sta == "chr_ang"
         ) # 2 sta

gage_meta_drop <- bind_rows(gage_meta_drop, drop_sta) # 17 + 2 = 19 sta
  
gage_meta <- gage_meta %>% 
  filter(sta != "bad_mid" &  
           sta != "chr_ang"
         ) %>% 
  arrange(min_yr) %>% 
  select(sta, min_yr, max_yr, count_yr, everything()) # 44 - 2 = 42 sta

# remove observations with many incomplete years
drop_obs <- gage %>% 
  filter(sta == "bad_mid" |   
           sta == "chr_ang"
         ) # 32,742 obs

gage_drop <- bind_rows(gage_drop, drop_obs) # 70,723 + 32,742 = 103,465

gage <- gage %>% 
  filter(sta != "bad_mid" &  
           sta != "chr_ang"
         ) %>% 
  arrange(min_yr) %>% 
  select(sta, min_yr, max_yr, count_yr, everything()) 
# 670,492 - 32,742 = 637,750

rm(drop_sta, drop_obs, gage_incomp, gage_full, gage_drop, 
   gage_meta_drop, gage_meta_full) 


``` 

```{r create_post1980_subset}
# This code chunk subsets gages with 1990+ observations for clustering.
# Note - using water year (10-01) as start of year...

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Original Gages; gage_full       = 61 gages & 741,215 obs  
#   Gages w/o 1980+ or missing data = 19 gages & 103,465 (dropped) 
#   Gages remaining; gage           = 42 gages & 637,750 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Gages pre-1980; gage_lt80       = 29 gages & 262,413 obs 
#   Gages remaining; gage           = 42 gages & 375,337 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
#   Remove gages w/o full yrs       =  1 gage  &     363 obs
#   Gages remaining; gage           = 41 gages & 374,974 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
#   Complete gages from 1992-1997   = 32 gages & 226,325 obs           
#   Identify reservation stations   = 13 gages 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Steps:
# 1. filter  pre-1980 gage observations  
# 2. remove post-1990 stations w/o full years
# 3. investigate remaining stations
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 

 
# 1. filter pre-1980 gages---- 
gage_lt80_meta <- gage_meta %>% 
  filter(min_yr < 1979) # 29 gages 

gage_lt80 <- gage %>% 
  filter(min_yr <= 1979) %>% 
  filter(Date < "1979-10-01")     #  262,413 obs; waterYear 1980 

# remove pre-1980 observations    
gage <- gage %>% 
  filter(Date >= "1979-10-01")     #  375,337 obs remaining

# export observations
export(gage_lt80, "data/gage_lt80.csv") 
export(gage_lt80_meta, "data/gage_lt80_meta.csv") 

rm(gage_lt80, gage_lt80_meta)


# 2. remove post-1990 stations w/o full years----

gage_comp <- gage %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  arrange(n) %>% 
  ungroup() %>% 
  filter(n >= 364) %>%
  group_by(sta) %>%
  count() %>% 
  ungroup() %>% 
  rename(yrs_post80 = nn) %>% 
  arrange(yrs_post80)

check_sta <- anti_join(gage, gage_comp, by = "sta")
# this shows rap_cre should be dropped   

# update stations by dropping rap_cre
gage_meta <- semi_join(gage_meta, gage_comp, by = "sta")     # 41 sta
gage      <- semi_join(gage, gage_comp)                 # 374,974 obs

rm(check_sta) 

# 3. Investigate remaining stations----
gage_incomp <- gage %>% 
  group_by(sta, waterYear) %>% 
  summarize(i_count = n()) %>% 
  filter(i_count <= 364) %>% 
  ungroup() %>% 
  filter(waterYear > 1990) %>% 
  arrange(i_count, waterYear, sta) 

# filter set of Reservation stations
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_res <- gage_meta %>% 
  filter(state_cd == 46) %>% 
  filter(county_cd == 7 | 
           county_cd == 71 |
           county_cd == 95 |
           county_cd == 102
  ) %>% 
  select(min_yr, max_yr, sta)

# join post-90 reservation stations 
gage_res <- left_join(gage_comp, gage_res, by = "sta") 

gage_res <- gage_res %>% 
  arrange(max_yr, yrs_post80) 

rm(gage_comp, gage_incomp) 

# The table below is the 13 stations on the reservation, which are 
# shown with min & max year and the other stations in the region) 

# gage_res 
# A tibble: 41 x 4
#   sta     yrs_post80 min_yr max_yr
#   <chr>        <int>  <dbl>  <dbl>
# 1 wkc_wok          5   1992   1997
# 2 whi_slm          6   1962   1997
# 3 wcc_ogl         14   1966   1999
# 4 lcr_abv         19   1938   2016
# 5 whi_int         15   1929   2017
# 6 blp_bel         25   1992   2017
# 7 brsf_co         29   1989   2017
# 8 whi_sta         30   1988   2017
# 9 lcr_bel         38   1939   2017
#10 lcr_vet         38   1959   2017
#11 lwr_mar         38   1938   2017
#12 lwr_whi         38   1950   2017
#13 whi_kad         38   1942   2017
#14 whi_ogl         38   1943   2017
#15 bev_abf          7     NA     NA
#16 che_sce         10     NA     NA
#17 che_buf         11     NA     NA
#18 nio_bbb         12     NA     NA
#19 nio_gor         12     NA     NA
#20 sna_dou         13     NA     NA
#21 whi_cra         13     NA     NA
#22 nio_abb         15     NA     NA
#23 sna_bur         15     NA     NA
#24 cas_hot         16     NA     NA
#25 whi_whi         16     NA     NA
#26 lwr_abv         18     NA     NA
#27 ros_ros         18     NA     NA
#28 che_red         19     NA     NA
#29 spr_her         25     NA     NA
#30 bev_pri         26     NA     NA
#31 bat_bhr         29     NA     NA
#32 hor_oel         34     NA     NA
#33 frn_fai         35     NA     NA
#34 rap_far         37     NA     NA
#35 bat_her         38     NA     NA
#36 bat_key         38     NA     NA
#37 bev_buf         38     NA     NA
#38 che_was         38     NA     NA
#39 fal_hot         38     NA     NA
#40 hat_edg         38     NA     NA
#41 lwr_ros         38     NA     NA

# wkc-wok is 1992-1997 - so first clustering is over these dates 
#   to identify a group for wkc-wok to estimate streamflows 
```

```{r create_9398_subset}
# This code chunk creates a cluster for wkc_wok active years
# Notes: Use water year Oct1-Sept31, w/ year on the majority of months 

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Gages post1980; gage               = 41 gages & 374,974 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
#     All gages from 93-98             = 31 gages &  64,331 obs           
#   Incomplete gages from 93-98        =  1 gage (lcr_abv) 
#____________________________________________________________________ 
#     Complete gages from 93-98        = 31 gages & 61,712 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


# 1. filter gages w/ complete 1993-98 obs (wkc_wok) ----
# this is to create an initial cluster set with wkc_wok
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# filter gages for water years 1993-1998
gage_9398_meta <- gage_meta %>% 
  filter(min_yr <= 1992)  %>%
  filter(max_yr >= 1997)           # 32 gages 

gage_9398 <- gage %>% 
  filter(waterYear >= 1993) %>% 
  filter(waterYear <= 1998)        # 64,331 obs

# Identify gages missing data 1992-1997 
gage_incomp <- gage_9398 %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  arrange(n) %>% 
  ungroup() %>% 
  filter(n < 364) %>% 
  arrange(waterYear, n) # 3 obs 

#gage_incomp 
# A tibble: 4 x 3 
#  sta     waterYear     n 
#  <chr>       <int> <int> 
#1 sna_dou      1995    17 
#2 sna_bur      1995   221 
#3 lcr_abv      1996   172 * on Rez - need to add in later 
#4 che_red      1998    19 
# ~~~~~~~~~~~~~~~~~~~~~~~~ 

#  make gage_incomp full record & remove gages w/ miss. yrs in 93-98 
gage_9398_incomp <- semi_join(gage_9398_meta, gage_incomp, by = "sta") 
gage_9398_meta <- anti_join(gage_9398_meta, gage_incomp, by = "sta") 

# removed lcr_abv - for now - 31 gages remaining  

# drop incomplete stations 
gage_9398 <- anti_join(gage_9398, gage_incomp, by = "sta") 
# 61,712 remaining obs 

# check results & clean up 
chk_sta <- anti_join(gage_meta, gage_9398_meta, by = "sta") %>% 
  select(1:3) 

# chk_sta 
# A tibble: 10 x 3
#   sta     min_yr max_yr
#   <chr>    <dbl>  <dbl>
# 1 nio_gor   1928   1991   ok to drop 
# 2 lcr_abv   1938   2016 * on Rez - need to add in later 
# 3 nio_bbb   1947   1991   ok to drop 
# 4 nio_abb   1947   1994   ok to drop 
# 5 sna_bur   1948   1995   ok to drop 
# 6 cas_hot   1976   1995   ok to drop 
# 7 sna_dou   1982   1995   ok to drop 
# 8 che_red   1998   2017   ok to drop 
# 9 whi_whi   2001   2017   ok to drop 
#10 che_sce   2007   2017   ok to drop 

# export 1993-1998 & clean up 
export(gage_9398, "data/gage_9398.csv") 
export(gage_9398_meta, "data/gage_meta_9398.csv") 

rm(chk_sta, gage_9398_incomp, gage_incomp) 
```

```{r create_9016_subset} 
# This code chunk creates a cluster for lcr_abv active years
#   Complete 1990-16 obs w/o 96 (lcr_abv); range of yrs [1938, 2016] 
# 
#   Remember waterYear 1990 = Oct 1989 - Sept 1990, 
#     so the last possible wateryear is 2016; but n(2006) = 61 obs,
#       so, use 2015 as last year
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Gages post1980; gage               = 41 gages & 374,974 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
#     All gages from 90-16             = 22 gages & 261,538 obs           
#   Incomp. gages !Rez & !93-98        =  5 gages &  18,458 obs *
#____________________________________________________________________ 
#     Intermediate gages               = 22 gages & 242,900 obs 
#   Incomp. gages in 90-16             =  8 gages &  39,837 obs 
#____________________________________________________________________ 
#     Intermediate gages               = 14 gages & 210,383 obs 


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# * these gages will not be used at all in the analysis



# 1. filter gages with 1990-16 obs---- 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# filter gages for water years 1990-2016; all observations  
gage_9016_meta <- gage_meta %>% 
  filter(min_yr <= 1989)  %>% 
  filter(max_yr >= 2015)                                #  22 gages 

gage_9016 <- gage %>% 
  filter(waterYear >= 1990) %>% 
  filter(waterYear <= 2015)                             # 261,538 obs

# identify gages w/ missing years in 1990-2016 & not in 1993-1998
gage_incomp <- gage_9016 %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  arrange(n) %>% 
  ungroup() %>% 
  filter(n < 364) %>% 
  arrange(waterYear, n)                                 #  16 obs 

# prepare to use the gage_missing to examine # incomplete observations
gage_missing <- anti_join(gage_incomp, gage_9398_meta, by = "sta") 

gage_missing <- gage_missing %>% 
  arrange(waterYear)

gage_missing <- gage_missing %>% 
  filter(sta != "lcr_abv")
  
#gage_missing 
# A tibble: 7 x 3
#  sta     waterYear     n
#  <chr>       <int> <int>
#1 sna_dou      1995    17  - ok to drop 
#2 sna_bur      1995   221  - ok to drop 
#3 che_red      1998    19  - ok to drop 
#4 whi_whi      2001   122  - ok to drop 
#5 che_sce      2007   183  - ok to drop 

# drop gages missing: the set is: not Rez, incomp. 93-98
gage_drop    <- semi_join(gage_9016, gage_missing, 
                            by = "sta")                 #  18,458 obs 

gage_9016      <- anti_join(gage_9016, gage_missing, by = "sta")
                                                        # 242,500 obs 

gage_9016_meta <- anti_join(gage_9016_meta, gage_missing, by = "sta") 
                                                        #    22 gages

# 2. Remove gages incomplete 1990-16 obs---- 

# find incomplete gages
gage_incomp <- gage_9016 %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  ungroup() %>% 
  filter(n < 364) %>% 
  arrange(sta) %>% 
  group_by(sta) %>%  
  count() %>% 
  ungroup() 

# gage_incomp 
# A tibble: 8 x 2 
#  sta        nn - this is the number of water years missing  
#  <chr>   <int> 
#1 bev_pri     1 
#2 blp_bel     1 
#3 che_buf     1 
#4 lcr_abv     2 
#5 lwr_abv     3 
#6 ros_ros     2 
#7 whi_slm     1 
#8 wkc_wok     1 

# drop gages w/ missing obs, the set is: not Rez, incomp. 90-16
gage_drop      <- semi_join(gage_9016, gage_incomp, 
                            by = "sta")                  # 39,837 obs 



#### This is where I am confused !!!!!
chk_sta <- gage_drop %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  arrange(n) %>% 
  ungroup() %>% 
  filter(n < 364) %>% 
  arrange(waterYear, n)           # 11 obs of gages w/ missing yrs


gage_drop_meta <- semi_join(gage_9016_meta, gage_incomp, 
                            by = "sta")          # 40,996 obs 




gage_9016      <- anti_join(gage_9016, gage_incomp, by = "sta")

gage_9016_meta <- anti_join(gage_9016_meta, gage_incomp, by = "sta") 


```


# lcr_abv is missing data for 1996 & 2016 for range [1990, 2015]
#rm(gage_incomp) 

# subset for lcr_abv with 1990-2015, without 1996
#gage_9016_no96 <- gage %>% 
#  filter(waterYear != 1996) %>%   
#  filter(waterYear < 2016)            # 345,487 obs 

gage_9016_no96_meta <- gage_meta %>% 
  filter(min_yr <= 1990) %>% 
  filter(max_yr >  2016)               # 21 gages

gage_9016_no96 <- semi_join(gage_9016_no96, gage_9016_no96_meta) 
                                       # 238,998 obs remaining 

#### Identify gages missing data 90-16 w/o 96
gage_incomp <- gage_9016_no96 %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  arrange(n) %>% 
  ungroup() %>% 
  filter(n < 364) %>% 
  arrange(waterYear, n)                # 3 obs 

# gage_incomp 
# A tibble: 3 x 3
#  sta     waterYear     n 
#  <chr>       <int> <int> 
#1 frn_fai      1982   183 
#2 hor_oel      1983   122 
#3 che_buf      2007   192 

# remove gages with missing data 90-16 w/o 96 
gage_9016_no96 <- anti_join(gage_9016_no96, gage_incomp, by = "sta")    
                                       # 238,491 remaining 

gage_9016_no96_meta <- anti_join(gage_9016_no96_meta, gage_incomp, 
                                 by = "sta")  # 18 obs remain 

# 3. Check what is not in the groups---- 
gage_comp <- bind_rows(gage_9398_meta, gage_9016_no96_meta) %>% 
  distinct()

gage_incomp <- anti_join(gage_meta, gage_comp, by = "sta")

#### NEED TO SEE WHY LCR_ABV IS IN THE INCOMPLETE PILE!

```













```{r subset_stations}
# This code chunk creates groups of stations for clustering; steps
# 1. filter the gages with 1992-1997 observations
# 2. split remaining stations 
# 3. filter & split observations 
# 4. identify gages with no annual data 1992-1997 
# 5. move station with missing data in 92-97 to post97 group 
# 6. check for other gages with missing data 
# 7. split incomplete years & add to post97
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Gages- original     = 61 sta & 741,215 obs  
#   Gages w/o 1990+ obs = 17 sta (dropped) 
#   Gages missing data  =  2 sta (dropped) & 103,465 (total dropped)
#   Gages remaining     = 42 sta & 637,750 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Gages 1992-1996 obs = 26 gages; 306,052 obs (1990+)
#   Gages post-1996 obs =  7 gages;  38,370 obs (1990+)
#   Gages dropped       = 28 gagesl 396,793
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. filter the gages with 1992-1997 observations---- 
drop_sta <- gage_meta %>% 
   filter(max_yr < 1997) %>% 
  arrange(max_yr) # 7 stations 

gage_meta <- anti_join(gage_meta, drop_sta, by = "sta") # 42 - 7 = 35 
gage_meta_drop <- bind_rows(gage_meta_drop, drop_sta) # 26 dp & 35 rem
# 35 rem + 26 drop = 61 sta

# 2. split remaining stations----
gage_meta_9297 <- gage_meta %>% 
  filter(min_yr <= 1997) %>% 
  arrange(max_yr) %>%
  as.tibble() # 32 stations

gage_meta_97post <- gage_meta %>% 
  filter(min_yr > 1997) %>% 
  arrange(max_yr) %>%
  as.tibble() # 3 stations
# 32 pre + 3 post = 35 remaining total
# 35 rem + 26 drp = 61 sta
rm(gage_meta, drop_sta)

# 3. filter & split observations----
# drop stations w/o 1980-1997 data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
drop_obs <- gage %>% 
   filter(max_yr < 1997) %>% 
  arrange(max_yr) # 82,595 obs; 

gage_drop <- bind_rows(gage_drop, drop_obs) 
# 103,465 + 82,595 = 186,060

gage <- anti_join(gage, gage_drop, by = "sta") 
# 741,215 = 103,465 + 637750 = 82,595 + 555,155 
# closed prior 1990 + closed prior 1997 + left = 741,215

# drop obs <1980 
# ~~~~~~~~~~~~~~
drop_obs <- gage %>% 
  filter(waterYear < 1980) # 210,733 obs 
# 741,215 = 103,465 + 637750 = 82,595 + 555,155 
# closed prior 1990 + closed prior 1997 + left = 741,215

gage_drop <- bind_rows(gage_drop, drop_obs) # 210,733 
# 186,060 + 210,733 = 396,793  
# closed prior 1997 + prior 1980

gage <- gage %>% 
  filter(waterYear >= 1980) # 344,422 stations

# 741,215 = 555,155 + 82,595 + 103,465 
#        = 82595 + 103465 (closed prior 1990 + closed prior 1997)
#                + 210733 (<1980) + 344,422 (leftover)

# split gage between 92-97 & 97post
gage_9297 <- gage %>% 
  filter(min_yr <= 1997) # 327,661

gage_97post <- gage %>% 
  filter(min_yr > 1997) # 16,761 obs 

rm(gage, drop_obs) 

# 4. identify serially complete observations---- 

# Identify gages with no annual data 1992-1997 
gage_incomp <- gage_9297 %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  arrange(n) %>% 
  ungroup() %>% 
  filter(n < 364) %>% 
  arrange(waterYear) %>% 
  arrange(sta)

#gage_incomp 
# A tibble: 14 x 3
#   sta     waterYear     n
#   <chr>       <int> <int>
#  2 blp_bel      1992   176
#  6 lcr_abv      1996   172
# 14 wkc_wok      1992   119

# So, remove lcr_abv & start in Sept 1992

# 5. move station with missing data in 92-97 to post97 group----

meta_lcr_abv <- gage_meta_9297 %>% 
  filter(sta == "lcr_abv") 
gage_meta_97post <- bind_rows(gage_meta_97post, meta_lcr_abv) 
# 3 to 4 sta

gage_meta_9297 <- gage_meta_9297 %>% 
  filter(sta != "lcr_abv") # 32 to 31 sta

obs_lcr_abv <- gage_9297 %>% 
  filter(sta == "lcr_abv") #7,172 obs
gage_97post <- bind_rows(gage_97post, obs_lcr_abv) 
# 16,761 + 7,172 = 23,933

gage_9297 <- gage_9297 %>% 
  filter(sta != "lcr_abv") 
# 327,661 - 7,172 = 320,489
# 396,793 (drop) + 320,489 (92-97) + 23,933 (97post)
rm(meta_lcr_abv, obs_lcr_abv, gage_incomp) 
  
# 6. check for other gages with missing data----

# create a count of complete water years
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_9297_comp <- gage_9297 %>% 
  group_by(sta, waterYear) %>% 
  count(waterYear) %>% 
  ungroup() %>% 
  filter(n >= 365) %>% 
  filter(waterYear >= 1992) %>% 
  filter(waterYear <= 1997) %>% 
  count(sta) # 28 sta

# join count to gage_meta 
# ~~~~~~~~~~~~~~~~~~~~~~~
gage_9297_comp <- full_join(gage_meta_9297, gage_9297_comp, 
                            by = "sta") 
gage_9297_comp <- gage_9297_comp %>% 
  select(sta, min_yr, max_yr, nn, everything())

# 7. split incomplete years & add to post97----

# find the incomplete gages; n=3 
gage_9297_incomp <- gage_9297_comp %>% 
  filter(is.na(nn)) %>% 
  select(-nn)

# dropped 3 gages -> from 31 to 28 gages 
gage_meta_9297 <- gage_9297_comp %>% 
  filter(!is.na(nn)) %>% 
  select(-nn) 

# moved incomplete gages -> from 4 to 7 gages
gage_meta_97post <- bind_rows(gage_meta_97post, gage_9297_incomp) 

rm(gage_9297_comp) 

# drop extra vars to use for a filtering join
gage_9297_incomp <- gage_9297_incomp %>% 
  select(sta) 

# filter out the gages with missing 92-97 data & add to 97post 
obs_9297_incomp <- semi_join(gage_9297, gage_9297_incomp, by = "sta")
# 14,437 obs

gage_97post <- bind_rows(gage_97post, obs_9297_incomp) 
# 23,933 + 14,437 = 38,370 

gage_9297 <- anti_join(gage_9297, gage_9297_incomp, by = "sta") 
# 320,489 - 14,437 = 306,052 obs
# 396,793 + 38,370 + 306,052  
rm(obs_9297_incomp, gage_9297_incomp) 

# 8. check on completeness of 97post gages 
# create a count of complete water years
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_97post_comp1 <- gage_97post %>% 
  group_by(sta, waterYear) %>% 
  count(waterYear) %>% 
  ungroup() %>% 
  filter(n >= 365) %>% 
  filter(waterYear > 1997) %>% 
  filter(waterYear <= 2016) %>% 
  count(sta) # count of complete year stations

gage_97post_comp2 <- gage_97post %>% 
  group_by(sta, waterYear) %>% 
  count(waterYear) %>% 
  ungroup() %>% 
  filter(n >= 365) %>% 
  filter(waterYear > 1997) %>% 
  group_by(sta) %>% 
  summarise(start_yr = min(waterYear)) # summary of starting year

# join the summaries together 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_97post_comp <- inner_join(gage_97post_comp1, gage_97post_comp2)
rm(gage_97post_comp1, gage_97post_comp2)

gage_97post_comp
# sta        nn start_yr
#  <chr>   <int>    <dbl>
#1 che_buf     9     2008
#2 che_red    18     1999 *
#3 che_sce     9     2008
#4 lcr_abv    18     1998 *
#5 whi_cra     1     2004
#6 whi_int    14     2003 *
#7 whi_whi    15     2002

# so, keep as a group2 stations with complete after 2003 data 

# join the summaries to the metadata 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_97post_comp <- full_join(gage_meta_97post, gage_97post_comp, 
                            by = "sta") 
gage_97post_comp <- gage_97post_comp %>% 
  select(sta, min_yr, max_yr, start_yr, nn, everything()) 

# split betweeen complete and incomplete
gage_97post_incomp <- gage_97post_comp %>%
  filter(nn < 10) %>% 
  select(-c(nn, start_yr))

gage_97post_comp <- gage_97post_comp %>%
  filter(nn >= 10) %>% 
  select(-c(nn, start_yr))

# drop extra vars to use for a filtering join
gage_97post_incomp <- gage_97post_incomp %>% 
  select(sta) 

# update metadata
gage_meta_97post <- anti_join(gage_meta_97post, gage_97post_incomp, 
                               by = "sta") # from 7 to 4 stations 

gage_meta_drop <- bind_rows(gage_meta_drop, gage_97post_incomp) 
# from 26 to 29 stations 

# update observations
obs_97post_incomp <- semi_join(gage_97post, gage_97post_incomp)
# 12,794 obs to move to dropped 

gage_drop <- bind_rows(gage_drop, obs_97post_incomp)
# 396,793 + 12,794 = 409,587 obs

gage_97post <- anti_join(gage_97post, gage_97post_incomp) 
# 38,370 - 12,794 = 25,576 obs

rm(gage_97post_comp, gage_97post_incomp, obs_97post_incomp)

# check results
306052 + 38370 + 409587


# 9. export results----

export(gage_9297, "data/gage_9297.csv") 
export(gage_97post, "data/gage_97post.csv") 
export(gage_drop, "data/gage_drop.csv") 

export(gage_meta_9297, "data/gage_meta_9297.csv") 
export(gage_meta_97post, "data/gage_meta_97post.csv") 
export(gage_meta_drop, "data/gage_meta_drop.csv") 
```

```{r create-a-second-clustering-group}
# check whi_int
gage_check <- gage_97post %>% 
  filter(sta == "whi_int")
# waterYear 2003 is start of record 

rm(gage_check) 

# join recent gages
gage_03post <- bind_rows(gage_9297, gage_97post) %>% 
  filter(waterYear >= 2003)

gage_meta_03post <- bind_rows(gage_meta_9297, gage_meta_97post)

# create a check variable with a count of records 
check_sta <- gage_03post %>% 
  group_by(sta) %>% 
  count() %>% 
  ungroup() %>% 
  arrange(n)

# bind the check variable to metadata
gage_meta_03post <- left_join(gage_meta_03post, check_sta, by = "sta") 

gage_meta_03post <- gage_meta_03post %>% 
  select(1:4, n, everything()) %>% 
  filter(!is.na(n)) %>% 
  filter(n > 5000) %>% 
  select(-n)

check_sta <- gage_meta_03post %>% 
  select(sta)

gage_03post <- semi_join(gage_03post, check_sta, by = "sta")

# check results
check_sta <- gage_03post %>% 
  group_by(sta) %>% 
  count() %>% 
  ungroup() %>% 
  arrange(n) 

# export results 
export(gage_03post, "data/gage_03post.csv") 
export(gage_meta_03post, "data/gage_meta_03post.csv") 
```





```{r remove_incomplete, eval=FALSE}
#  6. Use the EGRET input data to increase serial completeness
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# bat_key discharge data jumps from 1947-07-31 to 1961-10-02 
chk_sta <- gage_fin5 %>% 
  filter(sta == "bat_key" & 
           waterYear < 1962) %>% 
  distinct(waterYear)

gage_int <- gage_fin5 %>% 
  filter(sta == "bat_key" & 
           waterYear < 1962) 

gage_fin6 <- gage_fin5 %>% 
  filter(sta != "bat_key" | 
           waterYear > 1961)

chk_sta <- anti_join(gage_fin5, gage_fin6) 
gage_drp6 <- bind_rows(gage_drp3, gage_int)

# che_was discharge data jumps from 1934-03-06 to 1934-03-18 
chk_sta <- gage_fin6 %>% 
  filter(sta == "che_was" & 
           waterYear < 1934) %>%
  distinct(waterYear)

gage_int <- gage_fin6 %>% 
  filter(sta == "che_was" & 
           waterYear < 1934) 

gage_fin7 <- gage_fin6 %>% 
  filter(sta != "che_was" | 
           waterYear > 1933)

chk_sta <- anti_join(gage_fin6, gage_fin7) 
gage_drp7 <- bind_rows(gage_drp6, gage_int)

# lcr_bel discharge data jumps from 1940-09-29 to 1962-08-01 
chk_sta <- gage_fin6 %>% 
  filter(sta == "lcr_bel" & 
           waterYear < 1963) %>%
  distinct(waterYear)

gage_int <- gage_fin6 %>% 
  filter(sta == "lcr_bel" & 
           waterYear < 1963) 

gage_fin7 <- gage_fin6 %>% 
  filter(sta != "lcr_bel" | 
           waterYear > 1962)

chk_sta <- anti_join(gage_fin6, gage_fin7) 
gage_drp7 <- bind_rows(gage_drp6, gage_int) 

# lwr_abv discharge data jumps from 1999-09-30 to 2000-01-01
chk_sta <- gage_fin7 %>% 
  filter(sta == "lwr_abv" & 
           waterYear > 1999) %>%
  distinct(waterYear)

gage_int <- gage_fin7 %>% 
  filter(sta == "lwr_abv" & 
           waterYear > 1999) 

gage_fin8 <- gage_fin7 %>% 
  filter(sta != "lwr_abv" | 
           waterYear < 2000)

chk_sta <- anti_join(gage_fin7, gage_fin8) 
gage_drp8 <- bind_rows(gage_drp7, gage_int)

# lwr_mar discharge data jumps from 1940-09-29 to 1962-08-01 
chk_sta <- gage_fin8 %>% 
  filter(sta == "lwr_mar" & 
           waterYear < 1963) %>%
  distinct(waterYear)

gage_int <- gage_fin8 %>% 
  filter(sta == "lwr_mar" & 
           waterYear < 1963) 

gage_fin9 <- gage_fin8 %>% 
  filter(sta != "lwr_mar" | 
           waterYear > 1962)

chk_sta <- anti_join(gage_fin8, gage_fin9) 
gage_drp9 <- bind_rows(gage_drp8, gage_int) 

# ros_ros   discharge data jumps from 1997-09-30 to 2003-03-16 
#  End @ 1997-09-30

# rap_far discharge data jumps from 1989-09-29 to 1990-10-01 
chk_sta <- gage_fin9 %>% 
  filter(sta == "rap_far" & 
           waterYear < 1990) %>%
  distinct(waterYear)

gage_int <- gage_fin9 %>% 
  filter(sta == "rap_far" & 
           waterYear < 1990) 

gage_fin10 <- gage_fin9 %>% 
  filter(sta != "rap_far" | 
           waterYear > 1991)

chk_sta    <- anti_join(gage_fin9, gage_fin10) 
gage_drp10 <- bind_rows(gage_drp9, gage_int) 

# wcc_ogl  discharge data jumps from 1981-09-29 to 1987-10-01 
# No change
# whi_slm   discharge data jumps from 1970-09-29 to  
# Start @ 1990-12-04















```

```{r next_steps_munging, eval=FALSE}
# Also add BEAR in the LODGE


# check ice - starts 2017-10-23 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ice <- gage_int %>%
  filter(code == "P Ice") %>% 
  arrange(date) 

# check provisional values 
# ~~~~~~~~~~~~~~~~~~~~~~~~
provis <- gage_int %>%
  filter(code == "P" | code == "P e" | code == "P <") %>%
  arrange(date) # starts 2016-10-05

# remove data after 2017-10-01
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int <- gage_int %>%
  filter(year != 2018)

gage_2017 <- gage_int %>%
  filter(year == 2017)

gage_prior <- gage_int %>%
  filter(year < 2017) 

gage_2017 <- gage_2017 %>%
  filter(month != 10) %>% 
  filter(month != 11) %>%
filter(month != 12)

gage_imp <- bind_rows(gage_prior, gage_2017) %>%
  arrange(desc(date)) 
rm(gage_2017, gage_int, gage_list, gage_prior, ice, provis, gage_raw) 

# simplify the naming convention for gages 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_imp <- gage_imp %>% 
  select(site_no, date, discharge, code)

station_nm <- gage_meta %>% 
  select(site_no, station_nm) %>% 
  as.tibble()

abrev <- c("whi_sta", "whi_ogl", "wcc_ogl", "whi_int", "wkc_wok", 
           "blc_wan", "whi_kad", "blp_bel", "lwr_mar", "lcr_bel", 
           "lcr_vet", "brsf_co", "bad_mid") %>%
  as.tibble() %>%
  rename(sta = value)

abrev <- bind_cols(abrev, station_nm) 

gage_imp <- full_join(abrev, gage_imp, by = "site_no")
gage_meta <- full_join(abrev, gage_meta, by = "site_no")
rm(station_nm, abrev)

# Split and spread data
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_dis_imp <- gage_imp %>% 
  select(sta, date, discharge)

gage_dis_imp <- gage_dis_imp %>% 
  spread(key = sta, value = discharge) 

# Add short name to metadata
# ~~~~~~~~~~~~~~~~~~~~~~~~~~
abrev <- gage_imp %>%
  distinct(sta, site_no)

gage_meta <- full_join(abrev, gage_meta, by = "site_no") 

# export and import station df by rio
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_raw, "data/gage_raw.csv") 
# write_lines(gage_json, "data/gage_list.json")
# export(gage_imp, "data/gage_imperial.csv") 

# export(gage_dis_imp, "data/gage_discharge_imp.csv") 


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# get site numbers from prior metadata
gage_meta <- import("data/gage_meta.csv")
#site_nums <- gage_meta %>%
#  select(sta, site_no) %>% 
#  print()


#Sample <- readNWISSample(siteNumber,parameter_cd,startDate,endDate)
# this code chunk uses dataRetreval to get discharge in cfs 
# removes provisional values and ice and saves the data as a csv.
```

```{r daily2monthly-precip}
# continued from above 
# General Purpose: prepare data for drought index 
# Specific purpose: convert daily precip to monthly precip  

# load metadata & data 
sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_day   <- as.tibble(import("data/stations_final2.csv")) 

# remove Murdo, Mission, Long Valley - see above 
#sta_day   <- sta_day %>% 
#  select(-c(lon, mur, mis)) 
#export(sta_day, file = "data/stations_final2.csv")  

# fix date & add year and month 
sta_day <- sta_day %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date)) %>% 
  mutate(year = year(date)) %>% 
  mutate(month = month(date)) %>% 
  select(date, year, month, everything()) 

# gather daily values 
sta_gath <- gather(sta_day, key = "station", value = "prcp", -date, 
                   -year, -month, factor_key = TRUE)

# create groups 
sta_group <- sta_gath %>% 
  group_by(year, month, station) 

# sum daily precip over a month 
sta_gath_mon <- sta_group %>% 
  summarize(prcp_tenths = sum(prcp)) %>% 
  mutate(prcp_mm = prcp_tenths/10) %>% 
  select(-prcp_tenths) 

# spread result - now in months  
#   ...and take a bow, because this is MAGIC!  Thnx Tidyverse. 
sta_mon <- sta_gath_mon %>% 
  spread(station, prcp_mm) %>% 
  mutate(day = 1) %>% 
  mutate(date = make_date(year = year, month = month, day = day)) %>% 
  select(date, year, month, everything()) %>% 
  select(-day) %>% 
  ungroup()

rm(sta_day, sta_gath, sta_gath_mon, sta_group) 
# export(sta_mon, file = "data/stations_monthly.csv") 
```


```{r ggplot_monthly}
# General Purpose: prepare data for drought index 
# Specific purpose: graphical EDA 
 
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_mon     <- as.tibble(import("data/stations_monthly.csv"))

# fix date & add year and month 
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date))  

# gather monthly values & order them
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE) 

# x$name <- factor(x$name, levels = x$name[order(x$val)])

# plot
ggplot(sta_gath_mon, aes(date, prcp)) +
  geom_line() +
  facet_grid(station ~ .) +
  theme_classic() + 
  labs(title = "Monthly precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1909-2018") +
       xlab("") +
       ylab("mm")

#ggplot2::ggsave(filename = "precip_mon.png", 
#                width = 6, height = 6, units = "in")
```

```{r monthly2yearly-precip}
# General Purpose: prepare data for drought index   
# Specific purpose: convert monthly precip to yearly prcp  
 
# load metadata & data 
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) 

# fix date & add year and month 
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date)) %>% 
  select(date, year, month, everything())  

# gather monthly values  
sta_gath <- gather(sta_mon, key = "station", value = "prcp", -date, 
                   -year, -month, factor_key = TRUE) 

# create groups 
sta_group <- sta_gath %>% 
  group_by(year,  station) 

# sum monthly precip over a year 
sta_gath_yr <- sta_group %>% 
  summarize(prcp = sum(prcp))  

# spread result - now in years 
sta_yr <- sta_gath_yr %>% 
  spread(station, prcp) %>% 
  filter(year != 1909) %>% 
  filter(year != 2018) %>% 
  ungroup()

rm(sta_mon, sta_gath, sta_gath_yr, sta_group)
# export(sta_yr, file = "data/stations_yearly.csv") 
```

```{r ggplot_yearly}
# General Purpose: prepare data for drought index 
# Specific purpose: graphical EDA - yearly 

# NEED TO FIX - screwed up variables 

sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_yr     <- as.tibble(import("data/stations_yearly.csv"))

# gather monthly values 
sta_gath <- gather(sta_yr, key = "station", value = "prcp",  
                   -year, factor_key = TRUE) 

# plot
ggplot(sta_gath, aes(year, prcp)) +
  geom_line() +
  facet_grid(station ~ .) +
  theme_classic() + 
  labs(title = "Annual precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1910-2017") +
       xlab("Date") +
       ylab("Depth, mm")

# ggplot2::ggsave(filename = "precip_yr.png", 
#                width = 6, height = 6, units = "in")
```


# Annual Summaries
```{r yearly_summaries}
# General Purpose: prepare data for drought index  
# Specific purpose: create summaries of data 
sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_yr   <- as.tibble(import("data/stations_yearly.csv")) 

# gather and summarize yearly values 
# Next step - do by water year???
sta_gath_yr <- gather(sta_yr, key = "station", value = "prcp", 
                   -year, factor_key = TRUE)

sta_summary_yr <- as.tibble(sta_gath_yr) %>%
  group_by(station) %>%
  summarise(mean = mean(prcp, na.rm = TRUE), 
            med = median(prcp, na.rm = TRUE),
            IQR = IQR(prcp, na.rm = TRUE), 
            min = min(prcp, na.rm = TRUE), 
            max = max(prcp, na.rm = TRUE)) %>%
  arrange(desc(med))

sta_summary_yr
# export(sta_summary_yr, file = "data/sta_summary_yr.csv") 
```

# Monthly Summaries
```{r  monthly_summaries}

# General Purpose: prepare data for drought index  
# Specific purpose: create summaries of data 
sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_mon   <- as.tibble(import("data/stations_monthly.csv")) 

# fix dates
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date)) %>% 
  select(date, year, month, everything()) 

# gather and summarize monthly values 
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE)

sta_summary_mon <- as.tibble(sta_gath_mon) %>%
  group_by(station, month) %>%
  summarise(mean = mean(prcp, na.rm = TRUE), 
            med = median(prcp, na.rm = TRUE),
            IQR = IQR(prcp, na.rm = TRUE), 
            min = min(prcp, na.rm = TRUE), 
            max = max(prcp, na.rm = TRUE)) %>%
  arrange(month) %>%
  arrange(station)

sta_summary_mon 
# export(sta_summary_mon, file = "data/sta_summary_mon.csv") 
```

```{r ggplot_monthly_boxplots}
# General Purpose: prepare data for drought index  
# Specific purpose: graphical EDA  
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) 

# fix date & add year and month  
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date))  

# gather monthly values 
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE) 

ggplot(sta_gath_mon, aes(month, prcp, group = month)) +
  geom_boxplot() +
  facet_wrap(~station) +
  theme_classic() + 
  labs(title = "Monthly precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1910-2017") +
       xlab("Date") +
       ylab("Depth, mm")

#ggplot2::ggsave(filename = "precip_yr.png", 
#                width = 6, height = 6, units = "in")
```

```{r ggplot_monthly_boxplots}
# General Purpose: prepare data for drought index  
# Specific purpose: graphical EDA  
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) 

# fix date & add year and month  
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date))  

# gather monthly values 
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE) 

ggplot(sta_gath_mon, aes(date, prcp)) +
  geom_line() +
  facet_grid(station~.) +
  theme_classic() + 
  labs(title = "Monthly precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1910-2017") +
       xlab("Date") +
       ylab("Depth, mm")

#ggplot2::ggsave(filename = "precip_yr.png", 
#                width = 6, height = 6, units = "in")
```

# Correlation Plots with Pearson Coefficients
```{r correlation}
# General Purpose: prepare data for drought index
# Specific purpose: graphical EDA - correlation plot

sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv"))
sta_yr   <- as.tibble(import("data/stations_yearly.csv"))

# fix date & add year and month
sta_yr <- sta_yr %>%
  arrange(year) 

# need to have a correlation matrix without any NA vals
# gather yearly values 
sta_gath <- gather(sta_yr, key = "station", value = "prcp", 
                   -year, factor_key = TRUE)

# filter NAs
sta_gath_72 <- sta_gath %>%
  filter(year > 1972) 

# spread remaining matrix & arrange from west to east
sta_72 <- sta_gath_72 %>%
  spread(station, prcp) %>%
  select(oel, ora, rap, int, cot)

# create a correlation matrix and plot it
sta_M <- cor(sta_72)
corrplot.mixed(sta_M,  order = "hclust", addrect = 2, upper = "ellipse", lower = "number", title = "Precipitation station correlation")
```
