
<!--
Exploratory Data Analysis Checklist by Roger Peng 
https://leanpub.com/exdata  

1.0  Formulate your question  
Spend a few minutes to figure out the question you’re really interested in, and narrow it down to be as specific as possible (without becoming uninteresting).

General question:
Are air pollution levels higher on the east coast than on the west coast?
More specific question:
Are hourly ozone levels on average higher in New York City than they are in Los Angeles?

2.0   Read in your data  
Sometimes the data will need some cleaning and every dataset has its unique quirks. The dataset is a comma-separated value (CSV) file, where each row of the file contains one daily measurement of precipation depth.  The readr package can rewrite column names to remove spaces.
> names(ozone) <- make.names(names(ozone))

3.0  Check the dataset 
3.1  Check the number of rows and columns.
3.2  Check the types of data
3.3  Look at the top and the bottom of your data 
3.4  Check your “n”s & NAs 
3.5  Validate with at least one external data source  
4.0  Try the easy solution first to answer question
5.0  Challenge your solution 
6.0  Follow up questions 

## Broad questions:
What is the drought history of the Pine Ridge Reservation?  
Does the drought extent differ across the study area?
What is streamflow variation across the Pine Ridge Reservation?

## Narrower questions:

What is streamflow variation across the Pine Ridge Reservation?

## Analysis Steps:
1.  Data read in from USGS website by EGRET (cfs) 
2.  Added names & station numbers & joined data 
3.  Data saved in a flat format (.csv) 

Didn't work these
1.  Data read in from USGS website by dataRetrieval (cfs)
2.  Data saved as array (.JSON), and flat format (.csv) 

# Next STEPS
1. blc_wan <- readNWISDaily("06446700") # this not working!
2. Identify percent coverage

2. Check on next steps from Chapter 2 list 


# Someday Maybe
# USGS 06447050 UNNAMED TRIB BUZZARD CREEK NR LONG VALLEY, SD -instant meas
https://nwis.waterdata.usgs.gov/usa/nwis/qwdata/?huc_cd=10140202&format=station_list&sort_key=site_no&index_pmcode_00065=3&index_pmcode_00060=4&index_pmcode_00062=5&index_pmcode_72020=6&sort_key=site_no&group_key=county_cd&sitefile_output_format=station_list

## Variable naming convention:   
  for USGS functions: EGRET & dataRetrieval:
startDate    Beginning date for downloading USGS gage data
endDate      End date for downloading USGS gage data
parameter_cd USGS parameter codes

xxx_yyy      individual gage names xxx = stream & yyy = location

gage         USGS streamgage station 
  _cont      set of active gages 
  _disc      set of discontinued gages   
  _othr      set of gages not found in initial analysis 

  _full      equals {_cont + _disc + _othr}; 741,215 obs for 61 sta 
  _drp#      observations sequentially dropped from _full
  _fin#      equals {_full} - {_drp#} 
  _int       intermediate dataframe for binding 
  
  _meta      metadata  
  _incomp    temporary variable to find station-years w/ incomp data 
  _mdp#      gages sequentially dropped from _meta
  _met#      equals {_meta} - {_mdp#} 
  _yr        temporary variable to calculate years of stations
  
check_sta    check variable


## Results: 


-->

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = FALSE) 
options(tibble.print_max = 70) # sets tibble output for printing 
```

```{r library, message=FALSE} 
# Sets up the library of packages   
library("here") # identifies where to save work  
library("dataRetrieval") # USGS data import  
library("EGRET") # Exploration and Graphics for RivEr Trends 
library("rio") # more robust I/O - to import and clean data  
library("lubridate") # easier dates 
library("tidyverse") 
library("janitor") # tools for examining and cleaning dirty data  
# library("DataExplorer") # quick look at NA vals 
#library('jsonlite') # tools for working with lists  
#library("magrittr") # provides aliases for easier reading 
# library("friendlyeval") 

# a useful description of commits: 
# http://r-pkgs.had.co.nz/git.html 
```

```{r import_daily_flow_active_EGRET, eval=FALSE} 
# Loads USGS gage data individually, bind_cols & exports data
# Note: found gage ids by USGS watermapper.  However, this was an
#   iterative process in deciding sites to choose.  This is reflected
#   in the row numbers (see table below) non-sequential arrangement
# Also note: the joined file of active & discontinued stations >87 mb 
# Saving this file separately may protect data integrity
# 
#   readNWISDaily(siteNumber, parameterCd = "00060", startDate = "",
#      endDate = "", interactive = TRUE, convert = TRUE) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# List of active sites
# ~~~~~~~~~~~~~~~~~~~~
# A tibble: 55 x 3
#   sta     site_no station_nm                                   
# * <chr>     <int> <chr>                                        
# 1 bad_mid 6441000 BAD R NEAR MIDLAND,SD                        
# 2 bat_bhr 6406500 BATTLE CR BELOW HERMOSA,SD                   
# 3 brsf_co 6440200 SOUTH FORK BAD R NEAR COTTONWOOD,SD          
# 4 blp_bel 6447230 BLACK PIPE CREEK NR BELVIDERE, SD            
# 5 bev_buf 6402500 BEAVER CR NEAR BUFFALO GAP,SD                
# 6 bev_pri 6402430 BEAVER CREEK NEAR PRINGLE, SD   
#26 che_buf 6402600 CHEYENNE R NEAR BUFFALO GAP SD                        
# 7 che_red 6403700 CHEYENNE RIVER AT RED SHIRT, SD              
# 8 che_sce 6408650 CHEYENNE RIVER NEAR SCENIC, SD       
#27 che_was 6423500 CHEYENNE RIVER NEAR WASTA, SD 
# 9 fal_hot 6402000 FALL R AT HOT SPRINGS,SD                     
#10 hat_edg 6400000 HAT CR NEAR EDGEMONT,SD                      
#11 hor_oel 6400875 HORSEHEAD CR AT OELRICHS,SD                  
#12 lcr_bel 6449000 LAKE CR BELOW REFUGE NEAR TUTHILL,SD 
#13 lcr_vet 6449100 LITTLE WHITE R NEAR VETAL,SD                 
#14 lwr_mar 6447500 LITTLE WHITE R NEAR MARTIN,SD                
#15 lwr_ros 6449500 LITTLE WHITE R NEAR ROSEBUD SD               
#16 lwr_whi 6450500 LITTLE WHITE R BELOW WHITE RIVER,SD          
#17 rap_far 6421500 RAPID CR NEAR FARMINGDALE,SD                 
#18 wcc_ogl 6445980 WHITE CLAY CR NEAR OGLALA SD                 
#19 whi_int 6446500 WHITE R NEAR INTERIOR,SD                     
#20 whi_kad 6447000 WHITE R NEAR KADOKA,SD                       
#21 whi_ogl 6446000 WHITE R NEAR OGLALA SD       
#28 whi_roc 6446200 WHITE R NEAR ROCKYFORD SD         
#22 whi_slm 6445700 WHITE RIVER AT SLIM BUTTE, SD                
#23 whi_sta 6445685 WHITE R NR NE-SD STATE LINE                  
#24 whi_whi 6447450 WHITE RIVER NEAR WHITE RIVER, SD             
#25 wkc_wok 6446100 WOUNDED KNEE CREEK AT WOUNDED KNEE, SD       
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. load individual gages
# add an end date to remove provisional data & gaps in vals
startDate    <- "" # blank gets earliest date
endDate      <- "2017-09-30"
parameter_cd <- "00060" 
# ~~~~~~~~~~~~~~~~~~~~~ 

bad_mid <- readNWISDaily("06441000", parameter_cd, startDate, endDate) 
bat_bhr <- readNWISDaily("06406500", parameter_cd, startDate, endDate) 
bev_buf <- readNWISDaily("06402500", parameter_cd, startDate, endDate) 
bev_pri <- readNWISDaily("06402430", parameter_cd, startDate, endDate) 
blp_bel <- readNWISDaily("06447230", parameter_cd, startDate, endDate) 
brsf_co <- readNWISDaily("06440200", parameter_cd, startDate, endDate) 
che_buf <- readNWISDaily("06402600", parameter_cd, startDate, endDate) 
che_red <- readNWISDaily("06403700", parameter_cd, startDate, endDate)  
che_sce <- readNWISDaily("06408650", parameter_cd, startDate, endDate) 
che_was <- readNWISDaily("06423500", parameter_cd, startDate, endDate) 
fal_hot <- readNWISDaily("06402000", parameter_cd, "1947-06-01", endDate) 
hat_edg <- readNWISDaily("06400000", parameter_cd, startDate, endDate) 
hor_oel <- readNWISDaily("06400875", parameter_cd, startDate, endDate) 
lcr_bel <- readNWISDaily("06449000", parameter_cd, startDate, endDate) 
lcr_vet <- readNWISDaily("06449100", parameter_cd, startDate, endDate) 
lwr_mar <- readNWISDaily("06447500", parameter_cd, startDate, endDate) 
lwr_ros <- readNWISDaily("06449500", parameter_cd, startDate, endDate) 
lwr_whi <- readNWISDaily("06450500", parameter_cd, startDate, endDate)
rap_far <- readNWISDaily("06421500", parameter_cd, startDate, endDate)
wcc_ogl <- readNWISDaily("06445980", parameter_cd, startDate, endDate) 
wkc_wok <- readNWISDaily("06446100", parameter_cd, startDate, endDate) 
whi_int <- readNWISDaily("06446500", parameter_cd, startDate, endDate) 
whi_kad <- readNWISDaily("06447000", parameter_cd, startDate, endDate)
whi_ogl <- readNWISDaily("06446000", parameter_cd, startDate, endDate)  
whi_roc <- readNWISDaily("06446200", parameter_cd, startDate, endDate) 
whi_slm <- readNWISDaily("06445700", parameter_cd, startDate, endDate) 
whi_sta <- readNWISDaily("06445685", parameter_cd, startDate, endDate) 
whi_whi <- readNWISDaily("06447450", parameter_cd, startDate ,endDate)

# 2. add short name and abbreviation to gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
bad_mid <- bad_mid %>% 
  mutate(sta = "bad_mid") %>%
  mutate(site_no = "06441000") 

bat_bhr <- bat_bhr %>%
  mutate(sta = "bat_bhr") %>%
  mutate(site_no = "06406500") 

bev_buf <- bev_buf %>%
  mutate(sta = "bev_buf") %>%
  mutate(site_no = "06402500") 

bev_pri <- bev_pri %>%
  mutate(sta = "bev_pri") %>%
  mutate(site_no = "06402430") 

blp_bel <- blp_bel %>% 
  mutate(sta = "blp_bel") %>%
  mutate(site_no = "06447230")

 brsf_co <- brsf_co %>% 
  mutate(sta = "brsf_co") %>%
  mutate(site_no = "06440200")

che_buf <- che_buf %>% 
  mutate(sta = "che_buf") %>%
  mutate(site_no = "06402600")

che_red <- che_red %>% 
  mutate(sta = "che_red") %>%
  mutate(site_no = "06403700")

che_sce <- che_sce %>% 
  mutate(sta = "che_sce") %>%
  mutate(site_no = "06408650") 

che_was <- che_was %>% 
  mutate(sta = "che_was") %>%
  mutate(site_no = "06423500") 

fal_hot <- fal_hot %>% 
  mutate(sta = "fal_hot") %>%
  mutate(site_no = "06402000") 

hat_edg <- hat_edg %>% 
  mutate(sta = "hat_edg") %>%
  mutate(site_no = "06400000") 

hor_oel <- hor_oel %>% 
  mutate(sta = "hor_oel") %>%
  mutate(site_no = "06400875") 

lcr_bel <- lcr_bel %>% 
  mutate(sta = "lcr_bel") %>%
  mutate(site_no = "06449000")

lcr_vet <- lcr_vet %>% 
  mutate(sta = "lcr_vet") %>%
  mutate(site_no = "06449100")

lwr_mar <- lwr_mar  %>% 
  mutate(sta = "lwr_mar") %>%
  mutate(site_no = "06447500")

lwr_ros <- lwr_ros  %>% 
  mutate(sta = "lwr_ros") %>%
  mutate(site_no = "06449500")

lwr_whi <- lwr_whi  %>% 
  mutate(sta = "lwr_whi") %>%
  mutate(site_no = "06450500")
 
rap_far <- rap_far  %>% 
  mutate(sta = "rap_far") %>%
  mutate(site_no = "06421500")

wcc_ogl <- wcc_ogl %>% 
  mutate(sta = "wcc_ogl") %>%
  mutate(site_no = "06445980") 

whi_int <- whi_int %>% 
  mutate(sta = "whi_int") %>%
  mutate(site_no = "06446500") 

whi_kad <- whi_kad %>% 
  mutate(sta = "whi_kad") %>%
  mutate(site_no = "06447000") 

whi_ogl <- whi_ogl %>% 
  mutate(sta = "whi_ogl") %>%
  mutate(site_no = "06446000") 

whi_slm <- whi_slm %>% 
  mutate(sta = "whi_slm") %>%
  mutate(site_no = "06445700") 

whi_roc <- whi_roc %>% 
  mutate(sta = "whi_roc") %>%
  mutate(site_no = "06446200") 

whi_sta <- whi_sta %>% 
  mutate(sta = "whi_sta") %>%
  mutate(site_no = "06445685") 

whi_whi <- whi_whi %>% 
  mutate(sta = "whi_whi") %>%
  mutate(site_no = "06447450") 

wkc_wok <- wkc_wok %>% 
  mutate(sta = "wkc_wok") %>%
  mutate(site_no = "06446100") 

# 3. join together in long format
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int1  <- bind_rows(bad_mid, bat_bhr) 
gage_int2  <- bind_rows(gage_int1, brsf_co) 
gage_int3  <- bind_rows(gage_int2, blp_bel) 
gage_int4  <- bind_rows(gage_int3, bev_buf) 
gage_int5  <- bind_rows(gage_int4, bev_pri) 
gage_int6  <- bind_rows(gage_int5, che_red) 
gage_int7  <- bind_rows(gage_int6, che_sce) 
gage_int8  <- bind_rows(gage_int7, fal_hot) 
gage_int9  <- bind_rows(gage_int8, hat_edg) 
gage_int10 <- bind_rows(gage_int9, hor_oel) 
gage_int11 <- bind_rows(gage_int10, lcr_bel) 
gage_int12 <- bind_rows(gage_int11, lcr_vet) 
gage_int13 <- bind_rows(gage_int12, lwr_mar) 
gage_int14 <- bind_rows(gage_int13, lwr_ros) 
gage_int15 <- bind_rows(gage_int14, lwr_whi) 
gage_int16 <- bind_rows(gage_int15, rap_far) 
gage_int17 <- bind_rows(gage_int16, wcc_ogl) 
gage_int18 <- bind_rows(gage_int17, whi_int) 
gage_int19 <- bind_rows(gage_int18, whi_kad) 
gage_int20 <- bind_rows(gage_int19, whi_ogl) 
gage_int21 <- bind_rows(gage_int20, whi_slm) 
gage_int22 <- bind_rows(gage_int21, whi_sta) 
gage_int23 <- bind_rows(gage_int22, whi_whi) 
gage_int24 <- bind_rows(gage_int23, wkc_wok) 
gage_int25 <- bind_rows(gage_int24, che_buf) 
gage_int26 <- bind_rows(gage_int25, che_was) 
gage_int27 <- bind_rows(gage_int26, whi_roc) 

# export daily flows to data folder
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_int27, "data/gage_cont.csv") 

#>>> git push origin refs/heads/master
#remote: warning: GH001: Large files detected. You may want to try Git #Large File Storage - https://git-lfs.github.com.        
#remote: warning: See http://git.io/iEPt8g for more information.        
#remote: warning: File data/gage_cont.csv is 60.77 MB; this is larger than #GitHub's recommended maximum file size of 50.00 MB        
#To https://github.com/cjtinant/eco-drought.git
#   be32000..a6c9c26  master -> master
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# export top half of active gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
export(gage_int14, "data/gage_cont_1st_half.csv")

# bind bottom half of active gage data - start at 36 to avoid dups
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

gage_int36 <- bind_rows(lwr_whi, rap_far) 
gage_int37 <- bind_rows(gage_int36, wcc_ogl) 
gage_int38 <- bind_rows(gage_int37, whi_int) 
gage_int39 <- bind_rows(gage_int38, whi_kad) 
gage_int40 <- bind_rows(gage_int39, whi_ogl) 
gage_int41 <- bind_rows(gage_int40, whi_slm) 
gage_int42 <- bind_rows(gage_int41, whi_sta) 
gage_int43 <- bind_rows(gage_int42, whi_whi) 
gage_int44 <- bind_rows(gage_int43, wkc_wok) 
gage_int45 <- bind_rows(gage_int44, che_buf) 
gage_int46 <- bind_rows(gage_int45, che_was) 
gage_int47 <- bind_rows(gage_int46, whi_roc) 

# export bottom half of active gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_int47, "data/gage_cont_2nd_half.csv")

```

```{r import_dailyflow_EGRET-bearLodge, eval=FALSE}
# long story, but Bear in the Lodge streamflow is restricted.  So,
# need to find another approach to getting the data. 
# one way is annual reports - but only to 2013
# Need to email the webmaster to get streamflow data.
# https://waterdata.usgs.gov/sd/nwis/inventory/?site_no=06446700&agency_cd= 

#blc_wan <- readNWISDaily("06446700") # this not working! 
#blc_wan <- blc_wan %>%
#  mutate(sta = blc_wan) %>%
#  mutate(site_no = "06446700")

```

```{r import_daily_flow_discontinued_EGRET} 

# List of discontinued sites w/in 30 mi. of PRR boundary
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# A tibble: 55 x 3
#   sta     site_no station_nm                                   
# * <chr>     <int> <chr>          
#29 ant_gor 6458000 Antelope Creek near Gordon, Nebr.           
#33 brnf_ph 6440500 NORTH FORK BAD R NEAR PHILIP SD    
#30 bea_eli 6458500 BEAR C NR ELI NEBR                           
#31 bev_abf 6402470 BEAVER CREEK ABOVE BUFFALO GAP, SD           
#32 bor_cha 6445590 BIG BORDEAUX CREEK NEAR CHADRON NEBR         
#34 cas_hot 6400497 CASCADE SPRINGS NEAR HOT SPRINGS SD          
#35 che_hot 6400500 CHEYENNE R NEAR HOT SPRINGS SD               
#36 fre_fai 6403500 FRENCH CR NEAR FAIRBURN SD                   
#37 hor_aoe 6400870 HORSEHEAD CR NEAR OELRICHS SD                
#38 lcr_abv 6448000 LAKE CR ABOVE REFUGE NEAR TUTHILL,SD         
#39 lwr_abv 6449300 LITTLE WHITE R ABV ROSEBUD SD                
#40 min_kil 6460900 MINNECHADUZA CREEK NEAR KILGORE, NEBRASKA   
#41 nio_abb 6454500 NIOBRARA RIVER ABOVE BOX BUTTE RESERVOIR, NE 
#42 nio_bbb 6455500 NIOBRARA RIVER BELOW BOX BUTTE RESERVOIR NEBR
#43 nio_cod 6459000 NIOBRARA R NEAR CODY, NEBR.                  
#44 nio_col 6457000 NIOBRARA RIVER NEAR COLCLESSER, NEBR.        
#45 nio_dun 6455900 NIOBRARA RIVER NEAR DUNLAP, NEBR.            
#46 nio_hay 6456500 NIOBRARA RIVER NR HAY SPRINGS, NEBR.         
#47 rap_cre 6422000 RAPID CR AT CRESTON SD                       
#48 ros_ros 6449400 ROSEBUD CR AT ROSEBUD SD                     
#49 sna_bur 6459500 SNAKE RIVER NEAR BURGE, NEBR.                
#50 sna_dou 6459175 SNAKE R AT DOUGHBOY, NE                      
#51 sna_mer 6459200 SNAKE RIVER ABV MERRITT RESERVOIR NEBR       
#52 spr_stf 6449250 SPRING CR NEAR ST FRANCIS SD                 
#53 whi_cha 6445500 WHITE R NEAR CHADRON NEBR                    
#54 whi_cra 6444000 White River at Crawford, Nebr.               
#55 whi_wht 6445000 WHITE R BELW COTTONWOOD C N WHITNEY, NEBR.  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. load individual gages
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# add an end date to remove provisional data & gaps in vals
startDate    <- "" #Gets earliest date
endDate      <- "2017-09-30"
parameter_cd <- "00060" 
# ~~~~~~~~~~~~~~~~~~~~~ 

ant_gor <- readNWISDaily("06458000", parameter_cd, startDate ,endDate) 
brnf_ph <- readNWISDaily("06440500", parameter_cd, startDate, endDate) 
bea_eli <- readNWISDaily("06458500", parameter_cd, startDate, endDate) 
bev_abf <- readNWISDaily("06402470", parameter_cd, startDate, endDate) 
bor_cha <- readNWISDaily("06445590", parameter_cd, startDate, endDate) 
cas_hot <- readNWISDaily("06400497", parameter_cd, startDate, endDate) 
che_hot <- readNWISDaily("06400500", parameter_cd, startDate, endDate) 
fre_fai <- readNWISDaily("06403500", parameter_cd, "1946-01-14", endDate) 
hor_aoe <- readNWISDaily("06400870", parameter_cd, startDate, endDate) 
lcr_abv <- readNWISDaily("06448000", parameter_cd, startDate, endDate) 
lwr_abv <- readNWISDaily("06449300", parameter_cd, startDate, endDate) 
min_kil <- readNWISDaily("06460900", parameter_cd, startDate, endDate) 
nio_abb <- readNWISDaily("06454500", parameter_cd, startDate, endDate) 
nio_bbb <- readNWISDaily("06455500", parameter_cd, startDate, endDate) 
nio_col <- readNWISDaily("06457000", parameter_cd, startDate, endDate) 
nio_cod <- readNWISDaily("06459000", parameter_cd, startDate, endDate) 
nio_dun <- readNWISDaily("06455900", parameter_cd, startDate, endDate) 
nio_hay <- readNWISDaily("06456500", parameter_cd, startDate, endDate) 
rap_cre <- readNWISDaily("06422000", parameter_cd, startDate, endDate) 
ros_ros <- readNWISDaily("06449400", parameter_cd, startDate, endDate) 
sna_bur <- readNWISDaily("06459500", parameter_cd, startDate, endDate) 
sna_dou <- readNWISDaily("06459175", parameter_cd, startDate, endDate) 
sna_mer <- readNWISDaily("06459200", parameter_cd, startDate, endDate) 
spr_stf <- readNWISDaily("06449250", parameter_cd, startDate, endDate) 
whi_cha <- readNWISDaily("06445500", parameter_cd, startDate, endDate) 
whi_cra <- readNWISDaily("06444000", parameter_cd, startDate, endDate)
whi_wht <- readNWISDaily("06445000", parameter_cd, startDate, endDate) 

# 2. add short name and abbreviation to gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ant_gor <- ant_gor %>% 
  mutate(sta = "ant_gor") %>%
  mutate(site_no = "06458000") 

brnf_ph <- brnf_ph %>% 
  mutate(sta = "brnf_ph") %>%
  mutate(site_no = "06440500") 

bea_eli <- bea_eli %>% 
  mutate(sta = "bea_eli") %>%
  mutate(site_no = "06458500") 

bev_abf <- bev_abf %>% 
  mutate(sta = "bev_abf") %>%
  mutate(site_no = "06402470") 

bor_cha <- bor_cha %>% 
  mutate(sta = "bor_cha") %>%
  mutate(site_no = "06445590") 

cas_hot <- cas_hot %>% 
  mutate(sta = "cas_hot") %>%
  mutate(site_no = "06400497") 

che_hot <- che_hot %>% 
  mutate(sta = "che_hot") %>%
  mutate(site_no = "06400500") 

fre_fai <- fre_fai %>% 
  mutate(sta = "fre_fai") %>%
  mutate(site_no = "06403500") 

hor_aoe <- hor_aoe %>% 
  mutate(sta = "hor_aoe") %>%
  mutate(site_no = "06400870") 

lcr_abv <- lcr_abv %>% 
  mutate(sta = "lcr_abv") %>%
  mutate(site_no = "06448000") 

lwr_abv <- lwr_abv %>% 
  mutate(sta = "lwr_abv") %>%
  mutate(site_no = "06449300") 

min_kil <- min_kil %>% 
  mutate(sta = "min_kil") %>%
  mutate(site_no = "06460900") 

nio_abb <- nio_abb %>% 
  mutate(sta = "nio_abb") %>%
  mutate(site_no = "06454500") 

nio_bbb <- nio_bbb %>% 
  mutate(sta = "nio_bbb") %>%
  mutate(site_no = "06455500") 

nio_col <- nio_col %>% 
  mutate(sta = "nio_col") %>%
  mutate(site_no = "06457000") 

nio_cod <- nio_cod %>% 
  mutate(sta = "nio_cod") %>%
  mutate(site_no = "06459000") 

nio_dun <- nio_dun %>% 
  mutate(sta = "nio_dun") %>%
  mutate(site_no = "06455900")

nio_hay <- nio_hay %>% 
  mutate(sta = "nio_hay") %>%
  mutate(site_no = "06456500") 

rap_cre <- rap_cre %>% 
  mutate(sta = "rap_cre") %>%
  mutate(site_no = "06422000")

ros_ros <- ros_ros %>% 
  mutate(sta = "ros_ros") %>%
  mutate(site_no = "06449400") 

sna_bur <- sna_bur %>% 
  mutate(sta = "sna_bur") %>%
  mutate(site_no = "06459500")

sna_dou <- sna_dou %>% 
  mutate(sta = "sna_dou") %>%
  mutate(site_no = "06459175") 

sna_mer <- sna_mer %>% 
  mutate(sta = "sna_mer") %>%
  mutate(site_no = "06459200")

spr_stf <- spr_stf %>% 
  mutate(sta = "spr_stf") %>%
  mutate(site_no = "06449250") 

whi_cha <- whi_cha %>% 
  mutate(sta = "whi_cha") %>%
  mutate(site_no = "06445500") 

whi_cra <- whi_cra %>% 
  mutate(sta = "whi_cra") %>%
  mutate(site_no = "06444000") 

whi_wht <- whi_wht %>% 
  mutate(sta = "whi_wht") %>%
  mutate(site_no = "06445000") 

# 3. join together in long format
# Next step: probably could be done more efficiently with map_df()
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int1  <- bind_rows(ant_gor, bea_eli) 
gage_int2  <- bind_rows(gage_int1, bev_abf) 
gage_int3  <- bind_rows(gage_int2, bor_cha) 
gage_int4  <- bind_rows(gage_int3, brnf_ph) 
gage_int5  <- bind_rows(gage_int4, cas_hot) 
gage_int6  <- bind_rows(gage_int5, che_hot) 
gage_int7  <- bind_rows(gage_int6, fre_fai) 
gage_int8  <- bind_rows(gage_int7, hor_aoe) 
gage_int9  <- bind_rows(gage_int8, lcr_abv) 
gage_int10 <- bind_rows(gage_int9, lwr_abv) 
gage_int11 <- bind_rows(gage_int10, min_kil) 
gage_int12 <- bind_rows(gage_int11, nio_abb) 
gage_int13 <- bind_rows(gage_int12, nio_bbb) 
gage_int14 <- bind_rows(gage_int13, nio_cod) 
gage_int15 <- bind_rows(gage_int14, nio_col) 
gage_int16 <- bind_rows(gage_int15, nio_dun) 
gage_int17 <- bind_rows(gage_int16, nio_hay) 
gage_int18 <- bind_rows(gage_int17, rap_cre) 
gage_int19 <- bind_rows(gage_int18, ros_ros) 
gage_int20 <- bind_rows(gage_int19, sna_bur) 
gage_int21 <- bind_rows(gage_int20, sna_dou) 
gage_int22 <- bind_rows(gage_int21, sna_mer) 
gage_int23 <- bind_rows(gage_int22, spr_stf) 
gage_int24 <- bind_rows(gage_int23, whi_cha) 
gage_int25 <- bind_rows(gage_int24, whi_cra) 
gage_int26 <- bind_rows(gage_int25, whi_wht) 

# export daily flows to data folder
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
export(gage_int26, "data/gage_disc.csv") 
```

```{r import_daily_flow_overlooked} 

# List of possible extra sites - list was iteratively constructed
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# A tibble: 6 x 2
#   sta     site_no station_nm                                   
# * <chr>     <int> <chr>          
#1 che_ang 06401500 CHEYENNE R BELOW ANGOSTURA DAM,SD
#2 frn_fai 06403300 FRENCH CR ABOVE FAIRBURN SD      
#3 bat_key 06404000 BATTLE CR NEAR KEYSTONE,SD       
#4 bat_bhr 06406000 BATTLE CR AT HERMOSA,SD          
#5 spr_her 06408500 SPRING CR NEAR HERMOSA,SD        
#6 nio_gor 06457500 NIOBRARA RIVER NEAR GORDON, NEBR.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# this is what was done to find the stations above: 

# this code chunk checks for "missed" stations.  
# for filtering info see: https://help.waterdata.usgs.gov/site_tp_cd
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. get huc codes for gages already selected
gage_meta <- import("data/gage_meta.csv") %>% 
  arrange(sta)

hucs <- gage_meta %>% 
  distinct(huc_cd) %>%
  arrange() %>%
  mutate(huc_cd = as.character(huc_cd))

# 2. split the API query into smaller parts
hucs1 <- hucs %>%
  slice(1:6)

hucs2 <- hucs %>%
  slice(7:13) 

# 3. get the set of NWIS data for each of the slices
gages1 <- hucs1 %>% 
     map_df(~ whatNWISdata(huc = .x)) 

gages2 <- hucs2 %>% 
     map_df(~ whatNWISdata(huc = .x)) 

# 4. create a single dataframe and clean up 
gages1 <- gages1 %>% 
  mutate(alt_acy_va = as.numeric(alt_acy_va))

gages_pos <- bind_rows(gages1, gages2)
rm(hucs, hucs1, hucs2, gages1, gages2)

# 5. explore data types
# ~~~~~~~~~~~~~~~~~~~~~~~

#   a. find site_types 
NWIS_type <- gages_pos %>% 
  distinct(site_tp_cd) %>%  
  arrange(site_tp_cd)

#   b. remove atmosphere (AT), land (LA), & subsurface (SB) site types
gage_pos1 <- gages_pos %>% 
  filter(site_tp_cd != "AT" &
           site_tp_cd != "LA-SH" & 
           site_tp_cd != "LA-SNK" &
           site_tp_cd != "SB-CV" &
           site_tp_cd != "SB" 
         ) %>% 
  arrange(site_tp_cd) 

#   c. remove facilities (FA) site type 
gage_pos2 <- gage_pos1 %>% 
  filter(site_tp_cd != "FA-CI" &
           site_tp_cd != "FA-OF" & 
           site_tp_cd != "FA-SEW" & 
           site_tp_cd != "FA-STS" & 
           site_tp_cd != "FA-WDS"
         )

#   d. remove groundwater (GW) & spring site types 
gw <- gage_pos2 %>% 
  filter(site_tp_cd == "GW" |
           site_tp_cd == "GW-CR" | 
           site_tp_cd == "GW-IW" |
           site_tp_cd == "GW-MW" | 
           site_tp_cd == "GW-TH" | 
          site_tp_cd == "SP"
         )

gage_pos3 <- gage_pos2 %>% 
  filter(site_tp_cd != "GW" &
           site_tp_cd != "GW-CR" & 
           site_tp_cd != "GW-IW" &
           site_tp_cd != "GW-MW" & 
           site_tp_cd != "GW-TH" & 
          site_tp_cd != "SP"
         )

#   e. remove lake (LK) & canal (CA) site types 
gage_pos4 <- gage_pos3 %>% 
  filter(site_tp_cd != "LK" & 
           site_tp_cd != "ST-CA" &
           site_tp_cd != "ST-DCH"
           ) 

#   e. check streams == gage_pos4 & clean up
gage_pos5 <- gage_pos4 %>% 
  filter(site_tp_cd != "ST") 

gage_strm <- gages_pos %>% 
  filter(site_tp_cd == "ST") 

rm(NWIS_type, gage_pos, gage_pos1, gage_pos2, gage_pos3, 
   gage_pos4, gage_pos5) 

#   f. remove bio, sediment, wq, report, peak, temp data
bio <- gage_strm %>% 
  filter(medium_grp_cd == "bio")

sed <- gage_strm %>% 
  filter(medium_grp_cd == "sed") 

wq <- gage_strm %>% 
  filter(data_type_cd == "qw") 

ad <- gage_strm %>% 
  filter(data_type_cd == "ad") 

pk <- gage_strm %>% 
  filter(data_type_cd == "pk") 

tmp <- gage_strm %>% 
  filter(parm_cd == "00010") 

gages_dv <- gage_strm %>% 
  filter(medium_grp_cd != "bio" & 
           medium_grp_cd != "sed" & 
           data_type_cd != "qw" & 
           data_type_cd != "uv" & 
           data_type_cd != "ad" &
           data_type_cd != "sv" &
           data_type_cd != "pk" & 
           parm_cd != "00010" & 
           parm_cd != "00065" & 
           parm_cd != "00095" & 
           parm_cd != "00300" & 
           parm_cd != "00400" & 
           parm_cd != "63680" & 
           parm_cd != "80154" & 
           parm_cd != "80155" 
           ) 

# g. clean dataframe to fit the area
gages_pot <- gages_dv %>% 
  mutate(alt_va = as.numeric(alt_va)) %>% 
  filter(count_nu > 365*5) %>%
  filter(dec_lat_va < 43.97) %>% 
  filter(dec_long_va > -103.58825) %>% 
  filter(dec_long_va < -100.55167) %>% 
  filter(alt_va < 4050) %>% 
  mutate(end_date = ymd(end_date)) %>% 
  mutate(end_yr = year(end_date)) %>% 
  filter(end_yr > 1990)

# bind new and old metadata cols together to check
gages_pot_list <- gages_pot %>% 
  select(site_no, station_nm) %>% 
  mutate(site_no = as.integer(site_no))
gages_exist <- gage_meta %>% 
    select(site_no, station_nm) 

gages_new <- full_join(gages_pot_list, gages_exist, by = "site_no") 
gages_new <- gages_new %>% 
  filter(is.na(station_nm.y)) %>% 
  rename(station_nm = station_nm.x) %>% 
  select(-station_nm.y) %>% 
  as.tibble() 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. load individual gages
# ~~~~~~~~~~~~~~~~~~~~~~~~~
# add an end date to remove provisional data & gaps in vals
startDate    <- "" #Gets earliest date
endDate      <- "2017-09-30"
parameter_cd <- "00060" 
# ~~~~~~~~~~~~~~~~~~~~~ 
bat_bhr <- readNWISDaily("06406000", parameter_cd, startDate ,endDate) 
bat_key <- readNWISDaily("06404000", parameter_cd, startDate ,endDate) 
che_ang <- readNWISDaily("06401500", parameter_cd, startDate ,endDate)
frn_fai <- readNWISDaily("06403300", parameter_cd, startDate ,endDate) 
nio_gor <- readNWISDaily("06457500", parameter_cd, startDate ,endDate) 
spr_her <- readNWISDaily("06408500", parameter_cd, startDate ,endDate)  

# 2. add short name and abbreviation to gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

bat_bhr <- bat_bhr %>% 
  mutate(sta = "bat_her") %>%
  mutate(site_no = "6406000") 

bat_key <- bat_key %>% 
  mutate(sta = "bat_key") %>%
  mutate(site_no = "6404000") 

che_ang <- che_ang  %>% 
  mutate(sta = "che_ang") %>%
  mutate(site_no = "6401500")

frn_fai <- frn_fai %>% 
  mutate(sta = "frn_fai") %>%
  mutate(site_no = "6403300") 

nio_gor <- nio_gor %>% 
  mutate(sta = "nio_gor") %>%
  mutate(site_no = "6457500") 

spr_her <- spr_her %>% 
  mutate(sta = "spr_her") %>%
  mutate(site_no = "6408500")

# 3. join together in long format
# Next step: probably could be done more efficiently with map_df()
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int1  <- bind_rows(bat_bhr, bat_key) 
gage_int2  <- bind_rows(gage_int1, che_ang) 
gage_int3  <- bind_rows(gage_int2, frn_fai) 
gage_int4  <- bind_rows(gage_int3, nio_gor) 
gage_int5  <- bind_rows(gage_int4, spr_her) 

# export daily flows to data folder
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_int5, "data/gage_other.csv") 

``` 

```{r import_gage_metadata, eval=FALSE} 
  
# import daily streamflow datasets  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_cont <- import("data/gage_cont.csv") 
gage_disc <- import("data/gage_disc.csv") 
gage_othr <- import("data/gage_other.csv") 
 
# check for duplicate data  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_cont_ck  <- gage_cont %>% 
  distinct(sta, site_no) 

gage_dist_ck  <- gage_disc %>% 
  distinct(sta, site_no) 

gage_othr_ck  <- gage_othr %>% 
  distinct(sta, site_no) 

gage_names <- bind_rows(gage_cont_ck, gage_dist_ck) 
gage_names <- bind_rows(gage_names, gage_othr_ck) 

rm(gage_cont_ck, gage_dist_ck, gage_othr_ck) 

# join data & import metadata 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~ 

gage_full  <- bind_rows(gage_cont, gage_disc)  
gage_full  <- bind_rows(gage_full, gage_othr) 

# gage$site_no is brought in as an integer but needs to be 8-dig char 
gage_full <- gage_full %>% 
  mutate(sta = as.character(sta)) %>%  
  mutate(site_no = zeroPad(site_no, 8)) %>% 
  select(site_no, sta, everything()) 

# reduces the set down to a small number to reduce API calls 
gage_id <- gage_full %>% 
  distinct(site_no, sta) 

# iterate across a list of gage ids by purrr::map_dfr 
# & get gage metadata using dataRetrieval::readNWISsite 
gage_meta_list <- map(gage_id$site_no, readNWISsite) 

# extract the wanted dataframe items from the list 
gage_meta <- gage_meta_list %>% 
  map_df(extract, 
               c("site_no", "station_nm", "site_tp_cd", "dec_lat_va", 
                 "dec_long_va", "dec_coord_datum_cd", "state_cd", 
                 "county_cd", "alt_va", "alt_datum_cd", "huc_cd", 
                 "drain_area_va", "contrib_drain_area_va")) 
rm(gage_meta_list) 

# join the abbreviation to the metadata 
gage_meta <- gage_meta %>%  
  full_join(gage_id, gage_meta, by = "site_no") 

gage_meta <- gage_meta %>% 
  select(sta, everything()) 

# check on integrity of the data by looking at counts 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
ck_sta <- gage_meta %>% 
  distinct(sta) 

ck_num <- gage_meta %>% 
  distinct(site_no) 

ck_sta_num <- gage_meta %>% 
  distinct(sta, site_no) 

ck_nam <- gage_meta %>% 
  distinct(station_nm) 

ck_sta_nam <- gage_meta %>% 
  distinct(sta, station_nm) 

num_nam <- gage_meta %>% 
  distinct(site_no, station_nm) 

ck_sta_nam_num <- gage_meta %>% 
  distinct(sta, site_no, station_nm) 

# export dataframes of the largest population of gages 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# export(gage, "data/gage_full.csv") # too big for GitHub 
# export(gage_meta, "data/gage_meta.csv")  

# create a table to show abbreviation, site no & station name 
gage_table <- gage_meta %>% 
  select(sta, site_no, station_nm) %>% 
  as.tibble() 
```

```{r clean_daily flow}
# this code chunk checks and removes gages w/o useful characteristics
#   for future analysis 
# This code is a refactor of prior code above, some of it broken
# 
# Steps: 
# 1. Assemble a full dataset (N = 61 stations)
# 2. Remove streams prior to 1990 from the analysis series 
# 3. Remove streams with substantial missing data
# 4. Investigate remaining stations

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1. Assemble a set of all possible recorded streamflows----
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_meta_full <- import("data/gage_meta.csv") %>% 
  arrange(sta) 

gage_cont <- import("data/gage_cont.csv") 
gage_disc <- import("data/gage_disc.csv") 
gage_othr <- import("data/gage_other.csv") 

# Assemble a complete set of stations identifed in prior steps
gage_full  <- bind_rows(gage_cont, gage_disc, gage_othr)  

gage_full <- gage_full %>% 
  arrange(sta) %>% 
  select(site_no, sta, Date, i, everything()) 

# check results - should be 61 stations; yes
check_sta <- gage_full %>% 
  distinct(sta)
rm(gage_cont, gage_disc, gage_othr, check_sta)  

# calculate the minimun and maximum years in the series in metadata
gage_yr <- gage_full %>% 
  group_by(sta) %>% 
  summarize(min_yr = min(waterYear), 
            max_yr = max(waterYear)) %>% 
  mutate(count_yr = 1 + max_yr - min_yr)

gage_meta_full <- full_join(gage_meta_full, gage_yr, by = "sta")

gage_meta_full <- gage_meta_full %>% 
  arrange(count_yr) %>% 
  select(-c(site_tp_cd, dec_coord_datum_cd, alt_datum_cd, huc_cd)) %>% 
  as.tibble() %>% 
  select(count_yr, everything())

# join together gage & gage metadata information
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_full <- full_join(gage_meta_full, gage_full, by = c("site_no", "sta"))
rm(gage_yr)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 2. Remove streams prior to 1990 from the analysis series----
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# identify old stations (<1990): n = 17 stations
gage_meta_drop <- gage_meta_full %>% 
  filter(max_yr < 1990) 

# identify stations for analysis: n = 44 stations; 17 + 44 = 61
gage_meta <- gage_meta_full %>% 
  filter(max_yr > 1989) # 44 sta

gage <- gage_full %>% 
    filter(max_yr > 1989) # 670,492 

gage_drop <- gage_full %>% 
  filter(max_yr <= 1988)  #  70,723

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3. Remove streams with substantial missing data----
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Identify serially incomplete observations 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_incomp <- gage %>% 
  group_by(sta, waterYear) %>% 
  summarize(i_count = n()) %>% 
  filter(i_count <= 364) %>% 
  ungroup() %>% 
  filter(waterYear > 1990) %>% 
  arrange(sta, waterYear, i_count) 

# 18 stations post-1990n are incomplete; two stations 
#   (bad_mid & chr_ang) have many incomplete years

# gage_incomp 
# A tibble: 62 x 3 - redacted & includes a note 
#   sta     waterYear i_count  note
#   <chr>       <int>   <int> <mine>
#  1 bad_mid      1991      28  most years incomplete; remove
# 17 bad_mid      2017       4
# 23 chr_ang      1991     181 most years incomplete; remove
#  7 chr_ang      2017     181

# remove stations with many incomplete years 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
drop_sta <- gage_meta %>% 
   filter(sta == "bad_mid" |    
           sta == "chr_ang"
         ) # 2 sta

gage_meta_drop <- bind_rows(gage_meta_drop, drop_sta) # 17 + 2 = 19 sta
  
gage_meta <- gage_meta %>% 
  filter(sta != "bad_mid" &  
           sta != "chr_ang"
         ) %>% 
  arrange(min_yr) %>% 
  select(sta, min_yr, max_yr, count_yr, everything()) # 44 - 2 = 42 sta

# remove observations with many incomplete years
drop_obs <- gage %>% 
  filter(sta == "bad_mid" |   
           sta == "chr_ang"
         ) # 32,742 obs

gage_drop <- bind_rows(gage_drop, drop_obs) # 70,723 + 32,742 = 103,465

gage <- gage %>% 
  filter(sta != "bad_mid" &  
           sta != "chr_ang"
         ) %>% 
  arrange(min_yr) %>% 
  select(sta, min_yr, max_yr, count_yr, everything()) 
# 670,492 - 32,742 = 637,750

rm(drop_sta, drop_obs, gage_incomp) 

# 4. Investigate remaining stations----
gage_incomp <- gage %>% 
  group_by(sta, waterYear) %>% 
  summarize(i_count = n()) %>% 
  filter(i_count <= 364) %>% 
  ungroup() %>% 
  filter(waterYear > 1990) %>% 
  arrange(waterYear, sta, i_count) 

# filter set of Reservation stations
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_met_res <- gage_meta %>% 
  filter(state_cd == 46) %>% 
  filter(county_cd == 7 | 
           county_cd == 71 |
           county_cd == 95 |
           county_cd == 102
  ) %>% 
  select(min_yr, max_yr, sta)

# join the incomplete & reservation stations 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_incomp <- left_join(gage_incomp, gage_met_res,  
                         by = "sta")

gage_incomp <- gage_incomp %>% 
  arrange(sta) 

rm(gage_met_res, gage_incomp)

#gage_incomp 
# these are the stations with missing data; NA is non-reservation 
#  sta     waterYear i_count min_yr max_yr
#   <chr>       <int>   <int>  <dbl>  <dbl>
# 1 bev_pri      1991     342     NA     NA
# 2 blp_bel      1992     176   1992   2017
# 3 che_buf      2007     192     NA     NA
# 4 che_red      1998      19     NA     NA
# 5 che_sce      2007     183     NA     NA
# 6 lcr_abv      1996     172   1938   2016
# 7 lcr_abv      2016      61   1938   2016
# 8 lwr_abv      2000     274     NA     NA 
# 9 lwr_abv      2003     316     NA     NA
#10 lwr_abv      2004      48     NA     NA
#11 nio_abb      1994     364     NA     NA
#12 nio_gor      1991     364     NA     NA
#13 ros_ros      2003     199     NA     NA
#14 ros_ros      2004      79     NA     NA
#15 sna_bur      1995     221     NA     NA
#16 sna_dou      1995      17     NA     NA
#17 wcc_ogl      1999     364   1966   1999 
#18 whi_slm      1991     301   1962   1997 
#19 whi_whi      2001     122     NA     NA 
#20 wkc_wok      1992     119   1992   1997

# wkc-wok is 1992-1997 - so first clustering is over these dates 
#   to identify a group for wkc-wok to estimate streamflows 
``` 

```{r subset_stations_92-97}
# This code chunk creates groups of stations for clustering; steps
# 1. filter the gages with 1992-1997 observations
# 2. split remaining stations 
# 3. filter & split observations 
# 4. identify gages with no annual data 1992-1997 
# 5. move station with missing data in 92-97 to post97 group 
# 6. check for other gages with missing data 
# 7. split incomplete years & add to post97
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Gages- original     = 61 sta & 741,215 obs  
#   Gages w/o 1990+ obs = 17 sta (dropped) 
#   Gages missing data  =  2 sta (dropped) & 103,465 (total dropped)
#   Gages remaining     = 42 sta & 637,750 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Gages 1992-1996 obs = 26 gages; 306,052 obs (1990+)
#   Gages post-1996 obs =  7 gages;  38,370 obs (1990+)
#   Gages dropped       = 28 gagesl 396,793
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. filter the gages with 1992-1997 observations---- 
drop_sta <- gage_meta %>% 
   filter(max_yr < 1997) %>% 
  arrange(max_yr) # 7 stations 

gage_meta <- anti_join(gage_meta, drop_sta, by = "sta") # 42 - 7 = 35 
gage_meta_drop <- bind_rows(gage_meta_drop, drop_sta) # 26 dp & 35 rem
# 35 rem + 26 drop = 61 sta

# 2. split remaining stations----
gage_meta_9297 <- gage_meta %>% 
  filter(min_yr <= 1997) %>% 
  arrange(max_yr) %>%
  as.tibble() # 32 stations

gage_meta_97post <- gage_meta %>% 
  filter(min_yr > 1997) %>% 
  arrange(max_yr) %>%
  as.tibble() # 3 stations
# 32 pre + 3 post = 35 remaining total
# 35 rem + 26 drp = 61 sta
rm(gage_meta, drop_sta)

# 3. filter & split observations----
# drop stations w/o 1980-1997 data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
drop_obs <- gage %>% 
   filter(max_yr < 1997) %>% 
  arrange(max_yr) # 82,595 obs; 

gage_drop <- bind_rows(gage_drop, drop_obs) 
# 103,465 + 82,595 = 186,060

gage <- anti_join(gage, gage_drop, by = "sta") 
# 741,215 = 103,465 + 637750 = 82,595 + 555,155 
# closed prior 1990 + closed prior 1997 + left = 741,215

# drop obs <1980 
# ~~~~~~~~~~~~~~
drop_obs <- gage %>% 
  filter(waterYear < 1980) # 210,733 obs 
# 741,215 = 103,465 + 637750 = 82,595 + 555,155 
# closed prior 1990 + closed prior 1997 + left = 741,215

gage_drop <- bind_rows(gage_drop, drop_obs) # 210,733 
# 186,060 + 210,733 = 396,793  
# closed prior 1997 + prior 1980

gage <- gage %>% 
  filter(waterYear >= 1980) # 344,422 stations

# 741,215 = 555,155 + 82,595 + 103,465 
#        = 82595 + 103465 (closed prior 1990 + closed prior 1997)
#                + 210733 (<1980) + 344,422 (leftover)

# split gage between 92-97 & 97post
gage_9297 <- gage %>% 
  filter(min_yr <= 1997) # 327,661

gage_97post <- gage %>% 
  filter(min_yr > 1997) # 16,761 obs 

rm(gage, drop_obs) 

# 4. identify serially complete observations---- 

# Identify gages with no annual data 1992-1997 
gage_incomp <- gage_9297 %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  arrange(n) %>% 
  ungroup() %>% 
  filter(n < 364) %>% 
  arrange(waterYear) %>% 
  arrange(sta)

#gage_incomp 
# A tibble: 14 x 3
#   sta     waterYear     n
#   <chr>       <int> <int>
#  2 blp_bel      1992   176
#  6 lcr_abv      1996   172
# 14 wkc_wok      1992   119

# So, remove lcr_abv & start in Sept 1992

# 5. move station with missing data in 92-97 to post97 group----

meta_lcr_abv <- gage_meta_9297 %>% 
  filter(sta == "lcr_abv") 
gage_meta_97post <- bind_rows(gage_meta_97post, meta_lcr_abv) 
# 3 to 4 sta

gage_meta_9297 <- gage_meta_9297 %>% 
  filter(sta != "lcr_abv") # 32 to 31 sta

obs_lcr_abv <- gage_9297 %>% 
  filter(sta == "lcr_abv") #7,172 obs
gage_97post <- bind_rows(gage_97post, obs_lcr_abv) 
# 16,761 + 7,172 = 23,933

gage_9297 <- gage_9297 %>% 
  filter(sta != "lcr_abv") 
# 327,661 - 7,172 = 320,489
# 396,793 (drop) + 320,489 (92-97) + 23,933 (97post)
rm(meta_lcr_abv, obs_lcr_abv, gage_incomp) 
  
# 6. check for other gages with missing data----

# create a count of complete water years
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_9297_comp <- gage_9297 %>% 
  group_by(sta, waterYear) %>% 
  count(waterYear) %>% 
  ungroup() %>% 
  filter(n >= 365) %>% 
  filter(waterYear >= 1992) %>% 
  filter(waterYear <= 1997) %>% 
  count(sta) # 28 sta

# join count to gage_meta 
# ~~~~~~~~~~~~~~~~~~~~~~~
gage_9297_comp <- full_join(gage_meta_9297, gage_9297_comp, 
                            by = "sta") 
gage_9297_comp <- gage_9297_comp %>% 
  select(sta, min_yr, max_yr, nn, everything())

# 7. split incomplete years & add to post97----

# find the incomplete gages; n=3 
gage_9297_incomp <- gage_9297_comp %>% 
  filter(is.na(nn)) %>% 
  select(-nn)

# dropped 3 gages -> from 31 to 28 gages 
gage_meta_9297 <- gage_9297_comp %>% 
  filter(!is.na(nn)) %>% 
  select(-nn) 

# moved incomplete gages -> from 4 to 7 gages
gage_meta_97post <- bind_rows(gage_meta_97post, gage_9297_incomp) 

rm(gage_9297_comp) 

# drop extra vars to use for a filtering join
gage_9297_incomp <- gage_9297_incomp %>% 
  select(sta) 

# filter out the gages with missing 92-97 data & add to 97post 
obs_9297_incomp <- semi_join(gage_9297, gage_9297_incomp, by = "sta")
# 14,437 obs

gage_97post <- bind_rows(gage_97post, obs_9297_incomp) 
# 23,933 + 14,437 = 38,370 

gage_9297 <- anti_join(gage_9297, gage_9297_incomp, by = "sta") 
# 320,489 - 14,437 = 306,052 obs
# 396,793 + 38,370 + 306,052  
rm(obs_9297_incomp, gage_9297_incomp) 

# 8. check on completeness of 97post gages 
# create a count of complete water years
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_97post_comp1 <- gage_97post %>% 
  group_by(sta, waterYear) %>% 
  count(waterYear) %>% 
  ungroup() %>% 
  filter(n >= 365) %>% 
  filter(waterYear > 1997) %>% 
  filter(waterYear <= 2016) %>% 
  count(sta) # count of complete year stations

gage_97post_comp2 <- gage_97post %>% 
  group_by(sta, waterYear) %>% 
  count(waterYear) %>% 
  ungroup() %>% 
  filter(n >= 365) %>% 
  filter(waterYear > 1997) %>% 
  group_by(sta) %>% 
  summarise(start_yr = min(waterYear)) # summary of starting year

# join the summaries together 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_97post_comp <- inner_join(gage_97post_comp1, gage_97post_comp2)
rm(gage_97post_comp1, gage_97post_comp2)

gage_97post_comp
# sta        nn start_yr
#  <chr>   <int>    <dbl>
#1 che_buf     9     2008
#2 che_red    18     1999 *
#3 che_sce     9     2008
#4 lcr_abv    18     1998 *
#5 whi_cra     1     2004
#6 whi_int    14     2003 *
#7 whi_whi    15     2002

# so, keep as a group2 stations with complete after 2003 data 

# join the summaries to the metadata 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_97post_comp <- full_join(gage_meta_97post, gage_97post_comp, 
                            by = "sta") 
gage_97post_comp <- gage_97post_comp %>% 
  select(sta, min_yr, max_yr, start_yr, nn, everything()) 

# split betweeen complete and incomplete
gage_97post_incomp <- gage_97post_comp %>%
  filter(nn < 10) %>% 
  select(-c(nn, start_yr))

gage_97post_comp <- gage_97post_comp %>%
  filter(nn >= 10) %>% 
  select(-c(nn, start_yr))

# drop extra vars to use for a filtering join
gage_97post_incomp <- gage_97post_incomp %>% 
  select(sta) 

# update metadata
gage_meta_97post <- anti_join(gage_meta_97post, gage_97post_incomp, 
                               by = "sta") # from 7 to 4 stations 

gage_meta_drop <- bind_rows(gage_meta_drop, gage_97post_incomp) 
# from 26 to 29 stations 

# update observations
obs_97post_incomp <- semi_join(gage_97post, gage_97post_incomp)
# 12,794 obs to move to dropped 

gage_drop <- bind_rows(gage_drop, obs_97post_incomp)
# 396,793 + 12,794 = 409,587 obs

gage_97post <- anti_join(gage_97post, gage_97post_incomp) 
# 38,370 - 12,794 = 25,576 obs

rm(gage_97post_comp, gage_97post_incomp, obs_97post_incomp)

# check results
306052 + 38370 + 409587


# 9. export results----

export(gage_9297, "data/gage_9297.csv") 
export(gage_97post, "data/gage_97post.csv") 
export(gage_drop, "data/gage_drop.csv") 

export(gage_meta_9297, "data/gage_meta_9297.csv") 
export(gage_meta_97post, "data/gage_meta_97post.csv") 
export(gage_meta_drop, "data/gage_meta_drop.csv") 
```

```{r create-a-second-clustering-group}
# check whi_int
gage_check <- gage_97post %>% 
  filter(sta == "whi_int")
# waterYear 2003 is start of record 

rm(gage_check) 

# join recent gages
gage_03post <- bind_rows(gage_9297, gage_97post) %>% 
  filter(waterYear >= 2003)

gage_meta_03post <- bind_rows(gage_meta_9297, gage_meta_97post)

# create a check variable with a count of records 
check_sta <- gage_03post %>% 
  group_by(sta) %>% 
  count() %>% 
  ungroup() %>% 
  arrange(n)

# bind the check variable to metadata
gage_meta_03post <- left_join(gage_meta_03post, check_sta, by = "sta") 

gage_meta_03post <- gage_meta_03post %>% 
  select(1:4, n, everything()) %>% 
  filter(!is.na(n)) %>% 
  filter(n > 5000) %>% 
  select(-n)

check_sta <- gage_meta_03post %>% 
  select(sta)

gage_03post <- semi_join(gage_03post, check_sta, by = "sta")

# check results
check_sta <- gage_03post %>% 
  group_by(sta) %>% 
  count() %>% 
  ungroup() %>% 
  arrange(n) 

# export results 
export(gage_03post, "data/gage_03post.csv") 
export(gage_meta_03post, "data/gage_meta_03post.csv") 
```





```{r remove_incomplete, eval=FALSE}
#  6. Use the EGRET input data to increase serial completeness
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# bat_key discharge data jumps from 1947-07-31 to 1961-10-02 
chk_sta <- gage_fin5 %>% 
  filter(sta == "bat_key" & 
           waterYear < 1962) %>% 
  distinct(waterYear)

gage_int <- gage_fin5 %>% 
  filter(sta == "bat_key" & 
           waterYear < 1962) 

gage_fin6 <- gage_fin5 %>% 
  filter(sta != "bat_key" | 
           waterYear > 1961)

chk_sta <- anti_join(gage_fin5, gage_fin6) 
gage_drp6 <- bind_rows(gage_drp3, gage_int)

# che_was discharge data jumps from 1934-03-06 to 1934-03-18 
chk_sta <- gage_fin6 %>% 
  filter(sta == "che_was" & 
           waterYear < 1934) %>%
  distinct(waterYear)

gage_int <- gage_fin6 %>% 
  filter(sta == "che_was" & 
           waterYear < 1934) 

gage_fin7 <- gage_fin6 %>% 
  filter(sta != "che_was" | 
           waterYear > 1933)

chk_sta <- anti_join(gage_fin6, gage_fin7) 
gage_drp7 <- bind_rows(gage_drp6, gage_int)

# lcr_bel discharge data jumps from 1940-09-29 to 1962-08-01 
chk_sta <- gage_fin6 %>% 
  filter(sta == "lcr_bel" & 
           waterYear < 1963) %>%
  distinct(waterYear)

gage_int <- gage_fin6 %>% 
  filter(sta == "lcr_bel" & 
           waterYear < 1963) 

gage_fin7 <- gage_fin6 %>% 
  filter(sta != "lcr_bel" | 
           waterYear > 1962)

chk_sta <- anti_join(gage_fin6, gage_fin7) 
gage_drp7 <- bind_rows(gage_drp6, gage_int) 

# lwr_abv discharge data jumps from 1999-09-30 to 2000-01-01
chk_sta <- gage_fin7 %>% 
  filter(sta == "lwr_abv" & 
           waterYear > 1999) %>%
  distinct(waterYear)

gage_int <- gage_fin7 %>% 
  filter(sta == "lwr_abv" & 
           waterYear > 1999) 

gage_fin8 <- gage_fin7 %>% 
  filter(sta != "lwr_abv" | 
           waterYear < 2000)

chk_sta <- anti_join(gage_fin7, gage_fin8) 
gage_drp8 <- bind_rows(gage_drp7, gage_int)

# lwr_mar discharge data jumps from 1940-09-29 to 1962-08-01 
chk_sta <- gage_fin8 %>% 
  filter(sta == "lwr_mar" & 
           waterYear < 1963) %>%
  distinct(waterYear)

gage_int <- gage_fin8 %>% 
  filter(sta == "lwr_mar" & 
           waterYear < 1963) 

gage_fin9 <- gage_fin8 %>% 
  filter(sta != "lwr_mar" | 
           waterYear > 1962)

chk_sta <- anti_join(gage_fin8, gage_fin9) 
gage_drp9 <- bind_rows(gage_drp8, gage_int) 

# ros_ros   discharge data jumps from 1997-09-30 to 2003-03-16 
#  End @ 1997-09-30

# rap_far discharge data jumps from 1989-09-29 to 1990-10-01 
chk_sta <- gage_fin9 %>% 
  filter(sta == "rap_far" & 
           waterYear < 1990) %>%
  distinct(waterYear)

gage_int <- gage_fin9 %>% 
  filter(sta == "rap_far" & 
           waterYear < 1990) 

gage_fin10 <- gage_fin9 %>% 
  filter(sta != "rap_far" | 
           waterYear > 1991)

chk_sta    <- anti_join(gage_fin9, gage_fin10) 
gage_drp10 <- bind_rows(gage_drp9, gage_int) 

# wcc_ogl  discharge data jumps from 1981-09-29 to 1987-10-01 
# No change
# whi_slm   discharge data jumps from 1970-09-29 to  
# Start @ 1990-12-04















```

```{r next_steps_munging, eval=FALSE}
# Also add BEAR in the LODGE


# check ice - starts 2017-10-23 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ice <- gage_int %>%
  filter(code == "P Ice") %>% 
  arrange(date) 

# check provisional values 
# ~~~~~~~~~~~~~~~~~~~~~~~~
provis <- gage_int %>%
  filter(code == "P" | code == "P e" | code == "P <") %>%
  arrange(date) # starts 2016-10-05

# remove data after 2017-10-01
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int <- gage_int %>%
  filter(year != 2018)

gage_2017 <- gage_int %>%
  filter(year == 2017)

gage_prior <- gage_int %>%
  filter(year < 2017) 

gage_2017 <- gage_2017 %>%
  filter(month != 10) %>% 
  filter(month != 11) %>%
filter(month != 12)

gage_imp <- bind_rows(gage_prior, gage_2017) %>%
  arrange(desc(date)) 
rm(gage_2017, gage_int, gage_list, gage_prior, ice, provis, gage_raw) 

# simplify the naming convention for gages 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_imp <- gage_imp %>% 
  select(site_no, date, discharge, code)

station_nm <- gage_meta %>% 
  select(site_no, station_nm) %>% 
  as.tibble()

abrev <- c("whi_sta", "whi_ogl", "wcc_ogl", "whi_int", "wkc_wok", 
           "blc_wan", "whi_kad", "blp_bel", "lwr_mar", "lcr_bel", 
           "lcr_vet", "brsf_co", "bad_mid") %>%
  as.tibble() %>%
  rename(sta = value)

abrev <- bind_cols(abrev, station_nm) 

gage_imp <- full_join(abrev, gage_imp, by = "site_no")
gage_meta <- full_join(abrev, gage_meta, by = "site_no")
rm(station_nm, abrev)

# Split and spread data
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_dis_imp <- gage_imp %>% 
  select(sta, date, discharge)

gage_dis_imp <- gage_dis_imp %>% 
  spread(key = sta, value = discharge) 

# Add short name to metadata
# ~~~~~~~~~~~~~~~~~~~~~~~~~~
abrev <- gage_imp %>%
  distinct(sta, site_no)

gage_meta <- full_join(abrev, gage_meta, by = "site_no") 

# export and import station df by rio
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_raw, "data/gage_raw.csv") 
# write_lines(gage_json, "data/gage_list.json")
# export(gage_imp, "data/gage_imperial.csv") 

# export(gage_dis_imp, "data/gage_discharge_imp.csv") 


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# get site numbers from prior metadata
gage_meta <- import("data/gage_meta.csv")
#site_nums <- gage_meta %>%
#  select(sta, site_no) %>% 
#  print()


#Sample <- readNWISSample(siteNumber,parameter_cd,startDate,endDate)
# this code chunk uses dataRetreval to get discharge in cfs 
# removes provisional values and ice and saves the data as a csv.
```

```{r daily2monthly-precip}
# continued from above 
# General Purpose: prepare data for drought index 
# Specific purpose: convert daily precip to monthly precip  

# load metadata & data 
sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_day   <- as.tibble(import("data/stations_final2.csv")) 

# remove Murdo, Mission, Long Valley - see above 
#sta_day   <- sta_day %>% 
#  select(-c(lon, mur, mis)) 
#export(sta_day, file = "data/stations_final2.csv")  

# fix date & add year and month 
sta_day <- sta_day %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date)) %>% 
  mutate(year = year(date)) %>% 
  mutate(month = month(date)) %>% 
  select(date, year, month, everything()) 

# gather daily values 
sta_gath <- gather(sta_day, key = "station", value = "prcp", -date, 
                   -year, -month, factor_key = TRUE)

# create groups 
sta_group <- sta_gath %>% 
  group_by(year, month, station) 

# sum daily precip over a month 
sta_gath_mon <- sta_group %>% 
  summarize(prcp_tenths = sum(prcp)) %>% 
  mutate(prcp_mm = prcp_tenths/10) %>% 
  select(-prcp_tenths) 

# spread result - now in months  
#   ...and take a bow, because this is MAGIC!  Thnx Tidyverse. 
sta_mon <- sta_gath_mon %>% 
  spread(station, prcp_mm) %>% 
  mutate(day = 1) %>% 
  mutate(date = make_date(year = year, month = month, day = day)) %>% 
  select(date, year, month, everything()) %>% 
  select(-day) %>% 
  ungroup()

rm(sta_day, sta_gath, sta_gath_mon, sta_group) 
# export(sta_mon, file = "data/stations_monthly.csv") 
```


```{r ggplot_monthly}
# General Purpose: prepare data for drought index 
# Specific purpose: graphical EDA 
 
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_mon     <- as.tibble(import("data/stations_monthly.csv"))

# fix date & add year and month 
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date))  

# gather monthly values & order them
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE) 

# x$name <- factor(x$name, levels = x$name[order(x$val)])

# plot
ggplot(sta_gath_mon, aes(date, prcp)) +
  geom_line() +
  facet_grid(station ~ .) +
  theme_classic() + 
  labs(title = "Monthly precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1909-2018") +
       xlab("") +
       ylab("mm")

#ggplot2::ggsave(filename = "precip_mon.png", 
#                width = 6, height = 6, units = "in")
```

```{r monthly2yearly-precip}
# General Purpose: prepare data for drought index   
# Specific purpose: convert monthly precip to yearly prcp  
 
# load metadata & data 
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) 

# fix date & add year and month 
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date)) %>% 
  select(date, year, month, everything())  

# gather monthly values  
sta_gath <- gather(sta_mon, key = "station", value = "prcp", -date, 
                   -year, -month, factor_key = TRUE) 

# create groups 
sta_group <- sta_gath %>% 
  group_by(year,  station) 

# sum monthly precip over a year 
sta_gath_yr <- sta_group %>% 
  summarize(prcp = sum(prcp))  

# spread result - now in years 
sta_yr <- sta_gath_yr %>% 
  spread(station, prcp) %>% 
  filter(year != 1909) %>% 
  filter(year != 2018) %>% 
  ungroup()

rm(sta_mon, sta_gath, sta_gath_yr, sta_group)
# export(sta_yr, file = "data/stations_yearly.csv") 
```

```{r ggplot_yearly}
# General Purpose: prepare data for drought index 
# Specific purpose: graphical EDA - yearly 

# NEED TO FIX - screwed up variables 

sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_yr     <- as.tibble(import("data/stations_yearly.csv"))

# gather monthly values 
sta_gath <- gather(sta_yr, key = "station", value = "prcp",  
                   -year, factor_key = TRUE) 

# plot
ggplot(sta_gath, aes(year, prcp)) +
  geom_line() +
  facet_grid(station ~ .) +
  theme_classic() + 
  labs(title = "Annual precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1910-2017") +
       xlab("Date") +
       ylab("Depth, mm")

# ggplot2::ggsave(filename = "precip_yr.png", 
#                width = 6, height = 6, units = "in")
```


# Annual Summaries
```{r yearly_summaries}
# General Purpose: prepare data for drought index  
# Specific purpose: create summaries of data 
sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_yr   <- as.tibble(import("data/stations_yearly.csv")) 

# gather and summarize yearly values 
# Next step - do by water year???
sta_gath_yr <- gather(sta_yr, key = "station", value = "prcp", 
                   -year, factor_key = TRUE)

sta_summary_yr <- as.tibble(sta_gath_yr) %>%
  group_by(station) %>%
  summarise(mean = mean(prcp, na.rm = TRUE), 
            med = median(prcp, na.rm = TRUE),
            IQR = IQR(prcp, na.rm = TRUE), 
            min = min(prcp, na.rm = TRUE), 
            max = max(prcp, na.rm = TRUE)) %>%
  arrange(desc(med))

sta_summary_yr
# export(sta_summary_yr, file = "data/sta_summary_yr.csv") 
```

# Monthly Summaries
```{r  monthly_summaries}

# General Purpose: prepare data for drought index  
# Specific purpose: create summaries of data 
sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_mon   <- as.tibble(import("data/stations_monthly.csv")) 

# fix dates
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date)) %>% 
  select(date, year, month, everything()) 

# gather and summarize monthly values 
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE)

sta_summary_mon <- as.tibble(sta_gath_mon) %>%
  group_by(station, month) %>%
  summarise(mean = mean(prcp, na.rm = TRUE), 
            med = median(prcp, na.rm = TRUE),
            IQR = IQR(prcp, na.rm = TRUE), 
            min = min(prcp, na.rm = TRUE), 
            max = max(prcp, na.rm = TRUE)) %>%
  arrange(month) %>%
  arrange(station)

sta_summary_mon 
# export(sta_summary_mon, file = "data/sta_summary_mon.csv") 
```

```{r ggplot_monthly_boxplots}
# General Purpose: prepare data for drought index  
# Specific purpose: graphical EDA  
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) 

# fix date & add year and month  
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date))  

# gather monthly values 
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE) 

ggplot(sta_gath_mon, aes(month, prcp, group = month)) +
  geom_boxplot() +
  facet_wrap(~station) +
  theme_classic() + 
  labs(title = "Monthly precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1910-2017") +
       xlab("Date") +
       ylab("Depth, mm")

#ggplot2::ggsave(filename = "precip_yr.png", 
#                width = 6, height = 6, units = "in")
```

```{r ggplot_monthly_boxplots}
# General Purpose: prepare data for drought index  
# Specific purpose: graphical EDA  
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) 

# fix date & add year and month  
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date))  

# gather monthly values 
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE) 

ggplot(sta_gath_mon, aes(date, prcp)) +
  geom_line() +
  facet_grid(station~.) +
  theme_classic() + 
  labs(title = "Monthly precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1910-2017") +
       xlab("Date") +
       ylab("Depth, mm")

#ggplot2::ggsave(filename = "precip_yr.png", 
#                width = 6, height = 6, units = "in")
```

# Correlation Plots with Pearson Coefficients
```{r correlation}
# General Purpose: prepare data for drought index
# Specific purpose: graphical EDA - correlation plot

sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv"))
sta_yr   <- as.tibble(import("data/stations_yearly.csv"))

# fix date & add year and month
sta_yr <- sta_yr %>%
  arrange(year) 

# need to have a correlation matrix without any NA vals
# gather yearly values 
sta_gath <- gather(sta_yr, key = "station", value = "prcp", 
                   -year, factor_key = TRUE)

# filter NAs
sta_gath_72 <- sta_gath %>%
  filter(year > 1972) 

# spread remaining matrix & arrange from west to east
sta_72 <- sta_gath_72 %>%
  spread(station, prcp) %>%
  select(oel, ora, rap, int, cot)

# create a correlation matrix and plot it
sta_M <- cor(sta_72)
corrplot.mixed(sta_M,  order = "hclust", addrect = 2, upper = "ellipse", lower = "number", title = "Precipitation station correlation")
```
