
<!--
Exploratory Data Analysis Checklist by Roger Peng 
https://leanpub.com/exdata  

1.0  Formulate your question  
Spend a few minutes to figure out the question you’re really interested in, and narrow it down to be as specific as possible (without becoming uninteresting).

General question:
Are air pollution levels higher on the east coast than on the west coast?
More specific question:
Are hourly ozone levels on average higher in New York City than they are in Los Angeles?

2.0   Read in your data  
Sometimes the data will need some cleaning and every dataset has its unique quirks. The dataset is a comma-separated value (CSV) file, where each row of the file contains one daily measurement of precipation depth.  The readr package can rewrite column names to remove spaces.
> names(ozone) <- make.names(names(ozone))

3.0  Check the dataset 
3.1  Check the number of rows and columns.
3.2  Check the types of data
3.3  Look at the top and the bottom of your data 
3.4  Check your “n”s & NAs 
3.5  Validate with at least one external data source  
4.0  Try the easy solution first to answer question
5.0  Challenge your solution 
6.0  Follow up questions 

## Broad questions:
What is the drought history of the Pine Ridge Reservation?  
Does the drought extent differ across the study area?
What is streamflow variation across the Pine Ridge Reservation?

## Narrower questions:

What is streamflow variation across the Pine Ridge Reservation?

## Analysis Steps:
1.  Data read in from USGS website by EGRET (cfs) 
2.  Added names & station numbers & joined data 
3.  Data saved in a flat format (.csv) 

Didn't work these
1.  Data read in from USGS website by dataRetrieval (cfs)
2.  Data saved as array (.JSON), and flat format (.csv) 

# Next STEPS
1. blc_wan <- readNWISDaily("06446700") # this not working!
2. Identify percent coverage

2. Check on next steps from Chapter 2 list 


# Someday Maybe
# USGS 06447050 UNNAMED TRIB BUZZARD CREEK NR LONG VALLEY, SD -instant meas
https://nwis.waterdata.usgs.gov/usa/nwis/qwdata/?huc_cd=10140202&format=station_list&sort_key=site_no&index_pmcode_00065=3&index_pmcode_00060=4&index_pmcode_00062=5&index_pmcode_72020=6&sort_key=site_no&group_key=county_cd&sitefile_output_format=station_list

## Variable naming convention:   
  for USGS functions: EGRET & dataRetrieval:
startDate    Beginning date for downloading USGS gage data
endDate      End date for downloading USGS gage data
parameter_cd USGS parameter codes

xxx_yyy      individual gage names xxx = stream & yyy = location

gage         USGS streamgage station 
  _cont      set of active gages 
  _disc      set of discontinued gages   
  _othr      set of gages not found in initial analysis 

  _full      equals {_cont + _disc + _othr}; 741,215 obs for 61 sta 
  _drp#      observations sequentially dropped from _full
  _fin#      equals {_full} - {_drp#} 

  _meta      metadata  
  _incomp    temporary variable to find station-years w/ incomp data 
  _mdp#      gages sequentially dropped from _meta
  _met#      equals {_meta} - {_mdp#} 
  _yr        temporary variable to calculate years of stations
 
 for filtering original set of gages 
  _ltxx      less than year xx
  _comp      complete {post-1990}
  _incomp    incomplete
  _res       within the Pine Ridge Reservation administrative boundary

check_sta    check variable 


-->

```{r setup, include=FALSE}  
#knitr::opts_chunk$set(echo = FALSE)  
options(tibble.print_max = 70) # sets tibble output for printing  
 
# Sets up the library of packages   
library("here") # identifies where to save work  
library("dataRetrieval") # USGS data import  
library("EGRET") # Exploration and Graphics for RivEr Trends 
library("rio") # more robust I/O - to import and clean data  
library("lubridate") # easier dates 
library("tidyverse") 
library("janitor") # tools for examining and cleaning dirty data  

library("cowplot") # Streamlined plot theme & annotations 

# library("drake") # gen.purpose computational engine for data analys
# library("DataExplorer") # quick look at NA vals 
# library('jsonlite') # tools for working with lists  
# library("magrittr") # provides aliases for easier reading 
# library("friendlyeval") 

# a useful description of commits: 
# http://r-pkgs.had.co.nz/git.html 

# Text for geocomputation in R
# https://geocompr.robinlovelace.net/intro.html
```

```{r import_daily_flow_active_EGRET, eval=FALSE} 
# Loads USGS gage data individually, bind_cols & exports data
# Note: found gage ids by USGS watermapper.  However, this was an
#   iterative process in deciding sites to choose.  This is reflected
#   in the row numbers (see table below) non-sequential arrangement
# Also note: the joined file of active & discontinued stations >87 mb 
# Saving this file separately may protect data integrity
# 
#   readNWISDaily(siteNumber, parameterCd = "00060", startDate = "",
#      endDate = "", interactive = TRUE, convert = TRUE) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# List of active sites
# ~~~~~~~~~~~~~~~~~~~~
# A tibble: 55 x 3
#   sta     site_no station_nm                                   
# * <chr>     <int> <chr>                                        
# 1 bad_mid 6441000 BAD R NEAR MIDLAND,SD                        
# 2 bat_bhr 6406500 BATTLE CR BELOW HERMOSA,SD                   
# 3 brsf_co 6440200 SOUTH FORK BAD R NEAR COTTONWOOD,SD          
# 4 blp_bel 6447230 BLACK PIPE CREEK NR BELVIDERE, SD            
# 5 bev_buf 6402500 BEAVER CR NEAR BUFFALO GAP,SD                
# 6 bev_pri 6402430 BEAVER CREEK NEAR PRINGLE, SD   
#26 che_buf 6402600 CHEYENNE R NEAR BUFFALO GAP SD                        
# 7 che_red 6403700 CHEYENNE RIVER AT RED SHIRT, SD              
# 8 che_sce 6408650 CHEYENNE RIVER NEAR SCENIC, SD       
#27 che_was 6423500 CHEYENNE RIVER NEAR WASTA, SD 
# 9 fal_hot 6402000 FALL R AT HOT SPRINGS,SD                     
#10 hat_edg 6400000 HAT CR NEAR EDGEMONT,SD                      
#11 hor_oel 6400875 HORSEHEAD CR AT OELRICHS,SD                  
#12 lcr_bel 6449000 LAKE CR BELOW REFUGE NEAR TUTHILL,SD 
#13 lcr_vet 6449100 LITTLE WHITE R NEAR VETAL,SD                 
#14 lwr_mar 6447500 LITTLE WHITE R NEAR MARTIN,SD                
#15 lwr_ros 6449500 LITTLE WHITE R NEAR ROSEBUD SD               
#16 lwr_whi 6450500 LITTLE WHITE R BELOW WHITE RIVER,SD          
#17 rap_far 6421500 RAPID CR NEAR FARMINGDALE,SD                 
#18 wcc_ogl 6445980 WHITE CLAY CR NEAR OGLALA SD                 
#19 whi_int 6446500 WHITE R NEAR INTERIOR,SD                     
#20 whi_kad 6447000 WHITE R NEAR KADOKA,SD                       
#21 whi_ogl 6446000 WHITE R NEAR OGLALA SD       
#28 whi_roc 6446200 WHITE R NEAR ROCKYFORD SD         
#22 whi_slm 6445700 WHITE RIVER AT SLIM BUTTE, SD                
#23 whi_sta 6445685 WHITE R NR NE-SD STATE LINE                  
#24 whi_whi 6447450 WHITE RIVER NEAR WHITE RIVER, SD             
#25 wkc_wok 6446100 WOUNDED KNEE CREEK AT WOUNDED KNEE, SD       
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. load individual gages
# add an end date to remove provisional data & gaps in vals
startDate    <- "" # blank gets earliest date
endDate      <- "2017-09-30"
parameter_cd <- "00060" 
# ~~~~~~~~~~~~~~~~~~~~~ 

bad_mid <- readNWISDaily("06441000", parameter_cd, startDate, endDate) 
bat_bhr <- readNWISDaily("06406500", parameter_cd, startDate, endDate) 
bev_buf <- readNWISDaily("06402500", parameter_cd, startDate, endDate) 
bev_pri <- readNWISDaily("06402430", parameter_cd, startDate, endDate) 
blp_bel <- readNWISDaily("06447230", parameter_cd, startDate, endDate) 
brsf_co <- readNWISDaily("06440200", parameter_cd, startDate, endDate) 
che_buf <- readNWISDaily("06402600", parameter_cd, startDate, endDate) 
che_red <- readNWISDaily("06403700", parameter_cd, startDate, endDate)  
che_sce <- readNWISDaily("06408650", parameter_cd, startDate, endDate) 
che_was <- readNWISDaily("06423500", parameter_cd, startDate, endDate) 
fal_hot <- readNWISDaily("06402000", parameter_cd, "1947-06-01", endDate) 
hat_edg <- readNWISDaily("06400000", parameter_cd, startDate, endDate) 
hor_oel <- readNWISDaily("06400875", parameter_cd, startDate, endDate) 
lcr_bel <- readNWISDaily("06449000", parameter_cd, startDate, endDate) 
lcr_vet <- readNWISDaily("06449100", parameter_cd, startDate, endDate) 
lwr_mar <- readNWISDaily("06447500", parameter_cd, startDate, endDate) 
lwr_ros <- readNWISDaily("06449500", parameter_cd, startDate, endDate) 
lwr_whi <- readNWISDaily("06450500", parameter_cd, startDate, endDate)
rap_far <- readNWISDaily("06421500", parameter_cd, startDate, endDate)
wcc_ogl <- readNWISDaily("06445980", parameter_cd, startDate, endDate) 
wkc_wok <- readNWISDaily("06446100", parameter_cd, startDate, endDate) 
whi_int <- readNWISDaily("06446500", parameter_cd, startDate, endDate) 
whi_kad <- readNWISDaily("06447000", parameter_cd, startDate, endDate)
whi_ogl <- readNWISDaily("06446000", parameter_cd, startDate, endDate)  
whi_roc <- readNWISDaily("06446200", parameter_cd, startDate, endDate) 
whi_slm <- readNWISDaily("06445700", parameter_cd, startDate, endDate) 
whi_sta <- readNWISDaily("06445685", parameter_cd, startDate, endDate) 
whi_whi <- readNWISDaily("06447450", parameter_cd, startDate ,endDate)

# 2. add short name and abbreviation to gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
bad_mid <- bad_mid %>% 
  mutate(sta = "bad_mid") %>%
  mutate(site_no = "06441000") 

bat_bhr <- bat_bhr %>%
  mutate(sta = "bat_bhr") %>%
  mutate(site_no = "06406500") 

bev_buf <- bev_buf %>%
  mutate(sta = "bev_buf") %>%
  mutate(site_no = "06402500") 

bev_pri <- bev_pri %>%
  mutate(sta = "bev_pri") %>%
  mutate(site_no = "06402430") 

blp_bel <- blp_bel %>% 
  mutate(sta = "blp_bel") %>%
  mutate(site_no = "06447230")

 brsf_co <- brsf_co %>% 
  mutate(sta = "brsf_co") %>%
  mutate(site_no = "06440200")

che_buf <- che_buf %>% 
  mutate(sta = "che_buf") %>%
  mutate(site_no = "06402600")

che_red <- che_red %>% 
  mutate(sta = "che_red") %>%
  mutate(site_no = "06403700")

che_sce <- che_sce %>% 
  mutate(sta = "che_sce") %>%
  mutate(site_no = "06408650") 

che_was <- che_was %>% 
  mutate(sta = "che_was") %>%
  mutate(site_no = "06423500") 

fal_hot <- fal_hot %>% 
  mutate(sta = "fal_hot") %>%
  mutate(site_no = "06402000") 

hat_edg <- hat_edg %>% 
  mutate(sta = "hat_edg") %>%
  mutate(site_no = "06400000") 

hor_oel <- hor_oel %>% 
  mutate(sta = "hor_oel") %>%
  mutate(site_no = "06400875") 

lcr_bel <- lcr_bel %>% 
  mutate(sta = "lcr_bel") %>%
  mutate(site_no = "06449000")

lcr_vet <- lcr_vet %>% 
  mutate(sta = "lcr_vet") %>%
  mutate(site_no = "06449100")

lwr_mar <- lwr_mar  %>% 
  mutate(sta = "lwr_mar") %>%
  mutate(site_no = "06447500")

lwr_ros <- lwr_ros  %>% 
  mutate(sta = "lwr_ros") %>%
  mutate(site_no = "06449500")

lwr_whi <- lwr_whi  %>% 
  mutate(sta = "lwr_whi") %>%
  mutate(site_no = "06450500")
 
rap_far <- rap_far  %>% 
  mutate(sta = "rap_far") %>%
  mutate(site_no = "06421500")

wcc_ogl <- wcc_ogl %>% 
  mutate(sta = "wcc_ogl") %>%
  mutate(site_no = "06445980") 

whi_int <- whi_int %>% 
  mutate(sta = "whi_int") %>%
  mutate(site_no = "06446500") 

whi_kad <- whi_kad %>% 
  mutate(sta = "whi_kad") %>%
  mutate(site_no = "06447000") 

whi_ogl <- whi_ogl %>% 
  mutate(sta = "whi_ogl") %>%
  mutate(site_no = "06446000") 

whi_slm <- whi_slm %>% 
  mutate(sta = "whi_slm") %>%
  mutate(site_no = "06445700") 

whi_roc <- whi_roc %>% 
  mutate(sta = "whi_roc") %>%
  mutate(site_no = "06446200") 

whi_sta <- whi_sta %>% 
  mutate(sta = "whi_sta") %>%
  mutate(site_no = "06445685") 

whi_whi <- whi_whi %>% 
  mutate(sta = "whi_whi") %>%
  mutate(site_no = "06447450") 

wkc_wok <- wkc_wok %>% 
  mutate(sta = "wkc_wok") %>%
  mutate(site_no = "06446100") 

# 3. join together in long format
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int1  <- bind_rows(bad_mid, bat_bhr) 
gage_int2  <- bind_rows(gage_int1, brsf_co) 
gage_int3  <- bind_rows(gage_int2, blp_bel) 
gage_int4  <- bind_rows(gage_int3, bev_buf) 
gage_int5  <- bind_rows(gage_int4, bev_pri) 
gage_int6  <- bind_rows(gage_int5, che_red) 
gage_int7  <- bind_rows(gage_int6, che_sce) 
gage_int8  <- bind_rows(gage_int7, fal_hot) 
gage_int9  <- bind_rows(gage_int8, hat_edg) 
gage_int10 <- bind_rows(gage_int9, hor_oel) 
gage_int11 <- bind_rows(gage_int10, lcr_bel) 
gage_int12 <- bind_rows(gage_int11, lcr_vet) 
gage_int13 <- bind_rows(gage_int12, lwr_mar) 
gage_int14 <- bind_rows(gage_int13, lwr_ros) 
gage_int15 <- bind_rows(gage_int14, lwr_whi) 
gage_int16 <- bind_rows(gage_int15, rap_far) 
gage_int17 <- bind_rows(gage_int16, wcc_ogl) 
gage_int18 <- bind_rows(gage_int17, whi_int) 
gage_int19 <- bind_rows(gage_int18, whi_kad) 
gage_int20 <- bind_rows(gage_int19, whi_ogl) 
gage_int21 <- bind_rows(gage_int20, whi_slm) 
gage_int22 <- bind_rows(gage_int21, whi_sta) 
gage_int23 <- bind_rows(gage_int22, whi_whi) 
gage_int24 <- bind_rows(gage_int23, wkc_wok) 
gage_int25 <- bind_rows(gage_int24, che_buf) 
gage_int26 <- bind_rows(gage_int25, che_was) 
gage_int27 <- bind_rows(gage_int26, whi_roc) 

# export daily flows to data folder
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_int27, "data/gage_cont.csv") 

#>>> git push origin refs/heads/master
#remote: warning: GH001: Large files detected. You may want to try Git #Large File Storage - https://git-lfs.github.com.        
#remote: warning: See http://git.io/iEPt8g for more information.        
#remote: warning: File data/gage_cont.csv is 60.77 MB; this is larger than #GitHub's recommended maximum file size of 50.00 MB        
#To https://github.com/cjtinant/eco-drought.git
#   be32000..a6c9c26  master -> master
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# export top half of active gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
export(gage_int14, "data/gage_cont_1st_half.csv")

# bind bottom half of active gage data - start at 36 to avoid dups
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

gage_int36 <- bind_rows(lwr_whi, rap_far) 
gage_int37 <- bind_rows(gage_int36, wcc_ogl) 
gage_int38 <- bind_rows(gage_int37, whi_int) 
gage_int39 <- bind_rows(gage_int38, whi_kad) 
gage_int40 <- bind_rows(gage_int39, whi_ogl) 
gage_int41 <- bind_rows(gage_int40, whi_slm) 
gage_int42 <- bind_rows(gage_int41, whi_sta) 
gage_int43 <- bind_rows(gage_int42, whi_whi) 
gage_int44 <- bind_rows(gage_int43, wkc_wok) 
gage_int45 <- bind_rows(gage_int44, che_buf) 
gage_int46 <- bind_rows(gage_int45, che_was) 
gage_int47 <- bind_rows(gage_int46, whi_roc) 

# export bottom half of active gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_int47, "data/gage_cont_2nd_half.csv")

```

```{r import_dailyflow_EGRET-bearLodge, eval=FALSE}
# long story, but Bear in the Lodge streamflow is restricted.  So,
# need to find another approach to getting the data. 
# one way is annual reports - but only to 2013
# Need to email the webmaster to get streamflow data.
# https://waterdata.usgs.gov/sd/nwis/inventory/?site_no=06446700&agency_cd= 

#blc_wan <- readNWISDaily("06446700") # this not working! 
#blc_wan <- blc_wan %>%
#  mutate(sta = blc_wan) %>%
#  mutate(site_no = "06446700")

```

```{r import_daily_flow_discontinued_EGRET, eval=FALSE} 

# List of discontinued sites w/in 30 mi. of PRR boundary
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# A tibble: 55 x 3
#   sta     site_no station_nm                                   
# * <chr>     <int> <chr>          
#29 ant_gor 6458000 Antelope Creek near Gordon, Nebr.           
#33 brnf_ph 6440500 NORTH FORK BAD R NEAR PHILIP SD    
#30 bea_eli 6458500 BEAR C NR ELI NEBR                           
#31 bev_abf 6402470 BEAVER CREEK ABOVE BUFFALO GAP, SD           
#32 bor_cha 6445590 BIG BORDEAUX CREEK NEAR CHADRON NEBR         
#34 cas_hot 6400497 CASCADE SPRINGS NEAR HOT SPRINGS SD          
#35 che_hot 6400500 CHEYENNE R NEAR HOT SPRINGS SD               
#36 fre_fai 6403500 FRENCH CR NEAR FAIRBURN SD                   
#37 hor_aoe 6400870 HORSEHEAD CR NEAR OELRICHS SD                
#38 lcr_abv 6448000 LAKE CR ABOVE REFUGE NEAR TUTHILL,SD         
#39 lwr_abv 6449300 LITTLE WHITE R ABV ROSEBUD SD                
#40 min_kil 6460900 MINNECHADUZA CREEK NEAR KILGORE, NEBRASKA   
#41 nio_abb 6454500 NIOBRARA RIVER ABOVE BOX BUTTE RESERVOIR, NE 
#42 nio_bbb 6455500 NIOBRARA RIVER BELOW BOX BUTTE RESERVOIR NEBR
#43 nio_cod 6459000 NIOBRARA R NEAR CODY, NEBR.                  
#44 nio_col 6457000 NIOBRARA RIVER NEAR COLCLESSER, NEBR.        
#45 nio_dun 6455900 NIOBRARA RIVER NEAR DUNLAP, NEBR.            
#46 nio_hay 6456500 NIOBRARA RIVER NR HAY SPRINGS, NEBR.         
#47 rap_cre 6422000 RAPID CR AT CRESTON SD                       
#48 ros_ros 6449400 ROSEBUD CR AT ROSEBUD SD                     
#49 sna_bur 6459500 SNAKE RIVER NEAR BURGE, NEBR.                
#50 sna_dou 6459175 SNAKE R AT DOUGHBOY, NE                      
#51 sna_mer 6459200 SNAKE RIVER ABV MERRITT RESERVOIR NEBR       
#52 spr_stf 6449250 SPRING CR NEAR ST FRANCIS SD                 
#53 whi_cha 6445500 WHITE R NEAR CHADRON NEBR                    
#54 whi_cra 6444000 White River at Crawford, Nebr.               
#55 whi_wht 6445000 WHITE R BELW COTTONWOOD C N WHITNEY, NEBR.  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. load individual gages
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# add an end date to remove provisional data & gaps in vals
startDate    <- "" #Gets earliest date
endDate      <- "2017-09-30"
parameter_cd <- "00060" 
# ~~~~~~~~~~~~~~~~~~~~~ 

ant_gor <- readNWISDaily("06458000", parameter_cd, startDate ,endDate) 
brnf_ph <- readNWISDaily("06440500", parameter_cd, startDate, endDate) 
bea_eli <- readNWISDaily("06458500", parameter_cd, startDate, endDate) 
bev_abf <- readNWISDaily("06402470", parameter_cd, startDate, endDate) 
bor_cha <- readNWISDaily("06445590", parameter_cd, startDate, endDate) 
cas_hot <- readNWISDaily("06400497", parameter_cd, startDate, endDate) 
che_hot <- readNWISDaily("06400500", parameter_cd, startDate, endDate) 
fre_fai <- readNWISDaily("06403500", parameter_cd, "1946-01-14", endDate) 
hor_aoe <- readNWISDaily("06400870", parameter_cd, startDate, endDate) 
lcr_abv <- readNWISDaily("06448000", parameter_cd, startDate, endDate) 
lwr_abv <- readNWISDaily("06449300", parameter_cd, startDate, endDate) 
min_kil <- readNWISDaily("06460900", parameter_cd, startDate, endDate) 
nio_abb <- readNWISDaily("06454500", parameter_cd, startDate, endDate) 
nio_bbb <- readNWISDaily("06455500", parameter_cd, startDate, endDate) 
nio_col <- readNWISDaily("06457000", parameter_cd, startDate, endDate) 
nio_cod <- readNWISDaily("06459000", parameter_cd, startDate, endDate) 
nio_dun <- readNWISDaily("06455900", parameter_cd, startDate, endDate) 
nio_hay <- readNWISDaily("06456500", parameter_cd, startDate, endDate) 
rap_cre <- readNWISDaily("06422000", parameter_cd, startDate, endDate) 
ros_ros <- readNWISDaily("06449400", parameter_cd, startDate, endDate) 
sna_bur <- readNWISDaily("06459500", parameter_cd, startDate, endDate) 
sna_dou <- readNWISDaily("06459175", parameter_cd, startDate, endDate) 
sna_mer <- readNWISDaily("06459200", parameter_cd, startDate, endDate) 
spr_stf <- readNWISDaily("06449250", parameter_cd, startDate, endDate) 
whi_cha <- readNWISDaily("06445500", parameter_cd, startDate, endDate) 
whi_cra <- readNWISDaily("06444000", parameter_cd, startDate, endDate)
whi_wht <- readNWISDaily("06445000", parameter_cd, startDate, endDate) 

# 2. add short name and abbreviation to gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ant_gor <- ant_gor %>% 
  mutate(sta = "ant_gor") %>%
  mutate(site_no = "06458000") 

brnf_ph <- brnf_ph %>% 
  mutate(sta = "brnf_ph") %>%
  mutate(site_no = "06440500") 

bea_eli <- bea_eli %>% 
  mutate(sta = "bea_eli") %>%
  mutate(site_no = "06458500") 

bev_abf <- bev_abf %>% 
  mutate(sta = "bev_abf") %>%
  mutate(site_no = "06402470") 

bor_cha <- bor_cha %>% 
  mutate(sta = "bor_cha") %>%
  mutate(site_no = "06445590") 

cas_hot <- cas_hot %>% 
  mutate(sta = "cas_hot") %>%
  mutate(site_no = "06400497") 

che_hot <- che_hot %>% 
  mutate(sta = "che_hot") %>%
  mutate(site_no = "06400500") 

fre_fai <- fre_fai %>% 
  mutate(sta = "fre_fai") %>%
  mutate(site_no = "06403500") 

hor_aoe <- hor_aoe %>% 
  mutate(sta = "hor_aoe") %>%
  mutate(site_no = "06400870") 

lcr_abv <- lcr_abv %>% 
  mutate(sta = "lcr_abv") %>%
  mutate(site_no = "06448000") 

lwr_abv <- lwr_abv %>% 
  mutate(sta = "lwr_abv") %>%
  mutate(site_no = "06449300") 

min_kil <- min_kil %>% 
  mutate(sta = "min_kil") %>%
  mutate(site_no = "06460900") 

nio_abb <- nio_abb %>% 
  mutate(sta = "nio_abb") %>%
  mutate(site_no = "06454500") 

nio_bbb <- nio_bbb %>% 
  mutate(sta = "nio_bbb") %>%
  mutate(site_no = "06455500") 

nio_col <- nio_col %>% 
  mutate(sta = "nio_col") %>%
  mutate(site_no = "06457000") 

nio_cod <- nio_cod %>% 
  mutate(sta = "nio_cod") %>%
  mutate(site_no = "06459000") 

nio_dun <- nio_dun %>% 
  mutate(sta = "nio_dun") %>%
  mutate(site_no = "06455900")

nio_hay <- nio_hay %>% 
  mutate(sta = "nio_hay") %>%
  mutate(site_no = "06456500") 

rap_cre <- rap_cre %>% 
  mutate(sta = "rap_cre") %>%
  mutate(site_no = "06422000")

ros_ros <- ros_ros %>% 
  mutate(sta = "ros_ros") %>%
  mutate(site_no = "06449400") 

sna_bur <- sna_bur %>% 
  mutate(sta = "sna_bur") %>%
  mutate(site_no = "06459500")

sna_dou <- sna_dou %>% 
  mutate(sta = "sna_dou") %>%
  mutate(site_no = "06459175") 

sna_mer <- sna_mer %>% 
  mutate(sta = "sna_mer") %>%
  mutate(site_no = "06459200")

spr_stf <- spr_stf %>% 
  mutate(sta = "spr_stf") %>%
  mutate(site_no = "06449250") 

whi_cha <- whi_cha %>% 
  mutate(sta = "whi_cha") %>%
  mutate(site_no = "06445500") 

whi_cra <- whi_cra %>% 
  mutate(sta = "whi_cra") %>%
  mutate(site_no = "06444000") 

whi_wht <- whi_wht %>% 
  mutate(sta = "whi_wht") %>%
  mutate(site_no = "06445000") 

# 3. join together in long format
# Next step: probably could be done more efficiently with map_df()
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int1  <- bind_rows(ant_gor, bea_eli) 
gage_int2  <- bind_rows(gage_int1, bev_abf) 
gage_int3  <- bind_rows(gage_int2, bor_cha) 
gage_int4  <- bind_rows(gage_int3, brnf_ph) 
gage_int5  <- bind_rows(gage_int4, cas_hot) 
gage_int6  <- bind_rows(gage_int5, che_hot) 
gage_int7  <- bind_rows(gage_int6, fre_fai) 
gage_int8  <- bind_rows(gage_int7, hor_aoe) 
gage_int9  <- bind_rows(gage_int8, lcr_abv) 
gage_int10 <- bind_rows(gage_int9, lwr_abv) 
gage_int11 <- bind_rows(gage_int10, min_kil) 
gage_int12 <- bind_rows(gage_int11, nio_abb) 
gage_int13 <- bind_rows(gage_int12, nio_bbb) 
gage_int14 <- bind_rows(gage_int13, nio_cod) 
gage_int15 <- bind_rows(gage_int14, nio_col) 
gage_int16 <- bind_rows(gage_int15, nio_dun) 
gage_int17 <- bind_rows(gage_int16, nio_hay) 
gage_int18 <- bind_rows(gage_int17, rap_cre) 
gage_int19 <- bind_rows(gage_int18, ros_ros) 
gage_int20 <- bind_rows(gage_int19, sna_bur) 
gage_int21 <- bind_rows(gage_int20, sna_dou) 
gage_int22 <- bind_rows(gage_int21, sna_mer) 
gage_int23 <- bind_rows(gage_int22, spr_stf) 
gage_int24 <- bind_rows(gage_int23, whi_cha) 
gage_int25 <- bind_rows(gage_int24, whi_cra) 
gage_int26 <- bind_rows(gage_int25, whi_wht) 

# export daily flows to data folder
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
export(gage_int26, "data/gage_disc.csv") 
```

```{r import_daily_flow_overlooked, eval=FALSE} 

# List of possible extra sites - list was iteratively constructed
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# A tibble: 6 x 2
#   sta     site_no station_nm                                   
# * <chr>     <int> <chr>          
#1 che_ang 06401500 CHEYENNE R BELOW ANGOSTURA DAM,SD
#2 frn_fai 06403300 FRENCH CR ABOVE FAIRBURN SD      
#3 bat_key 06404000 BATTLE CR NEAR KEYSTONE,SD       
#4 bat_bhr 06406000 BATTLE CR AT HERMOSA,SD          
#5 spr_her 06408500 SPRING CR NEAR HERMOSA,SD        
#6 nio_gor 06457500 NIOBRARA RIVER NEAR GORDON, NEBR.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# this is what was done to find the stations above: 

# this code chunk checks for "missed" stations.  
# for filtering info see: https://help.waterdata.usgs.gov/site_tp_cd
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. get huc codes for gages already selected
gage_meta <- import("data/gage_meta.csv") %>% 
  arrange(sta)

hucs <- gage_meta %>% 
  distinct(huc_cd) %>%
  arrange() %>%
  mutate(huc_cd = as.character(huc_cd))

# 2. split the API query into smaller parts
hucs1 <- hucs %>%
  slice(1:6)

hucs2 <- hucs %>%
  slice(7:13) 

# 3. get the set of NWIS data for each of the slices
gages1 <- hucs1 %>% 
     map_df(~ whatNWISdata(huc = .x)) 

gages2 <- hucs2 %>% 
     map_df(~ whatNWISdata(huc = .x)) 

# 4. create a single dataframe and clean up 
gages1 <- gages1 %>% 
  mutate(alt_acy_va = as.numeric(alt_acy_va))

gages_pos <- bind_rows(gages1, gages2)
rm(hucs, hucs1, hucs2, gages1, gages2)

# 5. explore data types
# ~~~~~~~~~~~~~~~~~~~~~~~

#   a. find site_types 
NWIS_type <- gages_pos %>% 
  distinct(site_tp_cd) %>%  
  arrange(site_tp_cd)

#   b. remove atmosphere (AT), land (LA), & subsurface (SB) site types
gage_pos1 <- gages_pos %>% 
  filter(site_tp_cd != "AT" &
           site_tp_cd != "LA-SH" & 
           site_tp_cd != "LA-SNK" &
           site_tp_cd != "SB-CV" &
           site_tp_cd != "SB" 
         ) %>% 
  arrange(site_tp_cd) 

#   c. remove facilities (FA) site type 
gage_pos2 <- gage_pos1 %>% 
  filter(site_tp_cd != "FA-CI" &
           site_tp_cd != "FA-OF" & 
           site_tp_cd != "FA-SEW" & 
           site_tp_cd != "FA-STS" & 
           site_tp_cd != "FA-WDS"
         )

#   d. remove groundwater (GW) & spring site types 
gw <- gage_pos2 %>% 
  filter(site_tp_cd == "GW" |
           site_tp_cd == "GW-CR" | 
           site_tp_cd == "GW-IW" |
           site_tp_cd == "GW-MW" | 
           site_tp_cd == "GW-TH" | 
          site_tp_cd == "SP"
         )

gage_pos3 <- gage_pos2 %>% 
  filter(site_tp_cd != "GW" &
           site_tp_cd != "GW-CR" & 
           site_tp_cd != "GW-IW" &
           site_tp_cd != "GW-MW" & 
           site_tp_cd != "GW-TH" & 
          site_tp_cd != "SP"
         )

#   e. remove lake (LK) & canal (CA) site types 
gage_pos4 <- gage_pos3 %>% 
  filter(site_tp_cd != "LK" & 
           site_tp_cd != "ST-CA" &
           site_tp_cd != "ST-DCH"
           ) 

#   e. check streams == gage_pos4 & clean up
gage_pos5 <- gage_pos4 %>% 
  filter(site_tp_cd != "ST") 

gage_strm <- gages_pos %>% 
  filter(site_tp_cd == "ST") 

rm(NWIS_type, gage_pos, gage_pos1, gage_pos2, gage_pos3, 
   gage_pos4, gage_pos5) 

#   f. remove bio, sediment, wq, report, peak, temp data
bio <- gage_strm %>% 
  filter(medium_grp_cd == "bio")

sed <- gage_strm %>% 
  filter(medium_grp_cd == "sed") 

wq <- gage_strm %>% 
  filter(data_type_cd == "qw") 

ad <- gage_strm %>% 
  filter(data_type_cd == "ad") 

pk <- gage_strm %>% 
  filter(data_type_cd == "pk") 

tmp <- gage_strm %>% 
  filter(parm_cd == "00010") 

gages_dv <- gage_strm %>% 
  filter(medium_grp_cd != "bio" & 
           medium_grp_cd != "sed" & 
           data_type_cd != "qw" & 
           data_type_cd != "uv" & 
           data_type_cd != "ad" &
           data_type_cd != "sv" &
           data_type_cd != "pk" & 
           parm_cd != "00010" & 
           parm_cd != "00065" & 
           parm_cd != "00095" & 
           parm_cd != "00300" & 
           parm_cd != "00400" & 
           parm_cd != "63680" & 
           parm_cd != "80154" & 
           parm_cd != "80155" 
           ) 

# g. clean dataframe to fit the area
gages_pot <- gages_dv %>% 
  mutate(alt_va = as.numeric(alt_va)) %>% 
  filter(count_nu > 365*5) %>%
  filter(dec_lat_va < 43.97) %>% 
  filter(dec_long_va > -103.58825) %>% 
  filter(dec_long_va < -100.55167) %>% 
  filter(alt_va < 4050) %>% 
  mutate(end_date = ymd(end_date)) %>% 
  mutate(end_yr = year(end_date)) %>% 
  filter(end_yr > 1990)

# bind new and old metadata cols together to check
gages_pot_list <- gages_pot %>% 
  select(site_no, station_nm) %>% 
  mutate(site_no = as.integer(site_no))
gages_exist <- gage_meta %>% 
    select(site_no, station_nm) 

gages_new <- full_join(gages_pot_list, gages_exist, by = "site_no") 
gages_new <- gages_new %>% 
  filter(is.na(station_nm.y)) %>% 
  rename(station_nm = station_nm.x) %>% 
  select(-station_nm.y) %>% 
  as.tibble() 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. load individual gages
# ~~~~~~~~~~~~~~~~~~~~~~~~~
# add an end date to remove provisional data & gaps in vals
startDate    <- "" #Gets earliest date
endDate      <- "2017-09-30"
parameter_cd <- "00060" 
# ~~~~~~~~~~~~~~~~~~~~~ 
bat_bhr <- readNWISDaily("06406000", parameter_cd, startDate ,endDate) 
bat_key <- readNWISDaily("06404000", parameter_cd, startDate ,endDate) 
che_ang <- readNWISDaily("06401500", parameter_cd, startDate ,endDate)
frn_fai <- readNWISDaily("06403300", parameter_cd, startDate ,endDate) 
nio_gor <- readNWISDaily("06457500", parameter_cd, startDate ,endDate) 
spr_her <- readNWISDaily("06408500", parameter_cd, startDate ,endDate)  

# 2. add short name and abbreviation to gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

bat_bhr <- bat_bhr %>% 
  mutate(sta = "bat_her") %>%
  mutate(site_no = "6406000") 

bat_key <- bat_key %>% 
  mutate(sta = "bat_key") %>%
  mutate(site_no = "6404000") 

che_ang <- che_ang  %>% 
  mutate(sta = "che_ang") %>%
  mutate(site_no = "6401500")

frn_fai <- frn_fai %>% 
  mutate(sta = "frn_fai") %>%
  mutate(site_no = "6403300") 

nio_gor <- nio_gor %>% 
  mutate(sta = "nio_gor") %>%
  mutate(site_no = "6457500") 

spr_her <- spr_her %>% 
  mutate(sta = "spr_her") %>%
  mutate(site_no = "6408500")

# 3. join together in long format
# Next step: probably could be done more efficiently with map_df()
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int1  <- bind_rows(bat_bhr, bat_key) 
gage_int2  <- bind_rows(gage_int1, che_ang) 
gage_int3  <- bind_rows(gage_int2, frn_fai) 
gage_int4  <- bind_rows(gage_int3, nio_gor) 
gage_int5  <- bind_rows(gage_int4, spr_her) 

# export daily flows to data folder
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_int5, "data/gage_other.csv") 

``` 

```{r import_gage_metadata, eval=FALSE} 
  
# import daily streamflow datasets  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_cont <- import("data/gage_cont.csv") 
gage_disc <- import("data/gage_disc.csv") 
gage_othr <- import("data/gage_other.csv") 
 
# check for duplicate data  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_cont_ck  <- gage_cont %>% 
  distinct(sta, site_no) 

gage_dist_ck  <- gage_disc %>% 
  distinct(sta, site_no) 

gage_othr_ck  <- gage_othr %>% 
  distinct(sta, site_no) 

gage_names <- bind_rows(gage_cont_ck, gage_dist_ck) 
gage_names <- bind_rows(gage_names, gage_othr_ck) 

rm(gage_cont_ck, gage_dist_ck, gage_othr_ck) 

# join data & import metadata 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~ 

gage_full  <- bind_rows(gage_cont, gage_disc)  
gage_full  <- bind_rows(gage_full, gage_othr) 

# gage$site_no is brought in as an integer but needs to be 8-dig char 
gage_full <- gage_full %>% 
  mutate(sta = as.character(sta)) %>%  
  mutate(site_no = zeroPad(site_no, 8)) %>% 
  select(site_no, sta, everything()) 

# reduces the set down to a small number to reduce API calls 
gage_id <- gage_full %>% 
  distinct(site_no, sta) 

# iterate across a list of gage ids by purrr::map  
# & get gage metadata using dataRetrieval::readNWISsite 
gage_meta_list <- map(gage_id$site_no, readNWISsite) 

# extract the wanted dataframe items from the list 

gage_meta <- gage_meta_list %>% 
  map_df(rbind, 
               c("site_no", "station_nm", "site_tp_cd", "dec_lat_va", 
                 "dec_long_va", "dec_coord_datum_cd", "state_cd", 
                 "county_cd", "alt_va", "alt_datum_cd", "huc_cd", 
                 "drain_area_va", "contrib_drain_area_va")) 

# and clean up
gage_meta <- gage_meta %>% 
  filter(agency_cd == "USGS") %>% 
  select(-agency_cd)  %>% 
  select(-country_cd) %>% 
  select(-(site_tp_cd:long_va)) %>% 
  select(-(coord_meth_cd:coord_acy_cd)) %>% 
  select(-district_cd) %>% 
  select(-(map_nm:map_scale_fc)) %>% 
  select(-(alt_meth_cd:alt_acy_va)) %>% 
  select(-(basin_cd:inventory_dt)) %>% 
  select(-(tz_cd:project_no)) %>% 
  select(dec_lat_va, dec_long_va, alt_va, drain_area_va, 
         contrib_drain_area_va, state_cd, county_cd, huc_cd,
         land_net_ds, everything()) %>% 
  select(station_nm, site_no, everything()) %>% 
  mutate(dec_lat_va = as.numeric(dec_lat_va)) %>% 
  mutate(dec_long_va = as.numeric(dec_long_va)) %>%   
  mutate(alt_va = as.numeric(alt_va)) %>%   
  mutate(drain_area_va = as.numeric(drain_area_va)) %>%  
  mutate(contrib_drain_area_va = as.numeric(contrib_drain_area_va)) %>% 
  mutate(contrib_drain_area_va = as.numeric(contrib_drain_area_va)) 

rm(gage_meta_list) 

# join the abbreviation to the metadata 
gage_meta <- gage_meta %>%  
  full_join(gage_id, gage_meta, by = "site_no") 

gage_meta <- gage_meta %>% 
  select(sta, everything()) 

# check on integrity of the data by looking at counts 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
ck_sta <- gage_meta %>% 
  distinct(sta) 

ck_num <- gage_meta %>% 
  distinct(site_no) 

ck_sta_num <- gage_meta %>% 
  distinct(sta, site_no) 

ck_nam <- gage_meta %>% 
  distinct(station_nm) 

ck_sta_nam <- gage_meta %>% 
  distinct(sta, station_nm) 

num_nam <- gage_meta %>% 
  distinct(site_no, station_nm) 

ck_sta_nam_num <- gage_meta %>% 
  distinct(sta, site_no, station_nm) 

# export dataframes of the largest population of gages 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# export(gage, "data/gage_full.csv") # too big for GitHub 
# export(gage_meta, "data/gage_meta_full.csv")  

# create a table to show abbreviation, site no & station name 
gage_table <- gage_meta %>% 
  select(sta, site_no, station_nm) %>% 
  as.tibble() 


```

```{r clean_daily flow} 
# this code chunk checks and removes gages w/o useful characteristics
#   for future analysis 
# This code is a refactor of prior code above, some of it broken
# 
# Steps: 
# 1. Assemble a full dataset (N = 61 stations; 741,215 obs)
# 2. Remove streams prior to 1990 from the analysis series 
#      (N = 19 stations, 103,465 obs) 
# 3. Remove streams with substantial missing data 
# 4. Investigate remaining stations 

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 1. Assemble a set of all possible recorded streamflows----
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_meta_full <- import("data/gage_meta_full.csv") %>% 
  arrange(sta) 

gage_cont <- import("data/gage_cont.csv") 
gage_disc <- import("data/gage_disc.csv") 
gage_othr <- import("data/gage_other.csv") 

# Assemble a complete set of stations identifed in prior steps
gage_full  <- bind_rows(gage_cont, gage_disc, gage_othr)  

gage_full <- gage_full %>% 
  arrange(sta) %>% 
  select(site_no, sta, Date, i, everything()) 

# check results - should be 61 stations; yes
check_sta <- gage_full %>% 
  distinct(sta)
rm(gage_cont, gage_disc, gage_othr, check_sta)  

# calculate the minimun and maximum years in the series in metadata
gage_yr <- gage_full %>% 
  group_by(sta) %>% 
  summarize(min_yr = min(waterYear), 
            max_yr = max(waterYear)) %>% 
  mutate(count_yr = 1 + max_yr - min_yr)

gage_meta_full <- full_join(gage_meta_full, gage_yr, by = "sta")

gage_meta_full <- gage_meta_full %>% 
  arrange(count_yr) %>% 
#  select(-c(site_tp_cd, dec_coord_datum_cd, alt_datum_cd, huc_cd)) %>% 
   as.tibble() %>% 
   select(count_yr, everything())

# join together gage & gage metadata information
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_full <- full_join(gage_meta_full, gage_full, by = c("site_no", 
                                                         "sta"))
rm(gage_yr)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 2. Remove streams prior to 1990 from the analysis series----
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# identify old stations (<1990): n = 17 stations
gage_meta_drop <- gage_meta_full %>% 
  filter(max_yr < 1990) 

# identify stations for analysis: n = 44 stations; 17 + 44 = 61
gage_meta <- gage_meta_full %>% 
  filter(max_yr > 1989) # 44 sta

gage <- gage_full %>% 
    filter(max_yr > 1989) # 670,492 

gage_drop <- gage_full %>% 
  filter(max_yr <= 1988)  #  70,723

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 3. Remove streams with substantial missing data----
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Identify serially incomplete observations 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
gage_incomp <- gage %>% 
  group_by(sta, waterYear) %>% 
  summarize(i_count = n()) %>% 
  filter(i_count <= 364) %>% 
  ungroup() %>% 
  filter(waterYear > 1990) %>% 
  arrange(sta, waterYear, i_count) 

# 18 stations post-1990n are incomplete; two stations 
#   (bad_mid & chr_ang) have many incomplete years

# gage_incomp 
# A tibble: 62 x 3 - redacted & includes a note 
#   sta     waterYear i_count  note
#   <chr>       <int>   <int> <mine>
#  1 bad_mid      1991      28  most years incomplete; remove
# 17 bad_mid      2017       4
# 23 chr_ang      1991     181  most years incomplete; remove
#  7 chr_ang      2017     181

# remove stations with many incomplete years 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
drop_sta <- gage_meta %>% 
   filter(sta == "bad_mid" |    
           sta == "chr_ang"
         ) # 2 sta

gage_meta_drop <- bind_rows(gage_meta_drop, drop_sta) # 17 + 2 = 19 sta
  
gage_meta <- gage_meta %>% 
  filter(sta != "bad_mid" &  
           sta != "chr_ang"
         ) %>% 
  arrange(min_yr) %>% 
  select(sta, min_yr, max_yr, count_yr, everything()) # 44 - 2 = 42 sta

# remove observations with many incomplete years
drop_obs <- gage %>% 
  filter(sta == "bad_mid" |   
           sta == "chr_ang"
         ) # 32,742 obs

gage_drop <- bind_rows(gage_drop, drop_obs) # 70,723 + 32,742 = 103,465

gage <- gage %>% 
  filter(sta != "bad_mid" &  
           sta != "chr_ang"
         ) %>% 
  arrange(min_yr) %>% 
  select(sta, min_yr, max_yr, count_yr, everything()) 
# 670,492 - 32,742 = 637,750

rm(drop_sta, drop_obs, gage_incomp, gage_full, gage_drop, 
   gage_meta_drop, gage_meta_full) 


``` 

```{r check_geology}
# quick check of the geology of watersheds

chk_sta <- gage_meta %>% 
  select(sta, station_nm) %>% 
  arrange(sta)

#chk_sta  # shows the watershed general type if not sedimentarty
# A tibble: 42 x 2 
#   sta     station_nm                                   
#   <chr>   <chr>                                         
# 1 bat_bhr BATTLE CR BELOW HERMOSA,SD                   
# 2 bat_her BATTLE CR AT HERMOSA,SD                      
# 3 bat_key BATTLE CR NEAR KEYSTONE,SD                   * igneous  
# 4 bev_abf BEAVER CREEK ABOVE BUFFALO GAP, SD           
# 5 bev_buf BEAVER CR NEAR BUFFALO GAP,SD                
# 6 bev_pri BEAVER CREEK NEAR PRINGLE, SD                
# 7 blp_bel BLACK PIPE CREEK NR BELVIDERE, SD            
# 8 brsf_co SOUTH FORK BAD R NEAR COTTONWOOD,SD          
# 9 cas_hot CASCADE SPRINGS NEAR HOT SPRINGS SD          
#10 che_buf CHEYENNE R NEAR BUFFALO GAP SD               
#11 che_red CHEYENNE RIVER AT RED SHIRT, SD              
#12 che_sce CHEYENNE RIVER NEAR SCENIC, SD               
#13 che_was CHEYENNE RIVER NEAR WASTA, SD                
#14 fal_hot FALL R AT HOT SPRINGS,SD                     
#15 frn_fai FRENCH CR ABOVE FAIRBURN SD                  
#16 hat_edg HAT CR NEAR EDGEMONT,SD                      
#17 hor_oel HORSEHEAD CR AT OELRICHS,SD                  
#18 lcr_abv LAKE CR ABOVE REFUGE NEAR TUTHILL,SD         
#19 lcr_bel LAKE CR BELOW REFUGE NEAR TUTHILL,SD         
#20 lcr_vet LITTLE WHITE R NEAR VETAL,SD                 
#21 lwr_abv LITTLE WHITE R ABV ROSEBUD SD                
#22 lwr_mar LITTLE WHITE R NEAR MARTIN,SD                
#23 lwr_ros LITTLE WHITE R NEAR ROSEBUD SD               
#24 lwr_whi LITTLE WHITE R BELOW WHITE RIVER,SD          
#25 nio_abb NIOBRARA RIVER ABOVE BOX BUTTE RESERVOIR, NE  
#26 nio_bbb NIOBRARA RIVER BELOW BOX BUTTE RESERVOIR NEBR 
#27 nio_gor NIOBRARA RIVER NEAR GORDON, NEBR.            
#28 rap_cre RAPID CR AT CRESTON SD                       
#29 rap_far RAPID CR NEAR FARMINGDALE,SD                 
#30 ros_ros ROSEBUD CR AT ROSEBUD SD                     
#31 sna_bur SNAKE RIVER NEAR BURGE, NEBR.                
#32 sna_dou SNAKE R AT DOUGHBOY, NE                      
#33 spr_her SPRING CR NEAR HERMOSA,SD                    
#34 wcc_ogl WHITE CLAY CR NEAR OGLALA SD                 
#35 whi_cra White River at Crawford, Nebr.               
#36 whi_int WHITE R NEAR INTERIOR,SD                      
#37 whi_kad WHITE R NEAR KADOKA,SD                       
#38 whi_ogl WHITE R NEAR OGLALA SD                       
#39 whi_slm WHITE RIVER AT SLIM BUTTE, SD                
#40 whi_sta WHITE R NR NE-SD STATE LINE                  
#41 whi_whi WHITE RIVER NEAR WHITE RIVER, SD             
#42 wkc_wok WOUNDED KNEE CREEK AT WOUNDED KNEE, SD    

# remove igneous PreCambrian station from analysis----
gage <- gage %>% 
  filter(sta != "bat_key")             # obs  from 637,750 -> 616,525 

gage_meta <- gage_meta %>% 
  filter(sta != "bat_key")             # gage from      42 ->      41 

rm(chk_sta)
```

```{r create_post1980_subset}
# This code chunk subsets gages with 1990+ observations for clustering.
# Note - using water year (10-01) as start of year...

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Original Gages; gage_full       = 61 gages & 741,215 obs  
#      Gages w/o 1980+ or missing data = 19 gages & 103,465 (dropped) 
#   Gages remaining; gage           = 42 gages & 637,750 obs 
#      Gages with PreC geology      =  1 gage &   21,225 obs (dropped)
#   Gages remaining; gage           = 41 gages & 616,525 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Gages pre-1980; gage_lt80       = 29 gages & 255,068 obs 
#   Gages remaining; gage           = 42 gages & 361,457 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
#   Remove gages w/o full yrs       =  1 gage  &     363 obs
#   Gages remaining; gage           = 40 gages & 361,094 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
#   Identify reservation gages     = 14 gages 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 

 
# 1. filter pre-1980 gages---- 
gage_lt80_meta <- gage_meta %>% 
  filter(min_yr < 1979) # 29 gages 

gage_lt80 <- gage %>% 
  filter(min_yr <= 1979) %>%                        # waterYear 1980
  filter(Date < "1979-10-01")                       #  255,068 obs  

# remove pre-1980 observations    
gage <- gage %>% 
  filter(Date >= "1979-10-01")                      #  361,457 obs 

# export observations
export(gage_lt80, "data/gage_lt80.csv") 
export(gage_lt80_meta, "data/gage_lt80_meta.csv") 

rm(gage_lt80, gage_lt80_meta)


# 2. remove post-1990 stations w/o full years----

gage_comp <- gage %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  arrange(n) %>% 
  ungroup() %>% 
  filter(n >= 364) %>%
  group_by(sta) %>%
  count() %>% 
  ungroup() %>% 
  rename(yrs_post80 = nn) %>% 
  arrange(yrs_post80)

check_sta <- anti_join(gage, gage_comp, by = "sta")
# this shows rap_cre should be dropped   

# update stations by dropping rap_cre
gage_meta <- semi_join(gage_meta, gage_comp, by = "sta")     # 40 sta
gage      <- semi_join(gage, gage_comp)                 # 361,094 obs

rm(check_sta) 

# 3. Investigate remaining stations----
gage_incomp <- gage %>% 
  group_by(sta, waterYear) %>% 
  summarize(i_count = n()) %>% 
  filter(i_count <= 364) %>% 
  ungroup() %>% 
  filter(waterYear > 1990) %>% 
  arrange(i_count, waterYear, sta) 

# filter set of Reservation stations
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_res <- gage_meta %>% 
  filter(state_cd == 46) %>% 
  filter(county_cd == 7 | 
           county_cd == 71 |
           county_cd == 95 |
           county_cd == 102
  ) %>% 
  select(min_yr, max_yr, sta)

# join post-90 reservation stations 
gage_res <- left_join(gage_comp, gage_res, by = "sta") 

gage_res <- gage_res %>% 
  arrange(max_yr, yrs_post80) 

rm(gage_comp, gage_incomp) 

# The table below is the 13 stations on the reservation, which are 
# shown with min & max year and the other stations in the region) 

# gage_res 
# A tibble: 41 x 4
#   sta     yrs_post80 min_yr max_yr
#   <chr>        <int>  <dbl>  <dbl>
# 1 wkc_wok          5   1992   1997
# 2 whi_slm          6   1962   1997
# 3 wcc_ogl         14   1966   1999
# 4 lcr_abv         19   1938   2016
# 5 whi_int         15   1929   2017
# 6 blp_bel         25   1992   2017
# 7 brsf_co         29   1989   2017
# 8 whi_sta         30   1988   2017
# 9 lcr_bel         38   1939   2017
#10 lcr_vet         38   1959   2017
#11 lwr_mar         38   1938   2017
#12 lwr_whi         38   1950   2017
#13 whi_kad         38   1942   2017
#14 whi_ogl         38   1943   2017
#15 bev_abf          7     NA     NA
#16 che_sce         10     NA     NA
#17 che_buf         11     NA     NA
#18 nio_bbb         12     NA     NA
#19 nio_gor         12     NA     NA
#20 sna_dou         13     NA     NA
#21 whi_cra         13     NA     NA
#22 nio_abb         15     NA     NA
#23 sna_bur         15     NA     NA
#24 cas_hot         16     NA     NA
#25 whi_whi         16     NA     NA
#26 lwr_abv         18     NA     NA
#27 ros_ros         18     NA     NA
#28 che_red         19     NA     NA
#29 spr_her         25     NA     NA
#30 bev_pri         26     NA     NA
#31 bat_bhr         29     NA     NA
#32 hor_oel         34     NA     NA
#33 frn_fai         35     NA     NA
#34 rap_far         37     NA     NA
#35 bat_her         38     NA     NA
#36 bat_key         38     NA     NA
#37 bev_buf         38     NA     NA
#38 che_was         38     NA     NA
#39 fal_hot         38     NA     NA
#40 hat_edg         38     NA     NA
#41 lwr_ros         38     NA     NA

# wkc-wok is 1993-1998 - so first clustering is over these dates 
#   to identify a group for wkc-wok to estimate streamflows 


```

```{r create_9398_subset}
# This code chunk creates a cluster for wkc_wok active years
# Notes: Use water year Oct1-Sept31, w/ year on the majority of months 

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Gages post1980; gage               = 40 gages & 361,094 obs
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
#     All gages from 93-98             = 31 gages &  58,599 obs           
#   Incomplete gages from 93-98        =  1 gage (lcr_abv)   
#____________________________________________________________________ 
#     Complete gages from 93-98        = 30 gages &  57,697 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


# 1. filter gages w/ complete 1993-98 obs (wkc_wok) ----
# this is to create an initial cluster set with wkc_wok
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# filter gages for water years 1993-1998
gage_9398_meta <- gage_meta %>% 
  filter(min_yr <= 1992)  %>%
  filter(max_yr >= 1997)                               #     32 gages 

gage_9398 <- gage %>% 
  filter(waterYear >= 1993) %>% 
  filter(waterYear <= 1998) %>%                        # 58,599   obs
  filter(min_yr <= 1992)    %>%
  filter(max_yr >= 1997)    

# Identify gages missing data 1993-1998 
gage_incomp <- gage_9398 %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  arrange(n) %>% 
  ungroup() %>% 
  filter(n < 364) %>% 
  arrange(waterYear, n) # 3 obs 

#gage_incomp 
# A tibble: 4 x 3 - the o
#  sta     waterYear     n 
#  <chr>       <int> <int> 
#1 lcr_abv      1996   172 * on Rez - need to add in later  
# ~~~~~~~~~~~~~~~~~~~~~~~~ 

#  make gage_incomp full record & remove gages w/ miss. yrs in 93-98 
gage_9398_incomp <- semi_join(gage_9398_meta, gage_incomp, by = "sta") 
gage_9398_meta <- anti_join(gage_9398_meta, gage_incomp, by = "sta") 

# removed lcr_abv - for now - 30 gages remaining  

# drop incomplete stations 
gage_9398 <- anti_join(gage_9398, gage_incomp, by = "sta") 
# 57,697 remaining obs 

# check results & clean up 
chk_sta <- anti_join(gage_meta, gage_9398_meta, by = "sta") %>% 
  select(1:3) 

chk_sta 
# A tibble: 10 x 3
#   sta     min_yr max_yr
#   <chr>    <dbl>  <dbl>
# 1 nio_gor   1928   1991   ok to drop 
# 2 lcr_abv   1938   2016 * on Rez - need to add in later 
# 3 nio_bbb   1947   1991   ok to drop 
# 4 nio_abb   1947   1994   ok to drop 
# 5 sna_bur   1948   1995   ok to drop 
# 6 cas_hot   1976   1995   ok to drop 
# 7 sna_dou   1982   1995   ok to drop 
# 8 che_red   1998   2017   ok to drop 
# 9 whi_whi   2001   2017   ok to drop 
#10 che_sce   2007   2017   ok to drop 

# final check 
chk_sta <- gage_9398 %>% 
  distinct(sta) 

chk_sta <- full_join(gage_test, gage_9398_meta, by = "sta")


# export 1993-1998 & clean up 
export(gage_9398, "data/gage_9398.csv") 
export(gage_9398_meta, "data/gage_meta_9398.csv") 

rm(chk_sta, gage_9398_incomp, gage_incomp) 
```

```{r create_9016_subset} 
# This code chunk creates a cluster for lcr_abv active years
#   Complete 1990-16 obs w/o 96 (lcr_abv); range of yrs [1938, 2016] 
# 
#   Remember waterYear 1990 = Oct 1989 - Sept 1990, 
#     so the last possible wateryear is 2016; but n(2006) = 61 obs,
#       so, use 2015 as last year
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#   Gages post1980; gage               = 40 gages & 361,094 obs 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
#     All gages from 90-16             = 21 gages & 251,862 obs           
#   Incomp. gages !Rez & !93-98        =  5 gages &  18,458 obs *
#____________________________________________________________________ 
#     Intermediate gages               = 21 gages & 233,404 obs 
#   Incomp. gages in 90-16             =  1 gage  &  32,726 obs * 
#____________________________________________________________________ 
#     Intermediate gages               = 20 gages & 200,678 obs 
#   1996 observations                  = NA gages &   8,224 obs   
#____________________________________________________________________ 
#  Final group of 90-16_no96           = 20 gages & 192,820 obs
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
# * these gages will not be used at all in the analysis


# 1. filter gages with 1990-16 obs---- 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# filter gages for water years 1990-2016; all observations  
gage_9016_meta <- gage_meta %>% 
  filter(min_yr <= 1989)  %>% 
  filter(max_yr >= 2015)                                #  21 gages 

gage_9016 <- gage %>% 
  filter(waterYear >= 1990) %>% 
  filter(waterYear <= 2015)                             # 251,862 obs

# identify gages w/ missing years in 1990-2016 & not in 1993-1998
gage_incomp <- gage_9016 %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  arrange(n) %>% 
  ungroup() %>% 
  filter(n < 364) %>% 
  arrange(waterYear, n)                       #  16 gages (but mixed)

# prepare to use the gage_missing to examine # incomplete observations
gage_missing <- anti_join(gage_incomp, gage_9398_meta, by = "sta") 

gage_missing <- gage_missing %>% 
  arrange(waterYear)

gage_missing <- gage_missing %>% 
  filter(sta != "lcr_abv")
  
#gage_missing 
# A tibble: 7 x 3
#  sta     waterYear     n
#  <chr>       <int> <int>
#1 sna_dou      1995    17  - ok to drop 
#2 sna_bur      1995   221  - ok to drop 
#3 che_red      1998    19  - ok to drop 
#4 whi_whi      2001   122  - ok to drop 
#5 che_sce      2007   183  - ok to drop              #       5 gages

# drop gages missing: the set is: not Rez, incomp. 93-98
gage_drop    <- semi_join(gage_9016, gage_missing, 
                            by = "sta")               #  18,458  obs 

gage_9016      <- anti_join(gage_9016, gage_missing, by = "sta")
                                                        # 233,404 obs 

gage_9016_meta <- anti_join(gage_9016_meta, gage_missing, by = "sta") 
                                                        #    21 gages


# 2. Remove gages incomplete 1990-16 obs---- 

# find incomplete gages
gage_incomp <- gage_9016 %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  ungroup() %>% 
  filter(n < 364) %>% 
  arrange(sta)  %>% 
  group_by(sta) %>%  
  count() %>% 
  ungroup() 

# gage_incomp 
# A tibble: 8 x 2 
#  sta        nn - this is the number of water years missing  
#  <chr>   <int> 
#1 bev_pri     1   - 1991 
#2 blp_bel     1   - 1992
#3 che_buf     1   - 2007 
#4 lcr_abv     2   - 1996  * this is the one to keep!
#5 lwr_abv     3   - 2000, 2003, 2004
#6 ros_ros     2   - 2004 
#7 whi_slm     1   - 1991
#8 wkc_wok     1   - 1992 
  
# prepare for a join by removing lcr_abv from file
gage_incomp <- gage_incomp %>% 
  filter(sta != "lcr_abv")

# drop gages w/ missing obs, the set is: not Rez, incomp. 90-16 
gage_drop      <- semi_join(gage_9016, gage_incomp, 
                            by = "sta")                 #  32,726 obs 

gage_drop_meta <- semi_join(gage_9016_meta, gage_incomp, 
                            by = "sta")                #       1 gage

gage_9016      <- anti_join(gage_9016, gage_incomp, by = "sta")
                                                       # 200,678  obs 
gage_9016_meta <- anti_join(gage_9016_meta, gage_incomp, by = "sta") 
                                                      #      20 gages

# check results 
chk_sta <- gage_9016 %>% 
  group_by(sta, waterYear) %>%  
  count() %>% 
  arrange(n) %>% 
  ungroup() %>% 
  filter(n < 364) %>% 
  arrange(waterYear, n)                # 1 obs of gage w/ missing yrs

# export results & clean up 
export(gage_9016, "data/gage_9016.csv") 
export(gage_9016_meta, "data/gage_meta.csv") 

rm(chk_sta, gage_drop, gage_drop_meta, gage_incomp, gage_missing) 


# 3. prepare cluster two for export---- 

# remove the year 1996 from result 
gage_9016_no96 <- gage_9016 %>% 
  filter(waterYear != 1996) 

export(gage_9016_no96, "data/gage_9016_no96.csv") 
export(gage_9016_meta, "data/gage_meta_9016.csv") 
```

```{r check_results_subset} 

# identify stations with full years 
chk_sta <- bind_rows(gage_9398_meta, gage_9016_meta) 

chk_sta <- chk_sta %>% 
  distinct(sta, .keep_all = TRUE) %>% 
  select(sta, station_nm, min_yr, max_yr, count_yr, everything()) %>% 
    arrange(station_nm) 

# identify stations dropped in the analysis
drop_sta <- anti_join(gage_meta, chk_sta, by = "sta") 

drop_sta <- drop_sta %>% 
  select(sta, station_nm, min_yr, max_yr, count_yr) %>% 
  arrange(station_nm)

# drop_sta 
# A tibble: 9 x 5 - thise are stations that won't be used in analysis
#  sta     station_nm                          min_yr max_yr count_yr 
#  <chr>   <chr>                                <dbl>  <dbl>    <dbl> 
#1 cas_hot CASCADE SPRINGS NEAR HOT SPRINGS SD   1976   1995       20 
#2 che_red CHEYENNE RIVER AT RED SHIRT, SD       1998   2017       20 
#3 che_sce CHEYENNE RIVER NEAR SCENIC, SD        2007   2017       11 
#4 nio_abb NIOBRARA RIVER ABOVE BOX BUTTE RES…   1947   1994       48 
#5 nio_bbb NIOBRARA RIVER BELOW BOX BUTTE RES…   1947   1991       45 
#6 nio_gor NIOBRARA RIVER NEAR GORDON, NEBR.     1928   1991       64 
#7 sna_dou SNAKE R AT DOUGHBOY, NE               1982   1995       14 
#8 sna_bur SNAKE RIVER NEAR BURGE, NEBR.         1948   1995       48 
#9 whi_whi WHITE RIVER NEAR WHITE RIVER, SD      2001   2017       17 
#x bat_key BATTLE CR NEAR KEYSTONE,SD            1945   2017       73


# chk_sta 
# A tibble: 32 x 5
#   sta     station_nm                         min_yr max_yr count_yr
#   <chr>   <chr>                               <dbl>  <dbl>    <dbl>
# 1 bat_her BATTLE CR AT HERMOSA,SD              1949   2017       69
# 2 bat_bhr BATTLE CR BELOW HERMOSA,SD           1951   2017       67
# 3 bev_buf BEAVER CR NEAR BUFFALO GAP,SD        1938   2017       80
# 4 bev_abf BEAVER CREEK ABOVE BUFFALO GAP, SD   1991   1997        7
# 5 bev_pri BEAVER CREEK NEAR PRINGLE, SD        1991   2017       27
# 6 blp_bel BLACK PIPE CREEK NR BELVIDERE, SD    1992   2017       26
# 7 che_buf CHEYENNE R NEAR BUFFALO GAP SD       1969   2017       49
# 8 che_was CHEYENNE RIVER NEAR WASTA, SD        1915   2017      103
# 9 fal_hot FALL R AT HOT SPRINGS,SD             1947   2017       71
#10 frn_fai FRENCH CR ABOVE FAIRBURN SD          1982   2017       36
#11 hat_edg HAT CR NEAR EDGEMONT,SD              1951   2017       67
#12 hor_oel HORSEHEAD CR AT OELRICHS,SD          1983   2017       35
#13 lcr_abv LAKE CR ABOVE REFUGE NEAR TUTHILL…   1938   2016       79
#14 lcr_bel LAKE CR BELOW REFUGE NEAR TUTHILL…   1939   2017       79
#15 lwr_abv LITTLE WHITE R ABV ROSEBUD SD        1982   2004       23
#16 lwr_whi LITTLE WHITE R BELOW WHITE RIVER,…   1950   2017       68
#17 lwr_mar LITTLE WHITE R NEAR MARTIN,SD        1938   2017       80
#18 lwr_ros LITTLE WHITE R NEAR ROSEBUD SD       1943   2017       75
#19 lcr_vet LITTLE WHITE R NEAR VETAL,SD         1959   2017       59
#20 rap_far RAPID CR NEAR FARMINGDALE,SD         1946   2017       72
#21 ros_ros ROSEBUD CR AT ROSEBUD SD             1975   2004       30
#22 brsf_co SOUTH FORK BAD R NEAR COTTONWOOD,…   1989   2017       29
#23 spr_her SPRING CR NEAR HERMOSA,SD            1949   2004       56
#24 wcc_ogl WHITE CLAY CR NEAR OGLALA SD         1966   1999       34
#25 whi_int WHITE R NEAR INTERIOR,SD             1929   2017       89
#26 whi_kad WHITE R NEAR KADOKA,SD               1942   2017       76
#27 whi_ogl WHITE R NEAR OGLALA SD               1943   2017       75
#28 whi_sta WHITE R NR NE-SD STATE LINE          1988   2017       30
#29 whi_cra White River at Crawford, Nebr.       1931   2004       74
#30 whi_slm WHITE RIVER AT SLIM BUTTE, SD        1962   1997       36
#31 wkc_wok WOUNDED KNEE CREEK AT WOUNDED KNE…   1992   1997        6


```

```{r next_steps_munging, eval=FALSE}
# Also add BEAR in the LODGE


# check ice - starts 2017-10-23 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ice <- gage_int %>%
  filter(code == "P Ice") %>% 
  arrange(date) 

# check provisional values 
# ~~~~~~~~~~~~~~~~~~~~~~~~
provis <- gage_int %>%
  filter(code == "P" | code == "P e" | code == "P <") %>%
  arrange(date) # starts 2016-10-05

# remove data after 2017-10-01
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int <- gage_int %>%
  filter(year != 2018)

gage_2017 <- gage_int %>%
  filter(year == 2017)

gage_prior <- gage_int %>%
  filter(year < 2017) 

gage_2017 <- gage_2017 %>%
  filter(month != 10) %>% 
  filter(month != 11) %>%
filter(month != 12)

gage_imp <- bind_rows(gage_prior, gage_2017) %>%
  arrange(desc(date)) 
rm(gage_2017, gage_int, gage_list, gage_prior, ice, provis, gage_raw) 

# simplify the naming convention for gages 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_imp <- gage_imp %>% 
  select(site_no, date, discharge, code)

station_nm <- gage_meta %>% 
  select(site_no, station_nm) %>% 
  as.tibble()

abrev <- c("whi_sta", "whi_ogl", "wcc_ogl", "whi_int", "wkc_wok", 
           "blc_wan", "whi_kad", "blp_bel", "lwr_mar", "lcr_bel", 
           "lcr_vet", "brsf_co", "bad_mid") %>%
  as.tibble() %>%
  rename(sta = value)

abrev <- bind_cols(abrev, station_nm) 

gage_imp <- full_join(abrev, gage_imp, by = "site_no")
gage_meta <- full_join(abrev, gage_meta, by = "site_no")
rm(station_nm, abrev)

# Split and spread data
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_dis_imp <- gage_imp %>% 
  select(sta, date, discharge)

gage_dis_imp <- gage_dis_imp %>% 
  spread(key = sta, value = discharge) 

# Add short name to metadata
# ~~~~~~~~~~~~~~~~~~~~~~~~~~
abrev <- gage_imp %>%
  distinct(sta, site_no)

gage_meta <- full_join(abrev, gage_meta, by = "site_no") 

# export and import station df by rio
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_raw, "data/gage_raw.csv") 
# write_lines(gage_json, "data/gage_list.json")
# export(gage_imp, "data/gage_imperial.csv") 

# export(gage_dis_imp, "data/gage_discharge_imp.csv") 


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# get site numbers from prior metadata
gage_meta <- import("data/gage_meta.csv")
#site_nums <- gage_meta %>%
#  select(sta, site_no) %>% 
#  print()


#Sample <- readNWISSample(siteNumber,parameter_cd,startDate,endDate)
# this code chunk uses dataRetreval to get discharge in cfs 
# removes provisional values and ice and saves the data as a csv.
```


```{r code = readlines(knitr::purl("/path/to/file", documentation = 1)), echo=T, eval=F}
# this R markdown chunk generates a code appendix 

#
```

