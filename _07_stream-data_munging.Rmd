
<!--
Exploratory Data Analysis Checklist by Roger Peng 
https://leanpub.com/exdata  

1.0  Formulate your question  
Spend a few minutes to figure out the question you’re really interested in, and narrow it down to be as specific as possible (without becoming uninteresting).

General question:
Are air pollution levels higher on the east coast than on the west coast?
More specific question:
Are hourly ozone levels on average higher in New York City than they are in Los Angeles?

2.0   Read in your data  
Sometimes the data will need some cleaning and every dataset has its unique quirks. The dataset is a comma-separated value (CSV) file, where each row of the file contains one daily measurement of precipation depth.  The readr package can rewrite column names to remove spaces.
> names(ozone) <- make.names(names(ozone))

3.0  Check the dataset 
3.1  Check the number of rows and columns.
3.2  Check the types of data
3.3  Look at the top and the bottom of your data 
3.4  Check your “n”s & NAs 
3.5  Validate with at least one external data source  
4.0  Try the easy solution first to answer question
5.0  Challenge your solution 
6.0  Follow up questions 


## Broad questions:
What is the drought history of the Pine Ridge Reservation?  
Does the drought extent differ across the study area?
What is streamflow variation across the Pine Ridge Reservation?

## Narrower questions:

What is streamflow variation across the Pine Ridge Reservation?

## Analysis Steps:
1.  Data read in from USGS website by EGRET (cfs) 
2.  Added names & station numbers & joined data 
3.  Data saved in a flat format (.csv) 

Didn't work these
1.  Data read in from USGS website by dataRetrieval (cfs)
2.  Data saved as array (.JSON), and flat format (.csv) 


# Next STEPS
1. blc_wan <- readNWISDaily("06446700") # this not working!
2. Check on next steps from Chapter 2 list 
3. Describe the precipitation seasonality

## Variable naming convention:   
gage         USGS streamgage station
_meta        metadata  
_raw         the "mostly" raw dataset  
_list        gage data as a list
_json        gage data as a list in JSON format 
_imp         gage data in imperial units in long format
_dis_imp     gage discharge in imperial units in wide format

## Results: 



# Someday Maybe
# USGS 06447050 UNNAMED TRIB BUZZARD CREEK NR LONG VALLEY, SD -instant meas
https://nwis.waterdata.usgs.gov/usa/nwis/qwdata/?huc_cd=10140202&format=station_list&sort_key=site_no&index_pmcode_00065=3&index_pmcode_00060=4&index_pmcode_00062=5&index_pmcode_72020=6&sort_key=site_no&group_key=county_cd&sitefile_output_format=station_list
-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r library, message=FALSE}
# Sets up the library of packages  
library("here") # identifies where to save work
library("dataRetrieval") # USGS data import
library("EGRET") # Exploration and Graphics for RivEr Trends
library("rio") # more robust I/O - to import and clean data 
library("lubridate") # easier dates
library("tidyverse")
library("janitor") # tools for examining and cleaning dirty data 
#library("DataExplorer") # quick look at NA vals
#library('jsonlite') # tools for working with lists 
#library("magrittr") # provides aliases for easier reading
# library("friendlyeval")

# a useful description of commits:
# http://r-pkgs.had.co.nz/git.html
```

```{r import_streamflow_EGRET, eval=FALSE}

# Loads USGS gage data individually and bind_cols
# 
#   readNWISDaily(siteNumber, parameterCd = "00060", startDate = "",
#      endDate = "", interactive = TRUE, convert = TRUE) 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# List of sites
# ~~~~~~~~~~~~~
## Site Number: 06406500 - BATTLE CR BELOW HERMOSA,SD 
#bad_mid <- "06441000" 
#brsf_co <- "06440200" 
#blp_bel <- "06447230" 
## Site Number: 06402500 - BEAVER CR NEAR BUFFALO GAP,SD
## Site Number: 06402430 - BEAVER CREEK NEAR PRINGLE, SD 
## Site Number: 06402600 - CHEYENNE R NEAR BUFFALO GAP SD 
## Site Number: 06403700 - CHEYENNE RIVER AT RED SHIRT, SD 
## Site Number: 06408650 - CHEYENNE RIVER NEAR SCENIC, SD 
# Site Number: 06423500 - CHEYENNE RIVER NEAR WASTA, SD 
## Site Number: 06402000 - FALL R AT HOT SPRINGS,SD 
## Site Number: 06400000 - HAT CR NEAR EDGEMONT,SD
## Site Number: 06400875 - HORSEHEAD CR AT OELRICHS,SD 
#lcr_tut <- "06449000" 
#lcr_vet <- "06449100"  
#lwr_mar <- "06447500" 
## Site Number: 06449500 - LITTLE WHITE R NEAR ROSEBUD SD
## Site Number: 06450500 - LITTLE WHITE R BELOW WHITE RIVER,SD 
## Site Number: 06421500 - RAPID CR NEAR FARMINGDALE,SD 
#wcc_ogl <- "06445980" 
#whi_int <- "06446500" 
#whi_kad <- "06447000"  
#whi_ogl <- "06446000"  
# Site Number: 06446200 - WHITE R NEAR ROCKYFORD SD 
#whi_sta <- "06445685" 
## Site Number: 06447450 - WHITE RIVER NEAR WHITE RIVER, SD 
#wkc_wok <- "06446100" 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 1. load individual gages
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# add an end date to remove provisional data & gaps in vals
startDate    <- "" #Gets earliest date
endDate      <- "2017-09-30"
parameter_cd <- "00060" 
# ~~~~~~~~~~~~~~~~~~~~~ 

bad_mid <- readNWISDaily("06441000", parameter_cd, startDate, endDate) 
#blc_wan <- readNWISDaily("06446700") # this not working!
bat_her <- readNWISDaily("06406500", parameter_cd, startDate, endDate) 
bev_buf <- readNWISDaily("06402500", parameter_cd, startDate, endDate) 
bev_pri <- readNWISDaily("06402430", parameter_cd, startDate, endDate) 
blp_bel <- readNWISDaily("06447230", parameter_cd, startDate, endDate) 
brsf_co <- readNWISDaily("06440200", parameter_cd, startDate, endDate) 
che_buf <- readNWISDaily("06402600", parameter_cd, startDate, endDate) 
che_red <- readNWISDaily("06403700", parameter_cd, startDate, endDate) 
che_sce <- readNWISDaily("06408650", parameter_cd, startDate, endDate) 
che_was <- readNWISDaily("06423500", parameter_cd, startDate, endDate) 
fal_hot <- readNWISDaily("06402000", parameter_cd, "1947-06-01", endDate) 
hat_edg <- readNWISDaily("06400000", parameter_cd, startDate, endDate) 
hor_oel <- readNWISDaily("06449500", parameter_cd, startDate, endDate) 
lcr_tut <- readNWISDaily("06449000", parameter_cd, startDate, endDate) 
lcr_vet <- readNWISDaily("06449100", parameter_cd, startDate, endDate) 
lwr_mar <- readNWISDaily("06447500", parameter_cd, startDate, endDate) 
lwr_ros <- readNWISDaily("06449500", parameter_cd, startDate, endDate) 
lwr_whi <- readNWISDaily("06450500", parameter_cd, startDate, endDate)
rap_far <- readNWISDaily("06421500", parameter_cd, startDate, endDate)
wcc_ogl <- readNWISDaily("06445980", parameter_cd, startDate, endDate) 
wkc_wok <- readNWISDaily("06446100", parameter_cd, startDate, endDate) 
whi_int <- readNWISDaily("06446500", parameter_cd, startDate, endDate) 
whi_kad <- readNWISDaily("06447000", parameter_cd, startDate, endDate)
whi_ogl <- readNWISDaily("06446000", parameter_cd, startDate, endDate)  
whi_roc <- readNWISDaily("06446200", parameter_cd, startDate, endDate) 
whi_slm <- readNWISDaily("06445700", parameter_cd, startDate, endDate) 
whi_sta <- readNWISDaily("06445685", parameter_cd, startDate, endDate) 
whi_whi <- readNWISDaily("06447450", parameter_cd, startDate ,endDate)

# 2. add short name and abbreviation to gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
bad_mid <- bad_mid %>% 
  mutate(sta = "bad_mid") %>%
  mutate(site_no = "06441000") 

#blc_wan <- blc_wan %>%
#  mutate(sta = blc_wan) %>%
#  mutate(site_no = "06446700")

bat_her <- bat_her %>%
  mutate(sta = "bat_her") %>%
  mutate(site_no = "06406500") 

bev_buf <- bev_buf %>%
  mutate(sta = "bev_buf") %>%
  mutate(site_no = "06402500") 

bev_pri <- bev_pri %>%
  mutate(sta = "bev_pri") %>%
  mutate(site_no = "06402430") 

blp_bel <- blp_bel %>% 
  mutate(sta = "blp_bel") %>%
  mutate(site_no = "06447230")

 brsf_co <- brsf_co %>% 
  mutate(sta = "brsf_co") %>%
  mutate(site_no = "06440200")

che_buf <- che_buf %>% 
  mutate(sta = "che_buf") %>%
  mutate(site_no = "06402600")

che_red <- che_red %>% 
  mutate(sta = "che_red") %>%
  mutate(site_no = "06403700")

che_sce <- che_sce %>% 
  mutate(sta = "che_sce") %>%
  mutate(site_no = "06408650") 

che_was <- che_was %>% 
  mutate(sta = "che_was") %>%
  mutate(site_no = "06423500") 

fal_hot <- fal_hot %>% 
  mutate(sta = "fal_hot") %>%
  mutate(site_no = "06402000") 

hat_edg <- hat_edg %>% 
  mutate(sta = "hat_edg") %>%
  mutate(site_no = "06400000") 

hor_oel <- hor_oel %>% 
  mutate(sta = "hor_oel") %>%
  mutate(site_no = "06449500") 

lcr_tut <- lcr_tut %>% 
  mutate(sta = "lcr_tut") %>%
  mutate(site_no = "06449000")

lcr_vet <- lcr_vet %>% 
  mutate(sta = "lcr_vet") %>%
  mutate(site_no = "06449100")

lwr_mar <- lwr_mar  %>% 
  mutate(sta = "lwr_mar") %>%
  mutate(site_no = "06447500")

lwr_ros <- lwr_ros  %>% 
  mutate(sta = "lwr_ros") %>%
  mutate(site_no = "06449500")

lwr_whi <- lwr_whi  %>% 
  mutate(sta = "lwr_whi") %>%
  mutate(site_no = "06450500")
 
rap_far <- rap_far  %>% 
  mutate(sta = "rap_far") %>%
  mutate(site_no = "06421500")

wcc_ogl <- wcc_ogl %>% 
  mutate(sta = "wcc_ogl") %>%
  mutate(site_no = "06445980") 

whi_int <- whi_int %>% 
  mutate(sta = "whi_int") %>%
  mutate(site_no = "06446500") 

whi_kad <- whi_kad %>% 
  mutate(sta = "whi_kad") %>%
  mutate(site_no = "06447000") 

whi_ogl <- whi_ogl %>% 
  mutate(sta = "whi_ogl") %>%
  mutate(site_no = "06446000") 

whi_slm <- whi_slm %>% 
  mutate(sta = "whi_slm") %>%
  mutate(site_no = "06445700") 

whi_roc <- whi_roc %>% 
  mutate(sta = "whi_roc") %>%
  mutate(site_no = "06446200") 

whi_sta <- whi_sta %>% 
  mutate(sta = "whi_sta") %>%
  mutate(site_no = "06445685") 

whi_whi <- whi_whi %>% 
  mutate(sta = "whi_whi") %>%
  mutate(site_no = "06447450") 

wkc_wok <- wkc_wok %>% 
  mutate(sta = "wkc_wok") %>%
  mutate(site_no = "06446100") 

# 3. join together in long format and save
gage_int1  <- bind_rows(bad_mid, bat_her) 
gage_int2  <- bind_rows(gage_int1, brsf_co) 
gage_int3  <- bind_rows(gage_int2, blp_bel) 
gage_int4  <- bind_rows(gage_int3, bev_buf) 
gage_int5  <- bind_rows(gage_int4, bev_pri) 
gage_int6  <- bind_rows(gage_int5, che_red) 
gage_int7  <- bind_rows(gage_int6, che_sce) 
gage_int8  <- bind_rows(gage_int7, fal_hot) 
gage_int9  <- bind_rows(gage_int8, hat_edg) 
gage_int10 <- bind_rows(gage_int9, hor_oel) 
gage_int11 <- bind_rows(gage_int10, lcr_tut) 
gage_int12 <- bind_rows(gage_int11, lcr_vet) 
gage_int13 <- bind_rows(gage_int12, lwr_mar) 
gage_int14 <- bind_rows(gage_int13, lwr_ros) 
gage_int15 <- bind_rows(gage_int14, lwr_whi) 
gage_int16 <- bind_rows(gage_int15, rap_far) 
gage_int17 <- bind_rows(gage_int16, wcc_ogl) 
gage_int18 <- bind_rows(gage_int17, whi_int) 
gage_int19 <- bind_rows(gage_int18, whi_kad) 
gage_int20 <- bind_rows(gage_int19, whi_ogl) 
gage_int21 <- bind_rows(gage_int20, whi_slm) 
gage_int22 <- bind_rows(gage_int21, whi_sta) 
gage_int23 <- bind_rows(gage_int22, whi_whi) 
gage_int24 <- bind_rows(gage_int23, wkc_wok) 
gage_int25 <- bind_rows(gage_int24, che_buf) 
gage_int26 <- bind_rows(gage_int25, che_was) 
gage_int27 <- bind_rows(gage_int26, whi_roc) 

# export daily flows to data folder
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_int27, "data/gage_cms.csv")
```

```{r import_streamflow_EGRET-bearLodge}
# long story, but Bear in the Lodge streamflow is restricted.  So,
# need to find another approach to getting the data.
# one way is annual reports - but only to 2013
# Need to email the webmaster to get streamflow data.
# https://waterdata.usgs.gov/sd/nwis/inventory/?site_no=06446700&agency_cd=
```

```{r import_streamflow_EGRET-discontinued}
# Discontinued Stations w/in 30 mi.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Site Number: 06458000 - Antelope Creek near Gordon, Nebr.
# Site Number: 06440500 - NORTH FORK BAD R NEAR PHILIP SD 
# Site Number: 06458500 - BEAR C NR ELI NEBR 
# Site Number: 06402470 - BEAVER CREEK ABOVE BUFFALO GAP, SD 
# Site Number: 06445590 - BIG BORDEAUX CREEK NEAR CHADRON NEBR 
# Site Number: 06400497 - CASCADE SPRINGS NEAR HOT SPRINGS SD 
# Site Number: 06400500 - CHEYENNE R NEAR HOT SPRINGS SD 
# Site Number: 06402140 - FALL RIVER ABOVE FALLS NR HOT SPRINGS, SD 
# Site Number: 06403500 - FRENCH CR NEAR FAIRBURN SD 
# Site Number: 06400870 - HORSEHEAD CR NEAR OELRICHS SD 
# Site Number: 06448000 - LAKE CR ABOVE REFUGE NEAR TUTHILL,SD 
# Site Number: 06449300 - LITTLE WHITE R ABV ROSEBUD SD 
# Site Number: 06460900 - MINNECHADUZA CREEK NEAR KILGORE, NEBRASKA 
# Site Number: 06454500 - NIOBRARA RIVER ABOVE BOX BUTTE RESERVOIR, NE 
# Site Number: 06455500 - NIOBRARA RIVER BELOW BOX BUTTE RESERVOIR NEBR 
# Site Number: 06457000 - NIOBRARA RIVER NEAR COLCLESSER, NEBR. 
# Site Number: 06459000 - NIOBRARA R NEAR CODY, NEBR. 
# Site Number: 06455900 - NIOBRARA RIVER NEAR DUNLAP, NEBR. 
# Site Number: 06456500 - NIOBRARA RIVER NR HAY SPRINGS, NEBR.
# Site Number: 06422000 - RAPID CR AT CRESTON SD 
# Site Number: 06449400 - ROSEBUD CR AT ROSEBUD SD 
# Site Number: 06459500 - SNAKE RIVER NEAR BURGE, NEBR. 
# Site Number: 06459175 - SNAKE R AT DOUGHBOY, NE 
# Site Number: 06459200 - SNAKE RIVER ABV MERRITT RESERVOIR NEBR 
# Site Number: 06449250 - SPRING CR NEAR ST FRANCIS SD 
# Site Number: 06445500 - WHITE R NEAR CHADRON NEBR 
# Site Number: 06444000 - White River at Crawford, Nebr. 
# Site Number: 06445700 - WHITE RIVER AT SLIM BUTTE, SD 
# Site Number: 06445000 - WHITE R BELW COTTONWOOD C N WHITNEY, NEBR. 

# 1. load individual gages
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# add an end date to remove provisional data & gaps in vals
startDate    <- "" #Gets earliest date
endDate      <- "2017-09-30"
parameter_cd <- "00060" 
# ~~~~~~~~~~~~~~~~~~~~~ 

ant_gor <- readNWISDaily("06458000", parameter_cd, startDate ,endDate) 
brnf_ph <- readNWISDaily("06440500", parameter_cd, startDate, endDate) 
bea_eli <- readNWISDaily("06458500", parameter_cd, startDate, endDate) 
bev_buf <- readNWISDaily("06402470", parameter_cd, startDate, endDate) 
bor_cha <- readNWISDaily("06445590", parameter_cd, startDate, endDate) 
cas_hot <- readNWISDaily("06400497", parameter_cd, startDate, endDate) 
che_hot <- readNWISDaily("06400500", parameter_cd, startDate, endDate) 
fre_fai <- readNWISDaily("06403500", parameter_cd, "1946-01-14", endDate) 
hor_aoe <- readNWISDaily("06400870", parameter_cd, startDate, endDate) 
lcr_abv <- readNWISDaily("06448000", parameter_cd, startDate, endDate) 
lwr_abv <- readNWISDaily("06449300", parameter_cd, startDate, endDate) 
min_kil <- readNWISDaily("06460900", parameter_cd, startDate, endDate) 
nio_abb <- readNWISDaily("06454500", parameter_cd, startDate, endDate) 
nio_bbb <- readNWISDaily("06455500", parameter_cd, startDate, endDate) 
nio_col <- readNWISDaily("06457000", parameter_cd, startDate, endDate) 
nio_cod <- readNWISDaily("06459000", parameter_cd, startDate, endDate) 
nio_dun <- readNWISDaily("06455900", parameter_cd, startDate, endDate) 
nio_hay <- readNWISDaily("06456500", parameter_cd, startDate, endDate) 
rap_cre <- readNWISDaily("06422000", parameter_cd, startDate, endDate) 
ros_ros <- readNWISDaily("06449400", parameter_cd, startDate, endDate) 
sna_bur <- readNWISDaily("06459500", parameter_cd, startDate, endDate) 
sna_dou <- readNWISDaily("06459175", parameter_cd, startDate, endDate) 
sna_mer <- readNWISDaily("06459200", parameter_cd, startDate, endDate) 
spr_stf <- readNWISDaily("06449250", parameter_cd, startDate, endDate) 
whi_cha <- readNWISDaily("06445500", parameter_cd, startDate, endDate) 
whi_cra <- readNWISDaily("06444000", parameter_cd, startDate, endDate)
whi_sli <- readNWISDaily("06445700", parameter_cd, startDate, endDate)
whi_wht <- readNWISDaily("06445000", parameter_cd, startDate, endDate) 

# 2. add short name and abbreviation to gage data 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ant_gor <- ant_gor %>% 
  mutate(sta = "ant_gor") %>%
  mutate(site_no = "06458000") 

brnf_ph <- brnf_ph %>% 
  mutate(sta = "brnf_ph") %>%
  mutate(site_no = "06440500") 

bea_eli <- bea_eli %>% 
  mutate(sta = "bea_eli") %>%
  mutate(site_no = "06458500") 

bev_buf <- bev_buf %>% 
  mutate(sta = "bev_buf") %>%
  mutate(site_no = "06402470") 

bor_cha <- bor_cha %>% 
  mutate(sta = "bor_cha") %>%
  mutate(site_no = "06445590") 

cas_hot <- cas_hot %>% 
  mutate(sta = "cas_hot") %>%
  mutate(site_no = "06400497") 

che_hot <- che_hot %>% 
  mutate(sta = "che_hot") %>%
  mutate(site_no = "06400500") 

fre_fai <- fre_fai %>% 
  mutate(sta = "fre_fai") %>%
  mutate(site_no = "06403500") 

hor_aoe <- hor_aoe %>% 
  mutate(sta = "hor_aoe") %>%
  mutate(site_no = "06400870") 

lcr_abv <- lcr_abv %>% 
  mutate(sta = "lcr_abv") %>%
  mutate(site_no = "06448000") 

lwr_abv <- lwr_abv %>% 
  mutate(sta = "lwr_abv") %>%
  mutate(site_no = "06449300") 

min_kil <- min_kil %>% 
  mutate(sta = "min_kil") %>%
  mutate(site_no = "06460900") 

nio_abb <- nio_abb %>% 
  mutate(sta = "nio_abb") %>%
  mutate(site_no = "06454500") 

nio_bbb <- nio_bbb %>% 
  mutate(sta = "nio_bbb") %>%
  mutate(site_no = "06455500") 

nio_col <- nio_col %>% 
  mutate(sta = "nio_col") %>%
  mutate(site_no = "06457000") 

nio_cod <- nio_cod %>% 
  mutate(sta = "nio_cod") %>%
  mutate(site_no = "06459000") 

nio_dun <- nio_dun %>% 
  mutate(sta = "nio_dun") %>%
  mutate(site_no = "06455900")

nio_hay <- nio_hay %>% 
  mutate(sta = "nio_hay") %>%
  mutate(site_no = "06456500") 

rap_cre <- rap_cre %>% 
  mutate(sta = "rap_cre") %>%
  mutate(site_no = "06422000")

ros_ros <- ros_ros %>% 
  mutate(sta = "ros_ros") %>%
  mutate(site_no = "06449400") 

sna_bur <- sna_bur %>% 
  mutate(sta = "sna_bur") %>%
  mutate(site_no = "06459500")

sna_dou <- sna_dou %>% 
  mutate(sta = "sna_dou") %>%
  mutate(site_no = "06459175") 

sna_mer <- sna_mer %>% 
  mutate(sta = "sna_mer") %>%
  mutate(site_no = "06459200")

spr_stf <- spr_stf %>% 
  mutate(sta = "spr_stf") %>%
  mutate(site_no = "06449250") 

whi_cha <- whi_cha %>% 
  mutate(sta = "whi_cha") %>%
  mutate(site_no = "06445500") 

whi_cra <- whi_cra %>% 
  mutate(sta = "whi_cra") %>%
  mutate(site_no = "06444000") 

whi_sli <- whi_sli %>% 
  mutate(sta = "whi_sli") %>%
  mutate(site_no = "06445700") 

whi_wht <- whi_wht %>% 
  mutate(sta = "whi_wht") %>%
  mutate(site_no = "06445000") 


# 3. join together in long format
# This could probably be done more efficiently with map_df()
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int1  <- bind_rows(ant_gor, bea_eli) 
gage_int2  <- bind_rows(gage_int1, bev_buf) 
gage_int3  <- bind_rows(gage_int2, bor_cha) 
gage_int4  <- bind_rows(gage_int3, brnf_ph) 
gage_int5  <- bind_rows(gage_int4, cas_hot) 
gage_int6  <- bind_rows(gage_int5, che_hot) 
gage_int7  <- bind_rows(gage_int6, fre_fai) 
gage_int8  <- bind_rows(gage_int7, hor_aoe) 
gage_int9  <- bind_rows(gage_int8, lcr_abv) 
gage_int10 <- bind_rows(gage_int9, lwr_abv) 
gage_int11 <- bind_rows(gage_int10, min_kil) 
gage_int12 <- bind_rows(gage_int11, nio_abb) 
gage_int13 <- bind_rows(gage_int12, nio_bbb) 
gage_int14 <- bind_rows(gage_int13, nio_cod) 
gage_int15 <- bind_rows(gage_int14, nio_col) 
gage_int16 <- bind_rows(gage_int15, nio_dun) 
gage_int17 <- bind_rows(gage_int16, nio_hay) 
gage_int18 <- bind_rows(gage_int17, rap_cre) 
gage_int19 <- bind_rows(gage_int18, ros_ros) 
gage_int20 <- bind_rows(gage_int19, sna_bur) 
gage_int21 <- bind_rows(gage_int20, sna_dou) 
gage_int22 <- bind_rows(gage_int21, sna_mer) 
gage_int23 <- bind_rows(gage_int22, spr_stf) 
gage_int24 <- bind_rows(gage_int23, whi_cha) 
gage_int25 <- bind_rows(gage_int24, whi_cra) 
gage_int26 <- bind_rows(gage_int25, whi_sli) 
gage_int27 <- bind_rows(gage_int26, whi_wht) 

# export daily flows to data folder
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_int27, "data/gage_cms_discontinued.csv") 
# export(gage_disc, "data/gage_nm_discontinued.csv")
```

```{r check_first_last_date}

# import daily streamflow datasets
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_cont <- import("data/gage_cms.csv")
gage_meta <- 
gage_disc <- import("data/gage_cms_discontinued.csv") 
gage_names_disc <- import("data/gage_nm_discontinued.csv")



# check on data
names <- gage_int27 %>%
  distinct(sta) 
id <- gage_int27 %>%
  distinct(site_no)
gage_disc <- bind_cols(names, id)

# check on data
names <- gage_int27 %>%
  distinct(sta)
# print(names)

id <- gage_int27 %>%
  distinct(site_no)
# print(names)

# 3) check on data jumps - should use a different start or end date 
# bad_mid discharge data jumps from 1979-09-29 to 1984-05-02
#          discharge data jumps from 1984-05-02 to 1984-06-05
#          discharge data jumps from 1984-06-07 to 1984-06-12
#          discharge data jumps from 1984-06-14 to 1984-06-16
#          discharge data jumps from 1984-06-18 to 1984-06-21
#          discharge data jumps from 1984-06-24 to 1991-05-18
#          discharge data jumps from 1991-05-20 to 1991-05-28
#          discharge data jumps from 1991-06-17 to 1991-06-30
#          discharge data jumps from 1991-07-03 to 1993-03-07
#          discharge data jumps from 1993-03-11 to 1993-04-23
#          discharge data jumps from 1993-04-25 to 1993-05-03
#          discharge data jumps from 1993-05-04 to 1993-05-07
#          discharge data jumps from 1993-05-14 to 1993-06-07
#          discharge data jumps from 1993-06-12 to 1993-06-16
#          discharge data jumps from 1993-06-23 to 1993-07-03
#          discharge data jumps from 1993-07-08 to 1993-07-16
#          discharge data jumps from 1993-07-16 to 1993-07-21
#          discharge data jumps from 1993-07-22 to 1993-07-28
#          discharge data jumps from 1993-07-30 to 1993-08-22
#          discharge data jumps from 1993-08-25 to 1994-02-17
#          discharge data jumps from 1994-03-15 to 1994-06-11
#          discharge data jumps from 1994-06-11 to 1994-07-13
#          discharge data jumps from 1994-07-13 to 1995-03-13
#          discharge data jumps from 1995-03-14 to 1995-04-15
#          discharge data jumps from 1995-04-28 to 1995-05-01
#          discharge data jumps from 1995-06-19 to 1995-06-22
#          discharge data jumps from 1995-06-29 to 1996-02-08
#          discharge data jumps from 1996-02-22 to 1996-03-11
#          discharge data jumps from 1996-03-19 to 1996-05-26
#          discharge data jumps from 1996-06-10 to 1996-07-07
#          discharge data jumps from 1996-07-09 to 1996-10-29
#          discharge data jumps from 1996-11-02 to 1997-01-04
#          discharge data jumps from 1997-01-27 to 1997-01-31
#          discharge data jumps from 1997-05-17 to 1997-05-26
#          discharge data jumps from 1997-06-25 to 1997-06-29
#          discharge data jumps from 1997-07-03 to 1997-07-22
#          discharge data jumps from 1997-08-12 to 1997-08-28
#          discharge data jumps from 1997-09-01 to 1998-03-20
#          discharge data jumps from 1998-04-12 to 1998-05-24
#          discharge data jumps from 1998-05-29 to 1998-06-10
#          discharge data jumps from 1998-06-29 to 1998-07-04
#          discharge data jumps from 1998-07-13 to 1998-08-23
#          discharge data jumps from 1998-08-24 to 1998-08-27
#          discharge data jumps from 1998-09-02 to 1998-10-06
#          discharge data jumps from 1998-10-10 to 1998-10-18
#          discharge data jumps from 1998-10-22 to 1998-11-01
#          discharge data jumps from 1998-11-01 to 1998-11-09
#          discharge data jumps from 1998-11-21 to 1999-03-18
#          discharge data jumps from 1999-03-19 to 1999-04-11
#          discharge data jumps from 1999-04-16 to 1999-04-22
#          discharge data jumps from 1999-05-05 to 1999-05-14
#          discharge data jumps from 1999-05-25 to 1999-06-05
#          discharge data jumps from 1999-06-20 to 1999-07-19
#          discharge data jumps from 1999-07-22 to 1999-09-03
#          discharge data jumps from 1999-09-07 to 2000-03-09
#          discharge data jumps from 2000-03-15 to 2000-04-20
#          discharge data jumps from 2000-05-09 to 2001-02-04
#          discharge data jumps from 2001-02-13 to 2001-03-08
#          discharge data jumps from 2001-03-24 to 2001-04-25
#          discharge data jumps from 2001-04-28 to 2003-02-21
#          discharge data jumps from 2003-02-21 to 2003-03-22
#          discharge data jumps from 2003-03-22 to 2004-06-11
#          discharge data jumps from 2004-06-14 to 2005-04-24
#          discharge data jumps from 2005-04-24 to 2005-05-12
#          discharge data jumps from 2005-05-18 to 2005-06-15
#          discharge data jumps from 2005-06-17 to 2006-04-01
#          discharge data jumps from 2006-04-02 to 2015-05-13
#          discharge data jumps from 2015-06-12 to 2015-06-14
#          discharge data jumps from 2015-07-07 to 2015-08-04
#          discharge data jumps from 2015-08-05 to 2015-08-09
#          discharge data jumps from 2015-08-11 to 2016-02-15
#          discharge data jumps from 2016-02-23 to 2016-04-17
#          discharge data jumps from 2016-05-06 to 2016-05-13
#          discharge data jumps from 2016-05-13 to 2016-05-25
#          discharge data jumps from 2016-05-25 to 2016-05-27
#          discharge data jumps from 2016-05-27 to 2016-07-23
#          discharge data jumps from 2016-07-23 to 2016-08-01
#          discharge data jumps from 2016-08-01 to 2017-02-21 
# bat_her  discharge data jumps from 1953-09-29 to 1988-10-01 
# che_buf  discharge data jumps from 1980-09-29 to 2007-03-23
# che_was  discharge data jumps from 1914-12-31 to 1915-02-01
#           discharge data jumps from 1915-06-30 to 1928-08-18
#           discharge data jumps from 1932-06-30 to 1934-03-06
#           discharge data jumps from 1934-03-06 to 1934-03-18
# lcr_tut discharge data jumps from 1940-09-29 to 1962-08-01 
# lwr_mar  discharge data jumps from 1940-09-29 to 1962-08-01 
# rap_far  discharge data jumps from 1989-09-29 to 1990-10-01 
# wcc_ogl  discharge data jumps from 1981-09-29 to 1987-10-01 
# whi_int  discharge data jumps from 1928-11-30 to 1929-03-01
#           discharge data jumps from 1930-11-30 to 1931-01-20
#           discharge data jumps from 1931-01-20 to 1931-02-01
#           discharge data jumps from 1931-10-16 to 1931-10-18
#           discharge data jumps from 1931-11-30 to 1932-02-01
#           discharge data jumps from 1932-06-30 to 1939-10-02
#           discharge data jumps from 1942-09-29 to 2002-10-01 
# whi_slm   discharge data jumps from 1970-09-29 to 1990-12-04 
# che_hot  discharge data jumps from 1919-12-06 to 1920-01-22
#           discharge data jumps from 1920-09-30 to 1943-03-01
# lcr_abv  discharge data jumps from 1940-09-29 to 1962-08-01
#           discharge data jumps from 1979-02-28 to 1996-04-12
#           discharge data jumps from 2015-11-12 to 2016-07-23
#           discharge data jumps from 2016-08-07 to 2016-08-0961 
#            discharge values are not reported (NA's). 
# lwr_abv   discharge data jumps from 1999-09-30 to 2000-01-01
#            discharge data jumps from 2000-09-30 to 2002-11-19 
# nio_col   discharge data jumps from 1946-11-30 to 1947-10-01 
# nio_dun   discharge data jumps from 1931-10-31 to 1932-03-01
#            discharge data jumps from 1932-12-31 to 1933-03-01
#            discharge data jumps from 1933-11-30 to 1934-02-01
#            discharge data jumps from 1942-09-29 to 1961-09-01
# rap_cre   discharge data jumps from 1929-11-30 to 1930-01-18
#            discharge data jumps from 1930-01-18 to 1930-03-01
#            discharge data jumps from 1930-12-31 to 1931-01-08
#            discharge data jumps from 1931-01-08 to 1931-02-01
#            discharge data jumps from 1931-11-30 to 1932-02-21
#            discharge data jumps from 1932-02-21 to 1932-03-01
#            discharge data jumps from 1932-06-30 to 1989-10-02
# ros_ros   discharge data jumps from 1997-09-30 to 2003-03-16 
# whi_cha   discharge data jumps from 1931-01-16 to 1931-02-26
#            discharge data jumps from 1931-02-26 to 1931-04-14
#            discharge data jumps from 1931-08-16 to 1931-09-12
#            discharge data jumps from 1931-09-16 to 1931-10-01
#            discharge data jumps from 1931-10-31 to 1931-11-07
#            discharge data jumps from 1931-11-07 to 1931-12-14
#            discharge data jumps from 1931-12-14 to 1932-02-03
#            discharge data jumps from 1932-02-03 to 1932-03-01
#            discharge data jumps from 1932-03-01 to 1932-03-03
#            discharge data jumps from 1932-03-03 to 1932-03-08
#            discharge data jumps from 1932-03-08 to 1932-03-13
#            discharge data jumps from 1932-03-13 to 1932-03-18
#            discharge data jumps from 1932-03-18 to 1932-03-23
#            discharge data jumps from 1932-03-23 to 1932-03-26
#            discharge data jumps from 1932-12-05 to 1932-12-08
#            discharge data jumps from 1932-12-08 to 1932-12-13
#            discharge data jumps from 1932-12-13 to 1932-12-18
#            discharge data jumps from 1932-12-18 to 1932-12-23
#            discharge data jumps from 1932-12-23 to 1932-12-28
#            discharge data jumps from 1932-12-28 to 1933-02-03
#            discharge data jumps from 1933-02-03 to 1933-03-03
#            discharge data jumps from 1933-03-03 to 1933-03-08
#            discharge data jumps from 1933-03-08 to 1933-03-11
#            discharge data jumps from 1933-11-30 to 1934-02-03
#            discharge data jumps from 1934-02-03 to 1934-02-08
#            discharge data jumps from 1934-02-08 to 1934-02-11
#            discharge data jumps from 1934-02-15 to 1934-02-18
#            discharge data jumps from 1934-02-18 to 1934-02-23
#            discharge data jumps from 1934-02-23 to 1934-02-27
#            discharge data jumps from 1934-02-27 to 1934-03-01
#            discharge data jumps from 1934-12-16 to 1934-12-20
#            discharge data jumps from 1934-12-20 to 1934-12-28
#            discharge data jumps from 1934-12-28 to 1935-01-15
#            discharge data jumps from 1935-01-15 to 1935-02-06
#            discharge data jumps from 1935-02-06 to 1935-02-12
#            discharge data jumps from 1935-02-12 to 1935-02-17
#            discharge data jumps from 1935-02-17 to 1935-02-23
#            discharge data jumps from 1935-09-30 to 1936-10-01
# whi_cra   discharge data jumps from 1943-09-30 to 1947-10-01
#            discharge data jumps from 1991-09-30 to 2003-10-01
# whi_sli   discharge data jumps from 1970-09-29 to 1990-12-04
# whi_wht   discharge data jumps from 1948-11-22 to 1948-11-26
#            discharge data jumps from 1948-11-26 to 1948-12-01
#            discharge data jumps from 1948-12-22 to 1948-12-27
#            discharge data jumps from 1948-12-27 to 1949-01-12
#            discharge data jumps from 1949-01-12 to 1949-01-28
#            discharge data jumps from 1949-01-28 to 1949-02-03
#            discharge data jumps from 1949-02-03 to 1949-02-06
#            discharge data jumps from 1949-02-06 to 1949-02-15
#            discharge data jumps from 1949-02-15 to 1949-02-24
#            discharge data jumps from 1950-09-30 to 1951-10-01

# # blc_wan <- readNWISDaily("06446700") # this not working!
```

```{r import_metadata, eval=FALSE}
# 'gage' is a USGS stream gage
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# get gage ids by USGS watermapper
# This is a mixed list of current and discontinued sites
gage_id <- data.frame(name = c("WHITE R NR NE-SD STATE LINE", 
                              "WHITE R NEAR OGLALA SD", 
                              "WHITE CLAY CR NEAR OGLALA SD", 
                              "WHITE R NEAR INTERIOR SD", 
                              "WOUNDED KNEE CREEK AT WOUNDED KNEE SD",
                              "BEAR IN THE LODGE CR NEAR WANBLEE SD", 
                              "WHITE R NEAR KADOKA SD", 
                              "BLACK PIPE CREEK NR BELVIDERE SD", 
                              "LITTLE WHITE R NEAR MARTIN SD", 
                              "LAKE CR BELOW REFUGE NEAR TUTHILL SD", 
                              "LITTLE WHITE R NEAR VETAL SD", 
                              "SOUTH FORK BAD R NEAR COTTONWOOD SD", 
                              "BAD R NEAR MIDLAND SD", 
                              "BATTLE CR BELOW HERMOSA,SD", 
                              "BEAVER CR NEAR BUFFALO GAP,SD", 
                              "BEAVER CREEK NEAR PRINGLE, SD",
                              "CHEYENNE R NEAR BUFFALO GAP SD", 
                              "CHEYENNE RIVER AT RED SHIRT, SD", 
                              "CHEYENNE RIVER NEAR SCENIC, SD", 
                              "CHEYENNE RIVER NEAR WASTA, SD", 
                              "HAT CR NEAR EDGEMONT,SD",
                              "HORSEHEAD CR AT OELRICHS,SD", 
                              "LITTLE WHITE R NEAR ROSEBUD SD", 
                              "LITTLE WHITE R BELOW WHITE RIVER,SD", 
                              "RAPID CR NEAR FARMINGDALE,SD", 
                              "WHITE RIVER NEAR WHITE RIVER, SD"), 
                     id = c("06445685", "06446000", "06445980", 
                            "06446500", "06446100", "06446700", 
                            "06447000", "06447230", "06447500", 
                            "06449000", "06449100", "06440200",
                            "06441000", "06406500", "06402500", 
                            "06402430", "06402600", "06403700", 
                            "06408650", "06423500", "06400000", 
                            "06400875", "06449500", "06450500", 
                            "06421500", "06447450"),
                     stringsAsFactors = FALSE)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Iterate across a list of gage ids by purrr::map_dfr 
# Get gage metadata using dataRetrieval::readNWISsite

gage_meta_list <- map(gage_id$id, readNWISsite) 
gage_meta <- gage_meta_list %>%
  map_df(extract, 
               c("site_no", "station_nm", "site_tp_cd", "dec_lat_va", 
                 "dec_long_va", "dec_coord_datum_cd", "state_cd", 
                 "county_cd", "alt_va", "alt_datum_cd", "huc_cd", 
                 "drain_area_va", "contrib_drain_area_va"))
export(gage_meta, "data/gage_meta.csv") 
```

```{r next_steps_munging}
# Also add BEAR in the LODGE


# check ice - starts 2017-10-23 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ice <- gage_int %>%
  filter(code == "P Ice") %>% 
  arrange(date) 

# check provisional values 
# ~~~~~~~~~~~~~~~~~~~~~~~~
provis <- gage_int %>%
  filter(code == "P" | code == "P e" | code == "P <") %>%
  arrange(date) # starts 2016-10-05

# remove data after 2017-10-01
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_int <- gage_int %>%
  filter(year != 2018)

gage_2017 <- gage_int %>%
  filter(year == 2017)

gage_prior <- gage_int %>%
  filter(year < 2017) 

gage_2017 <- gage_2017 %>%
  filter(month != 10) %>% 
  filter(month != 11) %>%
filter(month != 12)

gage_imp <- bind_rows(gage_prior, gage_2017) %>%
  arrange(desc(date)) 
rm(gage_2017, gage_int, gage_list, gage_prior, ice, provis, gage_raw) 

# simplify the naming convention for gages 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_imp <- gage_imp %>% 
  select(site_no, date, discharge, code)

station_nm <- gage_meta %>% 
  select(site_no, station_nm) %>% 
  as.tibble()

abrev <- c("whi_sta", "whi_ogl", "wcc_ogl", "whi_int", "wkc_wok", 
           "blc_wan", "whi_kad", "blp_bel", "lwr_mar", "lcr_tut", 
           "lcr_vet", "brsf_co", "bad_mid") %>%
  as.tibble() %>%
  rename(sta = value)

abrev <- bind_cols(abrev, station_nm) 

gage_imp <- full_join(abrev, gage_imp, by = "site_no")
gage_meta <- full_join(abrev, gage_meta, by = "site_no")
rm(station_nm, abrev)

# Split and spread data
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gage_dis_imp <- gage_imp %>% 
  select(sta, date, discharge)

gage_dis_imp <- gage_dis_imp %>% 
  spread(key = sta, value = discharge) 

# Add short name to metadata
# ~~~~~~~~~~~~~~~~~~~~~~~~~~
abrev <- gage_imp %>%
  distinct(sta, site_no)

gage_meta <- full_join(abrev, gage_meta, by = "site_no") 

# export and import station df by rio
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# export(gage_raw, "data/gage_raw.csv") 
# write_lines(gage_json, "data/gage_list.json")
# export(gage_imp, "data/gage_imperial.csv") 

# export(gage_dis_imp, "data/gage_discharge_imp.csv") 


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# get site numbers from prior metadata
gage_meta <- import("data/gage_meta.csv")
#site_nums <- gage_meta %>%
#  select(sta, site_no) %>% 
#  print()


#Sample <- readNWISSample(siteNumber,parameter_cd,startDate,endDate)
# this code chunk uses dataRetreval to get discharge in cfs 
# removes provisional values and ice and saves the data as a csv.
```

```{r daily2monthly-precip}
# continued from above 
# General Purpose: prepare data for drought index 
# Specific purpose: convert daily precip to monthly precip  

# load metadata & data 
sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_day   <- as.tibble(import("data/stations_final2.csv")) 

# remove Murdo, Mission, Long Valley - see above 
#sta_day   <- sta_day %>% 
#  select(-c(lon, mur, mis)) 
#export(sta_day, file = "data/stations_final2.csv")  

# fix date & add year and month 
sta_day <- sta_day %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date)) %>% 
  mutate(year = year(date)) %>% 
  mutate(month = month(date)) %>% 
  select(date, year, month, everything()) 

# gather daily values 
sta_gath <- gather(sta_day, key = "station", value = "prcp", -date, 
                   -year, -month, factor_key = TRUE)

# create groups 
sta_group <- sta_gath %>% 
  group_by(year, month, station) 

# sum daily precip over a month 
sta_gath_mon <- sta_group %>% 
  summarize(prcp_tenths = sum(prcp)) %>% 
  mutate(prcp_mm = prcp_tenths/10) %>% 
  select(-prcp_tenths) 

# spread result - now in months  
#   ...and take a bow, because this is MAGIC!  Thnx Tidyverse. 
sta_mon <- sta_gath_mon %>% 
  spread(station, prcp_mm) %>% 
  mutate(day = 1) %>% 
  mutate(date = make_date(year = year, month = month, day = day)) %>% 
  select(date, year, month, everything()) %>% 
  select(-day) %>% 
  ungroup()

rm(sta_day, sta_gath, sta_gath_mon, sta_group) 
# export(sta_mon, file = "data/stations_monthly.csv") 
```


```{r ggplot_monthly}
# General Purpose: prepare data for drought index 
# Specific purpose: graphical EDA 
 
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_mon     <- as.tibble(import("data/stations_monthly.csv"))

# fix date & add year and month 
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date))  

# gather monthly values & order them
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE) 

# x$name <- factor(x$name, levels = x$name[order(x$val)])

# plot
ggplot(sta_gath_mon, aes(date, prcp)) +
  geom_line() +
  facet_grid(station ~ .) +
  theme_classic() + 
  labs(title = "Monthly precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1909-2018") +
       xlab("") +
       ylab("mm")

#ggplot2::ggsave(filename = "precip_mon.png", 
#                width = 6, height = 6, units = "in")
```

```{r monthly2yearly-precip}
# General Purpose: prepare data for drought index   
# Specific purpose: convert monthly precip to yearly prcp  
 
# load metadata & data 
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) 

# fix date & add year and month 
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date)) %>% 
  select(date, year, month, everything())  

# gather monthly values  
sta_gath <- gather(sta_mon, key = "station", value = "prcp", -date, 
                   -year, -month, factor_key = TRUE) 

# create groups 
sta_group <- sta_gath %>% 
  group_by(year,  station) 

# sum monthly precip over a year 
sta_gath_yr <- sta_group %>% 
  summarize(prcp = sum(prcp))  

# spread result - now in years 
sta_yr <- sta_gath_yr %>% 
  spread(station, prcp) %>% 
  filter(year != 1909) %>% 
  filter(year != 2018) %>% 
  ungroup()

rm(sta_mon, sta_gath, sta_gath_yr, sta_group)
# export(sta_yr, file = "data/stations_yearly.csv") 
```

```{r ggplot_yearly}
# General Purpose: prepare data for drought index 
# Specific purpose: graphical EDA - yearly 

# NEED TO FIX - screwed up variables 

sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_yr     <- as.tibble(import("data/stations_yearly.csv"))

# gather monthly values 
sta_gath <- gather(sta_yr, key = "station", value = "prcp",  
                   -year, factor_key = TRUE) 

# plot
ggplot(sta_gath, aes(year, prcp)) +
  geom_line() +
  facet_grid(station ~ .) +
  theme_classic() + 
  labs(title = "Annual precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1910-2017") +
       xlab("Date") +
       ylab("Depth, mm")

# ggplot2::ggsave(filename = "precip_yr.png", 
#                width = 6, height = 6, units = "in")
```


# Annual Summaries
```{r yearly_summaries}
# General Purpose: prepare data for drought index  
# Specific purpose: create summaries of data 
sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_yr   <- as.tibble(import("data/stations_yearly.csv")) 

# gather and summarize yearly values 
# Next step - do by water year???
sta_gath_yr <- gather(sta_yr, key = "station", value = "prcp", 
                   -year, factor_key = TRUE)

sta_summary_yr <- as.tibble(sta_gath_yr) %>%
  group_by(station) %>%
  summarise(mean = mean(prcp, na.rm = TRUE), 
            med = median(prcp, na.rm = TRUE),
            IQR = IQR(prcp, na.rm = TRUE), 
            min = min(prcp, na.rm = TRUE), 
            max = max(prcp, na.rm = TRUE)) %>%
  arrange(desc(med))

sta_summary_yr
# export(sta_summary_yr, file = "data/sta_summary_yr.csv") 
```

# Monthly Summaries
```{r  monthly_summaries}

# General Purpose: prepare data for drought index  
# Specific purpose: create summaries of data 
sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv")) 
sta_mon   <- as.tibble(import("data/stations_monthly.csv")) 

# fix dates
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date)) %>% 
  select(date, year, month, everything()) 

# gather and summarize monthly values 
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE)

sta_summary_mon <- as.tibble(sta_gath_mon) %>%
  group_by(station, month) %>%
  summarise(mean = mean(prcp, na.rm = TRUE), 
            med = median(prcp, na.rm = TRUE),
            IQR = IQR(prcp, na.rm = TRUE), 
            min = min(prcp, na.rm = TRUE), 
            max = max(prcp, na.rm = TRUE)) %>%
  arrange(month) %>%
  arrange(station)

sta_summary_mon 
# export(sta_summary_mon, file = "data/sta_summary_mon.csv") 
```

```{r ggplot_monthly_boxplots}
# General Purpose: prepare data for drought index  
# Specific purpose: graphical EDA  
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) 

# fix date & add year and month  
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date))  

# gather monthly values 
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE) 

ggplot(sta_gath_mon, aes(month, prcp, group = month)) +
  geom_boxplot() +
  facet_wrap(~station) +
  theme_classic() + 
  labs(title = "Monthly precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1910-2017") +
       xlab("Date") +
       ylab("Depth, mm")

#ggplot2::ggsave(filename = "precip_yr.png", 
#                width = 6, height = 6, units = "in")
```

```{r ggplot_monthly_boxplots}
# General Purpose: prepare data for drought index  
# Specific purpose: graphical EDA  
sta_meta    <- as.tibble(import("data/sta_meta_fin3.csv"))  
sta_mon     <- as.tibble(import("data/stations_monthly.csv")) 

# fix date & add year and month  
sta_mon <- sta_mon %>% 
  mutate(date = ymd(date)) %>% 
  arrange(desc(date))  

# gather monthly values 
sta_gath_mon <- gather(sta_mon, key = "station", value = "prcp", 
                       -date, -year, -month, factor_key = TRUE) 

ggplot(sta_gath_mon, aes(date, prcp)) +
  geom_line() +
  facet_grid(station~.) +
  theme_classic() + 
  labs(title = "Monthly precipitation depths",
       subtitle = "Pine Ridge Reservation, SD for 1910-2017") +
       xlab("Date") +
       ylab("Depth, mm")

#ggplot2::ggsave(filename = "precip_yr.png", 
#                width = 6, height = 6, units = "in")
```

# Correlation Plots with Pearson Coefficients
```{r correlation}
# General Purpose: prepare data for drought index
# Specific purpose: graphical EDA - correlation plot

sta_meta  <- as.tibble(import("data/sta_meta_fin3.csv"))
sta_yr   <- as.tibble(import("data/stations_yearly.csv"))

# fix date & add year and month
sta_yr <- sta_yr %>%
  arrange(year) 

# need to have a correlation matrix without any NA vals
# gather yearly values 
sta_gath <- gather(sta_yr, key = "station", value = "prcp", 
                   -year, factor_key = TRUE)

# filter NAs
sta_gath_72 <- sta_gath %>%
  filter(year > 1972) 

# spread remaining matrix & arrange from west to east
sta_72 <- sta_gath_72 %>%
  spread(station, prcp) %>%
  select(oel, ora, rap, int, cot)

# create a correlation matrix and plot it
sta_M <- cor(sta_72)
corrplot.mixed(sta_M,  order = "hclust", addrect = 2, upper = "ellipse", lower = "number", title = "Precipitation station correlation")
```
