---
output: html_document
editor_options: 
  chunk_output_type: console
---

<!--  
These are some useful thoughts:    

lmomco <- citation("lmomco") 
a useful description of commits -- http://r-pkgs.had.co.nz/git.html  

# Some shortcuts in a code chunk styling format----  
# key-bindings====     
# insert operators####    
# pipe operator        %>% 	      Cmd+Shift+M
# assignment operator  <-    	    Option+-  

# Code chunks====  
# collapse                        Cmd+Option+L
# expand                          Cmd+Shift+Option+L
# collapse all                    Cmd+Option+O
# expand all                      Cmd+Shift+Option+O

# Navigation====
# insert section                 Cmd+Shift+R 
# jump to                        Shift+Alt+J

Exploratory Data Analysis Checklist by Roger Peng 
https://leanpub.com/exdata  

1.0   Formulate your question  
2.0   Read in your data  
3.0   Check the dataset 
3.1   Check the number of rows and columns.
3.2   Check the types of data
3.3   Look at the top and the bottom of your data 
3.4   Check your “n”s & NAs 
3.5   Validate with at least one external data source  
4.0   Try the easy solution first to answer question
5.0   Challenge your solution 
6.0  Follow up questions 


-->  

<!-- 
Purpose:  
This R markdown file calculates SCI 
Standardized precipitation index - SPI  
Streamflow runoff index - SRI  

Analysis steps 
1.0)  sets up the library and settings 

2.0)  downloads precipitation daily data and metadata (sta_orig); 
2.1)    creates groups by location;   
2.2)    creates short names;  
2.3)    downloads daily data for original stations (30-years);  
2.4)    removes incomplete years (sta_plus)  
2.5)    defines the final stations  (sta_fin)

3.0)  plot study area map;  
3.1)    prepare map elements: Theissen line segments, stream gages, location  
        data: states, counties, USA map-grob

4.0)  check data flags  




-- identified & filled NA
2.0)  convert daily precip to monthly precip  
2.1)  Updated unit vals - originally in tenths of mm; now in mm 
3.0)  Created plots 


Data:
Predominant datasets used are:  
1) NOAA data from NOAA GHCN database - 60-years (1959-2019)
2) USGS daily streamflow and station metadata,  
3) 

3)  prepare data for drought index 


1. Recreated analysis from the lmomco text ch 12 (author?) in Tidyverse
2. Imported cleaned precipitation data (see 04_prcp-data_munging)   

5. Applied Weibull plotting position and graphed the data on sqrt plot
6. Calculated L-moments and L-moment ratios 
7. Calculated SPI for 'cot', 'oel', 'rap', 'int', and 'ora' datasets using Pearson III. 


3. Applied sqrt & log10 transform to explore effects on skew 
4. Explored the data with box plots, violin plot.


####3) Summary data from a QGIS analysis of ungaged watersheds of interest.  

## Results: Fits a PE3 distribution
The results from the precipitation analysis indicate: 1) an annual trend of increasing aridity across the project area that trends from northwest to southeast that may be a result of the Black Hills rainshadow, 2) the 1900s were the wettest time in regions recorded history.  ??? what about the seasonal trend?  

Variable naming convention----  
a_session    list variable of session information  

precipitation and spi variables====  
dateMin       minimum date for downloading data   
dateMax       maximum date for downloading data  
sta           NOAA weather station locations  
  _dv         daily values  
  _meta       metadata  
  _orig       all stations (n = 46 sations)  
  _plus       potential stations (n = 14 stations)  
  _fin        final dvs used in the analysis   
  _mon        monthly precipitation depths (60-years)  
  _pres       monthly precipitation depths (30-years)  

daily value check & fill variables==== 
sta  
  _check       used to summarize station flags
  _alt         alternate station dv data for filling missing values 
  _fil         station to be filled 
  _miss_day    checks for missing days 
  _short_name  adds a short name for the station to be filled
  _rap         Rapid City Regional Airport station (NW)  
  _cot         Cottonwood station (NC)  
  _oni         Onida station (NE)   
  _ora         Oral station (SW)   
  _gor         Gordon staion (SC)   
  _mis         Mission station (SE)  

L-moment variables====  
lmom          L-moments  
  _sta        L-moments for stations
  _nm        station name
lmrdia       list of L-moment distributions 
gev          Generalized Extreme Value Distribution
glo          Generalized Logistic Distribution
gpa          Generalized Pareto Distribution
gno          Generalized Logistic Distribution 
gov          Govindarajulu Distribution
pe3          Pearson Type III Distribution  
L1           first L-moment, similiar to mean
L_CV         first L-moment ratio, similiar to coefficient of var
L_skew       second L-moment ratio, similiar to skewness 
L_kurtosis   third L-moment ratio, similiar to kurtosis
n            number of months in a given record
  



sta_input)   
sta_meta_input,

spi           Standardized Precipitation Index vals from NOAA precip data  

01          one-month SPI etc.
_freq       frequency of periodicity -- used in seasonality calculations  
_trend      trend of periodicity -- used in seasonality calculations  


gage          USGS streamgage station  

'site' is a variable for OST monitoring stations 

## Broad questions:
What is the drought history of the Pine Ridge Reservation?  
Does the drought extent differ across the study area?

## Narrower question:
What is the underlying distribution of precipitation data?  

# Next STEPS  
3. Describe the precipitation seasonality
-->  

```{r setup_&_library, message=FALSE}  
  
knitr::opts_chunk$set(echo = FALSE)     
options(tibble.print_max = 70) # sets tibble output for printing        
  
# increase memory allocation for dabest()  
# usethis::edit_r_environ("project")  
  
# Get API key (aka, token) for downloading precip data at   http://www.ncdc.noaa.gov/cdo-web/token  
# token for NOAA API tied to jtinant@olc.edu -- see 'rnoaa' for details  
options(noaakey = "VpcuARumMpCfFyclKHPfvskEYnaiLJHD")  
  
# Sets up the library of packages   
library("conflicted")        # An alternative conflict resolution strategy  
library("here")              # identifies where to save work  
library("rnoaa")             # R wrapper for NOAA data inc. NCDC  
library("rio")               # more robust I/O - to import and clean data  
library("lubridate")         # easier dates   
library("lmomco")            # lmoments to find distribution   
library('deldir')            # for Vorononi tesselation - Theissen polygons  
library("SCI")               # calculates SPI & RDI   
library("forecast")          # using the BoxCox function   
library("broom")             # tidies linear models   
library("ggbeeswarm")        # plot 1D data as a violin / beeswarm plot  
library("scales")            # graphical scales map data to aesthetics,  
                             #   & methods for determining breaks and labels  
                             #   for axes and legends  
library("anomalize")         # detect anomalies using the tidyverse   
library("dabestr")           # data analysis using bootstrap estimation   
library("cowplot")  
#library("flextable")        # construct complex table with 'kable'  
#library("officer")          # facilitates '.docx' access for table export   
library("tidyverse")  

# resolve conflicted packages----  
conflict_prefer("filter", "dplyr")  
conflict_prefer("select", "dplyr")  

# other packages I have thought about ---------------------------------------  
# library("ggfortify")        # data vis tools for statistical analysis 
# library("ggpubr")           # some easy ggplot wrappers for publication ready                                #   'ggplot2'- based plots  
  
# library("standardize")      # tools for controlling continuous variable   
#  scaling and factor contrasts for linear models   
# library("pdftools")         # utilities for extracting text, fonts,  
#   attachments and metadata from a pdf file.  
  
# Packages to consider----  
# Spatial data====  
#library("biogeo")            # Functions for error detection & correction  
#   in point-data datasets; includes functions   
#   to parse & convert coords to decimal-degrees  
#library("maps")              # Outlines of continents, countries, states &  
#   counties  
#library("mapdata")           # higher-resolution outlines  
#library('ggmap')             # Spatial visualization with ggplot2  
#library("sf")                # Simple features--spatial geometries for R  
#library("RColorBrewer")      # Provides color schemes for maps -- see  
#   http://colorbrewer2.org  
  
# Colors====  
#library("colorspace")        # Manipulate & assess colors & palettes  
#library("munsell")           # Access & manipulate munsell system colours  
#   https://github.com/cwickham/munsell  
  
# working with lists and urls====  
#library("jsonlite")          # Convert between JSON data and R objects  
#library("curl")              # Drop-in replacement for base url  
#library("listviewer")        # htmlwidget for interactive views of R lists  

  
#library("forecast")         # for BoxCox.lambda   
#library("magrittr") # provides aliases for easier reading  
#library("workflowr") # creates a research website  
#library("bookdown") #  
#library(unpivotr) # fix nasty Excel files  
#library("friendlyeval")  
#library("mathpix")                # support for 'Mathpix' image to 'LaTeX'   
#library("grateful") - not yet ready for R 3.5.0  
#lmomco <- citation("lmomco")  
#toBibtex(lmomco)  
  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
why_to_write <- function()   
{today <- today(tzone = "") 
paper2 <- ymd("2019-11-15")  
until <- paper2 - today  
print(paste("You have", until, "days until the second paper is due"  
))  
}  
why_to_write()

```  

```{r download_prcp_data, eval=FALSE} 
 
# Get possible station metadata----   
# It's also possible to check station id with the mapping tool at:    
# https://www.ncdc.noaa.gov/cdo-web/datatools/findstation   
  
# The geographical extent given as SElat, SElon, NWlat, NWlon  
sta_meta_orig <- ncdc_stations(extent = c(42.0, -104.5, 45, -99.5),  
                               limit = 1000) %>%      # n = 777  
  # get possible stations into a dataframe  
  pluck("data") %>%  
  # turn min & max date into lubridates  
  mutate(mindate = ymd(mindate)) %>%  
  mutate(maxdate = ymd(maxdate)) %>%                  
  # remove 'young' stations  
  filter(mindate < "1988-01-01") %>%                    # n = 434  
  # remove 'dead' stations  
  filter(maxdate > "2018-01-01") %>%                    # n =  66    
  # keep only the GHCND stations  
  filter(str_detect(id, "^GHCND"))  %>%                 # n =  60      
  filter(!str_detect(name, "^MAGPIE")) %>%              # n =  59  
  filter(elevation < 1200)                              # n =  46    
  
# create groups of stations by region====      
#   Notes: the string "GHCND:" doesn't appear in calls to get Global Historical  
#   Climatology Network (GHCN) Daily Data  
sta_meta_orig <- sta_meta_orig %>%   
  mutate(north_group = case_when(   
    latitude > 43.5 ~ "N",   
    TRUE ~ "S")   
  ) %>%   
  mutate(east_group = case_when(  
    longitude > -100.67 ~ "E",  
    longitude > -102.33 ~ "C",    
    TRUE ~ "W")  
  )  %>%  
  mutate(group = str_c(north_group, east_group, sep = "")) %>%  
  dplyr::select(-c(north_group, east_group)) %>%  
  separate(  
    col = id,  
    sep = ":",   
    into = c("type", "sta_id")   
  ) %>%  
  arrange(name)  
  
# add short names to metadata====   
sta_meta_orig <- sta_meta_orig %>%  
  mutate(sta = case_when(  
    str_detect(name, "^AINSWORTH")        ~ "AIN",  
    str_detect(name, "^BELLE FOURCHE 22") ~ "BE2",      
    str_detect(name, "^BELLE FOURCHE,")   ~ "BEL",       
    str_detect(name, "^CHADRON")          ~ "CHA",      
    str_detect(name, "^COTTONWOOD")       ~ "COT",  
    str_detect(name, "^DUPREE")           ~ "DUP",  
    str_detect(name, "^EDGEMONT")         ~ "EDG",   
    str_detect(name, "^ELLSWORTH")        ~ "ELL",  
    str_detect(name, "^ELM SPRINGS")      ~ "ELM",  
    str_detect(name, "^ELSMERE")          ~ "ELS",  
    str_detect(name, "^FORT MEADE")       ~ "FME",      
    str_detect(name, "^FORT PIERRE")      ~ "FPI",  
    str_detect(name, "^FORT ROBINSON")    ~ "FRO",      
    str_detect(name, "^GORDON")           ~ "GOR",    
    str_detect(name, "^HARROLD")          ~ "HAR",      
    str_detect(name, "^HAY SPRINGS")      ~ "HAY",   
    str_detect(name, "^HOT SPRINGS")      ~ "HOT",  
    str_detect(name, "^INTERIOR")         ~ "INT",  
    str_detect(name, "^KENNEBEC")         ~ "KEN", 
    str_detect(name, "^KIRLEY")           ~ "KIR",     
    str_detect(name, "^KYLE")             ~ "KYL", 
    str_detect(name, "^MAURINE")          ~ "MAU",     
    str_detect(name, "^MILESVILLE")       ~ "MIL",    
    str_detect(name, "^MISSION")          ~ "MIS",  
    str_detect(name, "^MULLEN")           ~ "MUL",  
    str_detect(name, "^MURDO")            ~ "MUR",      
    str_detect(name, "^NEWELL")           ~ "NEW",    
    str_detect(name, "^OAHE DAM")         ~ "OAH",      
    str_detect(name, "^NEWELL")           ~ "NEW",    
    str_detect(name, "^OELRICHS")         ~ "OEL",  
    str_detect(name, "^ONIDA")            ~ "ONI",  
    str_detect(name, "^ORAL")             ~ "ORA",  
    str_detect(name, "^PHILIP")           ~ "PHI",  
    str_detect(name, "^PLAINVIEW")        ~ "PLA",  
    str_detect(name, "^PIERRE")           ~ "PIE",  
    str_detect(name, "^PURDUM")           ~ "PUR",   
    str_detect(name, "^RAPID CITY 4")     ~ "RA4",        
    str_detect(name, "^RAPID CITY R")     ~ "RAP",   
    str_detect(name, "^SPEARFISH")        ~ "SPE",        
    str_detect(name, "^SPRINGVIEW")       ~ "SPR",      
    str_detect(name, "^RED OWL")          ~ "RED",  
    str_detect(name, "^REDBIRD")          ~ "REB",  
    str_detect(name, "^VALENTINE MILLER") ~ "VAL",  
    str_detect(name, "^VALENTINE NWR")    ~ "VNW",  
    str_detect(name, "^WASTA")            ~ "WAS",  
    str_detect(name, "^WINNER")           ~ "WIN",     
    str_detect(name, "^WOOD")             ~ "WOO",  
    TRUE ~ "ERROR"  
  )   
  ) %>%   
  select(sta, name, longitude, latitude, elevation, group, everything())  
  
# download daily precip data from NOAA GHCN database-all_stations====      
# date function calls start one-year early for long-term drought calcs  
dateMin = "1959-01-01"      
dateMax = "2018-12-31"    
  
sta_dv_orig <- sta_meta_orig %>%   
  select(sta_id) %>%  
  split(.$sta_id) %>%  
  map_dfr(~meteo_tidy_ghcnd(stationid = .$sta_id,   
                            keep_flags   = TRUE,   
                            var          = "PRCP",   
                            date_min     = dateMin,   
                            date_max     = dateMax)  
  )     
  
# fix date & add year and month & add metadata====   
sta_dv_orig <- sta_dv_orig %>%   
  mutate(date  = ymd(date)) %>%   
  arrange(desc(date)) %>%  
  mutate(year  = year(date)) %>%  
  mutate(month = month(date)) %>%  
  select(date, year, month, everything())   
   
sta_dv_orig <- left_join(sta_dv_orig, sta_meta_orig,  
                         by = c("id" = "sta_id"))  
  
# check for missing years====           
sta_miss_yr <- sta_dv_orig %>%    
  group_by(name, year)     %>%   
  summarise(num_day = n()) %>%   
  filter(num_day < 345)    %>%   
  ungroup() %>%  
  group_by(name) %>%  
  summarise(num_year = n()) %>%  
  filter(num_year > 3)   
   
# remove stations with 3 years of > 95% completeness====     
sta_dv_plus <- anti_join(sta_dv_orig, sta_miss_yr,   
                         by = "name")    
   
sta_meta_plus <- semi_join(sta_meta_orig, sta_dv_plus,     
                           by = "name")   

# select final stations for each group====   
# this was created from the map below   
sta_meta_fin <- subset(sta_meta_orig,   
                       sta %in%  
                         c("RAP",  
                           "COT",  
                           "ONI",  
                           "OEL",  
                           "GOR",  
                           "MIS"  
                         )    
)   
  
sta_dv_fin <- semi_join(sta_dv_plus, sta_meta_fin,  
                        by = "sta")  
  
sta_dv_alt <- sta_dv_orig %>% 
  filter(sta == "RAP" |  
           sta == "COT" |   
           sta == "ONI" |   
           sta == "OEL" |   
           sta == "GOR" |  
           sta == "MIS" |   
           sta == "DUP" |
           sta == "ELL" |  
           sta == "ELM" |  
           sta == "HOT" |  
           sta == "INT" | 
           sta == "KEN" | 
           sta == "MIL" |    
           sta == "MUL" |  
           sta == "ORA" | 
           sta == "PIE" |
           sta == "RA4" |
           sta == "VAL" | 
           sta == "VNW" | 
           sta == "WOO"  
  ) 
  


# export files and clean up global environment====     
export(sta_meta_orig, "data/sta_meta_orig.csv")    
export(sta_meta_plus, "data/sta_meta_plus.csv")    
export(sta_meta_fin, "data/sta_meta_fin.csv")    
export(sta_dv_alt, "data/sta_dv_alt.csv")   

rm(sta_miss_yr,  
   dateMin,  
   dateMax,  
   sta_dv_plus,  
   sta_dv_orig  
)     
  
```   

```{r check_prcp_data_quality, eval=FALSE}  
  
# Table of Measurement Flag/Attributes -- mflag----    
# Blank = no measurement information applicable            
# A     = precip depth is a multi-day total, accumulated since last meas         
# B     = precipitation total formed from two twelve-hour totals  
# D     = precipitation total formed from four six-hour totals           
# H     = represents TMAX or TMIN or average of hourly values (TAVG)           
# K     = converted from knots            
# L     = temperature appears lagged w/ respect to reported hr of observation  
# O     = converted from oktas  
# P     = identified as "missing presumed zero" in DSI 3200 and 3206           
# T     = trace of precipitation, snowfall, or snow depth   
# W    = converted from 16-point WBAN code (for wind direction)  

# Table of Quality Flag/Attributes----    
# Blank = did not fail any quality assurance check   
# D     = failed duplicate check           
# G     = failed gap check           
# I     = failed internal consistency check           
# K     = failed streak/frequent-value check           
# L     = failed check on length of multiday period  
# M     = failed mega-consistency check            
# N     = failed naught check            
# O     = failed climatological outlier check            
# R     = failed lagged range check           
# S     = failed spatial consistency check            
# T     = failed temporal consistency check            
# W     = temperature too warm for snow            
# X     = failed bounds check           
# Z     = flagged as a result of an official Datzilla investigation  

# Table Source Flag/Attributes----     
# Blank = No source (i.e., data value missing)  
# 0  = U.S. Cooperative Summary of the Day (NCDC DSI-3200)   
# 6  = CDMP Cooperative Summary of the Day (NCDC DSI-3206)   
# 7  = U.S. Cooperative Summary of the Day -- Transmitted via WxCoder  
# A  = U.S. Automated Surface Observing System (ASOS) real-time data  
# a  = Australian data from the Australian Bureau of Meteorology           
# B  = U.S. ASOS data for October 2000-December 2005 (NCDC  DSI-3211)  
# b  = Belarus update           
# C  = Environment Canada            
# E  = European Climate Assessment and Dataset (Klein Tank et al., 2002)      
# F  = U.S. Fort data             
# G  = Off Global Climate Observing System (GCOS) or other gov-supplied data   
# H  = High Plains Regional Climate Center real-time data            
# I  = International collection (non U.S. data received thru pers. contacts   
# K  = U.S. Coop Summary of the Day data digitized from paper observer forms  
# M  = Monthly METAR Extract (additional ASOS data)           
# N  = Community Collaborative Rain, Hail,and Snow (CoCoRaHS)           
# Q  = Data from African countries w/ later permission granted  
# R  = NCDC Reference Network Database  
# r  = All-Russian Research Inst. Hydromet Information-World Data Center    
# S  = Global Summary of the Day (NCDC DSI-9618)  
#        NOTE: "S" values are derived from hourly synoptic reports   
#         exchanged on the Global Telecommunications System (GTS).  
#         Daily values derived in this fashion may differ significantly from  
#        "true" daily data, particularly for precip (i.e., use with caution).  
# s  = China Met Admn/Nat Met Info/Climate Data Centr (http://cdc.cma.gov.cn)   
# T  = SNOwpack TELemtry (SNOTEL) data from Western Regional Climate Center   
# U  = Remote Automatic Weather Station (RAWS) data from West Reg Climate Centr  
# u  = Ukraine update           
# W  = WBAN/ASOS Summary of the Day from NCDC's Integrated Surface Data (ISD)  
# X  = U.S. First-Order Summary of the Day (NCDC DSI-3210)           
# Z  = Datzilla official additions or replacements           
# z  = Uzbekistan update   

sta_check <- sta_dv_orig %>%  
  group_by(sta, mflag_prcp) %>%  
  summarise(mflag = n()) %>% 
  filter(mflag_prcp != " ") %>%  
  group_by(mflag_prcp) %>%    
  summarise(mflag = n()) %>% 
  ungroup()    

# Measurement flags are T & P flags  
# P     = identified as "missing presumed zero" in DSI 3200 and 3206           
# T     = trace of precipitation, snowfall, or snow depth   

sta_check <- sta_dv_orig %>%  
  group_by(sta, qflag_prcp) %>%  
  summarise(qflag = n()) %>% 
  filter(qflag_prcp != " ") %>%  
  group_by(qflag_prcp) %>%    
  summarise(qflag = n()) %>% 
  ungroup()    

# quality flags are D, I, K, L, O flags  
# D     = failed duplicate check           
# I     = failed internal consistency check           
# K     = failed streak/frequent-value check           
# L     = failed check on length of multiday period  
# O     = failed climatological outlier check            

sta_check <- sta_dv_orig %>%  
  group_by(sta, sflag_prcp) %>%  
  summarise(sflag = n()) %>% 
  filter(sflag_prcp != " ") %>%  
  group_by(sflag_prcp) %>%    
  summarise(sflag = n()) %>% 
  ungroup()    

# flags are 0, 7, B, H, K, W, X, Z  
# 0  = U.S. Cooperative Summary of the Day (NCDC DSI-3200)   
# 7  = U.S. Cooperative Summary of the Day -- Transmitted via WxCoder  
# A  = U.S. Automated Surface Observing System (ASOS) real-time data  
# B  = U.S. ASOS data for October 2000-December 2005 (NCDC  DSI-3211)  
# H  = High Plains Regional Climate Center real-time data            
# K  = U.S. Coop Summary of the Day data digitized from paper observer forms  
# W  = WBAN/ASOS Summary of the Day from NCDC's Integrated Surface Data (ISD)  
# X  = U.S. First-Order Summary of the Day (NCDC DSI-3210)           
# Z  = Datzilla official additions or replacements           

rm(sta_check)   
  
```  

```{r fill-station-data, eval=FALSE}

# create a df of monthly precipitation values-NW-RAP---- 
station <- "RAP"  
sta_fil <- sta_dv_alt %>% 
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_dv_alt   %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     

sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   

# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^RAPID CITY 4")) %>%        
  filter(!is.na(prcp))    

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^ELM")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# make a filled prcp df & clean up     
sta_rap <- sta_fil  

rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     

# create a df of monthly precipitation values-NC-COT----  
station <- "COT"  
sta_fil <- sta_dv_alt %>% 
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_fil       %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     

sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   

# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^MILES")) %>%        
  filter(!is.na(prcp))    

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^INTERIOR")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# get alternate site data & check if sta_mis_day = 0  
# Phillip & Plainview were big zeros
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^DUPREE")) %>%        
  filter(!is.na(prcp))  

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)  

sta_miss_day <- sta_fil        %>%   
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)   

# make a filled prcp df & clean up      
sta_cot <- sta_fil  

rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     

# create a df of monthly precipitation values-NE-ONI---- 
station <- "ONI"  
sta_fil <- sta_dv_alt %>% 
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_fil       %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     

sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   

# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^KENNE")) %>%        
  filter(!is.na(prcp))    

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^PIERRE")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# make a summary & monthly prcp df & clean up       
sta_oni <- sta_fil  

rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     

# create a df of monthly precipitation values-SW-OEL----   
station <- "OEL"  
sta_fil <- sta_dv_alt %>% 
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_fil       %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     

sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   

# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^ORAL")) %>%        
  filter(!is.na(prcp))    

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^HOT SPRINGS")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# make a filled prcp df & clean up     
sta_oel <- sta_fil  

rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     

# create a df of monthly precipitation values-SC-GOR----  
station <- "GOR"  
sta_fil <- sta_dv_alt %>% 
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_fil       %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     

sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   

# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^VALENTINE NWR")) %>%        
  filter(!is.na(prcp))    

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^MULLEN")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^ELLSWORTH")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# make a filled prcp df & clean up     
sta_gor <- sta_fil  

rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     

# create a df of monthly precipitation values-SW-MIS----  
station <- "MIS"  
sta_fil <- sta_dv_alt %>% 
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_fil       %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     

sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   

# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^WOOD")) %>%        
  filter(!is.na(prcp))    

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^VALENTINE MILLER")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# make a filled prcp df & clean up     
sta_mis <- sta_fil  

rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     

# join the filled data & clean up----  
sta_dv_fill <- bind_rows(sta_rap,  
                         sta_cot,  
                         sta_oni,  
                         sta_oel,  
                         sta_gor,  
                         sta_mis  
                         )  

rm(sta_rap,  
   sta_cot,  
   sta_oni,  
   sta_oel,  
   sta_gor,  
   sta_mis, 
   station  
)  

# create monthly data from the daily data----    
sta_mon <- sta_dv_fill          %>%  
  arrange(date)                 %>%  
  group_by(sta, month, year)    %>%  
  summarize(prcp = sum(prcp))   %>%  
  ungroup()                     %>% 
  mutate(day     = 15)          %>%  
  mutate(date    = make_date(year   = year,  
                              month = month,  
                              day   = day)  
  ) %>%           
  select(sta, date, prcp) 

# export and clean-up data 
export(sta_dv_fill, "data/sta_dv_fill.csv")    
export(sta_mon, "data/sta_mon.csv")  

rm(sta_dv_alt,  
   sta_dv_fill)

```  

# use bootstrapping to check precip differences 
```{r bootstrap_precip}  
  
# Construct bootstrap confidence intervals of precipitation----   
#   to identify differences in means   
# Monthly precipitation data is from 1954 to 2018 = 65 years  
#   Split data into two groups of 30 years & test for differences  
  
# Notes on dabest and memory -- see setup for how to increase memory  
# dabest for 14,027 obs; 40,000 reps takes ~2 hours.    
#   Still had memory allocation issues @ 50,000 reps after increasing memory.   
  
# import final monthly precip data & prepare for bootstrapping====   
sta_mon <- import("data/sta_mon.csv") %>%  
  mutate(date = ymd(date)) %>%  
  mutate(yr = year(date)) %>%     
  
  # create an id variable  
  mutate(Period = case_when(   
    yr < 1989 ~ "<1989",  
    TRUE ~ ">1989")  
  ) %>%  
  # create a grouping variable   
  unite("group",   
        c("sta", "Period"),  
        sep = "",   
        remove = FALSE) %>%   
  arrange(date)   
  
# print a summary of the data====  
sta_mon %>%   
  group_by(group) %>%   
  summarise(count = n()) %>%   
  ungroup() %>%   
  mutate(num_yr = count/(12))  
  
# construct bootstrap confidence interval of prcp====   
prcp_dabest <- sta_mon %>%   
  dabest(x = group,             # grouping variable  
         y = prcp,              # measurement variable   
# list order shows control as first group on the list   
         idx = list(c("RAP<1989",  
                      "OEL<1989",  
                      "COT<1989",  
                      "GOR<1989",  
                      "ONI<1989",  
                      "MIS<1989"),   
                    c("RAP>1989",  
                      "OEL>1989",  
                      "COT>1989",   
                      "GOR>1989",  
                      "ONI>1989",  
                      "MIS>1989")  
         ),  
         paired    = TRUE,  
         reps      = 20000,  
         id.column = group   
  )  
  
# plot the dabest bootstrap====   
plot(prcp_dabest,  
     color.column = Period,  
     tick.fontsize = 5,  
     rawplot.type = "sinaplot",  
     axes.title.fontsize = 9,  
     rawplot.ylabel = "Monthly precipitation (mm)",  
     rawplot.groupwidth = 0.3,  
     palette = "Greys")  
  
# save results====   
ggplot2::ggsave(filename = "figure/prcp_dif.png",   
                width = 6.5, height = 4.5, units = "in")  
  
rm(prcp_dabest)    
```

<!--
need to finish this 
```{r ci_result_table, eval=FALSE}  

# get mean precipitation 
prcp <- spi_fin %>%  
  group_by(group) %>%  
  summarise(prcp = mean(prcp)) %>% 
  ungroup() 

rap_bef <- prcp %>% 
  filter(group == "RAP<1989") %>% 
  select(-group) %>% 
  as.double()

# pluck results for summary tables & bind====
prcp_results <- prcp_dabest %>% 
  pluck("result") %>% 
  select(-c(func,  
            paired,  
            variable,  
            bootstraps,  
            nboots,  
            pct_ci_low,  
            pct_ci_high  
  )  
  )   

prcp_results <- full_join(prcp_results, prcp, 
                  by = c("test_group" = "group")  
                  ) %>% 
  filter(test_group != "RAP<1989") %>% 
  mutate(control_group = case_when(  
    is.na(control_group) ~ "RAP<1989",  
    TRUE ~ control_group  
    )
  ) %>%  
  mutate(difference = case_when(  
    is.na(difference) ~ prcp - rap_bef,  
    TRUE ~ difference  
    )
  ) %>% 
  mutate(ci = as.integer(ci))  %>% 
  mutate_if(is.numeric, round, digits = 0)  


# convert tibble to a flextable after fixing vars for presentation==== 
prcp_table <- prcp_table %>% 
  flextable() %>% 
  #  colformat_num(col_keys = col_key_num, 
  #                big.mark=",", 
  #                digits = 1, na_str = "N/A") %>% 
  set_header_labels(control_group = "Control Group", 
                    test_group = "Test Groups", 
                    control_size = "Control Size",
                    test_size = "Test Size", 
                    func = "Test Statistic", 
                    variable = "Variable",
                    difference = "Mean Difference", 
                    ci = "CI", 
                    bca_ci_low = "Lower Limit", 
                    bca_ci_high = "Upper Limit") %>% 
  autofit() %>% 
  align(., part = "all", align = "center") %>% 
  theme_booktabs() 


ci_table2 <- read_docx() %>% 
  body_add_flextable(value = ci_table)  

print(ci_table2, target = "output/ci_table.docx") 

rm(ci_results_pc1, ci_results_pc2, ci_table2, ci_table) 

```  
-->

```{r compare_precip_locations}  
  
# the bootstrapping showed there is some difference between past & present  
sta_pres <- sta_mon %>%  
  filter(yr > 1988)  
  
export(sta_pres, "data/sta_pres.csv")  
  
# comparison of locations----   
# split out northwest & southeast to prepare for plot    
nw <- sta_pres %>%  
  filter(sta == "COT" |  
         sta == "RAP" |  
         sta == "OEL") %>%  
  select(sta, date, prcp) %>%  
  mutate(prcp = prcp + 1) %>%  
  spread(sta, prcp) %>%   
  gather(other, prcp, -c(date, COT)) %>%  
  mutate(location = "COT") %>%  
  rename(control = COT)   
  
se <- sta_pres %>%  
  filter(sta == "GOR" |  
         sta == "ONI" |  
         sta == "MIS") %>%  
  select(sta, date, prcp) %>%  
  mutate(prcp = prcp + 1) %>%  
  spread(sta, prcp) %>%   
  gather(other, prcp, -c(date, GOR)) %>%  
  mutate(location = "GOR")  %>%  
  rename(control = GOR)  
  
# join splits & create factor     
prcp_compare <- bind_rows(nw, se) %>%  
  mutate(diff = control - prcp) %>%    
  mutate(other = fct_relevel(other,  
                           "RAP",  
                           "OEL",  
                           "ONI",  
                           "MIS"  
  ))  
  
# plot location differences  
prcp_compare %>%   
ggplot(aes(date, diff)) +  
  theme_bw() +  
  xlab("") +  
  ylab("Monthly precipitation difference (mm)") +  
  facet_grid(cols    = vars(location),  
             rows    = vars(other)) +  
  geom_line(color    = "gray60") +  
  geom_smooth(method = "lm",  
              color  = "gray30",  
              size   = 0.5  
              )  
  
ggplot2::ggsave(filename = "figure/prcp_loc_dif.png",   
                width = 6.5, height = 4.5, units = "in")  

rm(nw,  
   se,  
   prcp_compare  
   )  

rm(sta_mon)  
  
```

```{r import_streamflow_data, eval=FALSE}   
 
# import full streamflow records----   
gage_mon_full <- import("data/gage_mon_full.csv") %>% 
# drop unneeded cols & duplicates
  select(sta, Date, q1_mon) %>% 
  distinct() 
 
gage_meta_lmom <-  import("data/gage_meta.csv")  
  
```

# L-moments 
```{r lmoments_prcp, eval=FALSE}

sta_pres     <- import("data/sta_pres.csv")  
sta_meta_fin <- import("data/sta_meta_fin.csv")

# Note that we might consider Weiss 1964 bias value of 1.018 for L1   
  
# Calculate L-moment ratios   
lmom_sta <- sta_pres %>%  
  split(.$sta) %>%  
  map(~ lmoms(.$prcp)) %>%    
  transpose() %>%  
  as_tibble() %>%  
  select(lambdas, ratios) %>%  
  mutate(lambdas = map(lambdas,   
                       ~as_tibble(t(.x))  
  )) %>%  
  mutate(lambdas = map(lambdas,   
                       ~set_names(.x,  
                                  c("L1", "L2", "L3", "L4", "L5")  
                       )  
  )) %>%  
  mutate(ratios = map(ratios,  
                      ~as_tibble(t(.x)   
                      )   
  )) %>%  
  mutate(ratios = map(ratios,  
                      ~set_names(.x,  
                                 c("T1", "T2", "T3", "T4", "T5")   
                      )   
  )) %>%  
  unnest(lambdas) %>%  
  unnest(ratios)  %>%   
  select(-T1) %>%  
  rename(L_CV = T2) %>%  
  rename(L_skew = T3) %>%  
  rename(L_kurtosis = T4) %>%  
  select(L1, L_CV, L_skew, L_kurtosis) %>%  
  mutate(L1 = round(L1,  
                    digits = 2)  
  )  
  
# get station names from the list  
lmom_sta_nm <- sta_pres %>%  
  split(.$sta) %>%  
  map(~ lmoms(.$prcp)) %>%  
  transpose()  
  
lmom_sta_nm <- lmom_sta_nm %>%  
  pluck(1) %>%  
  enframe()  
  
lmom_sta_nm <- lmom_sta_nm %>%  
  unnest(value)  
  
lmom_sta_nm <- lmom_sta_nm %>%  
  group_by(name) %>%  
  summarize(L1 = first(value)) %>%  
  ungroup() %>%  
  mutate(L1 = round(L1,  
                    digits = 2))  
  
# join name to lmom vals & to the metadata  
lmom_sta <- full_join(lmom_sta_nm, lmom_sta,  
                      by = "L1") %>%  
  rename(sta = name) %>%  
  mutate(L_CV = round(L_CV,  
                      digits = 2)  
  ) %>%  
  mutate(L_skew = round(L_skew,  
                        digits = 2)  
  ) %>%  
  mutate(L_kurtosis = round(L_kurtosis,  
                            digits = 2)  
  )  
  
# join the lmoments to the metadata   
sta_meta_lmom <- full_join(sta_meta_fin, lmom_sta,   
                           by = "sta")   
  

  
export(sta_meta_lmom, "data/sta_meta_lmom.csv")    
  
rm(lmom_sta,  
   lmom_sta_nm  
   )  
  
```

```{r lmoments_streamflow, eval=FALSE}
  
# Note that we might consider Weiss 1964 bias value of 1.018 for L1   
  
# Calculate L-moment ratios   
lmom_gage <- gage_mon_full %>%  
  split(.$sta) %>%  
  map(~ lmoms(.$q1_mon)) %>%    
  transpose() %>%  
  as_tibble() %>%  
  select(lambdas, ratios) %>%  
  mutate(lambdas = map(lambdas,   
                       ~as_tibble(t(.x))  
  )) %>%  
  mutate(lambdas = map(lambdas,   
                       ~set_names(.x,  
                                  c("L1", "L2", "L3", "L4", "L5")  
                       )  
  )) %>%  
  mutate(ratios = map(ratios,  
                      ~as_tibble(t(.x)   
                      )   
  )) %>%  
  mutate(ratios = map(ratios,  
                      ~set_names(.x,  
                                 c("T1", "T2", "T3", "T4", "T5")   
                      )   
  )) %>%  
  unnest(lambdas) %>%  
  unnest(ratios)  %>%   
  select(-T1) %>%  
  rename(L_CV = T2) %>%  
  rename(L_skew = T3) %>%  
  rename(L_kurtosis = T4) %>%  
  select(L1, L_CV, L_skew, L_kurtosis) %>%  
  mutate(L1 = round(L1,  
                    digits = 2)  
  )  
  
# get station names from the list  
lmom_gage_nm <- gage_mon_full %>%  
  split(.$sta) %>%  
  map(~ lmoms(.$q1_mon)) %>%  
  transpose()  
  
lmom_gage_nm <- lmom_gage_nm %>%  
  pluck(1) %>%  
  enframe()  
  
lmom_gage_nm <- lmom_gage_nm %>%  
  unnest(value)  
  
lmom_gage_nm <- lmom_gage_nm %>%  
  group_by(name) %>%  
  summarize(L1 = first(value)) %>%  
  ungroup() %>%  
  mutate(L1 = round(L1,  
                    digits = 2))  
  
# join name to lmom vals & to the metadata  
lmom_gage <- full_join(lmom_gage_nm, lmom_gage,  
                      by = "L1") %>%  
  rename(sta = name) %>%  
  mutate(L_CV = round(L_CV,  
                      digits = 2)  
  ) %>%  
  mutate(L_skew = round(L_skew,  
                        digits = 2)  
  ) %>%  
  mutate(L_kurtosis = round(L_kurtosis,  
                            digits = 2)  
  )  
  
# join the lmoments to the metadata & drop unneeded cols   
gage_meta_lmom <- full_join(gage_meta_lmom, lmom_gage,   
                            by = "sta")   

gage_meta_lmom <- gage_meta_lmom %>% 
  select(-c(yrs_incomp:yeas_rec))

export(gage_meta_lmom, "data/gage_meta_lmom.csv")    
  
rm(lmom_gage,  
   lmom_gage_nm,  
   gage_mon_full  
   )  
  
```

```{r Lmoment_diagram_ratios}
# extract elements from the lmrdia list to plot in ggplot2    
#   the x-value is the L-skewness and y-value is L-kurtosis   
  
# get vals from the lmrdia list  
# note that as gamma distribution is a 2-parameter dist, it is not shown  
lmrdia <- lmrdia()  
  
# extract L-skew & L-kurtosis values for several distributions  
#   note:  aep4 <- lmrdia %>% extract2(2) %>% as.tibble()   
  
gev <- lmrdia[[5]]  %>%  
  as_tibble() %>%  
  mutate(distribution = "GEV")  
  
glo <- lmrdia[[6]]  %>%  
  as_tibble() %>%  
  mutate(distribution = "GLO")  
  
gpa <- lmrdia[[7]]  %>%  
  as_tibble() %>%  
  mutate(distribution = "GPA")   
  
gno <- lmrdia[[9]]  %>%  
  as_tibble() %>%  
  mutate(distribution = "GNO")  
  
gov <- lmrdia[[10]] %>%  
  as_tibble() %>%  
  mutate(distribution = "GOV")  
  
pe3 <- lmrdia[[12]] %>%  
  as_tibble() %>%  
  mutate(distribution = "PE3")     
  
lmom_theo <- bind_rows(gev,  
                  glo,  
                  gpa,  
                  gno,  
                  gov,  
                  pe3  
                  ) %>%  
  rename(L_skew = V1) %>%  
  rename(L_kurtosis = V2)  
  
rm(gev,  
   glo,  
   gpa,  
   gno,  
   gov,  
   pe3,  
   lmrdia  
   )  
  
```

```{r plot-lmoment-diagram}
 
lmom_gage <- import("data/gage_meta_lmom.csv") %>% 
  select(sta, L1:L_kurtosis) %>% 
  mutate(type = "gage")  
  
lmom_sta <- import("data/sta_meta_lmom.csv") %>% 
  select(sta, L1:L_kurtosis) %>% 
  mutate(type = "sta")  

lmom_data <- 


# plot the theoretical distributions, and sample vals----    

ggplot(midwest, aes(x=area, y=poptotal)) + geom_point()

ggplot(midwest, 
       aes(x = area, 
           y = poptotal
           )) + 
  theme_bw() + 
  geom_point()    


ggplot(lmom_sta,   
       aes(x = L_skew,  
           y = L_kurtosis  
       )) +  
  labs(x = "L-skew",  
       y = "L-kurtosis"  
  ) +   
  #  xlim(-0.25, 0.5) +  
  #  ylim(-0.25, 0.5) +  
  theme_bw() +    
  geom_point() +   
  geom_line(data = lmom_theo,  
            aes(L_skew,  
                L_kurtosis,  
                group = distribution,  
                linetype = distribution  
            ))     



  
#ggplot2::ggsave(filename = "figure/lmom_plot.png",  
#                width = 6, height = 4, units = "in")  
  
rm(lmom_theo  
   )      
  
```  

# calculate SCI  
```{r SCI_prepare, eval=FALSE}
  
# fitSCI identifies Standardized Climate Index (SCI) parameters----      
#   some notes about the SCI package:   
#     the SCI package doesn't like snake_case variables,    
#     need to change tibble to a vector as double:   
#       cot <- as.double(sta_cot$depth_mm)   
  
# Initial values for SCI calculations====     
time_scale <- 1     # sets the length of the averaging period   
distrib    <- "pe3" # sets the distribution type   
p_zero     <- TRUE  # sets a function to reduce zero-precip bias  
p_zero_cm  <- TRUE  # uses Weibull plotting position for p_zero    
scale      <- "sd"  # scales input by subtract mean & divide by sd    
warn_me    <- TRUE  # sets explicit warning   
first_mon  <- 1     # Set first month for each station  
sci.limit  <- 3     # Sets a limit of [-3, 3] for limit  
  
# sci function====                                         
sci.fun <- function(sta, time_scale) fitSCI( x = sta,   
                                             start.fun.fix  = TRUE,   
                                             time.scale     = time_scale,   
                                             first.mon      = first_mon,  
                                             distr          = distrib,  
                                             p0             = p_zero,    
                                             p0.center.mass = p_zero_cm,    
                                             scaling        = scale,    
                                             sci.limit      = sci_limit,   
                                             warn	         = warn_me    
)  
  
```  

```{r calculate_SPI}
  
# prepare spi function vector inputs (1986-2018)----   
# north-west (NW)   
sta_rap <- sta_pres %>%  
  arrange(date) %>%  
  filter(sta == "RAP")   
  
rap <- as.double(sta_rap$prcp)   
  
# north-central (NC)  
sta_cot <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "COT")   
  
cot <- as.double(sta_cot$prcp)   

# north-east (NE)  
sta_oni <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "ONI")    
  
oni <- as.double(sta_oni$prcp)   

# south-west (SW)  
sta_oel <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "OEL")   
  
oel <- as.double(sta_oel$prcp)   

# south-central (SC)  
sta_gor <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "GOR")    
  
gor <- as.double(sta_gor$prcp)   

# south-east (SE)  
sta_mis <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "MIS")   
  
mis <- as.double(sta_mis$prcp)   

# calculate SPI-rap----  
# set up the station for spi & make spi list vars====  
sta      <- rap  
spi_1mo  <- spi.fun(sta, 1)                             
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                             
spi_4mo  <- spi.fun(sta, 4)    
spi_6mo  <- spi.fun(sta, 6)    
spi_9mo  <- spi.fun(sta, 9)    
spi_12mo <- spi.fun(sta, 12)   
  
# Apply the transformation identified by fitSCI function====  
spi_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = spi_1mo) %>%  
  enframe(name                     = NULL)   
  
spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_2mo) %>%   
  enframe(name                     = NULL)  
  
spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = spi_3mo) %>%  
  enframe(name                     = NULL)  
  
spi_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = spi_4mo) %>%  
  enframe(name                     = NULL)    
  
spi_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = spi_6mo) %>%  
  enframe(name                     = NULL)  
  
spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = spi_9mo) %>%  
  enframe(name                     = NULL)  
  
spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_12mo) %>%   
  enframe(name                     = NULL)   
  
# bind and rename the spi vals====     
spi_rap <- bind_cols(sta_rap,     
                     spi_1mo,   
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,   
                     spi_6mo,  
                     spi_9mo,   
                     spi_12mo  
) %>%      
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%   
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%   
  rename(spi_6mo = value4)  %>%   
  rename(spi_9mo = value5)  %>%  
  rename(spi_12mo = value6) 
  
# clean up global environment====  
rm(spi_1mo,  
   spi_2mo,  
   spi_3mo,  
   spi_4mo,   
   spi_6mo,  
   spi_9mo,  
   spi_12mo  
   )      
rm(sta_rap, rap)   
  
# calculate SPI-cot----  
# set up the station for spi & make spi list vars   
sta      <- cot  
spi_1mo  <- spi.fun(sta, 1)                               
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                            
spi_4mo  <- spi.fun(sta, 4)    
spi_6mo  <- spi.fun(sta, 6)   
spi_9mo  <- spi.fun(sta, 9)   
spi_12mo <- spi.fun(sta, 12)  
  
# Apply the transformation identified by fitSCI function    
spi_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_1mo) %>%  
  enframe(name                     = NULL)  
  
spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_2mo) %>%  
  enframe(name                     = NULL)  

spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_3mo) %>%  
  enframe(name                     = NULL)  

spi_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_4mo) %>%  
  enframe(name                     = NULL)  

spi_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_6mo) %>%  
  enframe(name                     = NULL)  

spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_9mo) %>%  
  enframe(name                     = NULL)  

spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_12mo) %>%  
  enframe(name                     = NULL)  

# bind and rename the spi vals     
spi_cot <- bind_cols(sta_cot,     
                     spi_1mo,  
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,  
                     spi_6mo,  
                     spi_9mo,   
                     spi_12mo   
) %>%    
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%  
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%  
  rename(spi_6mo = value4)  %>%  
  rename(spi_9mo = value5)  %>%   
  rename(spi_12mo = value6) 

# clean up global environment  
rm(spi_1mo,  
   spi_2mo,  
   spi_3mo,  
   spi_4mo,  
   spi_6mo,  
   spi_9mo,  
   spi_12mo  
   )     
rm(sta_cot, cot)  

# calculate SPI-oni----  
# set up the station for spi & make spi list vars     
sta      <- oni    
spi_1mo  <- spi.fun(sta, 1)                              
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                            
spi_4mo  <- spi.fun(sta, 4)   
spi_6mo  <- spi.fun(sta, 6)   
spi_9mo  <- spi.fun(sta, 9)   
spi_12mo <- spi.fun(sta, 12)  

# Apply the transformation identified by fitSCI function      
spi_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_1mo) %>%  
  enframe(name                     = NULL)  

spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_2mo) %>%  
  enframe(name                     = NULL)  

spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_3mo) %>%  
  enframe(name                     = NULL)  

spi_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_4mo) %>%  
  enframe(name                     = NULL)  

spi_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_6mo) %>%  
  enframe(name                     = NULL)  

spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_9mo) %>%  
  enframe(name                     = NULL)  

spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_12mo) %>%  
  enframe(name                     = NULL)  

# bind and rename the spi vals     
spi_oni <- bind_cols(sta_oni,     
                     spi_1mo,  
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,  
                     spi_6mo,  
                     spi_9mo,  
                     spi_12mo  
) %>%  
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%  
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%  
  rename(spi_6mo = value4)  %>%  
  rename(spi_9mo = value5)  %>%  
  rename(spi_12mo = value6)  

# clean up global environment  
rm(spi_1mo,  
   spi_2mo,  
   spi_3mo,  
   spi_4mo,  
   spi_6mo,  
   spi_9mo,  
   spi_12mo  
   )    
rm(sta_oni, oni)  

# calculate SPI-oel----  
# set up the station for spi & make spi list vars  
sta      <- oel  
spi_1mo  <- spi.fun(sta, 1)                              
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                            
spi_4mo  <- spi.fun(sta, 4)   
spi_6mo  <- spi.fun(sta, 6)   
spi_9mo  <- spi.fun(sta, 9)    
spi_12mo <- spi.fun(sta, 12)  

# Apply the transformation identified by fitSCI function       
spi_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_1mo) %>%  
  enframe(name = NULL)  

spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_2mo) %>%  
  enframe(name = NULL)  

spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_3mo) %>%  
  enframe(name = NULL)  

spi_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_4mo) %>%  
  enframe(name = NULL)  

spi_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_6mo) %>%  
  enframe(name = NULL)  

spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_9mo) %>%  
  enframe(name = NULL)  

spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_12mo) %>%  
  enframe(name = NULL)  
  
# bind and rename the spi vals   
spi_oel <- bind_cols(sta_oel,     
                     spi_1mo,  
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,  
                     spi_6mo,   
                     spi_9mo,    
                     spi_12mo  
) %>%   
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%  
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%  
  rename(spi_6mo = value4)  %>%  
  rename(spi_9mo = value5)  %>%  
  rename(spi_12mo = value6)      

# clean up global environment        
rm(spi_1mo,  
   spi_2mo,  
   spi_3mo,  
   spi_4mo,  
   spi_6mo,  
   spi_9mo,  
   spi_12mo  
   )    
rm(sta_oel, oel)    
  
# calculate SPI-gor----  
# set up the station for spi & make spi list vars  
sta      <- gor    
spi_1mo  <- spi.fun(sta, 1)                              
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                            
spi_4mo  <- spi.fun(sta, 4)   
spi_6mo  <- spi.fun(sta, 6)   
spi_9mo  <- spi.fun(sta, 9)   
spi_12mo <- spi.fun(sta, 12)  

# Apply the transformation identified by fitSCI function        
spi_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_1mo) %>%  
  enframe(name                     = NULL)  

spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_2mo) %>%  
  enframe(name                     = NULL)  

spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_3mo) %>%  
  enframe(name                     = NULL)  

spi_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_4mo) %>%  
  enframe(name                     = NULL)  

spi_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_6mo) %>%  
  enframe(name                     = NULL)  

spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_9mo) %>%  
  enframe(name                     = NULL)  

spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_12mo) %>%  
  enframe(name                     = NULL)  
  
# bind and rename the spi vals      
spi_gor <- bind_cols(sta_gor,     
                     spi_1mo,  
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,  
                     spi_6mo,  
                     spi_9mo,   
                     spi_12mo     
) %>%  
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%  
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%  
  rename(spi_6mo = value4)  %>%  
  rename(spi_9mo = value5)  %>%  
  rename(spi_12mo = value6)    

# clean up global environment    
rm(spi_1mo,   
   spi_2mo,  
   spi_3mo,   
   spi_4mo,  
   spi_6mo,  
   spi_9mo,  
   spi_12mo   
   )    
rm(sta_gor, gor)    
  
# calculate SPI-mis----  
# set up the station for spi & make spi list vars  
sta      <- mis  
spi_1mo  <- spi.fun(sta, 1)                              
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                            
spi_4mo  <- spi.fun(sta, 4)    
spi_6mo  <- spi.fun(sta, 6)   
spi_9mo  <- spi.fun(sta, 9)   
spi_12mo <- spi.fun(sta, 12)  
  
# Apply the transformation identified by fitSCI function     
spi_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_1mo) %>%  
  enframe(name                     = NULL)  
  
spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_2mo) %>%  
  enframe(name                     = NULL)  
  
spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_3mo) %>%  
  enframe(name                     = NULL)  
  
spi_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_4mo) %>%  
  enframe(name                     = NULL)  
  
spi_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_6mo) %>%  
  enframe(name                     = NULL)  
  
spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_9mo) %>%  
  enframe(name                     = NULL)  
  
spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_12mo) %>%  
  enframe(name                     = NULL)  
  
# bind and rename the spi vals     
spi_mis <- bind_cols(sta_mis,     
                     spi_1mo,  
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,  
                     spi_6mo,  
                     spi_9mo,   
                     spi_12mo   
) %>%  
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%  
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%  
  rename(spi_6mo = value4)  %>%  
  rename(spi_9mo = value5)  %>%  
  rename(spi_12mo = value6) 
  
# clean up global environment  
rm(spi_1mo,  
   spi_2mo,  
   spi_3mo,  
   spi_4mo,  
   spi_6mo,  
   spi_9mo,  
   spi_12mo   
   )   
rm(sta_mis, mis)      
  
# join spi data----  
spi_sta <- bind_rows(spi_rap,  
                 spi_cot,  
                 spi_oni,  
                 spi_oel,  
                 spi_gor,  
                 spi_mis,  
                 ) %>% 
  select(-c(Period, group)) %>%  
    # truncate spi vals to [-3, 3]    
  gather(key = type, val = value, -c(sta, date, yr, prcp)) %>%  
  mutate(value = case_when(     
    value < -3.0 ~ -3.0,    
    value >  3.0 ~  3.0,  
    TRUE ~ value)) %>%  
  spread(type, value) %>%    
  # move the longer spi-values to the end of the df    
  select(-spi_12mo, spi_12mo)    
  
# export spi data        
export(spi_sta, "data/spi_sta.csv")  

# clean up workspace    
rm(distrib,  
   first_mon,   
   p_zero,   
   p_zero_cm,   
   scale,   
   sci.limit,   
   sta,   
   time_scale,   
   warn_me,  
   spi.fun,  
   spi_cot,  
   spi_gor,  
   spi_mis,  
   spi_oel,  
   spi_oni,  
   spi_rap, 
   sta_pres  
   )         

```  

```{r calculate_SCI}

# prepare spi function vector inputs (1986-2018)----   
# north-west (NW)   
sta_rap <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "RAP")   
  
rap <- as.double(sta_rap$prcp)   
  
# north-central (NC)  
sta_cot <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "COT")   
  
cot <- as.double(sta_cot$prcp)   

# north-east (NE)  
sta_oni <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "ONI")    
  
oni <- as.double(sta_oni$prcp)   

# south-west (SW)  
sta_oel <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "OEL")   
  
oel <- as.double(sta_oel$prcp)   

# south-central (SC)  
sta_gor <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "GOR")    
  
gor <- as.double(sta_gor$prcp)   

# south-east (SE)  
sta_mis <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "MIS")   
  
mis <- as.double(sta_mis$prcp)   

# calculate SPI-rap----  
# set up the station for spi & make spi list vars====  
sta      <- rap  
spi_1mo  <- spi.fun(sta, 1)                             
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                             
spi_4mo  <- spi.fun(sta, 4)    
spi_6mo  <- spi.fun(sta, 6)    
spi_9mo  <- spi.fun(sta, 9)    
spi_12mo <- spi.fun(sta, 12)   
  
# Apply the transformation identified by fitSCI function====  
spi_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = spi_1mo) %>%  
  enframe(name                     = NULL)   
  
spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_2mo) %>%   
  enframe(name                     = NULL)  
  
spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = spi_3mo) %>%  
  enframe(name                     = NULL)  
  
spi_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = spi_4mo) %>%  
  enframe(name                     = NULL)    
  
spi_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = spi_6mo) %>%  
  enframe(name                     = NULL)  
  
spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = spi_9mo) %>%  
  enframe(name                     = NULL)  
  
spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_12mo) %>%   
  enframe(name                     = NULL)   
  
# bind and rename the spi vals====     
spi_rap <- bind_cols(sta_rap,     
                     spi_1mo,   
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,   
                     spi_6mo,  
                     spi_9mo,   
                     spi_12mo  
) %>%      
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%   
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%   
  rename(spi_6mo = value4)  %>%   
  rename(spi_9mo = value5)  %>%  
  rename(spi_12mo = value6) 
  
# clean up global environment====  
rm(spi_1mo,  
   spi_2mo,  
   spi_3mo,  
   spi_4mo,   
   spi_6mo,  
   spi_9mo,  
   spi_12mo  
   )      
rm(sta_rap, rap)   
  
# calculate SPI-cot----  
# set up the station for spi & make spi list vars   
sta      <- cot  
spi_1mo  <- spi.fun(sta, 1)                               
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                            
spi_4mo  <- spi.fun(sta, 4)    
spi_6mo  <- spi.fun(sta, 6)   
spi_9mo  <- spi.fun(sta, 9)   
spi_12mo <- spi.fun(sta, 12)  
  
# Apply the transformation identified by fitSCI function    
spi_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_1mo) %>%  
  enframe(name                     = NULL)  
  
spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_2mo) %>%  
  enframe(name                     = NULL)  

spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_3mo) %>%  
  enframe(name                     = NULL)  

spi_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_4mo) %>%  
  enframe(name                     = NULL)  

spi_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_6mo) %>%  
  enframe(name                     = NULL)  

spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_9mo) %>%  
  enframe(name                     = NULL)  

spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_12mo) %>%  
  enframe(name                     = NULL)  

# bind and rename the spi vals     
spi_cot <- bind_cols(sta_cot,     
                     spi_1mo,  
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,  
                     spi_6mo,  
                     spi_9mo,   
                     spi_12mo   
) %>%    
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%  
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%  
  rename(spi_6mo = value4)  %>%  
  rename(spi_9mo = value5)  %>%   
  rename(spi_12mo = value6) 

# clean up global environment  
rm(spi_1mo,  
   spi_2mo,  
   spi_3mo,  
   spi_4mo,  
   spi_6mo,  
   spi_9mo,  
   spi_12mo  
   )     
rm(sta_cot, cot)  

# calculate SPI-oni----  
# set up the station for spi & make spi list vars     
sta      <- oni    
spi_1mo  <- spi.fun(sta, 1)                              
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                            
spi_4mo  <- spi.fun(sta, 4)   
spi_6mo  <- spi.fun(sta, 6)   
spi_9mo  <- spi.fun(sta, 9)   
spi_12mo <- spi.fun(sta, 12)  

# Apply the transformation identified by fitSCI function      
spi_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_1mo) %>%  
  enframe(name                     = NULL)  

spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_2mo) %>%  
  enframe(name                     = NULL)  

spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_3mo) %>%  
  enframe(name                     = NULL)  

spi_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_4mo) %>%  
  enframe(name                     = NULL)  

spi_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_6mo) %>%  
  enframe(name                     = NULL)  

spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_9mo) %>%  
  enframe(name                     = NULL)  

spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_12mo) %>%  
  enframe(name                     = NULL)  

# bind and rename the spi vals     
spi_oni <- bind_cols(sta_oni,     
                     spi_1mo,  
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,  
                     spi_6mo,  
                     spi_9mo,  
                     spi_12mo  
) %>%  
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%  
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%  
  rename(spi_6mo = value4)  %>%  
  rename(spi_9mo = value5)  %>%  
  rename(spi_12mo = value6)  

# clean up global environment  
rm(spi_1mo,  
   spi_2mo,  
   spi_3mo,  
   spi_4mo,  
   spi_6mo,  
   spi_9mo,  
   spi_12mo  
   )    
rm(sta_oni, oni)  

# calculate SPI-oel----  
# set up the station for spi & make spi list vars  
sta      <- oel  
spi_1mo  <- spi.fun(sta, 1)                              
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                            
spi_4mo  <- spi.fun(sta, 4)   
spi_6mo  <- spi.fun(sta, 6)   
spi_9mo  <- spi.fun(sta, 9)    
spi_12mo <- spi.fun(sta, 12)  

# Apply the transformation identified by fitSCI function       
spi_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_1mo) %>%  
  enframe(name = NULL)  

spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_2mo) %>%  
  enframe(name = NULL)  

spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_3mo) %>%  
  enframe(name = NULL)  

spi_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_4mo) %>%  
  enframe(name = NULL)  

spi_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_6mo) %>%  
  enframe(name = NULL)  

spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_9mo) %>%  
  enframe(name = NULL)  

spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = spi_12mo) %>%  
  enframe(name = NULL)  
  
# bind and rename the spi vals   
spi_oel <- bind_cols(sta_oel,     
                     spi_1mo,  
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,  
                     spi_6mo,   
                     spi_9mo,    
                     spi_12mo  
) %>%   
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%  
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%  
  rename(spi_6mo = value4)  %>%  
  rename(spi_9mo = value5)  %>%  
  rename(spi_12mo = value6)      

# clean up global environment        
rm(spi_1mo,  
   spi_2mo,  
   spi_3mo,  
   spi_4mo,  
   spi_6mo,  
   spi_9mo,  
   spi_12mo  
   )    
rm(sta_oel, oel)    
  
# calculate SPI-gor----  
# set up the station for spi & make spi list vars  
sta      <- gor    
spi_1mo  <- spi.fun(sta, 1)                              
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                            
spi_4mo  <- spi.fun(sta, 4)   
spi_6mo  <- spi.fun(sta, 6)   
spi_9mo  <- spi.fun(sta, 9)   
spi_12mo <- spi.fun(sta, 12)  

# Apply the transformation identified by fitSCI function        
spi_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_1mo) %>%  
  enframe(name                     = NULL)  

spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_2mo) %>%  
  enframe(name                     = NULL)  

spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_3mo) %>%  
  enframe(name                     = NULL)  

spi_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_4mo) %>%  
  enframe(name                     = NULL)  

spi_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_6mo) %>%  
  enframe(name                     = NULL)  

spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_9mo) %>%  
  enframe(name                     = NULL)  

spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_12mo) %>%  
  enframe(name                     = NULL)  
  
# bind and rename the spi vals      
spi_gor <- bind_cols(sta_gor,     
                     spi_1mo,  
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,  
                     spi_6mo,  
                     spi_9mo,   
                     spi_12mo     
) %>%  
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%  
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%  
  rename(spi_6mo = value4)  %>%  
  rename(spi_9mo = value5)  %>%  
  rename(spi_12mo = value6)    

# clean up global environment    
rm(spi_1mo,   
   spi_2mo,  
   spi_3mo,   
   spi_4mo,  
   spi_6mo,  
   spi_9mo,  
   spi_12mo   
   )    
rm(sta_gor, gor)    
  
# calculate SPI-mis----  
# set up the station for spi & make spi list vars  
sta      <- mis  
spi_1mo  <- spi.fun(sta, 1)                              
spi_2mo  <- spi.fun(sta, 2)                             
spi_3mo  <- spi.fun(sta, 3)                            
spi_4mo  <- spi.fun(sta, 4)    
spi_6mo  <- spi.fun(sta, 6)   
spi_9mo  <- spi.fun(sta, 9)   
spi_12mo <- spi.fun(sta, 12)  
  
# Apply the transformation identified by fitSCI function     
spi_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_1mo) %>%  
  enframe(name                     = NULL)  
  
spi_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_2mo) %>%  
  enframe(name                     = NULL)  
  
spi_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_3mo) %>%  
  enframe(name                     = NULL)  
  
spi_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_4mo) %>%  
  enframe(name                     = NULL)  
  
spi_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_6mo) %>%  
  enframe(name                     = NULL)  
  
spi_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_9mo) %>%  
  enframe(name                     = NULL)  
  
spi_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = spi_12mo) %>%  
  enframe(name                     = NULL)  
  
# bind and rename the spi vals     
spi_mis <- bind_cols(sta_mis,     
                     spi_1mo,  
                     spi_2mo,   
                     spi_3mo,  
                     spi_4mo,  
                     spi_6mo,  
                     spi_9mo,   
                     spi_12mo   
) %>%  
  rename(spi_1mo = value)   %>%  
  rename(spi_2mo = value1)  %>%  
  rename(spi_3mo = value2)  %>%  
  rename(spi_4mo = value3)  %>%  
  rename(spi_6mo = value4)  %>%  
  rename(spi_9mo = value5)  %>%  
  rename(spi_12mo = value6) 
  
# clean up global environment  
rm(spi_1mo,  
   spi_2mo,  
   spi_3mo,  
   spi_4mo,  
   spi_6mo,  
   spi_9mo,  
   spi_12mo   
   )   
rm(sta_mis, mis)      
  
# join spi data----  
spi_sta <- bind_rows(spi_rap,  
                 spi_cot,  
                 spi_oni,  
                 spi_oel,  
                 spi_gor,  
                 spi_mis,  
                 ) %>% 
  select(-c(Period, group)) %>%  
    # truncate spi vals to [-3, 3]    
  gather(key = type, val = value, -c(sta, date, yr, prcp)) %>%  
  mutate(value = case_when(     
    value < -3.0 ~ -3.0,    
    value >  3.0 ~  3.0,  
    TRUE ~ value)) %>%  
  spread(type, value) %>%    
  # move the longer spi-values to the end of the df    
  select(-spi_12mo, spi_12mo)    
  
# export spi data        
export(spi_sta, "data/spi_sta.csv")  

# clean up workspace    
rm(distrib,  
   first_mon,   
   p_zero,   
   p_zero_cm,   
   scale,   
   sci.limit,   
   sta,   
   time_scale,   
   warn_me,  
   spi.fun,  
   spi_cot,  
   spi_gor,  
   spi_mis,  
   spi_oel,  
   spi_oni,  
   spi_rap, 
   sta_pres  
   )         

``` 


# Identify seasonality & trend of SCI data 
```{r make_stl-decomp_function}  
  
# make function to decompose into seasonal, trend, & remainder----  
#    the target is 'groups'   
decomp_fun <- function(df) {  
  arrange(df, .data$date) %>%  
    group_by(.data$group) %>%  
    time_decompose(  
      target         = , TARGET,    
      data           = .,  
      method         = "stl",  
      frequency      = , FREQ,  
      trend          = , TREND,  
      merge          = TRUE,  
      message        = TRUE   
    ) %>%  
    ungroup() %>%  
    anomalize(remainder,  
              method = "gesd",  
              alpha  = 0.003) %>%   
    select(-observed)   
}   
  
# notes: map_dfr can cause issues with indexing; use split and combine  
#   input needs to be a tibble   
  
```

```{r deconvolute_spi}  
  
# deconvolute the grouped prcp into trend, seasonal & random components----  
  
# import working data####     
#spi_sta <- import("data/spi_sta.csv") %>%    
# mutate(date = ymd(date))   
  
#sta_meta_fin <- import("data/sta_meta_fin.csv")   
  
# prepare for deconvoluting the grouped precip====  
spi_sta <- spi_sta %>%   
  mutate(prcp = as.numeric(prcp)) %>%   
  arrange(date) %>%   
  as_tibble() %>%  
  # make groups 
  mutate(group = case_when(  
    sta == "RAP" ~ "NW",  
    sta == "COT" ~ "NC",     
    sta == "OEL" ~ "NE",     
    sta == "GOR" ~ "SW",  
    sta == "ONI" ~ "SC",  
    sta == "MIS" ~ "SE"  
  )   
  ) 
  
# identify frequency of seasonality -- should be 12 months====      
#   the level is group rather than station - so need to combine stations  
freq <- spi_sta  %>%    
  split(.$group) %>%   
  map_dfc(~ anomalize::time_frequency(  
    period       = "auto",  
    data = .)   
  ) %>%  
  gather(key     = group,  
         value   = freq) %>%   
  summarise(freq = mean(freq),   
            max  = max(freq),   
            min  = min(freq),   
            sd   = sd(freq)  
  )   
  
#   identify trend of periodicity -- should be 60 months====  
trend <- spi_sta  %>%  
  split(.$group) %>%  
  map_dfc(~ anomalize::time_trend(  
    period       = "auto", data = .)   
  ) %>%  
  gather(key     = grpup, value = freq) %>%   
  summarise(freq = mean(freq),  
            max  = max(freq),  
            min  = min(freq),  
            sd   = sd(freq)  
  )  
  
# decompose prcp into seasonal, trend, & remainder====    
FREQ   <- "12 months"  
TREND  <- "60 months"   
TARGET <- "spi_1mo"  
  
spi_seas <- spi_sta %>%   
  decomp_fun() 


  
# clean up global environment####  
rm(freq,  
   trend,      
   FREQ,  
   TARGET,  
   TREND,  
   decomp_fun  
   )    
  
```  

# Seasonality plotting  
```{r plot_seasonality}

# check for anomonies====     
spi_anom <- spi_seas %>% 
  filter(anomaly == "Yes")  
  
# vars for plotting====    
sta_size   <- 0.2  
sta_color  <- "black"  
  
# prcp observations plot====  
spi_obs <- 
spi_seas %>%  
  ggplot(aes(date, spi_1mo)) +     
  theme_bw() +  
  xlab("") +  
  ylab("SPI 1-month") +   
  scale_y_continuous(limits = c(-3, 3)) +
  facet_wrap(vars(group)) +   
# plot station vals  
geom_line(size            = sta_size,  
          colour          = sta_color  
          )    
  
# precipitation seasons plot====  
spi_seas_plot <- 
spi_seas %>%  
  ggplot(aes(date, season)) +     
  theme_bw() +  
  xlab("") +  
  ylab("SPI 1-month") +   
  scale_y_continuous(limits = c(-3, 3)) +
  facet_wrap(vars(group),  
             nrow = 2) +   
# plot group vals  
geom_line(size            = sta_size,  
          colour          = sta_color  
          )    
  
# precipitation trend plot====  
spi_trend <- 
spi_seas %>%  
  ggplot(aes(date, trend)) +     
  theme_bw() +  
  xlab("") +  
  ylab("SPI 1-month") +   
  scale_y_continuous(limits = c(-3, 3)) +
  facet_wrap(vars(group), 
             nrow = 2) +   
# plot group vals  
geom_line(size            = sta_size,  
          colour          = sta_color  
          )    
  
# precipitation remainder plot====  
spi_remain <- 
spi_seas %>%  
  ggplot(aes(date, remainder)) +     
  theme_bw() +  
  xlab("") +  
  ylab("SPI 1-month") +   
  scale_y_continuous(limits = c(-3, 3)) +
  facet_wrap(vars(group)) +   
# plot station vals  
geom_line(size            = sta_size,  
          colour          = sta_color  
          )     
  
# plot the plots above as a grid & save====  
cowplot::plot_grid(  
  spi_obs, spi_seas_plot, spi_trend, spi_remain,  
  ncol = 1,   
  align = "v"  
)  
  
cowplot::ggsave2("figure/spi_deconv.png",  
                 units = "in",  
                 width = 7,  
                 height = 9)  
  
rm(spi_obs,  
   spi_seas,  
   spi_seas_plot,  
   spi_trend, 
   spi_remain,  
   spi_anom,  
   sta_color, 
   sta_size   
   )  

```  

# TO DO Monthly plot PRCP_MON  
```{r plot-annual}
# plot annual precips
sta_mon_plus %>% 
  ggplot(aes(year, depth_mm, group = year)) + 
  facet_grid(rows =vars(group)) +  
  #  geom_quasirandom(size = 0.2,  
  #                position = position_beeswarm()) +  
  geom_boxplot() +  
  theme_bw() +   
  labs(title = "Annual precipitation depths",  
       subtitle = "1990-2017") +  
  xlab("") +  
  ylab("mm")  
```

```{r ggplot_monthly, eval=FALSE} 
#sta_mon <- import(file = "data/stations_monthly.csv") %>% 
#  mutate(date = ymd(date))

#sta_mon %>% 
#  group_by(sta) %>% 
#  summarize(count = n())

sta_mon_plus$group <- factor(sta_mon_plus$group,  
                             levels = c("NW", "NC", "NE", "SW", "SC", "SE"))  

# plot monthly precips  
sta_mon_plus %>%   
  ggplot(aes(month, depth_mm, group = month)) +  
  facet_grid(rows = vars(group)) +   
  geom_quasirandom(size = 0.2, 
                   position = position_beeswarm()  
  ) + 
  scale_x_discrete(limits = c("1", "2", "3", "4", "5", "6", 
                              "7", "8", "9", "10", "11", "12"),   
                   labels = c("J", "F", "M", "A", "M", "J", 
                              "J", "A", "S", "O", "N", "D")  
  ) + 
  theme_bw() +  
  #  labs(title = "Monthly precipitation depths",  
  #       subtitle = "Southwestern South Dakota for 1990-2017") +   
  xlab("") +  
  ylab("mm")  


ggplot2::ggsave(path = "figure/", filename = "precip_mon.png", 
                width = 6, height = 6, units = "in")

````  


```{r things-tsible}  

spi_all2 %>% 
  ggplot(aes(date, spi_1mo)) + 
  facet_grid(rows = vars(sta)) + 
  geom_line() 




spi_1mo %>% 
  ggplot(aes(ONI, MIS)) + 
  #  facet_grid(rows = vars(sta)) + 
  geom_point() 
# time series arima 
library(tsibble)  
library(feasts) 

spi_1mo <- spi_all2 %>% 
  select(sta, date, spi_1mo) %>% 
  as_tibble()  

spi_1mot <- spi_1mo %>% 
  as_tsibble(key = spi_1mo)



tourism_melb <- tourism %>%
  filter(Region == "Melbourne")
tourism_melb %>%
  group_by(Purpose) %>%
  slice(1)

spi_1mot %>% 
  group_by(sta) %>%
  slice(1)


spi_1mot %>%
  autoplot(spi_1mo)

```

```{r precip-EDA, include=FALSE, eval=FALSE}
# Purpose: EDA of precipitation data.
# Outcome: Differences among stations 1971-2018 are small.  
#          less than +/-5 mm on average.  
 
# the anomolously wet month series is dominated by May & June events.  
# what drives precip during this time?   
#   In May & June the area recieves low-level moisture from the Gulf   
#   of Mexico, strong cold fronts, and active upper-level pattern  
#   leading to greater chance for convection.  
```

```{r spi-correlation-analysis}
# visually check results
#spi_index_plot <- spi_index %>% 
#  filter(spi_length == 12)

#ggplot(spi_index_plot, aes(date, spi_index)) + 
#  geom_line() +
#  facet_wrap(vars(sta)) + 
#  theme_classic() +
#  geom_hline(yintercept = 0, aes)

#ggplot2::ggsave(path = "figure/", filename = "spi_1mo.png", 
#                width = 6, height = 6, units = "in")  

# create correlation matrix inputs
spi_M <- spi_index %>% 
  select(-date) %>% 
  group_by(sta, spi_length) %>% 
  mutate(grouped_id = row_number()) %>% 
  spread(key = sta, value = spi_index) %>% 
  drop_na() %>% 
  ungroup() %>% 
  select(-grouped_id) %>% 
  select(spi_length, cot, int, oel, ora, rap) # ensure vars order 

# create correlation matrix names from the correlation matrix vars
spi_M_names <- spi_M %>% 
  filter(spi_length == 1) %>% 
  cor() %>% 
  as.tibble() %>% 
  names() %>% 
  as.tibble() %>% 
  slice(-1) %>% 
  mutate(value2 = value) %>% 
  mutate(value3 = value) %>%  
  mutate(value4 = value) %>%
  mutate(value5 = value) %>% 
  gather(key, sta2) %>% 
  select(-key) %>% 
  rownames_to_column() 

# create second station names column 
spi_M_names2 <- spi_M_names %>% 
  arrange(sta2) %>% 
  rename(sta1 = sta2) %>% 
  select(-rowname)

# bind the names columns
spi_M_names <- bind_cols(spi_M_names, spi_M_names2)  
rm(spi_M_names2)

# create a correlation matrix from SPI vals
spi_M <- spi_M %>% 
  split(.$spi_length) %>% 
  purrr::map_dfr(~ cor(.)) %>% 
  drop_na() %>% 
  slice(-1) %>% 
  rownames_to_column() 

# bind names to the correlation matrix 
spi_M <- full_join(spi_M_names, spi_M, by = "rowname")
spi_M <- spi_M %>% 
  select(sta1, sta2, everything()) %>%
  select(-rowname)

# prepare lookup table of lat-lons
sta_loc <- sta_meta %>% 
  arrange(name) %>%
  mutate(sta = c("cot", "int", "oel", "ora", "rap")) %>% 
  select(sta, lat, lon, dur_year)

# join the 'from' lat lons
spi_corr <- full_join(spi_M, sta_loc, by = c("sta1" = "sta")) %>% 
  rename(lat1 = lat) %>% 
  rename(lon1 = lon) 

# join the 'to' lat lons
spi_corr <- full_join(spi_corr, sta_loc, by = c("sta2" = "sta")) %>% 
  rename(lat2 = lat) %>% 
  rename(lon2 = lon) %>% 
  mutate(year_dif = abs(dur_year.x - dur_year.y))


# convert the 'to' and 'from' lat-lons to northings & eastings & distance
lat_to_km <- 111.03 # 1 degree lat to km @ lat 40-degrees 
lon_to_km <- 85.39  # 1 degree lon to km @ lat 40-degrees 

spi_corr <- spi_corr %>% 
  mutate(northing = abs((lat1 - lat2)) * lat_to_km) %>% 
  mutate(easting = abs((lon1 - lon2)) * lat_to_km) %>% 
  mutate(distance = sqrt(northing^2 + easting^2)) %>% 
  select(year_dif, everything()) %>%
  select(-(lat1:easting)) %>% 
  mutate(stations = paste(sta1, sta2, sep = "_")) %>% 
  gather(key = spi_length, value = pears_r, -distance, 
         -stations, -sta1, -sta2, -year_dif) %>% 
  filter(distance > 0) %>% 
  mutate(spi_length = as.double(spi_length))


# clean up the global environment 
rm(spi_M, spi_M_names, sta_loc, lat_to_km, lon_to_km)

# model effect of averaging time & distance on correlation----
# fit a linear model
spi_lm <- lm(pears_r ~ distance + spi_length + year_dif, 
             data = spi_corr)

# augment & gather the original data
spi_corr_aug <- augment(spi_lm, spi_corr) 

spi_corr_gath <- spi_corr_aug %>% 
  select(-(sta1:sta2)) %>%
  select(year_dif:.fitted) %>% 
  gather(key = factor, val, -stations, -pears_r) %>% 
  mutate(val = as.double(val))  

# plot the original data and fitted model for SPI----  
ggplot(spi_corr_gath, aes(val, pears_r)) + 
  geom_point(aes(color = factor(stations))) +
  facet_wrap(ncol = 1, vars(factor), scales = "free") +
  geom_smooth(method = lm) + 
  theme_classic()

spi_lm_fit <- glance(spi_lm) 

spi_lm_tidy <- tidy(spi_lm) %>% 
  mutate(
    low = estimate - std.error,
    high = estimate + std.error
  )

# clean-up Global Environment----
spi_corr <- spi_corr_aug 
rm(spi_corr_aug, spi_corr_gath, spi_lm ,spi_lm_fit)


rm(spi_corr, spi_lm_tidy)
```