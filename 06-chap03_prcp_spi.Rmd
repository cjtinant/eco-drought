---
output: html_document
editor_options: 
  chunk_output_type: console
---

<!--  
These are some useful thoughts:    

lmomco <- citation("lmomco") 
a useful description of commits -- http://r-pkgs.had.co.nz/git.html  

# Some shortcuts in a code chunk styling format----  
# key-bindings====     
# insert operators####    
# pipe operator        %>% 	      Cmd+Shift+M
# assignment operator  <-    	    Option+-  

# Code chunks====  
# collapse                        Cmd+Option+L
# expand                          Cmd+Shift+Option+L
# collapse all                    Cmd+Option+O
# expand all                      Cmd+Shift+Option+O

# Navigation====
# insert section                 Cmd+Shift+R 
# jump to                        Shift+Alt+J

Exploratory Data Analysis Checklist by Roger Peng 
https://leanpub.com/exdata  

1.0   Formulate your question  
2.0   Read in your data  
3.0   Check the dataset 
3.1   Check the number of rows and columns.
3.2   Check the types of data
3.3   Look at the top and the bottom of your data 
3.4   Check your “n”s & NAs 
3.5   Validate with at least one external data source  
4.0   Try the easy solution first to answer question
5.0   Challenge your solution 
6.0  Follow up questions 


-->  

<!-- 
Purpose:  
This R markdown file calculates SCI 
Standardized precipitation index - SPI  
Streamflow runoff index - SRI  

Analysis steps 
1.0)  sets up the library and settings 

2.0)  downloads precipitation daily data and metadata (sta_orig); 
2.1)    creates groups by location;   
2.2)    creates short names;  
2.3)    downloads daily data for original stations (30-years);  
2.4)    removes incomplete years (sta_plus)  
2.5)    defines the final stations  (sta_fin)

3.0)  plot study area map;  
3.1)    prepare map elements: Theissen line segments, stream gages, location  
        data: states, counties, USA map-grob

4.0)  check data flags  




-- identified & filled NA
2.0)  convert daily precip to monthly precip  
2.1)  Updated unit vals - originally in tenths of mm; now in mm 
3.0)  Created plots 


Data:
Predominant datasets used are:  
1) NOAA data from NOAA GHCN database - 60-years (1959-2019)
2) USGS daily streamflow and station metadata,  
3) 

3)  prepare data for drought index 


1. Recreated analysis from the lmomco text ch 12 (author?) in Tidyverse
2. Imported cleaned precipitation data (see 04_prcp-data_munging)   

5. Applied Weibull plotting position and graphed the data on sqrt plot
6. Calculated L-moments and L-moment ratios 
7. Calculated SPI for 'cot', 'oel', 'rap', 'int', and 'ora' datasets using Pearson III. 


3. Applied sqrt & log10 transform to explore effects on skew 
4. Explored the data with box plots, violin plot.


####3) Summary data from a QGIS analysis of ungaged watersheds of interest.  

## Results: Fits a PE3 distribution
The results from the precipitation analysis indicate: 1) an annual trend of increasing aridity across the project area that trends from northwest to southeast that may be a result of the Black Hills rainshadow, 2) the 1900s were the wettest time in regions recorded history.  ??? what about the seasonal trend?  

Variable naming convention----  
a_session    list variable of session information  

precipitation and spi variables====  
dateMin       minimum date for downloading data   
dateMax       maximum date for downloading data  
sta           NOAA weather station locations  
  _dv         daily values  
  _meta       metadata  
  _orig       all stations (n = 46 sations)  
  _plus       potential stations (n = 14 stations)  
  _fin        final dvs used in the analysis   
  _mon        monthly precipitation depths (60-years)  
  _pres       monthly precipitation depths (30-years)  

daily value check & fill variables==== 
sta  
  _check       used to summarize station flags
  _alt         alternate station dv data for filling missing values 
  _fil         station to be filled 
  _miss_day    checks for missing days 
  _short_name  adds a short name for the station to be filled
  _rap         Rapid City Regional Airport station (NW)  
  _cot         Cottonwood station (NC)  
  _oni         Onida station (NE)   
  _ora         Oral station (SW)   
  _gor         Gordon staion (SC)   
  _mis         Mission station (SE)  

L-moment variables====  
lmom          L-moments  
  _sta        L-moments for stations
  _nm        station name
lmrdia       list of L-moment distributions 
gev          Generalized Extreme Value Distribution
glo          Generalized Logistic Distribution
gpa          Generalized Pareto Distribution
gno          Generalized Logistic Distribution 
gov          Govindarajulu Distribution
pe3          Pearson Type III Distribution  
L1           first L-moment, similiar to mean
L_CV         first L-moment ratio, similiar to coefficient of var
L_skew       second L-moment ratio, similiar to skewness 
L_kurtosis   third L-moment ratio, similiar to kurtosis
n            number of months in a given record

dischord     the Hosking and Wallis discordancy of the first three L-moment 
             ratios according to their implementation in Hosking and Wallis 
             (1997) and earlier. Discordancy triplets of these L-moment ratios 
             is heuristically measured by locating the triplet from the mean
             center of the 3-dim. cloud of values. 
  $Dmax	     The maximum discordancy D_{max} = (n-1)/3.
  $Dalpha1   The critical value of D for α_1 = 0.10 (default) 
  $Dalpha2	 The critical value of D for α_2 = 0.01 (default) 
  $Dcrit	   The critical value of discordancy (user or tabled).
  $D	       The discordancy of the L-moment ratios used to trigger isD	
  $isD       Are the L-moment ratios discordant (if starred) 
  $signif	   A hyphen, star, or double star based on Dalpha1 and Dalpha2 vals.

# SCI calculation variables----   
spi           Standardized Precipitation Index vals from NOAA precip data  
sri           Standardized Runoff Index vals from USGS streamflow gage data  
sci           Generalized variable for SPI and SRI calculations  
  _1mo        One    month duration                           
  _2mo        Two    month duration                             
  _3mo        Three  month duration                           
  _4mo        Four   month duration  
  _6mo        Six    month duration  
  _9mo        Nine   month duration   
  _12mo       Twelve month duration  

_freq       frequency of periodicity -- used in seasonality calculations  
_trend      trend of periodicity -- used in seasonality calculations  

# individual station variables for SRI====  
bhp_         Black Hills Plateau  
  _bat       Battle Creek above Hermosa  
  _bev       Beaver Creek  
  _fal       Fall River  
  _frn       French Creek  
kpt_         Keya Paha Tablelands  
  _key       Keya Paha River at Keya Paha   
  _wew       Keya Paha River at Wewila  
psp_         Pierre Shale Plains  
  _bat       Battle Creek below Hermosa   
  _brs       South Fork of the Bad River   
  _che       Cheyenne River at Wa??   
  _elk       Elk Creek at Elm Springs   
  _hat       Hat Creek at Edgemont  
  _whi       White River at Oacoma 
pre_         Pine Ridge Escarpment  
  _ogl       White River at Oglala  
  _sta       White River at Stateline 
snd_         Sand Hills  
  _lcr       Lake Creek below Refuge?
  _lon       Long River   
  _mar       Little White River at Martin  
  _ros       Little White River at Rosebud   
  _vet       Little White River at Vetal     
  _whi       Little White River at White River   
  _nio       Niobrera River at SPA??
whi_         White River Badlands  
  _kad       White River at Kadoka
    _v       as a double vector  


gage          USGS streamgage station  

'site' is a variable for OST monitoring stations 

## Broad questions:
What is the drought history of the Pine Ridge Reservation?  
Does the drought extent differ across the study area?

## Narrower question:
What is the underlying distribution of precipitation data?  

# Next STEPS  
3. Describe the precipitation seasonality
-->  

```{r setup_&_library, message=FALSE}   
  
knitr::opts_chunk$set(echo = FALSE)      
options(tibble.print_max = 70) # sets tibble output for printing         
  
# increase memory allocation for dabest()   
# usethis::edit_r_environ("project")  
  
# Get API key (aka, token) for downloading precip data at   http://www.ncdc.noaa.gov/cdo-web/token  
# token for NOAA API tied to jtinant@olc.edu -- see 'rnoaa' for details  
options(noaakey = "VpcuARumMpCfFyclKHPfvskEYnaiLJHD")  
  
# Sets up the library of packages   
library("conflicted")        # An alternative conflict resolution strategy  
library("here")              # identifies where to save work  
library("rnoaa")             # R wrapper for NOAA data inc. NCDC  
library("rio")               # more robust I/O - to import and clean data  
library("lubridate")         # easier dates   
library("lmomco")            # lmoments to find distribution   
library('deldir')            # for Vorononi tesselation - Theissen polygons  
library("SCI")               # calculates SPI & RDI   
library("forecast")          # using the BoxCox function   
library("broom")             # tidies linear models   
library("ggbeeswarm")        # plot 1D data as a violin / beeswarm plot  
library("scales")            # graphical scales map data to aesthetics,  
                             #   & methods for determining breaks and labels  
                             #   for axes and legends  
library("anomalize")         # detect anomalies using the tidyverse   
library("dabestr")           # data analysis using bootstrap estimation   
library("cowplot")           # multiple plots with plot_grid()
library("timetk")            # tool kit for working with time series in R 
library("tidyquant")         # integrate quant. analysis tools w/ tidyverse
library("corrr")             # Tidy correlation tables and correlation plotting
library("cranlogs")          # For inspecting package downloads over time
library("tidyverse")  
  
# resolve conflicted packages----  
conflict_prefer("filter", "dplyr")  
conflict_prefer("select", "dplyr")  
conflict_prefer("as.dist", "stats")

# used in time series clustering example--
#library(gridExtra)           # merge plots  
#library(ggdendro)            # dendrograms
#library(gplots)              # heatmap
#library(tseries)             # bootstrap
#library(TSclust)             # cluster time series
#library(dtwclust)            # cluster time series with dynamic time warping    
# other packages I have thought about ---------------------------------------  
# library("ggfortify")        # data vis tools for statistical analysis  
# library("ggpubr")           # some easy ggplot wrappers for publication ready 
#                             #   'ggplot2'- based plots  
  
# library("standardize")      # tools for controlling continuous variable   
#  scaling and factor contrasts for linear models   
# library("pdftools")         # utilities for extracting text, fonts,  
#   attachments and metadata from a pdf file.  
  
# Spatial data====  
#library("biogeo")            # Functions for error detection & correction  
#   in point-data datasets; includes functions   
#   to parse & convert coords to decimal-degrees  
#library("maps")              # Outlines of continents, countries, states &  
#   counties  
#library("mapdata")           # higher-resolution outlines  
#library('ggmap')             # Spatial visualization with ggplot2   
#library("sf")                # Simple features--spatial geometries for R  
#library("RColorBrewer")      # Provides color schemes for maps -- see  
#   http://colorbrewer2.org  
  
# Colors====  
#library("colorspace")        # Manipulate & assess colors & palettes  
#library("munsell")           # Access & manipulate munsell system colours  
#   https://github.com/cwickham/munsell  
  
# working with lists and urls====  
#library("jsonlite")          # Convert between JSON data and R objects  
#library("curl")              # Drop-in replacement for base url  
#library("listviewer")        # htmlwidget for interactive views of R lists  
#library("forecast")         # for BoxCox.lambda   
#library("magrittr") # provides aliases for easier reading  
#library("workflowr") # creates a research website  
#library("bookdown") #  
#library(unpivotr) # fix nasty Excel files  
#library("friendlyeval")  
#library("mathpix")                # support for 'Mathpix' image to 'LaTeX'    
#library("grateful") - not yet ready for R 3.5.0  
#lmomco <- citation("lmomco")  
#toBibtex(lmomco)  
  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
why_to_write <- function()   
{today <- today(tzone = "")  
paper2 <- ymd("2019-11-15")  
until <- paper2 - today  
print(paste("You have", until, "days until the second paper is due"  
))   
}   
why_to_write()  
  
```  

```{r download_prcp_data, eval=FALSE} 
  
# Get possible station metadata----    
# It's also possible to check station id with the mapping tool at:    
# https://www.ncdc.noaa.gov/cdo-web/datatools/findstation   
  
# The geographical extent given as SElat, SElon, NWlat, NWlon  
sta_meta_orig <- ncdc_stations(extent = c(42.0, -104.5, 45, -99.5),  
                               limit = 1000) %>%      # n = 777  
  # get possible stations into a dataframe  
  pluck("data") %>%  
  # turn min & max date into lubridates  
  mutate(mindate = ymd(mindate)) %>%  
  mutate(maxdate = ymd(maxdate)) %>%                  
  # remove 'young' stations    
  filter(mindate < "1988-01-01") %>%                    # n = 434  
  # remove 'dead' stations    
  filter(maxdate > "2018-01-01") %>%                    # n =  66    
  # keep only the GHCND stations   
  filter(str_detect(id, "^GHCND"))  %>%                 # n =  60      
  filter(!str_detect(name, "^MAGPIE"))                  # n =  59  
  
sta_meta_orig <- sta_meta_orig %>% 
  mutate(elev_flag = case_when(  
    elevation > 1200 ~ "yes",  
    TRUE ~ "no"
      )                              # n =  46    
  )  
  
# create groups of stations by region====       
#   Notes: the string "GHCND:" doesn't appear in calls to get Global Historical  
#   Climatology Network (GHCN) Daily Data  
sta_meta_orig <- sta_meta_orig %>%   
  mutate(north_group = case_when(   
    latitude > 43.5 ~ "N",   
    TRUE ~ "S")   
  ) %>%   
  mutate(east_group = case_when(  
    longitude > -100.67 ~ "E",  
    longitude > -102.33 ~ "C",    
    TRUE ~ "W")  
  )  %>%  
  mutate(group = str_c(north_group, east_group, sep = "")) %>%  
  dplyr::select(-c(north_group, east_group)) %>%  
  separate(  
    col = id,  
    sep = ":",   
    into = c("type", "sta_id")   
  ) %>%  
  arrange(name)  
  
# add short names to metadata====    
sta_meta_orig <- sta_meta_orig %>%  
  mutate(sta = case_when(  
    str_detect(name, "^AGATE")            ~ "AGA",  
    str_detect(name, "^AINSWORTH")        ~ "AIN",  
    str_detect(name, "^BEAR")             ~ "BEA",  
    str_detect(name, "^BELLE FOURCHE 22") ~ "BE2",      
    str_detect(name, "^BELLE FOURCHE,")   ~ "BEL",       
    str_detect(name, "^CHADRON")          ~ "CHA",      
    str_detect(name, "^COTTONWOOD")       ~ "COT",  
    str_detect(name, "^CUSTER")           ~ "CUS",  
    str_detect(name, "^DUPREE")           ~ "DUP",  
    str_detect(name, "^EDGEMONT")         ~ "EDG",   
    str_detect(name, "^ELLSWORTH")        ~ "ELL",  
    str_detect(name, "^ELM SPRINGS")      ~ "ELM",  
    str_detect(name, "^ELSMERE")          ~ "ELS",  
    str_detect(name, "^FORT MEADE")       ~ "FME",      
    str_detect(name, "^FORT PIERRE")      ~ "FPI",  
    str_detect(name, "^FORT ROBINSON")    ~ "FRO",      
    str_detect(name, "^GORDON")           ~ "GOR",    
    str_detect(name, "^HARRISON")         ~ "HAI",   
    str_detect(name, "^HARROLD")          ~ "HAR",   
    str_detect(name, "^HEMINGFORD")       ~ "HEM",   
    str_detect(name, "^HAY SPRINGS")      ~ "HAY",   
    str_detect(name, "^HILL CITY")        ~ "HIL",   
    str_detect(name, "^HOT SPRINGS")      ~ "HOT",  
    str_detect(name, "^INTERIOR")         ~ "INT",  
    str_detect(name, "^KENNEBEC")         ~ "KEN",  
    str_detect(name, "^KIRLEY")           ~ "KIR",     
    str_detect(name, "^KYLE")             ~ "KYL",  
    str_detect(name, "^LEAD")             ~ "LEA",  
    str_detect(name, "^LINGLE")           ~ "LIN",  
    str_detect(name, "^KYLE")             ~ "KYL",  
    str_detect(name, "^MAURINE")          ~ "MAU",     
    str_detect(name, "^MILESVILLE")       ~ "MIL",    
    str_detect(name, "^MISSION")          ~ "MIS",  
    str_detect(name, "^MOUNT")            ~ "MTR",  
    str_detect(name, "^MULLEN")           ~ "MUL",  
    str_detect(name, "^MURDO")            ~ "MUR",   
    str_detect(name, "^NEWCASTLE")        ~ "NEC",  
    str_detect(name, "^NEWELL")           ~ "NEW",    
    str_detect(name, "^OAHE DAM")         ~ "OAH",      
    str_detect(name, "^NEWELL")           ~ "NEW",    
    str_detect(name, "^OELRICHS")         ~ "OEL",  
    str_detect(name, "^ONIDA")            ~ "ONI",  
    str_detect(name, "^ORAL")             ~ "ORA",  
    str_detect(name, "^PACTOLA")          ~ "PAC",  
    str_detect(name, "^PHILIP")           ~ "PHI",  
    str_detect(name, "^PLAINVIEW")        ~ "PLA",  
    str_detect(name, "^PIERRE")           ~ "PIE",  
    str_detect(name, "^PURDUM")           ~ "PUR",   
    str_detect(name, "^RAPID CITY 4")     ~ "RA4",        
    str_detect(name, "^RAPID CITY R")     ~ "RAP",   
    str_detect(name, "^SPEARFISH")        ~ "SPE",        
    str_detect(name, "^SPRINGVIEW")       ~ "SPR",      
    str_detect(name, "^RED OWL")          ~ "RED",  
    str_detect(name, "^REDBIRD")          ~ "REB",  
    str_detect(name, "^SUNDANCE")         ~ "SUN",  
    str_detect(name, "^VALENTINE MILLER") ~ "VAL",  
    str_detect(name, "^VALENTINE NWR")    ~ "VNW",  
    str_detect(name, "^WASTA")            ~ "WAS",  
    str_detect(name, "^WIND CAVE")        ~ "WIN",  
    str_detect(name, "^WINNER")           ~ "WIN",     
    str_detect(name, "^WOOD")             ~ "WOO",  
    TRUE ~ "ERROR"  
  )   
  ) %>%   
  select(sta, name, longitude, latitude, elevation, group, everything())  
  
# download daily precip data from NOAA GHCN database-all_stations====       
# date function calls start one-year early for long-term drought calcs  
dateMin = "1959-01-01"      
dateMax = "2018-12-31"    
  
sta_dv_orig <- sta_meta_orig %>%   
  filter(elev_flag == "no") %>%  
  select(sta_id) %>%  
  split(.$sta_id) %>%  
  map_dfr(~meteo_tidy_ghcnd(stationid = .$sta_id,   
                            keep_flags   = TRUE,   
                            var          = "PRCP",   
                            date_min     = dateMin,   
                            date_max     = dateMax)  
  )     
  
# fix date & add year and month & add metadata====    
sta_dv_orig <- sta_dv_orig %>%   
  mutate(date  = ymd(date)) %>%   
  arrange(desc(date)) %>%  
  mutate(year  = year(date)) %>%  
  mutate(month = month(date)) %>%  
  select(date, year, month, everything())   
  
sta_dv_orig <- left_join(sta_dv_orig, sta_meta_orig,  
                         by = c("id" = "sta_id"))  
  
# check for missing years====            
sta_miss_yr <- sta_dv_orig  %>%   
  filter(year > 1988)       %>% 
  mutate(year = year(date)) %>%  
  group_by(name, year)      %>%   
  summarise(num_day = n())  %>%   
  filter(num_day < 345)     %>%   
  ungroup() %>%  
  group_by(name) %>%  
  summarise(num_year = n()) 

sta_miss_zero <- anti_join(sta_meta_orig, sta_miss_yr,  
                           by = "name") %>% 
  filter(elev_flag == "no") %>%  
  mutate(num_year = 0) %>%  
  select(name, num_year)  

sta_miss_yr <- bind_rows(sta_miss_yr, sta_miss_zero)  

# add missing year flag to table====    
sta_meta_orig <- left_join(sta_meta_orig, sta_miss_yr,  
                           by = "name")  
  
sta_meta_orig <- sta_meta_orig %>%  
  mutate(missing_flag = case_when(  
    num_year <= 3 ~ "no",  
    num_year >  3 ~ "yes"  
    )) %>%  
  select(-num_year) 
  
# remove stations with 3 years of > 95% completeness====      
sta_dv_orig <- left_join(sta_dv_orig, sta_meta_orig, 
                          by = c("sta", 
                                 "name", 
                                 "longitude", 
                                 "latitude", 
                                 "elevation", 
                                 "group", 
                                 "mindate", 
                                 "maxdate", 
                                 "datacoverage", 
                                 "type", 
                                 "elevationUnit", 
                                 "elev_flag")) %>%  
  select(-c(sta_id, type))  
  
# select final stations for each group====    
# this was created from the map below   
sta_meta_fin <- subset(sta_meta_orig,   
                       sta %in%  
                         c("RAP",  
                           "COT",  
                           "ONI",  
                           "OEL",  
                           "GOR",  
                           "MIS"  
                         )    
)   
  
sta_dv_fin <- semi_join(sta_dv_orig, sta_meta_fin,  
                        by = "sta")  
  
# export files and prepare for table below====    
export(sta_meta_fin, "data/sta_meta_fin.csv")    
  
sta_meta_fin <- sta_meta_fin %>% 
  select(sta) %>% 
  mutate(selected = "yes")

sta_meta_orig <- left_join(sta_meta_orig, sta_meta_fin, 
                           by = "sta")  

export(sta_meta_orig, "data/sta_meta_orig.csv")   

# clean up global environment==== 
rm(sta_miss_yr,   
   dateMin,  
   dateMax,  
   sta_meta_fin, 
   sta_miss_zero,  
   sta_dv_orig    
)     
  
```   

```{r check_prcp_data_quality, eval=FALSE}  
  
# Table of Measurement Flag/Attributes -- mflag----     
# Blank = no measurement information applicable            
# A     = precip depth is a multi-day total, accumulated since last meas         
# B     = precipitation total formed from two twelve-hour totals  
# D     = precipitation total formed from four six-hour totals           
# H     = represents TMAX or TMIN or average of hourly values (TAVG)           
# K     = converted from knots            
# L     = temperature appears lagged w/ respect to reported hr of observation  
# O     = converted from oktas  
# P     = identified as "missing presumed zero" in DSI 3200 and 3206           
# T     = trace of precipitation, snowfall, or snow depth   
# W    = converted from 16-point WBAN code (for wind direction)  
  
# Table of Quality Flag/Attributes----    
# Blank = did not fail any quality assurance check   
# D     = failed duplicate check           
# G     = failed gap check           
# I     = failed internal consistency check           
# K     = failed streak/frequent-value check           
# L     = failed check on length of multiday period  
# M     = failed mega-consistency check            
# N     = failed naught check            
# O     = failed climatological outlier check            
# R     = failed lagged range check           
# S     = failed spatial consistency check            
# T     = failed temporal consistency check            
# W     = temperature too warm for snow            
# X     = failed bounds check           
# Z     = flagged as a result of an official Datzilla investigation  

# Table Source Flag/Attributes----     
# Blank = No source (i.e., data value missing)  
# 0  = U.S. Cooperative Summary of the Day (NCDC DSI-3200)   
# 6  = CDMP Cooperative Summary of the Day (NCDC DSI-3206)   
# 7  = U.S. Cooperative Summary of the Day -- Transmitted via WxCoder  
# A  = U.S. Automated Surface Observing System (ASOS) real-time data  
# a  = Australian data from the Australian Bureau of Meteorology           
# B  = U.S. ASOS data for October 2000-December 2005 (NCDC  DSI-3211)  
# b  = Belarus update           
# C  = Environment Canada            
# E  = European Climate Assessment and Dataset (Klein Tank et al., 2002)      
# F  = U.S. Fort data             
# G  = Off Global Climate Observing System (GCOS) or other gov-supplied data   
# H  = High Plains Regional Climate Center real-time data            
# I  = International collection (non U.S. data received thru pers. contacts   
# K  = U.S. Coop Summary of the Day data digitized from paper observer forms  
# M  = Monthly METAR Extract (additional ASOS data)           
# N  = Community Collaborative Rain, Hail,and Snow (CoCoRaHS)           
# Q  = Data from African countries w/ later permission granted  
# R  = NCDC Reference Network Database  
# r  = All-Russian Research Inst. Hydromet Information-World Data Center    
# S  = Global Summary of the Day (NCDC DSI-9618)  
#        NOTE: "S" values are derived from hourly synoptic reports   
#         exchanged on the Global Telecommunications System (GTS).  
#         Daily values derived in this fashion may differ significantly from  
#        "true" daily data, particularly for precip (i.e., use with caution).  
# s  = China Met Admn/Nat Met Info/Climate Data Centr (http://cdc.cma.gov.cn)   
# T  = SNOwpack TELemtry (SNOTEL) data from Western Regional Climate Center   
# U  = Remote Automatic Weather Station (RAWS) data from West Reg Climate Centr  
# u  = Ukraine update           
# W  = WBAN/ASOS Summary of the Day from NCDC's Integrated Surface Data (ISD)  
# X  = U.S. First-Order Summary of the Day (NCDC DSI-3210)           
# Z  = Datzilla official additions or replacements           
# z  = Uzbekistan update   
  
sta_check <- sta_dv_orig %>%  
  group_by(sta, mflag_prcp) %>%  
  summarise(mflag = n()) %>% 
  filter(mflag_prcp != " ") %>%  
  group_by(mflag_prcp) %>%    
  summarise(mflag = n()) %>% 
  ungroup()    
  
# Measurement flags are T & P flags  
# P     = identified as "missing presumed zero" in DSI 3200 and 3206           
# T     = trace of precipitation, snowfall, or snow depth   
  
sta_check <- sta_dv_orig %>%  
  group_by(sta, qflag_prcp) %>%  
  summarise(qflag = n()) %>% 
  filter(qflag_prcp != " ") %>%  
  group_by(qflag_prcp) %>%    
  summarise(qflag = n()) %>% 
  ungroup()    
  
# quality flags are D, I, K, L, O flags  
# D     = failed duplicate check           
# I     = failed internal consistency check           
# K     = failed streak/frequent-value check           
# L     = failed check on length of multiday period  
# O     = failed climatological outlier check            
  
sta_check <- sta_dv_orig %>%  
  group_by(sta, sflag_prcp) %>%  
  summarise(sflag = n()) %>% 
  filter(sflag_prcp != " ") %>%  
  group_by(sflag_prcp) %>%    
  summarise(sflag = n()) %>% 
  ungroup()    
  
# flags are 0, 7, B, H, K, W, X, Z  
# 0  = U.S. Cooperative Summary of the Day (NCDC DSI-3200)   
# 7  = U.S. Cooperative Summary of the Day -- Transmitted via WxCoder  
# A  = U.S. Automated Surface Observing System (ASOS) real-time data  
# B  = U.S. ASOS data for October 2000-December 2005 (NCDC  DSI-3211)  
# H  = High Plains Regional Climate Center real-time data            
# K  = U.S. Coop Summary of the Day data digitized from paper observer forms  
# W  = WBAN/ASOS Summary of the Day from NCDC's Integrated Surface Data (ISD)  
# X  = U.S. First-Order Summary of the Day (NCDC DSI-3210)           
# Z  = Datzilla official additions or replacements           
  
rm(sta_check)   
  
```  

```{r fill-prcp-na, eval=FALSE}
  
# create a df of monthly precipitation values-NW-RAP---- 
station <- "RAP"  
sta_fil <- sta_dv_alt %>%  
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_dv_alt   %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     
  
sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   
  
# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^RAPID CITY 4")) %>%        
  filter(!is.na(prcp))    
  
sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  
  
sta_fil <- bind_rows(sta_alt, sta_fil)   
  
sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    
  
# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^ELM")) %>%        
  filter(!is.na(prcp))                             
  
sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   
  
sta_fil <- bind_rows(sta_alt, sta_fil)   
  
sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   
  
# make a filled prcp df & clean up     
sta_rap <- sta_fil  
  
rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     
  
# create a df of monthly precipitation values-NC-COT----  
station <- "COT"  
sta_fil <- sta_dv_alt %>% 
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_fil       %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     

sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   

# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^MILES")) %>%        
  filter(!is.na(prcp))    

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^INTERIOR")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# get alternate site data & check if sta_mis_day = 0  
# Phillip & Plainview were big zeros
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^DUPREE")) %>%        
  filter(!is.na(prcp))  

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)  

sta_miss_day <- sta_fil        %>%   
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)   

# make a filled prcp df & clean up      
sta_cot <- sta_fil  

rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     

# create a df of monthly precipitation values-NE-ONI---- 
station <- "ONI"  
sta_fil <- sta_dv_alt %>% 
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_fil       %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     

sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   

# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^KENNE")) %>%        
  filter(!is.na(prcp))    

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^PIERRE")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# make a summary & monthly prcp df & clean up       
sta_oni <- sta_fil  

rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     

# create a df of monthly precipitation values-SW-OEL----   
station <- "OEL"  
sta_fil <- sta_dv_alt %>% 
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_fil       %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     

sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   

# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^ORAL")) %>%        
  filter(!is.na(prcp))    

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^HOT SPRINGS")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# make a filled prcp df & clean up     
sta_oel <- sta_fil  

rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     

# create a df of monthly precipitation values-SC-GOR----  
station <- "GOR"  
sta_fil <- sta_dv_alt %>% 
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_fil       %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     

sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   

# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^VALENTINE NWR")) %>%        
  filter(!is.na(prcp))    

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^MULLEN")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^ELLSWORTH")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# make a filled prcp df & clean up     
sta_gor <- sta_fil  

rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     

# create a df of monthly precipitation values-SW-MIS----  
station <- "MIS"  
sta_fil <- sta_dv_alt %>% 
  filter(sta == station)  

# fill missing data & check for missing days     
sta_fil <- sta_fil       %>%   
  filter(sta == station) %>%   
  filter(!is.na(prcp))                                     

sta_miss_day <- sta_fil        %>%     
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)     

sta_short_name <- sta_fil %>%   
  slice(1) %>%  
  select(sta, id)   

# get alternate site data & check if sta_mis_day = 0      
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^WOOD")) %>%        
  filter(!is.na(prcp))    

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)  

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%    
  summarise(num_day = n())     %>%  
  ungroup()                    %>%  
  filter(num_day < 365)    

# get alternate site data & check if sta_mis_day = 0        
sta_alt <- sta_dv_alt %>%   
  filter(str_detect(name, "^VALENTINE MILLER")) %>%        
  filter(!is.na(prcp))                             

sta_alt <- anti_join(sta_alt, sta_fil, by = "date") %>%  
  mutate(sta = sta_short_name$sta)   

sta_fil <- bind_rows(sta_alt, sta_fil)   

sta_miss_day <- sta_fil        %>%    
  group_by(sta, year)          %>%   
  summarise(num_day = n())     %>%  
  ungroup()                    %>%   
  filter(num_day < 365)   

# make a filled prcp df & clean up     
sta_mis <- sta_fil  

rm(sta_alt,  
   sta_fil,  
   sta_miss_day,  
   sta_short_name  
   )     

# join the filled data & clean up----  
sta_dv_fill <- bind_rows(sta_rap,  
                         sta_cot,  
                         sta_oni,  
                         sta_oel,  
                         sta_gor,  
                         sta_mis  
                         )  

rm(sta_rap,  
   sta_cot,  
   sta_oni,  
   sta_oel,  
   sta_gor,  
   sta_mis, 
   station  
)  

# create monthly data from the daily data----    
sta_mon <- sta_dv_fill          %>%  
  arrange(date)                 %>%  
  group_by(sta, month, year)    %>%  
  summarize(prcp = sum(prcp))   %>%  
  ungroup()                     %>% 
  mutate(day     = 15)          %>%  
  mutate(date    = make_date(year   = year,  
                              month = month,  
                              day   = day)  
  ) %>%           
  select(sta, date, prcp) 

# export and clean-up data 
export(sta_dv_fill, "data/sta_dv_fill.csv")    
export(sta_mon, "data/sta_mon.csv")  

rm(sta_dv_alt,  
   sta_dv_fill)

```  

```{r import_streamflow_data, eval=FALSE}   
  
# import full streamflow records----   
#gage_mon_full <- import("data/gage_mon_full.csv")  
#gage_meta <-  import("data/gage_meta.csv")  
  
#gage_eco <- gage_mon_full %>% 
#  select(sta, ecoreg) %>% 
#  distinct()  
  
# add ecoregions 
#lmom_gage_meta <- left_join(gage_meta, gage_eco, 
#                            by = "sta")  

#lmom_gage_meta <- right_join(gage_meta, gage_eco, 
#                            by = "sta")  
  
#rm(gage_eco)    
  
```

# use bootstrapping to check precip differences 
```{r bootstrap_precip}  
  
# Construct bootstrap confidence intervals of precipitation----   
#   to identify differences in means   
# Monthly precipitation data is from 1954 to 2018 = 65 years  
#   Split data into two groups of 30 years & test for differences  
  
# Notes on dabest and memory -- see setup for how to increase memory  
# dabest for 14,027 obs; 40,000 reps takes ~2 hours.    
#   Still had memory allocation issues @ 50,000 reps after increasing memory.   
  
# import final monthly precip data & prepare for bootstrapping====   
sta_mon <- import("data/sta_mon.csv") %>%  
  mutate(date = ymd(date)) %>%  
  mutate(yr = year(date)) %>%     
  
  # create an id variable  
  mutate(Period = case_when(   
    yr < 1989 ~ "<1989",  
    TRUE ~ ">1989")  
  ) %>%  
  # create a grouping variable   
  unite("group",   
        c("sta", "Period"),  
        sep = "",   
        remove = FALSE) %>%   
  arrange(date)   
  
# print a summary of the data====  
sta_mon %>%   
  group_by(group) %>%   
  summarise(count = n()) %>%   
  ungroup() %>%   
  mutate(num_yr = count/(12))  
  
# construct bootstrap confidence interval of prcp====   
prcp_dabest <- sta_mon %>%   
  dabest(x = group,             # grouping variable  
         y = prcp,              # measurement variable   
# list order shows control as first group on the list   
         idx = list(c("RAP<1989",  
                      "OEL<1989",  
                      "COT<1989",  
                      "GOR<1989",  
                      "ONI<1989",  
                      "MIS<1989"),   
                    c("RAP>1989",  
                      "OEL>1989",  
                      "COT>1989",   
                      "GOR>1989",  
                      "ONI>1989",  
                      "MIS>1989")  
         ),  
         paired    = TRUE,  
         reps      = 20000,  
         id.column = group   
  )  
  
# plot the dabest bootstrap====   
plot(prcp_dabest,  
     color.column = Period,  
     tick.fontsize = 5,  
     rawplot.type = "sinaplot",  
     axes.title.fontsize = 9,  
     rawplot.ylabel = "Monthly precipitation (mm)",  
     rawplot.groupwidth = 0.3,  
     palette = "Greys")  
  
# save results====   
ggplot2::ggsave(filename = "figure/prcp_dif.png",   
                width = 6.5, height = 4.5, units = "in")  
  
rm(prcp_dabest)    
```

<!--
need to finish this 
```{r ci_result_table, eval=FALSE}  

# get mean precipitation 
prcp <- spi_fin %>%  
  group_by(group) %>%  
  summarise(prcp = mean(prcp)) %>% 
  ungroup() 

rap_bef <- prcp %>% 
  filter(group == "RAP<1989") %>% 
  select(-group) %>% 
  as.double()

# pluck results for summary tables & bind====
prcp_results <- prcp_dabest %>% 
  pluck("result") %>% 
  select(-c(func,  
            paired,  
            variable,  
            bootstraps,  
            nboots,  
            pct_ci_low,  
            pct_ci_high  
  )  
  )   

prcp_results <- full_join(prcp_results, prcp, 
                  by = c("test_group" = "group")  
                  ) %>% 
  filter(test_group != "RAP<1989") %>% 
  mutate(control_group = case_when(  
    is.na(control_group) ~ "RAP<1989",  
    TRUE ~ control_group  
    )
  ) %>%  
  mutate(difference = case_when(  
    is.na(difference) ~ prcp - rap_bef,  
    TRUE ~ difference  
    )
  ) %>% 
  mutate(ci = as.integer(ci))  %>% 
  mutate_if(is.numeric, round, digits = 0)  


# convert tibble to a flextable after fixing vars for presentation==== 
prcp_table <- prcp_table %>% 
  flextable() %>% 
  #  colformat_num(col_keys = col_key_num, 
  #                big.mark=",", 
  #                digits = 1, na_str = "N/A") %>% 
  set_header_labels(control_group = "Control Group", 
                    test_group = "Test Groups", 
                    control_size = "Control Size",
                    test_size = "Test Size", 
                    func = "Test Statistic", 
                    variable = "Variable",
                    difference = "Mean Difference", 
                    ci = "CI", 
                    bca_ci_low = "Lower Limit", 
                    bca_ci_high = "Upper Limit") %>% 
  autofit() %>% 
  align(., part = "all", align = "center") %>% 
  theme_booktabs() 


ci_table2 <- read_docx() %>% 
  body_add_flextable(value = ci_table)  

print(ci_table2, target = "output/ci_table.docx") 

rm(ci_results_pc1, ci_results_pc2, ci_table2, ci_table) 

```  
-->

```{r compare_precip_locations}  
   
# the bootstrapping showed there is some difference between past & present   
sta_pres <- sta_mon %>%   
  filter(yr > 1988)   
  
export(sta_pres, "data/sta_pres.csv")  
  
# comparison of locations----   
# split out northwest & southeast to prepare for plot    
nw <- sta_pres %>%  
  filter(sta == "COT" |  
         sta == "RAP" |  
         sta == "OEL") %>%  
  select(sta, date, prcp) %>%  
  mutate(prcp = prcp + 1) %>%  
  spread(sta, prcp) %>%   
  gather(other, prcp, -c(date, COT)) %>%  
  mutate(location = "COT") %>%  
  rename(control = COT)   
  
se <- sta_pres %>%  
  filter(sta == "GOR" |  
         sta == "ONI" |  
         sta == "MIS") %>%  
  select(sta, date, prcp) %>%  
  mutate(prcp = prcp + 1) %>%  
  spread(sta, prcp) %>%   
  gather(other, prcp, -c(date, GOR)) %>%  
  mutate(location = "GOR")  %>%  
  rename(control = GOR)  
  
# join splits & create factor     
prcp_compare <- bind_rows(nw, se) %>%  
  mutate(diff = control - prcp) %>%    
  mutate(other = fct_relevel(other,  
                           "RAP",  
                           "OEL",  
                           "ONI",  
                           "MIS"  
  ))  
  
# plot location differences  
prcp_compare %>%   
ggplot(aes(date, diff)) +  
  theme_bw() +  
  xlab("") +  
  ylab("Monthly precipitation difference (mm)") +  
  facet_grid(cols    = vars(location),  
             rows    = vars(other)) +  
  geom_line(color    = "gray60") +  
  geom_smooth(method = "lm",  
              color  = "gray30",  
              size   = 0.5  
              )  
  
ggplot2::ggsave(filename = "figure/prcp_loc_dif.png",   
                width = 6.5, height = 4.5, units = "in")  

rm(nw,  
   se,  
   prcp_compare  
   )  

rm(sta_mon)  
  
```

# L-moments 
```{r lmoments_prcp, eval=FALSE}

sta_pres     <- import("data/sta_pres.csv")  
sta_meta_fin <- import("data/sta_meta_fin.csv")

# Note that we might consider Weiss 1964 bias value of 1.018 for L1   
  
# Calculate L-moment ratios   
lmom_sta <- sta_pres %>%  
  split(.$sta) %>%  
  map(~ lmoms(.$prcp)) %>%    
  transpose() %>%  
  as_tibble() %>%  
  select(lambdas, ratios) %>%  
  mutate(lambdas = map(lambdas,   
                       ~as_tibble(t(.x))  
  )) %>%   
  mutate(lambdas = map(lambdas,    
                       ~set_names(.x,   
                                  c("L1", "L2", "L3", "L4", "L5")  
                       )  
  )) %>%   
  mutate(ratios = map(ratios,   
                      ~as_tibble(t(.x)    
                      )   
  )) %>%  
  mutate(ratios = map(ratios,  
                      ~set_names(.x,  
                                 c("T1", "T2", "T3", "T4", "T5")   
                      )   
  )) %>%  
  unnest(lambdas) %>%  
  unnest(ratios)  %>%   
  select(-T1) %>%  
  rename(L_CV = T2) %>%  
  rename(L_skew = T3) %>%  
  rename(L_kurtosis = T4) %>%  
  select(L1, L_CV, L_skew, L_kurtosis) %>%  
  mutate(L1 = round(L1,  
                    digits = 2)  
  )  
  
# get station names from the list  
lmom_sta_nm <- sta_pres %>%  
  split(.$sta) %>%  
  map(~ lmoms(.$prcp)) %>%  
  transpose()  
  
lmom_sta_nm <- lmom_sta_nm %>%  
  pluck(1) %>%  
  enframe()  
  
lmom_sta_nm <- lmom_sta_nm %>%  
  unnest(value)  
  
lmom_sta_nm <- lmom_sta_nm %>%  
  group_by(name) %>%  
  summarize(L1 = first(value)) %>%  
  ungroup() %>%  
  mutate(L1 = round(L1,  
                    digits = 2))  
  
# join name to lmom vals & to the metadata  
lmom_sta <- full_join(lmom_sta_nm, lmom_sta,  
                      by = "L1") %>%  
  rename(sta = name) %>%  
  mutate(L_CV = round(L_CV,  
                      digits = 2)  
  ) %>%  
  mutate(L_skew = round(L_skew,  
                        digits = 2)  
  ) %>%  
  mutate(L_kurtosis = round(L_kurtosis,  
                            digits = 2)  
  )  
  
# join the lmoments to the metadata   
sta_meta_lmom <- full_join(sta_meta_fin, lmom_sta,   
                           by = "sta")   

export(sta_meta_lmom, "data/sta_meta_lmom.csv")    
   
rm(sta_meta_fin,   
   lmom_sta_nm,  
   sta_pres  
   )   
  
```

```{r lmoments_streamflow, eval=FALSE} 
  
# import full streamflow records----   
gage_mon_full <- import("data/gage_mon_full.csv")  
gage_meta <-  import("data/gage_meta.csv")  
  
# Note -- we might consider Weiss 1964 bias value of 1.018 for L1     
  
# Calculate L-moment ratios   
lmom_gage <- gage_mon_full %>%  
  split(.$sta) %>%  
  map(~ lmoms(.$log_q1_mon)) %>%    
  transpose() %>%  
  as_tibble(rownames = sta) %>%  
  select(lambdas, ratios) %>%  
  mutate(lambdas = map(lambdas,   
                       ~as_tibble(t(.x))  
  )) %>%  
  mutate(lambdas = map(lambdas,   
                       ~set_names(.x,  
                                  c("L1", "L2", "L3", "L4", "L5")  
                       )  
  )) %>%  
  mutate(ratios = map(ratios,  
                      ~as_tibble(t(.x)   
                      )   
  )) %>%  
  mutate(ratios = map(ratios,  
                      ~set_names(.x,  
                                 c("T1", "T2", "T3", "T4", "T5")   
                      )   
  )) %>%  
  unnest(lambdas) %>%  
  unnest(ratios)  %>%   
  select(-T1) %>%  
  rename(L_CV = T2) %>%  
  rename(L_skew = T3) %>%  
  rename(L_kurtosis = T4) %>%  
  select(L1, L_CV, L_skew, L_kurtosis) %>%  
  mutate(L1 = round(L1,  
                    digits = 2)  
  )  
  
# get station names from the list  
lmom_gage_list <- gage_mon_full %>%  
  split(.$sta) %>%  
  map(~ lmoms(.$log_q1_mon)) %>%  
  transpose()  
  
lmom_gage_nm <- lmom_gage_list %>%  
  pluck(2) %>%                     # plucks lmom-ratios  
  enframe()  
  
lmom_gage_nm <- lmom_gage_nm %>%  
  unnest(value) %>%  
  drop_na() %>%  
  rename(sta = name) %>%  
  group_by(sta) %>%  
  summarize(L_CV = first(value))  
  
# join name to lmom vals & to the metadata  
lmom_gage <- full_join(lmom_gage_nm, lmom_gage,  
                        by = ("L_CV"))  
  
# check value  
bad_fpi <- tibble(lmom_gage_list[["ratios"]][["bad_fpi"]])  
  
# clean up df & join with metadata====  
lmom_gage <- lmom_gage %>%  
  gather(type, value, -sta) %>%  
  mutate(value = round(value,  
                       digits = 2)  
         ) %>%   
  spread(type, value) %>%  
  select(sta, L1, L_CV, L_skew, L_kurtosis)  
  
lmom_gage <- full_join(gage_meta, lmom_gage,    
                            by = "sta") %>%  
  drop_na()  
  
# check stations for discordance & prepare for join====    
dischord <- lmrdiscord(site = lmom_gage$sta,  
                       #                       Dcrit = 2.5,  
                       digits = 2,  
                       t2 = lmom_gage$L_CV,  
                       t3 = lmom_gage$L_skew,   
                       t4 = lmom_gage$L_kurtosis  
) %>%  
  mutate(site = as.character(site)) %>%  
  rename(sta = site) %>%  
  rename(L_CV = t2) %>%  
  rename(L_skew = t3) %>%  
  rename(L_kurtosis = t4)  
  
lmom_gage <- full_join(lmom_gage, dischord, 
                  by = c("sta", "L_CV", "L_skew", 'L_kurtosis'))  
  
export(lmom_gage, "data/gage_meta_lmom.csv")   
  
# clean up  
rm(gage_meta,  
   bad_fpi,  
   lmom_gage_list,  
   lmom_gage_nm,  
   lmom_gage,  
   gage_mon_full,  
   dischord  
   )  
  
```

```{r Lmoment_diagram_ratios}
# extract elements from the lmrdia list to plot in ggplot2        
#   the x-value is the L-skewness and y-value is L-kurtosis    
  
# get vals from the lmrdia list   
# note that as gamma distribution is a 2-parameter dist, it is not shown  
lmrdia <- lmrdia()   
  
# extract L-skew & L-kurtosis values for several distributions   
#   note:  aep4 <- lmrdia %>% extract2(2) %>% as.tibble()    
  
gev <- lmrdia[[5]]  %>%  
  as_tibble() %>%  
  mutate(distribution = "GEV")      
  
glo <- lmrdia[[6]]  %>%   
  as_tibble() %>%          
  mutate(distribution = "GLO")  
  
gpa <- lmrdia[[7]]  %>%   
  as_tibble() %>%         
  mutate(distribution = "GPA")   
  
gno <- lmrdia[[9]]  %>%   
  as_tibble() %>%      
  mutate(distribution = "GNO")  
  
gov <- lmrdia[[10]] %>%    
  as_tibble() %>%     
  mutate(distribution = "GOV")  
  
pe3 <- lmrdia[[12]] %>%   
  as_tibble() %>%         
  mutate(distribution = "PE3")     
  
lmom_theo <- bind_rows(gev,   
                  glo,   
                  gpa,   
                  gno,   
                  gov,   
                  pe3   
                  ) %>%  
  rename(L_skew = V1) %>%  
  rename(L_kurtosis = V2)  
  
rm(gev,   
   glo,   
   gpa,   
   gno,   
   gov,   
   pe3,   
   lmrdia   
   )   
  
```  

# need to improve the plot with adding high discord gages 
```{r plot-lmoment-diagram} 
  
# prepare station data for plot====  
lmom_sta <- import("data/sta_meta_lmom.csv") %>%  
  select(sta,  
         L1,  
         L_CV,  
         L_skew,  
         L_kurtosis  
  ) %>%  
  mutate(flow_regime = "precipitation") %>%  
  mutate(ecoreg = "NA") %>%  
  mutate(type = "sta")  
  
# prepare gage data for plot====       
# drop discordant stations & calculate ecoregion vals  
lmom_gage <- import("data/gage_meta_lmom.csv") 

discord <- lmom_gage %>% 
  filter(isD == TRUE)  

lmom_gage <- lmom_gage %>%  
  select(sta,  
         flow_regime,  
         ecoreg,  
         L1,   
         L_CV,   
         L_skew,   
         L_kurtosis,  
         isD   
  ) %>%  
  filter(isD == FALSE)  %>% 
  select(-isD) %>%  
  mutate(type = "gage")  

# calculate ecoregion values  
lmom_ecoreg <- lmom_gage %>%  
  group_by(ecoreg) %>%  
  summarise(L1         = mean(L1),  
            L_CV       = mean(L_CV),  
            L_skew     = mean(L_skew),  
            L_kurtosis = mean(L_kurtosis),  
            n          = n()  
            ) %>%  
  ungroup() %>%  
  gather(key, val, -ecoreg) %>%  
  mutate(val           = round(val, digits = 2)) %>%  
  spread(key, val) %>%  
  select(ecoreg, L1, L_CV, L_skew, L_kurtosis) %>%  
  mutate(sta           = NA) %>%  
  mutate(flow_regime   = "ecoregion mean") %>%  
  mutate(type          = "gage")  
  
# join station & individual gage data  
lmom_data <- bind_rows(lmom_gage,  
                       lmom_sta,   
                       lmom_ecoreg  
)  
  

# refactor levels and provide label names====   
lmom_data <- lmom_data %>%   
  mutate(ecoreg = fct_relevel(ecoreg,   
                              "NA",   
                              "Sand Hills",   
                              "Keya Paha Tablelands",  
                              "Black Hills Plateau",  
                              "White River Badlands",  
                              "Pine Ridge Escarpment",  
                              "Pierre Shale Plains")    
  ) %>%   
  mutate(flow_regime = fct_relevel(flow_regime,   
                                   "precipitation",   
                                   "perennial",   
                                   "intermittent",   
                                   "ecoregion mean"  
  ))    
  
type_labels <- c(  
  gage = "stream gages",  
  sta = "weather stations"  
)  
  
# plot the theoretical distributions, and sample vals----    
ggplot(lmom_data,    
       aes(x = L_skew,  
           y = L_kurtosis  
       )) +  
  labs(x = "L-skew",  
       y = "L-kurtosis"  
  ) +   
  xlim(-0.4, 0.4) +  
  ylim(-0.1, 0.3) +  
  theme_bw() +    
  theme(legend.title      = element_text(size = 10),  
        legend.text       = element_text(size = 8),  
        legend.key.height = unit(0.3, 'cm'),  
        legend.spacing    = unit(0.1, "cm")) +  
  guides(linetype         = guide_legend(order = 1),  
         color            = guide_legend(order = 2),   
         shape            = guide_legend(order = 3)  
  ) +     
  facet_grid(cols     = vars(type),   
             rows     = NULL,  
             scale    = "fixed",   
             labeller = labeller(  
               type     = type_labels  
             )  
  ) +  
  # add l-moments 
  geom_line(data = lmom_theo,  
            size = 0.5, 
            color = "gray30", 
            aes(L_skew,  
                L_kurtosis,  
                group = distribution,  
                linetype = distribution
            )) + 
  scale_linetype_discrete(name = "Distribution") + 
  # add individual station data 
  geom_point(
    size = 2, 
    aes(shape = flow_regime,   
        color = ecoreg
    )) + 
  scale_shape_discrete(name = "Type") +
  scale_colour_grey(
    breaks = rev(
      levels(lmom_data$ecoreg)  
    ), 
    guide = "legend", 
    start      = 0.0,    
    end        = 0.6,    
    na.value   = "red",   
    aesthetics = "colour",  
    name       = 'Ecoregion'  
  ) 
  
# save plot & table====  
ggplot2::ggsave(filename = "figure/lmom_plot.png",  
                width = 6, height = 3.6, units = "in")  
  
export(lmom_data, "data/lmom_table.csv")  
  
# clean-up====   
rm(lmom_theo,   
   lmom_gage,   
   lmom_ecoreg,    
   lmom_sta,   
   type_labels,  
   lmom_gage_meta,  
   sta_meta_lmom,  
   lmom_data   
)        
  
```  

# calculate SCI  
```{r identify_representive_gages} 
  
# import streamflow records & metadata----     
gage_mon <- import("data/gage_mon_full.csv")  
  
# remove discordant stations & discord calcs  
gage_meta <- import("data/gage_meta_lmom.csv") %>%  
  filter(isD == FALSE) %>%  
  select(-c(Dmax:Dcrit, isD, signif))  
  
gage_mon <- semi_join(gage_mon, gage_meta,  
                      by = c("sta", "ecoreg"))  


# get mean L-statistic values from discord calculations  
gage_mean <-  import("data/lmom_table.csv") %>%  
  filter(sta == "") %>%  
  select(ecoreg, L_CV, L_skew, L_kurtosis) %>%  
  rename(L_CV_mean   = L_CV) %>%   
  rename(L_skew_mean = L_skew) %>%  
  rename(L_kurt_mean = L_kurtosis)  
  
# find distance from centers  
gage_meta <- left_join(gage_meta, gage_mean,  
                       by = "ecoreg") %>%  
  mutate(L_CV_diff   = L_CV - L_CV_mean) %>%  
  mutate(L_skew_diff = L_skew - L_skew_mean) %>%  
  mutate(L_kurt_diff = L_kurtosis - L_kurt_mean) %>%  
  mutate(D2 = round(digits = 2,  
                    sqrt(L_CV_diff^2 + L_skew_diff^2 + L_kurt_diff^2)  
                    )  
         ) %>%  
  arrange(D2)  
  
# select gages by ecoreg by distance from centroid====     
#gage_pick <- gage_meta %>%   
#  group_by(ecoreg) %>%  
#  summarise(sta    = first(sta),  
#            L1     = first(L1),  
#            L_CV   = first(L_CV),  
#            L_skew = first(L_skew),  
#            L_kurt = first(L_kurtosis),  
#            D      = first(D),  
#            D2     = first(D2)  
#  )  
#gage_pick <- semi_join(gage_mon, gage_pick,  
#                        by = "sta") %>%  
  
# create a 30-year record for input  
sri_input <- gage_mon %>% 
  mutate(yr = year(Date)) %>%  
  filter(yr > 1988)     
  
# export selection and clean-up  
export(sri_input, "data/sri_input.csv")  
  
rm(sri_input,  
   gage_mean,  
   gage_meta,  
#   gage_pick,    
   gage_mon
  )   
  
```

```{r SCI_function, eval=FALSE} 
  
# fitSCI identifies Standardized Climate Index (SCI) parameters----       
#   some notes about the SCI package:      
#     the SCI package doesn't like snake_case variables,     
#     need to change tibble to a vector as double:    
#       cot <- as.double(sta_cot$depth_mm)      
  
# Initial values for SCI calculations====       
time_scale <- 1     # sets the length of the averaging period    
distrib    <- "pe3" # sets the distribution type    
p_zero     <- TRUE  # sets a function to reduce zero-precip bias   
p_zero_cm  <- TRUE  # uses Weibull plotting position for p_zero     
scale      <- "sd"  # scales input by subtract mean & divide by sd     
warn_me    <- TRUE  # sets explicit warning    
first_mon  <- 1     # Set first month for each station   
sci.limit  <- 3.5     # Sets a limit of [-3, 3] for limit   
  
# sci function====                                            
sci.fun <- function(sta, time_scale) fitSCI( x = sta,    
                                             start.fun.fix  = TRUE,    
                                             time.scale     = time_scale,    
                                             first.mon      = first_mon,   
                                             distr          = distrib,   
                                             p0             = p_zero,     
                                             p0.center.mass = p_zero_cm,     
                                             scaling        = scale,     
                                             warn	         = warn_me     
)     
  
```  

```{r prepare_calculate_SPI, eval=FALSE}
  
# prepare sci function vector inputs (1989-01 to 2017-01)----     
# north-west (NW)   
sta_rap <- sta_pres %>%   
  arrange(date) %>%   
  filter(sta == "RAP")   
  
rap <- as.double(sta_rap$prcp)   
  
# north-central (NC)  
sta_cot <- sta_pres %>%   
  arrange(date) %>%  
  filter(sta == "COT")   
  
cot <- as.double(sta_cot$prcp)   
  
# north-east (NE)  
sta_oni <- sta_pres %>%  
  arrange(date) %>%   
  filter(sta == "ONI")    
  
oni <- as.double(sta_oni$prcp)   
  
# south-west (SW)   
sta_oel <- sta_pres %>%  
  arrange(date) %>%  
  filter(sta == "OEL")   
  
oel <- as.double(sta_oel$prcp)   
  
# south-central (SC)  
sta_gor <- sta_pres %>%  
  arrange(date) %>%  
  filter(sta == "GOR")    
  
gor <- as.double(sta_gor$prcp)   
  
# south-east (SE)  
sta_mis <- sta_pres %>%  
  arrange(date) %>% 
  filter(sta == "MIS")   
  
mis <- as.double(sta_mis$prcp)   
  
# calculate SCI-rap----  
# set up the station for sci & make sci list vars====   
sta      <- rap  
sci_1mo  <- sci.fun(sta, 1)                             
sci_2mo  <- sci.fun(sta, 2)                             
sci_3mo  <- sci.fun(sta, 3)                             
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)    
sci_9mo  <- sci.fun(sta, 9)    
sci_12mo <- sci.fun(sta, 12)   
  
# Apply the transformation identified by fitSCI function====   
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,    
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   
  
# bind and rename the sci vals====      
sci_rap <- bind_cols(sta_rap,     
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%      
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# clean up global environment====  
rm(sci_1mo,  
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(sta_rap, rap)   
  
# calculate SCI-cot----   
# set up the station for sci & make sci list vars   
sta      <- cot  
sci_1mo  <- sci.fun(sta, 1)                               
sci_2mo  <- sci.fun(sta, 2)                             
sci_3mo  <- sci.fun(sta, 3)                            
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)   
sci_9mo  <- sci.fun(sta, 9)   
sci_12mo <- sci.fun(sta, 12)  
  
# Apply the transformation identified by fitSCI function    
sci_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)  
  
sci_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%  
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)  
  
sci_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%  
  enframe(name                     = NULL)  
  
# bind and rename the sci vals     
sci_cot <- bind_cols(sta_cot,     
                     sci_1mo,  
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,  
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo   
) %>%    
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%  
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%  
  rename(sci_6mo = value4)  %>%  
  rename(sci_9mo = value5)  %>%   
  rename(sci_12mo = value6)  
  
# clean up global environment  
rm(sci_1mo,  
   sci_2mo,  
   sci_3mo,  
   sci_4mo,  
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )     
rm(sta_cot, cot)  
  
# calculate SCI-oni----   
# set up the station for sci & make sci list vars     
sta      <- oni    
sci_1mo  <- sci.fun(sta, 1)                              
sci_2mo  <- sci.fun(sta, 2)                             
sci_3mo  <- sci.fun(sta, 3)                            
sci_4mo  <- sci.fun(sta, 4)   
sci_6mo  <- sci.fun(sta, 6)   
sci_9mo  <- sci.fun(sta, 9)   
sci_12mo <- sci.fun(sta, 12)  
  
# Apply the transformation identified by fitSCI function      
sci_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)  
  
sci_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%  
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)  
  
sci_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%  
  enframe(name                     = NULL)  
  
# bind and rename the sci vals     
sci_oni <- bind_cols(sta_oni,     
                     sci_1mo,  
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,  
                     sci_6mo,  
                     sci_9mo,  
                     sci_12mo  
) %>%  
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%  
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%  
  rename(sci_6mo = value4)  %>%  
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# clean up global environment  
rm(sci_1mo,  
   sci_2mo,  
   sci_3mo,  
   sci_4mo,  
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )    
rm(sta_oni, oni)  
  
# calculate SCI-oel----  
# set up the station for sci & make sci list vars   
sta      <- oel  
sci_1mo  <- sci.fun(sta, 1)                              
sci_2mo  <- sci.fun(sta, 2)                             
sci_3mo  <- sci.fun(sta, 3)                            
sci_4mo  <- sci.fun(sta, 4)   
sci_6mo  <- sci.fun(sta, 6)   
sci_9mo  <- sci.fun(sta, 9)    
sci_12mo <- sci.fun(sta, 12)  
  
# Apply the transformation identified by fitSCI function       
sci_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = sci_1mo) %>%  
  enframe(name = NULL)  
  
sci_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = sci_2mo) %>%  
  enframe(name = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = sci_3mo) %>%  
  enframe(name = NULL)  
  
sci_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = sci_4mo) %>%  
  enframe(name = NULL)  
  
sci_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = sci_6mo) %>%  
  enframe(name = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = sci_9mo) %>%  
  enframe(name = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj = sci_12mo) %>%  
  enframe(name = NULL)  
  
# bind and rename the sci vals   
sci_oel <- bind_cols(sta_oel,     
                     sci_1mo,  
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,  
                     sci_6mo,   
                     sci_9mo,    
                     sci_12mo  
) %>%   
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%  
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%  
  rename(sci_6mo = value4)  %>%  
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)      
  
# clean up global environment        
rm(sci_1mo,  
   sci_2mo,  
   sci_3mo,  
   sci_4mo,  
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )    
rm(sta_oel, oel)    
  
# calculate SCI-gor----  
# set up the station for sci & make sci list vars   
sta      <- gor    
sci_1mo  <- sci.fun(sta, 1)                              
sci_2mo  <- sci.fun(sta, 2)                             
sci_3mo  <- sci.fun(sta, 3)                            
sci_4mo  <- sci.fun(sta, 4)   
sci_6mo  <- sci.fun(sta, 6)   
sci_9mo  <- sci.fun(sta, 9)   
sci_12mo <- sci.fun(sta, 12)  
  
# Apply the transformation identified by fitSCI function        
sci_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)  
  
sci_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%  
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)  
  
sci_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%  
  enframe(name                     = NULL)  
  
# bind and rename the sci vals      
sci_gor <- bind_cols(sta_gor,     
                     sci_1mo,  
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,  
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo     
) %>%  
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%  
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%  
  rename(sci_6mo = value4)  %>%  
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)    
  
# clean up global environment    
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,   
   sci_4mo,  
   sci_6mo,  
   sci_9mo,  
   sci_12mo   
   )    
rm(sta_gor, gor)    
  
# calculate sci-mis----  
# set up the station for sci & make sci list vars   
sta      <- mis  
sci_1mo  <- sci.fun(sta, 1)                              
sci_2mo  <- sci.fun(sta, 2)                             
sci_3mo  <- sci.fun(sta, 3)                            
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)   
sci_9mo  <- sci.fun(sta, 9)   
sci_12mo <- sci.fun(sta, 12)  
  
# Apply the transformation identified by fitSCI function     
sci_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)  
  
sci_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%  
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)  
  
sci_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%  
  enframe(name                     = NULL)  
  
# bind and rename the sci vals     
sci_mis <- bind_cols(sta_mis,     
                     sci_1mo,  
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,  
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo   
) %>%  
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%  
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%  
  rename(sci_6mo = value4)  %>%  
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6) 
  
# clean up global environment  
rm(sci_1mo,  
   sci_2mo,  
   sci_3mo,  
   sci_4mo,  
   sci_6mo,  
   sci_9mo,  
   sci_12mo   
   )   
rm(sta_mis, mis)      
  
# join sci data----   
sci_sta <- bind_rows(  
  sci_rap,  
  sci_cot,  
  sci_oni,  
  sci_oel,  
  sci_gor,  
  sci_mis  
) %>%  
  select(-c(Period, group)) %>%  
    # truncate sci vals to [-3, 3]    
  gather(key = type, val = value, -c(sta, date, yr, prcp)) %>%  
  mutate(value = case_when(     
    value < -3.0 ~ -3.0,    
    value >  3.0 ~  3.0,  
    TRUE ~ value)) %>%  
  spread(type, value) %>%    
  # move the longer sci-values to the end of the df    
  select(-sci_12mo, sci_12mo)    
  
# export sci data        
export(sci_sta, "data/sci_sta.csv")  
  
# clean up workspace    
rm(distrib,  
   first_mon,   
   p_zero,   
   p_zero_cm,   
   scale,   
   sci.limit,   
   sta,   
   time_scale,   
   warn_me,  
   sci.fun,  
   sci_cot,  
   sci_gor,  
   sci_mis,  
   sci_oel,  
   sci_oni,  
   sci_rap,  
   sta_pres  
   )         
  
```  

```{r prepare_SRI, eval=FALSE} 
  
# import and check gage data (1989-01 to 2017-01)----    
sri_input <- import("data/sri_input.csv") %>%    
  rename(date = Date) %>%   
  arrange(date) %>%  
  select(  
    sta,  
    ecoreg,  
    date,  
    log_q1_mon,  
    yr  
  )  
  
sri_check <- sri_input %>%  
  group_by(sta) %>%  
  summarise(min_yr = min(yr), 
            max_yr = max(yr)  
  )  
  
sri_check <- sri_input %>%  
  filter(yr == "1989") %>%  
  mutate(mon = month(date)) %>%   
  arrange(date) %>%              
  group_by(sta, ecoreg) %>%  
  summarise(min_mon = min(mon), 
            max_mon = max(mon)  
  ) %>%  
  ungroup() %>%  
  arrange(ecoreg)  
  
sri_input <- sri_input %>%  
  select(-yr)  
  
# prepare vector inputs as double for SCI fun----   
# Black Hills Plateau (bhp) gages====    
bhp_bat <- sri_input %>%  
  filter(sta == "bat_her")    
  
bhp_bev <- sri_input %>%  
  filter(sta == "bev_buf")  
  
bhp_fal <- sri_input %>%  
  filter(sta == "fal_hot")   
  
bhp_frn <- sri_input %>%  
  filter(sta == "frn_fai")    
  
bhp_bat_v <- as.double(bhp_bat$log_q1_mon)   
bhp_bev_v <- as.double(bhp_bev$log_q1_mon)  
bhp_fal_v <- as.double(bhp_fal$log_q1_mon)  
bhp_frn_v <- as.double(bhp_frn$log_q1_mon)  
  
# Keya Paha Tablelands (kpt) gages====   
kpt_key <- sri_input %>%   
  filter(sta == "key_key")   
  
kpt_wew <- sri_input %>%  
  filter(sta == "key_wew")   
  
kpt_key_v <- as.double(kpt_key$log_q1_mon)   
kpt_wew_v <- as.double(kpt_wew$log_q1_mon)   
  
# Pine Ridge Escarpment (pre) gages====   
pre_ogl <- sri_input %>%  
  filter(sta == "whi_ogl")   
  
pre_sta <- sri_input %>%  
  filter(sta == "whi_sta")   
  
pre_ogl_v <- as.double(pre_ogl$log_q1_mon)   
pre_sta_v <- as.double(pre_sta$log_q1_mon)   
  
# Pierre Shale Plains (psp) gages====     
psp_bat <- sri_input %>%  
  filter(sta == "bat_bhr")    
  
psp_brs <- sri_input %>%  
  filter(sta == "brsf_co")    
  
psp_che <- sri_input %>%  
  filter(sta == "che_was")    
  
psp_elk <- sri_input %>%  
  filter(sta == "elk_elm")    
  
psp_hat <- sri_input %>%  
  filter(sta == "hat_edg")    
  
psp_whi <- sri_input %>%  
  filter(sta == "whi_oac")    
  
psp_bat_v <- as.double(psp_bat$log_q1_mon)   
psp_brs_v <- as.double(psp_brs$log_q1_mon)   
psp_che_v <- as.double(psp_che$log_q1_mon)   
psp_elk_v <- as.double(psp_elk$log_q1_mon)   
psp_hat_v <- as.double(psp_hat$log_q1_mon)   
psp_whi_v <- as.double(psp_whi$log_q1_mon)  
   
# Sand Hills (snd) gages====   
snd_lcr <- sri_input %>%  
  filter(sta == "lcr_bel")     
  
snd_lon <- sri_input %>%  
  filter(sta == "lon_riv")     
  
snd_mar <- sri_input %>%  
  filter(sta == "lwr_mar")     
  
snd_ros <- sri_input %>%  
  filter(sta == "lwr_ros")     
  
snd_vet <- sri_input %>%  
  filter(sta == "lwr_vet")     
  
snd_whi <- sri_input %>%  
  filter(sta == "lwr_whi")    
  
snd_nio <- sri_input %>%  
  filter(sta == "nio_spa")     
  
snd_lcr_v <- as.double(snd_lcr$log_q1_mon)   
snd_lon_v <- as.double(snd_lon$log_q1_mon)   
snd_mar_v <- as.double(snd_mar$log_q1_mon)   
snd_ros_v <- as.double(snd_ros$log_q1_mon)   
snd_vet_v <- as.double(snd_vet$log_q1_mon)   
snd_whi_v <- as.double(snd_whi$log_q1_mon)   
snd_nio_v <- as.double(snd_nio$log_q1_mon)   
  
# White River Badlands (bad) gages====     
bad_whi <- sri_input %>%  
  filter(sta == "whi_kad")   
  
bad_whi_v <- as.double(bad_whi$log_q1_mon)   
  
# clean up====    
rm(sri_check,  
   sri_input  
)   
  
```  

```{r calculate_SRI}

# calculate SCI_blp----  
# SCI calcs - bha_bat -- set up the station for sci & make sci list vars====  
sta      <- bhp_bat_v   
sci_1mo  <- sci.fun(sta, 1)                             
sci_2mo  <- sci.fun(sta, 2)                             
sci_3mo  <- sci.fun(sta, 3)                           
sci_4mo  <- sci.fun(sta, 4)     
sci_6mo  <- sci.fun(sta, 6)    # month 12 fail  
sci_9mo  <- sci.fun(sta, 9)    
sci_12mo <- sci.fun(sta, 12)   
  
# bha_bat -- apply the transformation identified by fitSCI function====      
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo, 
                         sci.limit = sci.limit  
                         ) %>%  
  enframe(name                     = NULL)    
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo,
                         sci.limit = sci.limit  
                         ) %>%  
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo, 
                         sci.limit = sci.limit  
                         ) %>%   
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo, 
                         sci.limit = sci.limit  
                         ) %>%    
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo, 
                         sci.limit = sci.limit  
                         ) %>%    
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo, 
                         sci.limit = sci.limit  
                         ) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo, 
                         sci.limit = sci.limit  
                         ) %>%    
  enframe(name                     = NULL)   
  
# bha_bat -- bind and rename the sci vals====         
sci_bhp_bat <- bind_cols(bhp_bat,     
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,   
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)   
  
# bha_bat -- clean up global environment====  
rm(sci_1mo,  
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(bhp_bat, bhp_bat_v)   
  
# SCI calcs - bhp_bev -- set up the station for sci & make sci list vars====    
sta      <- bhp_bev_v  
sci_1mo  <- sci.fun(sta, 1)                             
sci_2mo  <- sci.fun(sta, 2)                             
sci_3mo  <- sci.fun(sta, 3)                             
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)    
sci_9mo  <- sci.fun(sta, 9)    
sci_12mo <- sci.fun(sta, 12)   
  

# bha_bev -- apply the transformation identified by fitSCI function====      
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   
  
# bha_bev -- bind and rename the sci vals====        
sci_bhp_bev <- bind_cols(bhp_bev,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%   
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# bha_bev -- clean up global environment====  
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(bhp_bev, bhp_bev_v)   
  
# SCI calcs - bha_fal -- set up the station for sci & make sci list vars====    
sta      <- bhp_fal_v   
sci_1mo  <- sci.fun(sta, 1)                             
sci_2mo  <- sci.fun(sta, 2)    # MLE fail for month 4                      
sci_3mo  <- sci.fun(sta, 3)    # MLE fail for month 1-, 5-        
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)    # MLE fail for month 6-  
sci_9mo  <- sci.fun(sta, 9)    # MLE fail for month 7-, 8-  
sci_12mo <- sci.fun(sta, 12)   # MLE fail for month 8-, 9-  
  

# bha_fal -- apply the transformation identified by fitSCI function====      
sci_1mo  <- transformSCI(sta,     
                         first.mon = first_mon,   
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   
  
# bha_fal -- bind and rename the sci vals====      
sci_bhp_fal <- bind_cols(bhp_fal,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# bha_fal -- clean up global environment====  
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(bhp_fal, bhp_fal_v)   
  
# SCI calcs - bha_frn -- set up the station for sci & make sci list vars====  
sta      <- bhp_frn_v   
sci_1mo  <- sci.fun(sta, 1)                             
sci_2mo  <- sci.fun(sta, 2)    # MLE fail for month 8-, 11-                 
sci_3mo  <- sci.fun(sta, 3)           
sci_4mo  <- sci.fun(sta, 4)    # MLE fail for month 1- 
sci_6mo  <- sci.fun(sta, 6)     
sci_9mo  <- sci.fun(sta, 9)      
sci_12mo <- sci.fun(sta, 12)   
  
# bha_frn -- apply the transformation identified by fitSCI function====    
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)    
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   
  
# bha_frn -- bind and rename the sci vals====      
sci_bhp_frn <- bind_cols(bhp_frn,       
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# bha_frn -- clean up global environment====  
rm(sci_1mo,    
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(bhp_frn, bhp_frn_v)   
  
# calculate SCI_kpt----  
# SCI calcs - kpt_key -- set up the station for sci & make sci list vars====   
sta      <- kpt_key_v  
sci_1mo  <- sci.fun(sta, 1)    # MLW fail for month 11-                      
sci_2mo  <- sci.fun(sta, 2)    # MLE fail for month 10-                        
sci_3mo  <- sci.fun(sta, 3)           
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)     
sci_9mo  <- sci.fun(sta, 9)    # MLE fail for month 2-, 8-       
sci_12mo <- sci.fun(sta, 12)   # MLE fail for month 8-, 10-     
  
# kpt_key -- apply the transformation identified by fitSCI function====     
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   
  
# kpt_key -- bind and rename the sci vals====      
sci_kpt_key <- bind_cols(kpt_key,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# kpt_key -- clean up global environment====  
rm(sci_1mo,    
   sci_2mo,   
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(kpt_key, kpt_key_v)   
  
# SCI calcs - kpt_wew -- set up the station for sci & make sci list vars==== 
sta      <- kpt_wew_v  
sci_1mo  <- sci.fun(sta, 1)                       
sci_2mo  <- sci.fun(sta, 2)                        
sci_3mo  <- sci.fun(sta, 3)           
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)     
sci_9mo  <- sci.fun(sta, 9)         
sci_12mo <- sci.fun(sta, 12)   
  
# kpt_wew -- apply the transformation identified by fitSCI function====    
sci_1mo  <- transformSCI(sta,     
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   
  
# kpt_wew -- bind and rename the sci vals====      
sci_kpt_wew <- bind_cols(kpt_wew,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# kpt_wew -- clean up global environment====   
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(kpt_wew, kpt_wew_v)   
  
# calculate SCI_pre---- 
# SCI calcs - pre_ogl -- set up the station for sci & make sci list vars====   
sta      <- pre_ogl_v  
sci_1mo  <- sci.fun(sta, 1)    # MLE fail month 9-, 11-                       
sci_2mo  <- sci.fun(sta, 2)    # MLE fail month 11-                     
sci_3mo  <- sci.fun(sta, 3)    # MLE fail month 12-     
sci_4mo  <- sci.fun(sta, 4)    # MLE fail month 2- 
sci_6mo  <- sci.fun(sta, 6)    # MLE fail month 3-, 4-, 5-   
sci_9mo  <- sci.fun(sta, 9)         
sci_12mo <- sci.fun(sta, 12)   
  
# pre_ogl -- apply the transformation identified by fitSCI function====     
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# pre_ogl -- bind and rename the sci vals====        
sci_pre_ogl <- bind_cols(pre_ogl,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# pre_ogl -- clean up global environment====   
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(pre_ogl, pre_ogl_v)   
  
# SCI calcs - pre_sta -- set up the station for sci & make sci list vars====   
sta      <- pre_sta_v  
sci_1mo  <- sci.fun(sta, 1)    # MLE fail month 9-                    
sci_2mo  <- sci.fun(sta, 2)    # MLE fail month 10-                     
sci_3mo  <- sci.fun(sta, 3)             
sci_4mo  <- sci.fun(sta, 4)          
sci_6mo  <- sci.fun(sta, 6)            
sci_9mo  <- sci.fun(sta, 9)         
sci_12mo <- sci.fun(sta, 12)   
  
# pre_sta -- apply the transformation identified by fitSCI function====      
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# pre_sta -- bind and rename the sci vals====       
sci_pre_sta <- bind_cols(pre_sta,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# pre_sta -- clean up global environment====   
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(pre_sta, pre_sta_v)  
  
# calculate SCI_psp---- 
# SCI calcs - psp_bat -- set up the station for sci & make sci list vars====   
sta      <- psp_bat_v  
sci_1mo  <- sci.fun(sta, 1)    # MLE fail month 10-                    
sci_2mo  <- sci.fun(sta, 2)    # MLE fail month 10-, 11-                      
sci_3mo  <- sci.fun(sta, 3)    # MLE fail month 9-, 11-              
sci_4mo  <- sci.fun(sta, 4)    # MLE fail month 8-, 11-            
sci_6mo  <- sci.fun(sta, 6)    # MLE fail month 10-, 11-              
sci_9mo  <- sci.fun(sta, 9)    # MLE fail month 1-            
sci_12mo <- sci.fun(sta, 12)   
  
# psp_bat -- apply the transformation identified by fitSCI function====      
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# psp_bat -- bind and rename the sci vals====       
sci_psp_bat <- bind_cols(psp_bat,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# psp_bat -- clean up global environment====   
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(psp_bat, psp_bat_v)  
  
# SCI calcs - psp_brs -- set up the station for sci & make sci list vars====   
sta      <- psp_brs_v  
sci_1mo  <- sci.fun(sta, 1)    # MLE fail month 4-, 6-, 12-                    
sci_2mo  <- sci.fun(sta, 2)    # MLE fail month 4-, 7-                      
sci_3mo  <- sci.fun(sta, 3)    # MLE fail month 1-, 2-               
sci_4mo  <- sci.fun(sta, 4)    # MLE fail month 3-, 8-            
sci_6mo  <- sci.fun(sta, 6)                   
sci_9mo  <- sci.fun(sta, 9)                
sci_12mo <- sci.fun(sta, 12)   # MLE fail month 1-, 11-   
  
# psp_brs -- apply the transformation identified by fitSCI function====      
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# psp_brs -- bind and rename the sci vals====       
sci_psp_brs <- bind_cols(psp_brs,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# psp_brs -- clean up global environment====   
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(psp_brs, psp_brs_v)  
  
# SCI calcs - psp_che -- set up the station for sci & make sci list vars====   
sta      <- psp_che_v  
sci_1mo  <- sci.fun(sta, 1)                       
sci_2mo  <- sci.fun(sta, 2)                        
sci_3mo  <- sci.fun(sta, 3)                 
sci_4mo  <- sci.fun(sta, 4)               
sci_6mo  <- sci.fun(sta, 6)                   
sci_9mo  <- sci.fun(sta, 9)                
sci_12mo <- sci.fun(sta, 12)      
  
# psp_che -- apply the transformation identified by fitSCI function====      
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# psp_che -- bind and rename the sci vals====       
sci_psp_che <- bind_cols(psp_che,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# psp_che -- clean up global environment====   
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(psp_che, psp_che_v)  
  
# SCI calcs - psp_elk -- set up the station for sci & make sci list vars====   
sta      <- psp_elk_v  
sci_1mo  <- sci.fun(sta, 1)    # MLE fail months 1-, 2-, 3-, 6-, 7-, 10-, 12-  
sci_2mo  <- sci.fun(sta, 2)    # MLE fail months 6-, 8-, 9-, 10-, 11-, 12-  
sci_3mo  <- sci.fun(sta, 3)    # MLE fail months 4-, 7-, 9-, 11-             
sci_4mo  <- sci.fun(sta, 4)    # MLE fail months 1-, 2-, 3-, 4-, 7-, 9-, 11-  
sci_6mo  <- sci.fun(sta, 6)    # MLE fail months 1-, 2-, 4-, 6-, 7-, 12-  
sci_9mo  <- sci.fun(sta, 9)    # MLE fail months 1-, 2-, 3-, 8-, 12-                  
sci_12mo <- sci.fun(sta, 12)   # MLE fail months 3-, 5-, 6-, 11-        
  
# psp_elk -- apply the transformation identified by fitSCI function====      
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# psp_elk -- bind and rename the sci vals====       
sci_psp_elk <- bind_cols(psp_elk,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# psp_elk -- clean up global environment====   
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(psp_elk, psp_elk_v)  
  
# SCI calcs - psp_hat -- set up the station for sci & make sci list vars====   
sta      <- psp_hat_v  
sci_1mo  <- sci.fun(sta, 1)    # MLE fail months 8-, 9-  
sci_2mo  <- sci.fun(sta, 2)    # MLE fail months 10-  
sci_3mo  <- sci.fun(sta, 3)    # MLE fail months 8-             
sci_4mo  <- sci.fun(sta, 4)    # MLE fail months 2-  
sci_6mo  <- sci.fun(sta, 6)    # MLE fail months 2-   
sci_9mo  <- sci.fun(sta, 9)                
sci_12mo <- sci.fun(sta, 12)   # MLE fail months 3-       
  
# psp_hat -- apply the transformation identified by fitSCI function====      
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# psp_hat -- bind and rename the sci vals====       
sci_psp_hat <- bind_cols(psp_hat,       
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# psp_hat -- clean up global environment====   
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(psp_hat, psp_hat_v)  
  
# SCI calcs - psp_whi -- set up the station for sci & make sci list vars====   
sta      <- psp_whi_v  
sci_1mo  <- sci.fun(sta, 1)    # MLE fail months 7-   
sci_2mo  <- sci.fun(sta, 2)      
sci_3mo  <- sci.fun(sta, 3)                
sci_4mo  <- sci.fun(sta, 4)     
sci_6mo  <- sci.fun(sta, 6)     
sci_9mo  <- sci.fun(sta, 9)                 
sci_12mo <- sci.fun(sta, 12)        
  
# psp_whi -- apply the transformation identified by fitSCI function====      
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# psp_whi -- bind and rename the sci vals====       
sci_psp_whi <- bind_cols(psp_whi,       
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# psp_whi -- clean up global environment====   
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(psp_whi, psp_whi_v)  
  
# calculate SCI_snd---- 
# SCI calcs - snd_lcr -- set up the station for sci & make sci list vars====    
sta      <- snd_lcr_v  
sci_1mo  <- sci.fun(sta, 1)    # MLE fail month 5-                  
sci_2mo  <- sci.fun(sta, 2)                       
sci_3mo  <- sci.fun(sta, 3)       
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)    # MLE fail month 5-   
sci_9mo  <- sci.fun(sta, 9)    # MLE fail month 5-     
sci_12mo <- sci.fun(sta, 12)   # MLE fail month 5-, 6- 
  
# snd_lcr -- apply the transformation identified by fitSCI function====      
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# snd_lcr -- bind and rename the sci vals====        
sci_snd_lcr <- bind_cols(snd_lcr,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# snd_lcr -- clean up global environment====   
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(snd_lcr, snd_lcr_v)   
  
# SCI calcs - snd_lon -- set up the station for sci & make sci list vars####  
sta      <- snd_lon_v  
sci_1mo  <- sci.fun(sta, 1)                      
sci_2mo  <- sci.fun(sta, 2)                       
sci_3mo  <- sci.fun(sta, 3)       
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)      
sci_9mo  <- sci.fun(sta, 9)         
sci_12mo <- sci.fun(sta, 12)   # MLE fail month 1-, 6- 
  
# snd_lon -- apply the transformation identified by fitSCI function####    
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# snd_lon -- bind and rename the sci vals####      
sci_snd_lon <- bind_cols(snd_lon,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# snd_lon -- clean up global environment====  
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(snd_lon, snd_lon_v)   
  
# SCI calcs - snd_mar -- set up the station for sci & make sci list vars####  
sta      <- snd_mar_v  
sci_1mo  <- sci.fun(sta, 1)                      
sci_2mo  <- sci.fun(sta, 2)                       
sci_3mo  <- sci.fun(sta, 3)       
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)      
sci_9mo  <- sci.fun(sta, 9)         
sci_12mo <- sci.fun(sta, 12)   
  
# snd_mar -- apply the transformation identified by fitSCI function####    
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# snd_mar -- bind and rename the sci vals####      
sci_snd_mar <- bind_cols(snd_mar,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# snd_mar -- clean up global environment====  
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(snd_mar, snd_mar_v)    
  
# SCI calcs - snd_nio -- set up the station for sci & make sci list vars####  
sta      <- snd_nio_v  
sci_1mo  <- sci.fun(sta, 1)                      
sci_2mo  <- sci.fun(sta, 2)    # MLE fail month 12-                        
sci_3mo  <- sci.fun(sta, 3)       
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)      
sci_9mo  <- sci.fun(sta, 9)         
sci_12mo <- sci.fun(sta, 12)   
  
# snd_nio -- apply the transformation identified by fitSCI function####    
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# snd_nio -- bind and rename the sci vals####      
sci_snd_nio <- bind_cols(snd_nio,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# snd_nio -- clean up global environment====  
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(snd_nio, snd_nio_v)    
  
# SCI calcs - snd_ros -- set up the station for sci & make sci list vars####  
sta      <- snd_ros_v  
sci_1mo  <- sci.fun(sta, 1)    # MLE fail month 10-                     
sci_2mo  <- sci.fun(sta, 2)    # MLE fail month 5-                        
sci_3mo  <- sci.fun(sta, 3)       
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)      
sci_9mo  <- sci.fun(sta, 9)         
sci_12mo <- sci.fun(sta, 12)   
  
# snd_ros -- apply the transformation identified by fitSCI function####    
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# snd_ros -- bind and rename the sci vals####      
sci_snd_ros <- bind_cols(snd_ros,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# snd_ros -- clean up global environment====  
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(snd_ros, snd_ros_v)    
  
# SCI calcs - snd_vet -- set up the station for sci & make sci list vars####  
sta      <- snd_vet_v  
sci_1mo  <- sci.fun(sta, 1)                      
sci_2mo  <- sci.fun(sta, 2)                             
sci_3mo  <- sci.fun(sta, 3)     # MLE fail month 5-   
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)      
sci_9mo  <- sci.fun(sta, 9)         
sci_12mo <- sci.fun(sta, 12)   
  
# snd_vet -- apply the transformation identified by fitSCI function####    
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# snd_vet -- bind and rename the sci vals####      
sci_snd_vet <- bind_cols(snd_vet,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# snd_vet -- clean up global environment====  
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(snd_vet, snd_vet_v)    
  
# SCI calcs - snd_whi -- set up the station for sci & make sci list vars####  
sta      <- snd_whi_v  
sci_1mo  <- sci.fun(sta, 1)                      
sci_2mo  <- sci.fun(sta, 2)                             
sci_3mo  <- sci.fun(sta, 3)       
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)      
sci_9mo  <- sci.fun(sta, 9)         
sci_12mo <- sci.fun(sta, 12)   
  
# snd_whi -- apply the transformation identified by fitSCI function####    
sci_1mo  <- transformSCI(sta,    
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)   
  
sci_2mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%   
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,    
                         first.mon = first_mon,   
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)    
  
sci_6mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,  
                         first.mon = first_mon,   
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%   
  enframe(name                     = NULL)   

# snd_whi -- bind and rename the sci vals####      
sci_snd_whi <- bind_cols(snd_whi,      
                     sci_1mo,   
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,   
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo  
) %>%                             
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%   
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%   
  rename(sci_6mo = value4)  %>%   
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# snd_whi -- clean up global environment====  
rm(sci_1mo,   
   sci_2mo,  
   sci_3mo,  
   sci_4mo,   
   sci_6mo,  
   sci_9mo,  
   sci_12mo  
   )      
rm(snd_whi, snd_whi_v)    
  
# calculate SCI-bad----  
# SCI calcs - bad_whi -- set up the station for sci & make sci list vars####  
sta      <- bad_whi_v    
sci_1mo  <- sci.fun(sta, 1)                              
sci_2mo  <- sci.fun(sta, 2)                             
sci_3mo  <- sci.fun(sta, 3)                            
sci_4mo  <- sci.fun(sta, 4)    
sci_6mo  <- sci.fun(sta, 6)    # MLE fail month 1-   
sci_9mo  <- sci.fun(sta, 9)    # MLE fail month 6-   
sci_12mo <- sci.fun(sta, 12)  
  
# bad_whi -- apply the transformation identified by fitSCI function####        
sci_1mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_1mo) %>%  
  enframe(name                     = NULL)  
  
sci_2mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_2mo) %>%  
  enframe(name                     = NULL)  
  
sci_3mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_3mo) %>%  
  enframe(name                     = NULL)  
  
sci_4mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_4mo) %>%  
  enframe(name                     = NULL)  
  
sci_6mo  <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_6mo) %>%  
  enframe(name                     = NULL)  
  
sci_9mo  <- transformSCI(sta,   
                         first.mon = first_mon,  
                         obj       = sci_9mo) %>%  
  enframe(name                     = NULL)  
  
sci_12mo <- transformSCI(sta,  
                         first.mon = first_mon,  
                         obj       = sci_12mo) %>%  
  enframe(name                     = NULL)  
  
# bad_whi -- bind and rename the sci vals####       
sci_bad_whi <- bind_cols(bad_whi,     
                     sci_1mo,  
                     sci_2mo,   
                     sci_3mo,  
                     sci_4mo,  
                     sci_6mo,  
                     sci_9mo,   
                     sci_12mo   
) %>%  
  rename(sci_1mo = value)   %>%  
  rename(sci_2mo = value1)  %>%  
  rename(sci_3mo = value2)  %>%  
  rename(sci_4mo = value3)  %>%  
  rename(sci_6mo = value4)  %>%  
  rename(sci_9mo = value5)  %>%  
  rename(sci_12mo = value6)  
  
# bad_whi -- clean up global environment====    
rm(sci_1mo,  
   sci_2mo,  
   sci_3mo,  
   sci_4mo,  
   sci_6mo,  
   sci_9mo,  
   sci_12mo   
   )   
rm(bad_whi, bad_whi_v)     
  
# clean up sci.fun vars====  
rm(  
  distrib,  
  first_mon,  
  p_zero,  
  p_zero_cm,  
  scale,  
  sci.limit,  
  sta,  
  time_scale,  
  warn_me  
  )   
  
```

```{r join_SRI}
# join sci data----  
# join black hills plateau SCI vals====  
sci_bhp <- bind_rows(sci_bhp_bat,  
                     sci_bhp_bev,  
                     sci_bhp_fal,  
                     sci_bhp_frn    
  )  

sci_bhp <- sci_bhp %>%    
  # truncate sci vals to [-3, 3]    
  gather(key = type, val = value, -c(sta, date, ecoreg, log_q1_mon)) %>%  
  mutate(value = case_when(     
    value < -3.0 ~ -3.0,    
    value >  3.0 ~  3.0,  
    TRUE ~ value)) %>%  
  spread(type, value) %>%    
  # move the longer sci-values to the end of the df    
  select(-sci_12mo, sci_12mo)    
  
# join keya paha tablelands SCI vals====  
sci_kpt <- bind_rows(sci_kpt_key,  
                     sci_kpt_wew  
  )  

sci_kpt <- sci_kpt %>%    
  # truncate sci vals to [-3, 3]    
  gather(key = type, val = value, -c(sta, date, ecoreg, log_q1_mon)) %>%  
  mutate(value = case_when(     
    value < -3.0 ~ -3.0,    
    value >  3.0 ~  3.0,  
    TRUE ~ value)) %>%  
  spread(type, value) %>%    
  # move the longer sci-values to the end of the df    
  select(-sci_12mo, sci_12mo)    
  
# join pine ridge excarpment SCI vals====  
sci_pre <- bind_rows(sci_pre_ogl,  
                     sci_pre_sta 
  )  
  
sci_pre <- sci_pre %>%    
  # truncate sci vals to [-3, 3]    
  gather(key = type, val = value, -c(sta, date, ecoreg, log_q1_mon)) %>%  
  mutate(value = case_when(     
    value < -3.0 ~ -3.0,    
    value >  3.0 ~  3.0,  
    TRUE ~ value)) %>%  
  spread(type, value) %>%    
  # move the longer sci-values to the end of the df    
  select(-sci_12mo, sci_12mo)    
  
# join pierre shale plains SCI vals====  
sci_psp <- bind_rows(sci_psp_bat,  
                     sci_psp_brs,  
                     sci_psp_che,  
                     sci_psp_elk,  
                     sci_psp_hat,  
                     sci_psp_whi      
  )  
  
sci_psp <- sci_psp %>%    
  # truncate sci vals to [-3, 3]    
  gather(key = type, val = value, -c(sta, date, ecoreg, log_q1_mon)) %>%  
  mutate(value = case_when(     
    value < -3.0 ~ -3.0,    
    value >  3.0 ~  3.0,  
    TRUE ~ value)) %>%  
  spread(type, value) %>%    
  # move the longer sci-values to the end of the df    
  select(-sci_12mo, sci_12mo)    
  
# join sand hills SCI vals====  
sci_snd <- bind_rows(sci_snd_lcr,  
                     sci_snd_lon,  
                     sci_snd_mar,  
                     sci_snd_nio,  
                     sci_snd_ros,  
                     sci_snd_vet,  
                     sci_snd_whi  
                     )  
  
sci_snd <- sci_snd %>%    
  # truncate sci vals to [-3, 3]    
  gather(key = type, val = value, -c(sta, date, ecoreg, log_q1_mon)) %>%  
  mutate(value = case_when(     
    value < -3.0 ~ -3.0,    
    value >  3.0 ~  3.0,  
    TRUE ~ value)) %>%  
  spread(type, value) %>%    
  # move the longer sci-values to the end of the df    
  select(-sci_12mo, sci_12mo)    
  
# join white river badlands SCI values====    
sci_bad <- sci_bad_whi  
  
sci_bad <- sci_bad %>%    
  # truncate sci vals to [-3, 3]    
  gather(key = type, val = value, -c(sta, date, ecoreg, log_q1_mon)) %>%  
  mutate(value = case_when(     
    value < -3.0 ~ -3.0,    
    value >  3.0 ~  3.0,  
    TRUE ~ value)) %>%  
  spread(type, value) %>%    
  # move the longer sci-values to the end of the df    
  select(-sci_12mo, sci_12mo)    

# export sci data====    
sci_gage <- bind_rows(sci_bhp,  
                      sci_kpt,  
                      sci_pre,  
                      sci_psp,  
                      sci_snd,  
                      sci_bad  
                      )     
  
export(sci_gage, "data/sci_gage.csv")  
  
# clean up====  
rm(sci_bhp_bat,  
   sci_bhp_bev,  
   sci_bhp_fal,  
   sci_bhp_frn,  
   sci_kpt_key,  
   sci_kpt_wew,  
   sci_pre_ogl,  
   sci_pre_sta,  
   sci_psp_bat,  
   sci_psp_brs,  
   sci_psp_che,  
   sci_psp_elk,  
   sci_psp_hat,  
   sci_psp_whi,  
   sci_snd_lcr,  
   sci_snd_lon,  
   sci_snd_mar,  
   sci_snd_nio,  
   sci_snd_ros,  
   sci_snd_vet,  
   sci_snd_whi,    
   sci_bad_whi, 
   sci_bad,  
   sci_bhp,  
   sci_kpt,  
   sci_pre,  
   sci_psp,  
   sci_snd,  
   sci.fun  
)  
  
```

# Identify seasonality & trend of SCI data -- plot seasonality 
```{r make_stl-decomp_function}    
  
# make function to decompose into seasonal, trend, & remainder----  
decomp_fun <- function(df) {    
  arrange(df, .data$date) %>%  
    group_by(.data$sta) %>%  
    time_decompose(   
      target         = , TARGET,     
      data           = .,   
      method         = "stl",   
      frequency      = , FREQ,   
      trend          = , TREND,   
      merge          = TRUE,   
      message        = TRUE    
    ) %>%                    
    ungroup() %>%   
    anomalize(remainder,   
              method = "gesd",  
              alpha  = 0.003) %>%    
    select(-observed)    
}   
  
# notes: map_dfr can cause issues with indexing; use split and combine  
#   input needs to be a tibble   
  
```

```{r deconvolute_spi}  
  
# deconvolute the grouped prcp into trend, seasonal & random components----   
  
# import working data====         
#spi_sta <- import("data/spi_sta.csv") %>%    
# mutate(date = ymd(date))   
  
sta_meta_fin <- import("data/sta_meta_fin.csv")      
  
# prepare for deconvoluting the grouped precip====    
spi_sta <- spi_sta %>%   
  mutate(prcp = as.numeric(prcp)) %>%    
  arrange(date) %>%   
  as_tibble() %>%   
  # make groups  
  mutate(group = case_when(  
    sta == "RAP" ~ "NW",    
    sta == "COT" ~ "NC",     
    sta == "OEL" ~ "NE",     
    sta == "GOR" ~ "SW",   
    sta == "ONI" ~ "SC",  
    sta == "MIS" ~ "SE"   
  )   
  )  
  
# identify frequency of seasonality -- should be 12 months====      
#   the level is group rather than station - so need to combine stations  
freq <- spi_sta  %>%     
  split(.$group) %>%   
  map_dfc(~ anomalize::time_frequency(  
    period       = "auto",  
    data = .)   
  ) %>%  
  gather(key     = group,  
         value   = freq) %>%   
  summarise(freq = mean(freq),    
            max  = max(freq),   
            min  = min(freq),   
            sd   = sd(freq)  
  )   
  
#   identify trend of periodicity -- should be 60 months====  
trend <- spi_sta  %>%  
  split(.$group) %>%   
  map_dfc(~ anomalize::time_trend(  
    period       = "auto", data = .)   
  ) %>%  
  gather(key     = grpup, value = freq) %>%   
  summarise(freq = mean(freq),  
            max  = max(freq),  
            min  = min(freq),  
            sd   = sd(freq)  
  )  
  
# decompose prcp into seasonal, trend, & remainder====    
FREQ   <- "12 months"  
TREND  <- "60 months"   
TARGET <- "spi_1mo"  
  
spi_seas <- spi_sta %>%   
  decomp_fun() 
  
# clean up global environment####  
rm(freq,  
   trend,      
   FREQ,  
   TARGET,  
   TREND,  
   decomp_fun  
   )    
  
```  

```{r plot_seasonality_spi} 
# this code chunk is set up for both spi & sri seasonality plotting 
  
# check for anomonies====     
spi_anom <- spi_seas %>%   
  filter(anomaly == "Yes") 
  
sri_anom <- sri_seas %>%   
  filter(anomaly == "Yes") 
  
# vars for plotting====    
sta_size   <- 0.2  
sta_color  <- "black"  
  
# prcp observations plot====  
spi_obs <- 
spi_seas %>%  
  ggplot(aes(date, spi_1mo)) +     
  theme_bw() +  
  xlab("") +  
  ylab("SPI 1-month") +   
  scale_y_continuous(limits = c(-3, 3)) +  
  facet_wrap(vars(group)) +   
# plot station vals  
geom_line(size            = sta_size,  
          colour          = sta_color  
          )    
  
# precipitation seasons plot====   
spi_seas_plot <-    
spi_seas %>%       
  ggplot(aes(date, season)) +     
  theme_bw() +  
  xlab("") +  
  ylab("SPI 1-month") +   
  scale_y_continuous(limits = c(-3, 3)) +   
  facet_wrap(vars(group),  
             nrow = 2) +   
# plot group vals              
geom_line(size            = sta_size,  
          colour          = sta_color  
          )    
   
# precipitation trend plot====   
spi_trend <-   
spi_seas %>%   
  ggplot(aes(date, trend)) +      
  theme_bw() +   
  xlab("") +   
  ylab("SPI 1-month") +    
  scale_y_continuous(limits = c(-3, 3)) +  
  facet_wrap(vars(group),        
             nrow = 2) +    
# plot group vals   
geom_line(size            = sta_size,   
          colour          = sta_color   
          )    
  
# precipitation remainder plot====   
spi_remain <-       
spi_seas %>%                
  ggplot(aes(date, remainder)) +     
  theme_bw() +                  
  xlab("") +                     
  ylab("SPI 1-month") +   
  scale_y_continuous(limits = c(-3, 3)) +  
  facet_wrap(vars(group)) +   
# plot station vals         
geom_line(size            = sta_size,  
          colour          = sta_color  
          )     
  
# plot the plots above as a grid & save====  
cowplot::plot_grid(  
  spi_obs, spi_seas_plot, spi_trend, spi_remain,  
  ncol = 1,   
  align = "v"  
)  
  
cowplot::ggsave2("figure/spi_deconv.png",  
                 units = "in",  
                 width = 7,  
                 height = 9)  
```  

```{r deconvolute_sri}  
  
# deconvolute the grouped prcp into trend, seasonal & random components----   

# import working data####    
gage_meta <-  import("data/gage_meta.csv")   

sci_gage <- import("data/sci_gage.csv") %>%    
  mutate(date = ymd(date))   
  
# prepare for deconvoluting the grouped precip====  
# the target for decomp_fun is 'group' -- RUN THIS FOR 'sci_gage' 
sci_gage <- sci_gage %>%   
    arrange(date) %>%   
  as_tibble() %>%  
  mutate(group = sta)   
  
# identify frequency of seasonality -- should be 12 months====      
freq <- sci_gage  %>%    
  split(.$sta) %>%   
  map_dfc(~ anomalize::time_frequency(  
    period       = "auto",  
    data = .)   
  ) %>%  
  gather(key     = group,  
         value   = freq) %>%   
  summarise(freq = mean(freq),   
            max  = max(freq),   
            min  = min(freq),   
            sd   = sd(freq)  
  )   
  
#   identify trend of periodicity -- should be 60 months====   
trend <- sci_gage  %>%   
  split(.$sta) %>%   
  map_dfc(~ anomalize::time_trend(   
    period       = "auto", data = .)    
  ) %>%                        
  gather(key     = grpup, value = freq) %>%   
  summarise(freq = mean(freq),   
            max  = max(freq),   
            min  = min(freq),   
            sd   = sd(freq)    
  )   
  
# decompose prcp into seasonal, trend, & remainder====     
FREQ   <- "12 months"   
TREND  <- "60 months"    
TARGET <- "sci_1mo"   
   
sri_seas <- sci_gage %>%   
  decomp_fun()   
  
# clean up global environment====     
rm(freq,  
   trend,       
   FREQ,  
   TARGET,  
   TREND,  
   decomp_fun, 
   sci_gage
   )    
  
# identify seasonally intermittant streams  
sri_intermit <- sri_seas %>%  
  group_by(sta) %>% 
  summarise(season_max = max(season)  
  ) %>% 
  ungroup() %>%  
  arrange(desc(season_max))  

gage_meta <- full_join(gage_meta, sri_intermit, 
                       by = "sta") 
gage_meta <- gage_meta %>% 
  mutate(flow_regime = case_when(  
    season_max > 1.5 ~ "strongly intermittent", 
    TRUE ~ flow_regime
    ))   

sri_intermit <- sri_intermit %>% 
  filter(season_max < 1.5)  

sri_seas <- semi_join(sri_seas, sri_intermit, 
                       by = "sta")

export(gage_meta, "data/gage_meta_seas.csv")  
export(sri_seas, "data/sri_seas.csv")  
  
```  
  
```{r prep_season_plot_sri}
  


# calculate group mean & sd====   
# note elk_elm has really high seasonality and is removed from future calcs
sri_1mo_mean <- sri_seas %>%  
  group_by(ecoreg, date) %>% 
  summarise(sci_1mo_sd = sd(sci_1mo),
            sci_1mo    = mean(sci_1mo) 
  ) %>%  
  ungroup() %>% 
  mutate(sci_1mo_hi = sci_1mo + sci_1mo_sd) %>% 
  mutate(sci_1mo_lo = sci_1mo - sci_1mo_sd) %>% 
  select(-c(sci_1mo_sd)) %>% 
  gather(key = sci_type, value = sci_hi_lo, 
         -c(ecoreg, date, sci_1mo)
         )    

sri_seas_mean <- sri_seas %>%  
  group_by(ecoreg, date) %>% 
  summarise(season_sd = sd(season),
            season    = mean(season) 
  ) %>%  
  ungroup() %>% 
  mutate(season_hi = season + season_sd) %>% 
  mutate(season_lo = season - season_sd) %>% 
  select(-c(season_sd)) %>% 
  gather(key = season_type, value = seas_hi_lo, 
         -c(ecoreg, date, season) 
         )   

sri_trend_mean <- sri_seas %>%  
  group_by(ecoreg, date) %>% 
  summarise(trend_sd = sd(trend),
            trend    = mean(trend) 
  ) %>%  
  ungroup() %>% 
  mutate(trend_hi = trend + trend_sd) %>% 
  mutate(trend_lo = trend - trend_sd) %>% 
  select(-c(trend_sd)) %>% 
  gather(key = trend_type, value = trend_hi_lo, 
         -c(ecoreg, date, trend)
  )  
  
sri_remain_mean <- sri_seas %>%  
  group_by(ecoreg, date) %>% 
  summarise(remain_sd = sd(remainder),
            remain    = mean(remainder) 
  ) %>%  
  ungroup() %>% 
  mutate(remain_hi = remain + remain_sd) %>% 
  mutate(remain_lo = remain - remain_sd) %>% 
  select(-c(remain_sd)) %>% 
  gather(key = remain_type, value = remain_hi_lo, 
         -c(ecoreg, date, remain)
  )  


sri_means <- full_join(sri_1mo_mean, sri_seas_mean, 
                       by = c("ecoreg", "date")  
                       )      
sri_means <- full_join(sri_means, sri_trend_mean, 
                       by = c("ecoreg", "date")  
                       ) 
sri_means <- full_join(sri_means, sri_remain_mean, 
                       by = c("ecoreg", "date")  
                       ) 
 
rm(sri_1mo_mean, sri_seas_mean, sri_trend_mean, sri_intermit)
```

```{r plot_seasonality_sri}

sri_anom <- sri_seas %>% 
  filter(sta != "elk_elm") %>%   
  filter(anomaly == "Yes") 

# set plotting position====     
sri_seas <- sri_seas %>% 
  mutate(ecoreg = fct_relevel(ecoreg,
                              "Pierre Shale Plains", 
                              "Pine Ridge Escarpment", 
                              "White River Badlands", 
                              "Black Hills Plateau", 
                              "Keya Paha Tablelands", 
                              "Sand Hills")     
  ) 

sri_means <- sri_means %>% 
  mutate(ecoreg = fct_relevel(ecoreg,
                              "Pierre Shale Plains", 
                              "Pine Ridge Escarpment", 
                              "White River Badlands", 
                              "Black Hills Plateau", 
                              "Keya Paha Tablelands", 
                              "Sand Hills")     
  ) 
  
# streamflow observations plot====  
sri_obs <- sri_seas %>%   
  ggplot(aes(date, sci_1mo)) +     
  theme_bw() +  
  xlab("") +  
  ylab("SRI 1-month") +   
  scale_y_continuous(limits = c(-3, 3)) +  
  facet_wrap(vars(ecoreg),   
             nrow = 2 
  ) +   
  # plot all station vals  
  geom_line(size            = 1,  
            colour          = "gray80"  
  )  + 
# plot mean +/- 1 SD 
  geom_line(data = sri_means,  
            aes(date, sci_hi_lo), 
            size            = 0.6,  
            colour          = "gray60"  
  )   +  
# plot mean 
  geom_line(data = sri_means,  
            size            = 0.3,  
            colour          = "black"  
  )  

# streamflow seasons plot====   
sri_seas_plot <- 
sri_seas %>% 
  ggplot(aes(date, season)) +     
  theme_bw() +  
  xlab("") +  
  ylab("SRI 1-month") +   
  scale_y_continuous(limits = c(-3, 3)) +   
  facet_wrap(vars(ecoreg),  
             nrow = 2) +   
  # plot all station vals  
  geom_line(size            = 1,  
            colour          = "gray80"  
  )  + 
# plot mean +/- 1 SD 
  geom_line(data = sri_means,  
            aes(date, seas_hi_lo), 
            size            = 0.3,  
            colour          = "gray60"  
  )   +  
# plot mean 
  geom_line(data = sri_means,  
            aes(date, season), 
            size            = 0.3,  
            colour          = "black"  
  )  
  
# streamflow trend plot====   
sri_trend <- sri_seas %>% 
  ggplot(aes(date, trend)) +     
  theme_bw() +  
  xlab("") +  
  ylab("SRI 1-month") +   
  scale_y_continuous(limits = c(-3, 3)) +   
  facet_wrap(vars(ecoreg),  
             nrow = 2) +   
  # plot all station vals  
  geom_line(size            = 1,  
            colour          = "gray80"  
  )  + 
# plot mean +/- 1 SD 
  geom_line(data = sri_means,  
            aes(date, trend_hi_lo), 
            size            = 0.3,  
            colour          = "gray60"  
  )   +  
# plot mean 
  geom_line(data = sri_means,  
            aes(date, trend), 
            size            = 0.3,  
            colour          = "black"  
  )  

# streamflow remainder plot====   
#sri_remain <- 
sri_seas %>% 
  ggplot(aes(date, remainder)) +     
  theme_bw() +  
  xlab("") +  
  ylab("SRI 1-month") +   
  scale_y_continuous(limits = c(-3, 3)) +   
  facet_wrap(vars(ecoreg),  
             nrow = 2) +   
  # plot all station vals  
  geom_line(size            = 1,  
            colour          = "gray80"  
  )  + 
# plot mean +/- 1 SD 
  geom_line(data = sri_means,  
            aes(date, remain_hi_lo), 
            size            = 0.3,  
            colour          = "gray60"  
  )   +  
# plot mean 
  geom_line(data = sri_means,  
            aes(date, remain), 
            size            = 0.3,  
            colour          = "black"  
  ) + 
# plot anomolies 
  geom_point(data = sri_anom,  
             aes(date, sci_1mo),  
             shape = 8)  
  
# plot the plots above as a grid & save====  
cowplot::plot_grid(  
  sri_obs, sri_seas_plot, sri_trend, sri_remain,  
  ncol = 1,   
  align = "v"  
)  
  
cowplot::ggsave2("figure/sri_deconv.png",  
                 units = "in",  
                 width = 7,  
                 height = 9)  
  
# clean-up====  
rm(spi_obs,  
   spi_seas_plot,  
   spi_trend,  
   spi_remain,  
   sri_obs,  
   sri_seas,  
   sri_seas_plot,  
   sri_trend,  
   sri_remain, 
   spi_anom,  
   sta_color,  
   sta_size   
   )         
  

 
```  

# TO DO Monthly plot PRCP_MON - check code   
```{r plot-annual-prcp}  
# plot annual precips  
sta_mon_plus %>%  
  ggplot(aes(year, depth_mm, group = year)) +  
  facet_grid(rows =vars(group)) +  
  #  geom_quasirandom(size = 0.2,  
  #                position = position_beeswarm()) +  
  geom_boxplot() +  
  theme_bw() +   
  labs(title = "Annual precipitation depths",  
       subtitle = "1990-2017") +  
  xlab("") +  
  ylab("mm")  
  
```

```{r ggplot_monthly, eval=FALSE} 
#sta_mon <- import(file = "data/stations_monthly.csv") %>%   
#  mutate(date = ymd(date))  
  
#sta_mon %>%   
#  group_by(sta) %>%   
#  summarize(count = n())  
  
sta_mon_plus$group <- factor(sta_mon_plus$group,  
                             levels = c("NW", "NC", "NE", "SW", "SC", "SE"))  
  
# plot monthly precips  
sta_mon_plus %>%   
  ggplot(aes(month, depth_mm, group = month)) +  
  facet_grid(rows = vars(group)) +   
  geom_quasirandom(size = 0.2,  
                   position = position_beeswarm()  
  ) + 
  scale_x_discrete(limits = c("1", "2", "3", "4", "5", "6",  
                              "7", "8", "9", "10", "11", "12"),    
                   labels = c("J", "F", "M", "A", "M", "J",  
                              "J", "A", "S", "O", "N", "D")   
  ) +  
  theme_bw() +  
  #  labs(title = "Monthly precipitation depths",  
  #       subtitle = "Southwestern South Dakota for 1990-2017") +   
  xlab("") +  
  ylab("mm")  
  
ggplot2::ggsave(path = "figure/", filename = "precip_mon.png",   
                width = 6, height = 6, units = "in")  
  
````  

```{r precip-EDA, include=FALSE, eval=FALSE}
# Purpose: EDA of precipitation data.
# Outcome: Differences among stations 1971-2018 are small.  
#          less than +/-5 mm on average.  
 
# the anomolously wet month series is dominated by May & June events.  
# what drives precip during this time?   
#   In May & June the area recieves low-level moisture from the Gulf   
#   of Mexico, strong cold fronts, and active upper-level pattern  
#   leading to greater chance for convection.  
```

```{r tidy_time-series} 
# overview of tidy time series----  
# https://www.business-science.io/timeseries-analysis/2017/07/02/tidy-timeseries-analysis.html 

# The period apply functions from xts can be used to apply aggregations using  
#   common time series intervals such as weekly, monthly, quarterly, and  
#   yearly. The tq_transmute() function from tidyquant enables efficient and  
#   “tidy” application of the functions. We were able to use the period apply  
#   functions to visualize trends and volatility and to expose relationships 
#   between statistical measures.

# get data for various tidyverse packages - count of downloads====  

pkgs <- c(
    "tidyr", "lubridate", "dplyr", 
    "broom", "tidyquant", "ggplot2", "purrr", 
    "stringr", "knitr"
    )

tidyverse_downloads <- cran_downloads(
    packages = pkgs, 
    from     = "2017-01-01", 
    to       = "2017-06-30") %>%
    tibble::as_tibble() %>%
    group_by(package)
  
# Visualize the package downloads====  
tidyverse_downloads %>%
    ggplot(aes(x = date, y = count, color = package)) +
    geom_point() +
    labs(title = "tidyverse packages: Daily downloads", x = "") +
    facet_wrap(~ package, ncol = 3, scale = "free_y") +
    scale_color_tq() +
    theme_tq() +
    theme(legend.position="none")

# Applying functions by period====     
# "apply" functions from xts    
tq_transmute_fun_options()$xts %>%
    stringr::str_subset("^apply")

# To perform weekly aggregation, we will use tq_transmute(), which applies  
#   the non-tidy functions in a “tidy” way. 
# The function we want to use is apply.weekly(), which takes the argument  
#   FUN (the function to be applied weekly) and 
#   ... (additional args that get passed to the FUN function). 
# Set FUN = mean to apply mean() on a weekly interval,and pass the argument 
#   na.rm = TRUE to remove NA values during the calculation.  

mean_tidyverse_downloads_w <- tidyverse_downloads %>%
    tq_transmute(
        select     = count,
        mutate_fun = apply.weekly, 
        FUN        = mean,
        na.rm      = TRUE,
        col_rename = "mean_count"
    )

mean_tidyverse_downloads_w %>%
    ggplot(aes(x = date, y = mean_count, color = package)) +
    geom_point() +
    geom_smooth(method = "loess") + 
    labs(title = "tidyverse packages: Average daily downloads by week", x = "", 
         y = "Mean Daily Downloads by Week") +
    facet_wrap(~ package, ncol = 3, scale = "free_y") +
    expand_limits(y = 0) + 
    scale_color_tq() +
    theme_tq() +
    theme(legend.position="none")

# Custom function to return mean, sd, quantiles====  
custom_stat_fun <- function(x, na.rm = TRUE, ...) {
    # x     = numeric vector
    # na.rm = boolean, whether or not to remove NA's
    # ...   = additional args passed to quantile
    c(mean    = mean(x, na.rm = na.rm),
      stdev   = sd(x, na.rm = na.rm),
      quantile(x, na.rm = na.rm, ...)) 
}

# Testing custom_stat_fun
options(digits = 4)
set.seed(3366)
nums  <- c(10 + 1.5*rnorm(10), NA)
probs <- c(0, 0.025, 0.25, 0.5, 0.75, 0.975, 1)
custom_stat_fun(nums, na.rm = TRUE, probs = probs)

# Apply the custom function by week -- tidy & visualize====   
stats_tidyverse_downloads_w <- tidyverse_downloads %>%  
    tq_transmute(  
        select = count,  
        mutate_fun = apply.weekly,  
        FUN = custom_stat_fun,  
        na.rm = TRUE,  
        probs = probs  
    )  

stats_tidyverse_downloads_w %>%   
    ggplot(aes(x = date, y = `50%`, color = package)) +  
    # Ribbon  
    geom_ribbon(aes(ymin = `25%`, ymax = `75%`),  
                color = palette_light()[[1]],  
                fill = palette_light()[[1]],  
                alpha = 0.5) +  
    # Points  
    geom_point() +  
    geom_smooth(method = "loess", se = FALSE) +  
    # Aesthetics  
    labs(title = "tidyverse packages: Median daily downloads by week",  
         x = "",  
         subtitle = "Range of 1st and 3rd quartile to show volatility",  
         y = "Median Daily Downloads By Week") +  
    facet_wrap(~ package, ncol = 3, scale = "free_y") +  
    expand_limits(y = 0) +  
    scale_color_tq(theme = "dark") +  
    theme_tq() +  
    theme(legend.position="none")  

stats_tidyverse_downloads_w %>%  
    ggplot(aes(x = stdev, y = mean, color = package)) +  
    geom_point() +  
    geom_smooth(method = "lm") +  
    labs(  
      title = "tidyverse packages: Mean vs SD of daily downloads by week") +  
    facet_wrap(~ package, ncol = 3, scale = "free") +  
    scale_color_tq() +  
    theme_tq() +  
    theme(legend.position="none")   

# Rolling Window Calculations====  
# The rollapply functions from zoo and TTR can be used to apply rolling  
#   window calculations. The tq_mutate() function from tidyquant enables  
#   efficient and “tidy” application of the functions. We were able to use  
#   the rollapply functions to visualize averages and standard deviations on  
#   a rolling basis, which gave us a better perspective of the dynamic trends.  
#   Using custom functions, we are unlimited to the statistics we can apply to  
#   rolling windows.  
#  
#   What are rolling window calculations, and why do we care? In time series  
#   analysis, nothing is static. A correlation may exist for a subset of time  
#   or an average may vary from one day to the next. Rolling calculations  
#   simply apply functions to a fixed width subset of the data (aka a window),  
#   indexing one observation each calculation.  
  
#   There are a few common reasons you may want to use a rolling calculation  
#   in time series analysis:  
#  
#    Measuring the central tendency over time (mean, median)  
#    Measuring the volatility over time (sd, var)  
#    Detecting changes in trend (fast vs slow moving averages)  
#    Measuring a relationship between two time series over time (cor, cov)  

# Sample Moving Average Calculation  
# Combining a rolling mean with a rolling standard deviation can help detect  
# regions of abnormal volatility and consolidation. This is the concept behind   
# Bollinger Bands in the financial industry. The bands can be useful in  
# detecting breakouts in trend.    

# Time Series Functions for rolling window====  
# "roll" functions from zoo  
tq_mutate_fun_options()$zoo %>%  
    stringr::str_subset("^roll")  

##  [1] "rollapply"          "rollapplyr"         "rollmax"            
##  [4] "rollmax.default"    "rollmaxr"           "rollmean"          
##  [7] "rollmean.default"   "rollmeanr"          "rollmedian"        
## [10] "rollmedian.default" "rollmedianr"        "rollsum"           
## [13] "rollsum.default"    "rollsumr"  

# "run" functions from TTR  
tq_mutate_fun_options()$TTR %>%  
    stringr::str_subset("^run")  
  
##  [1] "runCor"         "runCov"         "runMAD"        
##  [4] "runMax"         "runMean"        "runMedian"     
##  [7] "runMin"         "runPercentRank" "runSD"         
## [10] "runSum"         "runVar"  
  
# Tidy Implementation of Time Series Functions====    
# Condensed function options====    
tq_mutate_fun_options() %>%  
    str()  

## List of 5  
##  $ zoo: chr [1:14] "rollapply" "rollapplyr" "rollmax" "rollmax.default" ...  
##  $ xts: chr [1:27] "apply.daily" "apply.monthly" "apply.quarterly"   
##      "apply.weekly" ...  
##  $ quantmod: chr [1:25] "allReturns" "annualReturn" "ClCl" "dailyReturn" ...  
##  $ TTR: chr [1:61] "adjRatios" "ADX" "ALMA" "aroon" ...  
##  $ PerformanceAnalytics: chr [1:7] "Return.annualized" "  
##      Return.annualized.excess" "Return.clean" "Return.cumulative" ...  

# Tidy Application of Rolling Functions====  
# Rolling Mean: Inspecting Fast and Slow Moving Averages  
#  Investigate if significant changes in trend are taking place such that  
#   future downloads are likely to continue to increase, decrease or stay the  
#   same. One way to do this is to use moving averages.  
# Rather than try to sift through the noise, we can use a combination of a  
#   fast and slow moving average to detect momentum.  

# We’ll create a fast moving average with width = 28 days (just enough to  
#   detrend the data) and a slow moving average with width = 84 days  
#   (slow window = 3X fast window). To do this we apply two calls to  
#   tq_mutate(), the first for the 28 day (fast) and the second for the  
#   84 day (slow) moving average. There are three groups of arguments we   
#   need to supply:  
# tq_mutate args -- These select the column to apply the mutation to “count”  
#   & the mutation function (mutate_fun) to apply (rollapply from zoo).  
# rollapply args: These set the width, align = "right"  
#   (aligns with end of data frame), and  
#   the FUN we wish to apply (mean in this case).  
# FUN args: These are arguments that get passed to the function.  
#   In this case we want to set na.rm = TRUE so NA values are skipped.  
# Also add an optional tq_mutate arg, col_rename, at the end to rename the  
#   column.   

# Rolling mean example====    
tidyverse_downloads_rollmean <- tidyverse_downloads %>%  
    tq_mutate(  
        # tq_mutate args  
        select     = count,  
        mutate_fun = rollapply,  
        # rollapply args  
        width      = 28,  
        align      = "right",  
        FUN        = mean,  
        # mean args  
        na.rm      = TRUE,  
        # tq_mutate args  
        col_rename = "mean_28"  
    ) %>%  
    tq_mutate(  
        # tq_mutate args  
        select     = count,  
        mutate_fun = rollapply,  
        # rollapply args  
        width      = 84,  
        align      = "right",  
        FUN        = mean,  
        # mean args  
        na.rm      = TRUE,  
        # tq_mutate args  
        col_rename = "mean_84"  
    )  

# ggplot results====  
tidyverse_downloads_rollmean %>%  
    ggplot(aes(x = date, y = count, color = package)) +  
    # Data  
    geom_point(alpha = 0.1) +  
    geom_line(aes(y = mean_28), color = palette_light()[[1]], size = 1) +  
    geom_line(aes(y = mean_84), color = palette_light()[[2]], size = 1) +  
    facet_wrap(~ package, ncol = 3, scale = "free_y") +  
    # Aesthetics  
    labs(title = "tidyverse packages: Daily Downloads", x = "",  
         subtitle = "28 and 84 Day Moving Average") +  
    scale_color_tq() +  
    theme_tq() +  
    theme(legend.position="none")  
  
# Drop the “count” data from the plots and inspect just the moving averages to  
#   identify points where the fast trend is above (has momentum)  
#   or below (is slowing) the slow trend, & inspect for cross-over,  
#   which indicates shifts in trend.  
  
tidyverse_downloads_rollmean %>%  
    ggplot(aes(x = date, color = package)) +  
    # Data  
    # geom_point(alpha = 0.5) +  # Drop "count" from plots  
    geom_line(aes(y = mean_28),  
              color = palette_light()[[1]],  
              linetype = 1,  
              size = 1) +  
    geom_line(aes(y = mean_84),  
              color = palette_light()[[2]],   
              linetype = 1,  
              size = 1) +  
    facet_wrap(~ package,  
               ncol = 3,  
               scale = "free_y") +  
    # Aesthetics  
    labs(title = "tidyverse packages: Daily downloads", x = "", y = "",  
         subtitle = "Zoomed In: 28 and 84 Day Moving Average") +  
    scale_color_tq() +  
    theme_tq() +  
    theme(legend.position="none")  

# The plot shows 'purrr' and 'lubridate' have strong upward momentum,   
#   'dplyr', 'knitr' and 'tidyr' seem to be cycling in a range, &   
#   'ggplot2' and 'stringr' have short term downward trends -- keep in mind  
#   these packages are getting the most downloads of the bunch.  
  
# Rolling Custom Functions: Useful for multiple statistics  
#   Create a custom function, custom_stat_fun_2(), that returns statistics:   
#    mean  
#    standard deviation  
#    95% confidence interval (mean +/- 2SD)  

# Custom function to return mean, sd, 95% conf interval====    
custom_stat_fun_2 <- function(x, na.rm = TRUE) {  
  # x     = numeric vector  
  # na.rm = boolean, whether or not to remove NA's  
  m  <- mean(x, na.rm = na.rm)  
  s  <- sd(x, na.rm = na.rm)  
  hi <- m + 2*s  
  lo <- m - 2*s  
  ret <- c(mean = m, stdev = s, hi.95 = hi, lo.95 = lo)   
  return(ret)  
}  
  
# Apply the custom_stat_fun_2() to groups====  
#   using tq_mutate() and the rolling function rollapply()  
#   The output returned is a “tidy” data frame 
#   with each statistic in its own column.
# The process is almost identical to the process of applying mean() with  
#   the main exception that we need to set by.column = FALSE to prevent a  
#   “length of dimnames [2]” error. 
  
# Roll apply using custom stat function====  
tidyverse_downloads_rollstats <- tidyverse_downloads %>%
    tq_mutate(
        select     = count,
        mutate_fun = rollapply, 
        # rollapply args
        width      = 28,
        align      = "right",
        by.column  = FALSE,
        FUN        = custom_stat_fun_2,
        # FUN args
        na.rm      = TRUE
    )
  
# We now have the data needed to visualize the rolling average (trend) and  
#   the 95% confidence bands (volatility) -- this is the concept of the  
#   Bollinger Bands to identify periods of consolidation and periods of high  
#   variability. 
# Many high variability periods are when the package downloads are rapidly  
#   increasing -- 'lubridate', 'purrr' and 'tidyquant' had spikes in  
#   downloads causing the 95% Confidence Interval (CI) bands to widen.
  
# plot results of roll-apply====      
tidyverse_downloads_rollstats %>%  
    ggplot(aes(x = date, color = package)) +  
    # Data  
    geom_point(aes(y = count), color = "grey40", alpha = 0.5) +  
    geom_ribbon(aes(ymin = lo.95, ymax = hi.95), alpha = 0.4) +  
    geom_point(aes(y = mean), size = 1, alpha = 0.5) +  
    facet_wrap(~ package, ncol = 3, scale = "free_y") +  
    # Aesthetics  
    labs(title = "tidyverse packages: Volatility and Trend", x = "",  
         subtitle = "28-Day Moving Average with 95% CI Bands (+/-2 SD)") +  
    scale_color_tq(theme = "light") +  
    theme_tq() +  
    theme(legend.position="none")  
  
# The Rolling Correlation====  
#   tidyquant::tq_mutate_xy() enables “tidy” application of TTR::runCor()  
#   and other functions with x and y arguments. The corrr package is useful  
#   for computing the correlations and visualizing relationships, and it fits  
#   nicely into the “tidy” framework.  
#   The cowplot package helps with arranging multiple ggplots.  
  
# Investigate correlations to the “broader market”====  
# get the total downloads using cran_downloads() leaving the package argument  
#  "NULL", which is the default.  
  
# Get data for total CRAN downloads and visualize====  
all_downloads <- cran_downloads(from = "2017-01-01",  
                                to = "2017-06-30") %>%  
    tibble::as_tibble()  

# Visualize the downloads
all_downloads %>%
    ggplot(aes(x = date, y = count)) +
    # Data
    geom_point(alpha = 0.5, color = palette_light()[[1]], size = 2) +
    # Aesthetics
    labs(title = "Total CRAN Packages: Daily downloads", x = "",
         subtitle = "2017-01-01 through 2017-06-30",
         caption = "Downloads data courtesy of cranlogs package") +
    scale_y_continuous(labels = scales::comma) +
    theme_tq() +
    theme(legend.position="none")

# Rolling Correlations====  
# Correlations in time series are very useful because if a relationship   
#   exists, you can actually model/predict/forecast using the correlation.  
# However -- a correlation is NOT static because it changes over time.  
#   Even the best models become useless during periods when correlation is low.  

# One of the most important calculations in time series analysis is the  
#   rolling correlation. Rolling correlations are simply applying a  
#   correlation between two time series (say sales of product x and product y)  
#   as a rolling window calculation.  
  
# Rolling Correlation Example====   
# One benefit of a rolling correlation is that we can visualize the change in   
#   correlation over time. Consider if there’s a relatively high correlation   
#   between Sales of Product X and Y until a big shift in December.   
#   The question becomes, “What happened in December?”   
  
# In addition to visualizations, the rolling correlation can signal:    
#   1. events that have occurred causing two correlated time series to   
#     deviate from each other.   
#   2. when modeling, timespans of low correlation can help in determining   
#     whether or not to trust a forecast model.  
#   3. Detect shifts in trend as time series become more or less correlated  
#     over time.  

# Time Series Functions====   
# "run" functions from TTR   
tq_mutate_fun_options()$TTR %>%  
    stringr::str_subset("^run")  
  
##  [1] "runCor"         "runCov"         "runMAD"        
##  [4] "runMax"         "runMean"        "runMedian"     
##  [7] "runMin"         "runPercentRank" "runSD"         
## [10] "runSum"         "runVar"   

# Tidy Implementation of Time Series Functions====  
# Use the tq_mutate_xy() funct. to apply time series functions in a “tidy” way.   
#   Similar to tq_mutate(), the tq_mutate_xy() function is used for tasks   
#   that result in column-wise dimension changes (not row-wise such as  
#   periodicity changes, use tq_transmute for those!).  
# tq_mutate_xy() adds columns to the existing data frame rather than   
#   returning a new data frame like tq_transmute()).  
  
# Most running statistic functions only take one data argument, x.  
#   In these cases you can use tq_mutate(), which has an argument, select.  
#   See how runSD only takes x.  
# If first arg is x (and no y) --> use tq_mutate()     
args(runSD)  
  
## function (x, n = 10, sample = TRUE, cumulative = FALSE)  
## NULL   
  
# Functions like runCor and runCov are setup to take in two data arguments,  
#   x and y. In these cases, use tq_mutate_xy(), which takes two arguments,  
#   x and y (as opposed to select from tq_mutate()). This makes it well suited   
#   for functions that have the first two arguments being x and y.  
#   See how runCor has two arguments x and y.  
# If first two arguments are x and y --> use tq_mutate_xy()  
args(runCor)  

## function (x, y, n = 10, use = "all.obs", sample = TRUE, cumulative = FALSE)  
## NULL  

# Static Correlations====  
# Before we jump into rolling correlations, let’s examine the static    
#   correlations of our package downloads. This gives us an idea of how in  
#   sync the various packages are with each other over the entire timespan.  
  
# Use the correlate() and shave() functions from the corrr package to output   
#   a tidy correlation table. We’ll hone in on the last column “all_cran”,   
#   which measures the correlation between individual packages and the   
#   broader market (i.e. total CRAN downloads).  

# Correlation table -- tidy====  
tidyverse_static_correlations <- tidyverse_downloads %>%  
    # Data wrangling  
    spread(key = package, value = count) %>%  
    left_join(all_downloads, by = "date") %>%  
    rename(all_cran = count) %>%  
    select(-date) %>%  
    # Correlation and formating  
    correlate()  

# Pretty printing
tidyverse_static_correlations %>%
    shave(upper = F)

# The corrr package has a nice visualization called a network_plot() --   
#   to identify strength of correlation. Similar to a “kmeans” analysis,  
#   we are looking for association by distance (or in this case by correlation).  
# The network plot shows us how well the data correlate with each other -- 
#   akin to how associated they are with each other.  
  
# Network plot of correlations====  
# Below, 'tidyquant' has a very low correlation to “all_cran” and the rest  
#   of the “tidyverse” packages -- this would lead us to believe that  
#   tidyquant is trending abnormally with respect to the rest, and thus is  
#   possibly not as associated as we think.  
# Is this really the case?  

gg_all <- tidyverse_static_correlations %>%  
    network_plot(colours = c(palette_light()[[2]],  
                             "white",   
                             palette_light()[[4]]),  
                 legend = TRUE) +  
    labs(  
        title = "Correlations of tidyverse downloads to total CRAN downloads",  
        subtitle = "January through June, tidyquant is a clear outlier"  
        ) +  
    expand_limits(x = c(-0.75, 0.25), y = c(-0.4, 0.4)) +  
    theme_tq() +  
    theme(legend.position = "bottom")  
gg_all  
  
#Rolling Correlations====  
# Incorporate time using a rolling correlation. The script below uses the 
#   runCor function from the TTR package. We apply it using tq_mutate_xy(),  
#   which is useful for applying functions such has runCor that have both an  
#   x and y input.

# Get rolling correlations  
tidyverse_rolling_corr <- tidyverse_downloads %>%  
    # Data wrangling  
    left_join(all_downloads, by = "date") %>%  
    select(date, package, count.x, count.y) %>%  
    # Mutation  
    tq_mutate_xy(  
        x          = count.x,  
        y          = count.y,  
        mutate_fun = runCor,  
        # runCor args  
        n          = 30,  
        use        = "pairwise.complete.obs",  
        # tq_mutate args  
        col_rename = "rolling_corr"  
    )  
  
# Join static correlations with rolling correlations====    
tidyverse_static_correlations <- tidyverse_static_correlations %>%  
    select(rowname, all_cran) %>%  
    rename(package = rowname)  
  
tidyverse_rolling_corr <- tidyverse_rolling_corr %>%  
    left_join(tidyverse_static_correlations, by = "package") %>%  
    rename(static_corr = all_cran)  
  
# Plot combined static and rolling correlations    
tidyverse_rolling_corr %>%  
    ggplot(aes(x = date, color = package)) +  
    # Data  
    geom_line(aes(y = static_corr), color = "red") +  
    geom_point(aes(y = rolling_corr), alpha = 0.5) +  
    facet_wrap(~ package, ncol = 3, scales = "free_y") +  
    # Aesthetics  
    scale_color_tq() +  
    labs(  
        title = "tidyverse: 30-Day Rolling Download Correlations, Package vs Total CRAN",  
        subtitle = "Relationships are dynamic vs static correlation (red line)",  
        x = "", y = "Correlation"  
    ) +  
    theme_tq() +  
    theme(legend.position="none")  

# The rolling correlation shows the dynamic nature of the relationship.  
#   If we just went by the static correlation over the full timespan (red line),  
#   we’d be misled about the dynamic nature of these time series. Further, we  
#   can see that most packages are highly correlated with the broader market  
#   (total CRAN downloads) with the exception of various periods where the  
#   correlations dropped. The drops could indicate events or changes in user  
#   behavior that resulted in shocks to the download patterns.  
# Focusing on the main outlier tidyquant, we can see that once April hit   
#   tidyquant is trending closer to a 0.60 correlation meaning that the 0.31  
#   relationship (red line) is likely too low going forward.  

# Last, we can redraw the network plot from April through June to investigate  
#   the shift in relationship. We can use the cowplot package to plot two  
#   ggplots (or corrr network plots) side-by-side.

# Redrawing Network Plot from April through June====    
gg_subset <- tidyverse_downloads %>%  
  # Filter by date >= April 1, 2017  
  filter(date >= ymd("2017-04-01")) %>%  
  # Data wrangling  
  spread(key = package, value = count) %>%  
  left_join(all_downloads, by = "date") %>%  
  rename(all_cran = count) %>%  
  select(-date) %>%  
  # Correlation and formating  
  correlate() %>%  
  # Network Plot  
  network_plot(colours = c(palette_light()[[2]], 
                           "white",  
                           palette_light()[[4]]), 
               legend = TRUE) +  
  labs(  
    title = "April through June (Last 3 Months)",  
    subtitle = "tidyquant correlation is increasing"  
  ) +  
  expand_limits(x = c(-0.75, 0.25), y = c(-0.4, 0.4)) +  
  theme_tq() +  
  theme(legend.position = "bottom")  

# Modify the January through June network plot (previous plot)  
gg_all <- gg_all +  
  labs(  
    title = "January through June (Last 6 months)",  
    subtitle = "tidyquant is an outlier"  
  )  
  
# Format cowplot  
cow_net_plots <- plot_grid(gg_all, gg_subset, ncol = 2)  
title <- ggdraw() +  
  draw_label(label = 'tidyquant is getting "tidy"-er',  
             fontface = 'bold', size = 18)  
cow_out <- plot_grid(title, cow_net_plots,  
                     ncol=1,  
                     rel_heights=c(0.1, 1))  
cow_out  
  
# Lags (Lag Operator) overview====  
# Calculate lags and analyze autocorrelation.  
# The lag operator (also known as backshift operator) is a function that  
#   shifts (offsets) a time series such that the “lagged” values are aligned   
#   with the actual time series. The lags can be shifted any number of units,  
#     which simply controls the length of the backshift.  
  
# Lags are useful in time series analysis because of a phenomenon called   
#   autocorrelation, which is a tendency for the values within a time series   
#   to be correlated with previous copies of itself. One benefit to   
#   autocorrelation is that we can identify patterns within the time series,    
#   which helps in determining seasonality, the tendency for patterns to   
#   repeat at periodic frequencies. 
  
# Lags and autocorrelation are central to forecasting models that incorporate  
#   autoregression, regressing a time series using previous values of itself.   
# Autoregression is the basis for one of the most widely used forecasting  
#   techniques, the autoregressive integrated moving average model or ARIMA  
# for short. The forecast package by Rob Hyndman, implements ARIMA and a  
# number of other forecast modeling techniques. 
# Note -- Autoregression and ARIMA not discussed below.  

# Lag and autocorrelation analysis is a good way to detect seasonality. 
#   The autocorrelation of the lagged values can be used to detect “abnormal”  
#   seasonal patterns. 
# The tq_mutate() function was used to apply lag.xts() to the daily download  
#   counts to efficiently get lags 1 through 28. Once the lags were retrieved,  
#   we use other dplyr functions such as gather() to pivot the data and  
#   summarize() to calculate the autocorrelations. Finally, we saw the power  
#   of visual analysis of the autocorrelations -- created an ACF plot that  
#   showed a visual trend. Then we used a boxplot to detect which lags had  
#   consistent outliers. Ultimately a weekly pattern was confirmed.   
  
# tidyquant Integrated functions====  
tq_mutate_fun_options() %>%  
    glimpse()  
  
## List of 5  
##  $ zoo: chr [1:14] "rollapply" "rollapplyr" "rollmax" "rollmax.default" ...  
##  $ xts: chr [1:27] "apply.daily" "apply.monthly" "apply.quarterly"  
##    "apply.weekly" ...  
##  $ quantmod: chr [1:25] "allReturns" "annualReturn" "ClCl" "dailyReturn" ...  
##  $ TTR: chr [1:62] "adjRatios" "ADX" "ALMA" "aroon" ...  
##  $ PerformanceAnalytics: chr [1:7] "Return.annualized"  
##    "Return.annualized.excess" "Return.clean" "Return.cumulative" ...

# lag.xts() -- tidy====  
# The lag.xts() function from the xts package, has a great function for getting  
#   multiple lags.  
# The lag.xts() function generates a sequence of lags (t-1, t-2, t-3, …, t-k)  
#   using the argument k. However, it only works on xts or other matrix,  
#   vector-based objects). In other words, it fails on our “tidy” tibble.  
#   And, we get an “unsupported type” error.   
  
# Consider a time series of ten values beginning in 2017.  
set.seed(1)  
my_time_series_tbl <- tibble(  
    date   = seq.Date(ymd("2017-01-01"),  
                      length.out = 10,  
                      by = "day"),  
    value  = 1:10 + rnorm(10)  
)  

# Bummer, man! -- I ran into this...   
my_time_series_tbl %>%           
        lag.xts(k = 1:5)  

## <simpleError in FUN(X[[i]], ...): unsupported type>

# The timetk package is a toolkit for working with time series. It has  
#   functions that simplify and make consistent the process of coercion --  
#   converting to and from different time series classes. In addition,  
#   it has functions to aid the process of time series machine learning and  
#   data mining. 

# Convert to an xts object -- use tk_xts() from the timetk package  
#   to coerce from a time-based tibble -- tibble with a date or time component 
#   and xts object.

# Success! Got our lags 1 through 5. One problem: no original values
my_time_series_tbl %>%
    tk_xts(silent = TRUE) %>%
    lag.xts(k = 1:5)

# We still need our original values so we can analyze the counts against  
#   the lags. 
# If we want to get the original values too, we can do something like this.

# Convert to xts  
my_time_series_xts <- my_time_series_tbl %>%  
    tk_xts(silent = TRUE)  
  
# Get original values and lags in xts  
my_lagged_time_series_xts <-   
    merge.xts(my_time_series_xts, lag.xts(my_time_series_xts, k = 1:5))  

# Convert back to tbl  
my_lagged_time_series_xts %>%  
    tk_tbl()  
  
# That’s a lot of work for a simple operation.  
# Fortunately we have tq_mutate() to the rescue!  
  
#  tq_mutate()====  
# The tq_mutate() function from tidyquant enables “tidy” application of the  
#   xts-based functions. The tq_mutate() function works similarly to mutate()  
#   from dplyr in the sense that it adds columns to the data frame.
 
# The tidyquant package enables a “tidy” implementation of the xts-based  
#   functions from packages such as xts, zoo, quantmod, TTR and  
# PerformanceAnalytics. 

# Quick example -- use the select = value to send the “value” column to the  
#   mutation function. In this case our mutate_fun = lag.xts. We supply k = 5  
#   as an additional argument.  
# That’s much easier -- we get the value column returned in addition to the  
#   lags, which is the benefit of using tq_mutate(). If you use tq_transmute()  
#   instead, the result would be the lags only, which is what lag.xts() returns.  
  
# This is nice, we didn't need to coerce to xts and it merged for us  
my_time_series_tbl %>%  
    tq_mutate(  
        select     = value,  
        mutate_fun = lag.xts,  
        k          = 1:5  
    )  
  
# Analyzing tidyverse Downloads: Lag and Autocorrelation Analysis----  
# Scaling the Lag and Autocorrelation Calculation  
# Get lags 1 through 28 (4 weeks of lags):  
#   Take the tidyverse_downloads data frame, which is grouped by package,  
#     and apply tq_mutate() using the lag.xts function.  
#   We can provide column names for the new columns by prefixing “lag_” to   
#   the lag numbers, k, which the sequence from 1 to 28.   
# The output is all of the lags for each package.  

# Use tq_mutate() to get lags 1:28 using lag.xts()====  
k <- 1:28  
col_names <- paste0("lag_", k)  
  
tidyverse_lags <- tidyverse_downloads %>%  
    tq_mutate(  
        select     = count,  
        mutate_fun = lag.xts,  
        k          = 1:28,  
        col_rename = col_names  
    )  

# Next steps with lag.xts====   
# The goal is to get count and each lag side-by-side so we can do a correlation. 
# Correlating each of the lags to the “count” column involves steps  
#   strung together in a dplyr pipe (%>%):  
# 1. Use gather() to pivot each lagged column into a “tidy” long-format df,   
#     and exclude columns: “package”, “date” and “count” columns from the pivot.   
# 2. Convert the new “lag” column from a character string (e.g. “lag_1”)  
#     to numeric (e.g. 1) using mutate() to make ordering the lags easier.  
# 3. group the long data frame by package and lag to calculate subsets of  
#     package and lag.  
# 4. apply the correlation to each group of lags. The summarize() function   
#     can be used to implement cor(), which takes x = count and y = lag_value.   
#   Make sure to pass use = "pairwise.complete.obs", which is almost always   
#   desired.  
# 5. The 95% upper and lower cutoff can be approximated by: cutoff=±2 / N^0.5  
#     Where:  
#       N = number of observations.  

# Calculate the autocorrelations and 95% cutoffs  
tidyverse_count_autocorrelations <- tidyverse_lags %>%  
    gather(key = "lag",  
           value = "lag_value",  
           -c(package, date, count)) %>%  
    mutate(lag = str_sub(lag, start = 5) %>% as.numeric) %>%  
    group_by(package, lag) %>%  
    summarize(  
        cor = cor(x = count,  
                  y = lag_value,  
                  use = "pairwise.complete.obs"),  
        cutoff_upper = 2/(n())^0.5,  
        cutoff_lower = -2/(n())^0.5  
        )  

#Visualizing Autocorrelation: ACF Plot====
# Now correlations are calculated by package and lag number in a “tidy” format,  
#   we can visualize the autocorrelations with ggplot to check for patterns.  
# The plot shown below is known as an ACF plot, which is simply the  
#   autocorrelations at various lags. Initial examination of the ACF plots  
# indicate a weekly frequency.

# Visualize the autocorrelations
tidyverse_count_autocorrelations %>%
    ggplot(aes(x = lag, y = cor, color = package, group = package)) +
    # Add horizontal line a y=0
    geom_hline(yintercept = 0) +
    # Plot autocorrelations
    geom_point(size = 2) +
    geom_segment(aes(xend = lag, yend = 0), size = 1) +
    # Add cutoffs
    geom_line(aes(y = cutoff_upper), color = "blue", linetype = 2) +
    geom_line(aes(y = cutoff_lower), color = "blue", linetype = 2) +
    # Add facets
    facet_wrap(~ package, ncol = 3) +
    # Aesthetics
    expand_limits(y = c(-1, 1)) +
    scale_color_tq() +
    theme_tq() +
    labs(
        title = paste0("Tidyverse ACF Plot: Lags ", rlang::expr_text(k)),
        subtitle = "Appears to be a weekly pattern",
        x = "Lags"
    ) +
    theme(
        legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1)
    )

# We see that there appears to be a weekly pattern, but we want to be sure.   
  
# Get the absolute autocorrelations====  
# Verify the weekly pattern assessment by reviewing the absolute value of the  
#   correlations independent of package. We take the absolute autocorrelation   
#   because we use the magnitude as a proxy for how much explanatory value the   
#   lag provides.   
# Use dplyr functions to manipulate the data for visualization:  
# 1. drop the package group constraint using ungroup(),    
# 2. calculate the absolute correlation using mutate(),  
# 3. convert the lag to a factor, which helps with reordering the plot.  
# 4. Select() only the “lag” and “cor_abs” columns,    
# 5.  group by “lag” to lump all of the lags together -- to determine the  
#       trend independent of package.  
  
tidyverse_absolute_autocorrelations <- tidyverse_count_autocorrelations %>%  
    ungroup() %>%  
    mutate(  
        lag = as_factor(as.character(lag)),  
        cor_abs = abs(cor)  
        ) %>%  
    select(lag, cor_abs) %>%  
    group_by(lag)   
  
# Visualize the absolute correlations====  
# 1. Use a box plot that lumps each of the lags together. 
# 2. Add a line to indicate the presence of outliers at values above 1.5IQR  
#     If the values are consistently above the 1.5IQR limit, the lag can be  
#     considered an outlier. Note that we use the fct_reorder() function from  
#     forcats to organize the boxplot in order of decending magnitude.  

# Visualize boxplot of absolute autocorrelations   
break_point <- 1.5 * IQR(tidyverse_absolute_autocorrelations$cor_abs) %>%  
  signif(3)  

tidyverse_absolute_autocorrelations %>%    
    ggplot(aes(x = fct_reorder(lag, cor_abs, .desc = TRUE),  
               y = cor_abs)) +  
    # Add boxplot   
    geom_boxplot(color = palette_light()[[1]]) +  
    # Add horizontal line at outlier break point  
    geom_hline(yintercept = break_point, color = "red") +  
    annotate("text", label = paste0("Outlier Break Point = ", break_point),  
             x = 24.5, y = break_point + .03, color = "red") +  
    # Aesthetics  
    expand_limits(y = c(0, 1)) +  
    theme_tq() +  
    labs(  
        title = paste0("Absolute Autocorrelations: Lags ", 
                       rlang::expr_text(k)),  
        subtitle = "Weekly pattern is consistently above outlier break point",  
        x = "Lags"  
    ) +  
    theme(  
        legend.position = "none",  
        axis.text.x = element_text(angle = 45, hjust = 1)  
    )  
  
# outcome -- lags in multiples of seven have the highest autocorrelation  
#   and are consistently above the outlier break point indicating the presence  
#   of a strong weekly pattern. The autocorrelation with the seven-day lag is  
#   the highest, with a median of approximately 0.75. Lags 14, 21, and 28 are  
#   also outliers with median autocorrelations in excess of our outlier break  
#   point of 0.471.

# Note -- the median of Lag 1 is essentially at the break point indicating  
#   that half of the packages have a presence of “abnormal” autocorrelation. 
#   However, this is not part of a seasonal pattern since a periodic frequency  
#   is not present.
# In the case above, the tidyverse packages exhibit a strong weekly pattern. 
  
```  